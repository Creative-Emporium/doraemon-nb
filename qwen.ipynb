{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMnCUbJYyaWaPhhYVVae9uW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7193533a1a124b1e951941d23d45f910": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_27a6e13abf714c5eac1cfec5144535fe",
              "IPY_MODEL_dd5e79ad07714da88073e835c06b9bf3",
              "IPY_MODEL_b146187a268844bcbd70a6c6b804e459"
            ],
            "layout": "IPY_MODEL_e80065ab941e484589aa70cf23e1ba8c"
          }
        },
        "27a6e13abf714c5eac1cfec5144535fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_586f4b9d9c8545aa9d72294031115b33",
            "placeholder": "​",
            "style": "IPY_MODEL_9cb4396e8f544f92984dec7b6532c7df",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "dd5e79ad07714da88073e835c06b9bf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae341ba0325a43b7b0994adb16f3bbf0",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_05ba9945ecd648999b8a8e69cb960ad5",
            "value": 2
          }
        },
        "b146187a268844bcbd70a6c6b804e459": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7504921d27cf4f129692942e8d5c55ce",
            "placeholder": "​",
            "style": "IPY_MODEL_472844d7558047289c773a8c9b71688b",
            "value": " 2/2 [00:02&lt;00:00,  1.07s/it]"
          }
        },
        "e80065ab941e484589aa70cf23e1ba8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "586f4b9d9c8545aa9d72294031115b33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cb4396e8f544f92984dec7b6532c7df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae341ba0325a43b7b0994adb16f3bbf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05ba9945ecd648999b8a8e69cb960ad5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7504921d27cf4f129692942e8d5c55ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "472844d7558047289c773a8c9b71688b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11a8971605c244f4a3542ba2b5560ead": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b2c9c5dffbf443719c31e55e166a8656",
              "IPY_MODEL_ca0a5ce00fe74d31bc06096ff27b5da9",
              "IPY_MODEL_e50ab60d74c041028eb479a92ecd0d51"
            ],
            "layout": "IPY_MODEL_070304130caf427bbd54569d6db952c7"
          }
        },
        "b2c9c5dffbf443719c31e55e166a8656": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc98556a237940a4aaf3e43ac9328fca",
            "placeholder": "​",
            "style": "IPY_MODEL_635700942f94418e9033634954fc3c52",
            "value": "config.json: 100%"
          }
        },
        "ca0a5ce00fe74d31bc06096ff27b5da9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e472a82438bb4c0daa98319201b3dcd2",
            "max": 910,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_45613cc5db6b4acdb5aac39911515aea",
            "value": 910
          }
        },
        "e50ab60d74c041028eb479a92ecd0d51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7292e3083a604496a04701e3b4bd6e5a",
            "placeholder": "​",
            "style": "IPY_MODEL_36e8aa5d957b4eceb12a843180655acb",
            "value": " 910/910 [00:00&lt;00:00, 69.5kB/s]"
          }
        },
        "070304130caf427bbd54569d6db952c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc98556a237940a4aaf3e43ac9328fca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "635700942f94418e9033634954fc3c52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e472a82438bb4c0daa98319201b3dcd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45613cc5db6b4acdb5aac39911515aea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7292e3083a604496a04701e3b4bd6e5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36e8aa5d957b4eceb12a843180655acb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "129fe838c939464684cb18d1cf30a471": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a57e5c1c196348009ee7380457d9d2c8",
              "IPY_MODEL_37a1398098d74b9c9d86f1969d087083",
              "IPY_MODEL_b6b41bdc3d9b44c481ba92ea6a6759c7"
            ],
            "layout": "IPY_MODEL_dd29b3cecb2f43e39a198293b41a88fb"
          }
        },
        "a57e5c1c196348009ee7380457d9d2c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34c7d609365749bbab9ab9567cbbc28a",
            "placeholder": "​",
            "style": "IPY_MODEL_3fddeafed0424f4db62a541c9ddbc394",
            "value": "configuration_qwen.py: 100%"
          }
        },
        "37a1398098d74b9c9d86f1969d087083": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_319971aad2404cef84f37ff24d5b46fd",
            "max": 2345,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b5e64ee9970a4099aa3b399c826dda50",
            "value": 2345
          }
        },
        "b6b41bdc3d9b44c481ba92ea6a6759c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_077e17250f394d67953145135a1ae344",
            "placeholder": "​",
            "style": "IPY_MODEL_0f2ecef152c044a68a702f0073a522fb",
            "value": " 2.35k/2.35k [00:00&lt;00:00, 170kB/s]"
          }
        },
        "dd29b3cecb2f43e39a198293b41a88fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34c7d609365749bbab9ab9567cbbc28a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fddeafed0424f4db62a541c9ddbc394": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "319971aad2404cef84f37ff24d5b46fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5e64ee9970a4099aa3b399c826dda50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "077e17250f394d67953145135a1ae344": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f2ecef152c044a68a702f0073a522fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "468c298d701a4d12877a9c941f386ba2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1d78f3bc110644f48cff309958caf30a",
              "IPY_MODEL_c0a4d4da5bbb4aaf9ab69c84afa97c86",
              "IPY_MODEL_56aec5e7290c47368bd8d23ea278494a"
            ],
            "layout": "IPY_MODEL_9398727f44cb4c5eaf57a0d3ce57ea3c"
          }
        },
        "1d78f3bc110644f48cff309958caf30a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a43bc198b04143f0b25aeb06e20f000b",
            "placeholder": "​",
            "style": "IPY_MODEL_62543729cee845d29b6fdbbd350132cb",
            "value": "modeling_qwen.py: 100%"
          }
        },
        "c0a4d4da5bbb4aaf9ab69c84afa97c86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc19f4bb7584432ca57f65f3d10783e4",
            "max": 55563,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c6c16541db7a48918349f9a8dc23d04b",
            "value": 55563
          }
        },
        "56aec5e7290c47368bd8d23ea278494a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12dbc6748ebe4f41b034906395b9dd75",
            "placeholder": "​",
            "style": "IPY_MODEL_15456f0d3fec44f5a12efa93dab08e1f",
            "value": " 55.6k/55.6k [00:00&lt;00:00, 4.24MB/s]"
          }
        },
        "9398727f44cb4c5eaf57a0d3ce57ea3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a43bc198b04143f0b25aeb06e20f000b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62543729cee845d29b6fdbbd350132cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc19f4bb7584432ca57f65f3d10783e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6c16541db7a48918349f9a8dc23d04b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "12dbc6748ebe4f41b034906395b9dd75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15456f0d3fec44f5a12efa93dab08e1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03381ec7859b4348b13631c0b5dc8aa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b2899218e955440c9ceb8e76024043ae",
              "IPY_MODEL_8ca1051ca42547b78ab343713a6ad6dd",
              "IPY_MODEL_1c11c56cc00848f9a39ba5ccdc9174cb"
            ],
            "layout": "IPY_MODEL_c7ee41856a784ed1a572da41c6858972"
          }
        },
        "b2899218e955440c9ceb8e76024043ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba680d35b76f4d3cafef82cf627d103f",
            "placeholder": "​",
            "style": "IPY_MODEL_022cf1d60f9740a2ad3db6d484157ebe",
            "value": "qwen_generation_utils.py: 100%"
          }
        },
        "8ca1051ca42547b78ab343713a6ad6dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_783d4f51a3004544b77176c18969c0db",
            "max": 14604,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b12c3aeed96341fb9da222067ef5ee12",
            "value": 14604
          }
        },
        "1c11c56cc00848f9a39ba5ccdc9174cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_204d8f76b5e94f2487986024e913913e",
            "placeholder": "​",
            "style": "IPY_MODEL_bfb0a70d514c44d9ab444f855c2f114a",
            "value": " 14.6k/14.6k [00:00&lt;00:00, 1.24MB/s]"
          }
        },
        "c7ee41856a784ed1a572da41c6858972": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba680d35b76f4d3cafef82cf627d103f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "022cf1d60f9740a2ad3db6d484157ebe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "783d4f51a3004544b77176c18969c0db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b12c3aeed96341fb9da222067ef5ee12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "204d8f76b5e94f2487986024e913913e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfb0a70d514c44d9ab444f855c2f114a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b6221fd6544a4ccebb6096a9a2044cb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_22e90961ccc34930895ea378be7d49a0",
              "IPY_MODEL_5d001dbadd02460b91c845eae5f4d64d",
              "IPY_MODEL_45a3e95ef35d4ed4b0da4a575d75cd1a"
            ],
            "layout": "IPY_MODEL_efd0fef66f254da3b1068a72990d4baa"
          }
        },
        "22e90961ccc34930895ea378be7d49a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a441bbb84a014661b308a6b8c7eb5e17",
            "placeholder": "​",
            "style": "IPY_MODEL_0355f142d5af4b24b60d4f47362e81f4",
            "value": "cpp_kernels.py: 100%"
          }
        },
        "5d001dbadd02460b91c845eae5f4d64d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ac1ac13203141a0a197dcd5162731fd",
            "max": 1924,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c359f3e7f3f240caaaa8e74d8360fae0",
            "value": 1924
          }
        },
        "45a3e95ef35d4ed4b0da4a575d75cd1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95629780b76a45cf8db28c9b194c65e4",
            "placeholder": "​",
            "style": "IPY_MODEL_9282c0a5f01a40cf84e3af8156538e40",
            "value": " 1.92k/1.92k [00:00&lt;00:00, 147kB/s]"
          }
        },
        "efd0fef66f254da3b1068a72990d4baa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a441bbb84a014661b308a6b8c7eb5e17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0355f142d5af4b24b60d4f47362e81f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ac1ac13203141a0a197dcd5162731fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c359f3e7f3f240caaaa8e74d8360fae0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "95629780b76a45cf8db28c9b194c65e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9282c0a5f01a40cf84e3af8156538e40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b27e04e73e240149f32e2c4b732c460": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9cee934448114c0e85b592b91949ecf4",
              "IPY_MODEL_12343c2b396d41bca61af1239cc295f2",
              "IPY_MODEL_6aafdbae7d264adbb50e1028f1d18ac1"
            ],
            "layout": "IPY_MODEL_4f77174147114b8d95ecd2cd39d6c418"
          }
        },
        "9cee934448114c0e85b592b91949ecf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0ff0dc59406461788ba0159d027f16c",
            "placeholder": "​",
            "style": "IPY_MODEL_f42ba8fee38c43449970120b0827ddfc",
            "value": "model.safetensors.index.json: 100%"
          }
        },
        "12343c2b396d41bca61af1239cc295f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2811d8fbfaca4cceb61064f54a4b4d5c",
            "max": 14706,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_730e43bb36b241fc989108e0c678e8dd",
            "value": 14706
          }
        },
        "6aafdbae7d264adbb50e1028f1d18ac1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2dbf09310e714d808665eae83a9e537e",
            "placeholder": "​",
            "style": "IPY_MODEL_a5ec7ccec4ab43099666bdddcbc4da9a",
            "value": " 14.7k/14.7k [00:00&lt;00:00, 1.07MB/s]"
          }
        },
        "4f77174147114b8d95ecd2cd39d6c418": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0ff0dc59406461788ba0159d027f16c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f42ba8fee38c43449970120b0827ddfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2811d8fbfaca4cceb61064f54a4b4d5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "730e43bb36b241fc989108e0c678e8dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2dbf09310e714d808665eae83a9e537e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5ec7ccec4ab43099666bdddcbc4da9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f202cd2d030f46a49076681677ebaf77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a4d5dca955214f59830bc5d807659b71",
              "IPY_MODEL_4c49f59cfe4e4472a63ba01fc233667c",
              "IPY_MODEL_fbbcc312c13849bd9140b7e3bba45b21"
            ],
            "layout": "IPY_MODEL_9015cc526cd04fb296a170df35357c8b"
          }
        },
        "a4d5dca955214f59830bc5d807659b71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea109408aae24de3bd49897fb895b555",
            "placeholder": "​",
            "style": "IPY_MODEL_64ffd56b62914d4b840906c0787b9e23",
            "value": "Downloading shards: 100%"
          }
        },
        "4c49f59cfe4e4472a63ba01fc233667c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e249b1eacf57439e8a004656b2e6cdc7",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_203489f223244d3da6aa3669a6ae7a25",
            "value": 2
          }
        },
        "fbbcc312c13849bd9140b7e3bba45b21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d5eabed18ee4d0bb0b994b9371b45a2",
            "placeholder": "​",
            "style": "IPY_MODEL_53bccc6ebf4e4830a3c330bffb6e89f2",
            "value": " 2/2 [00:16&lt;00:00,  8.23s/it]"
          }
        },
        "9015cc526cd04fb296a170df35357c8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea109408aae24de3bd49897fb895b555": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64ffd56b62914d4b840906c0787b9e23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e249b1eacf57439e8a004656b2e6cdc7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "203489f223244d3da6aa3669a6ae7a25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8d5eabed18ee4d0bb0b994b9371b45a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53bccc6ebf4e4830a3c330bffb6e89f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba087ed7d08e4ee79e6eea4f3db80a37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_13e0ae8cc88345f1a2626774ce1795c6",
              "IPY_MODEL_0b0ab05f84874804940f789cba9c096e",
              "IPY_MODEL_6ae6f46786bb4314be0b9c9749ba9f77"
            ],
            "layout": "IPY_MODEL_55f6524bd9a046cf98622683bd7d7b22"
          }
        },
        "13e0ae8cc88345f1a2626774ce1795c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_182f0929a9ae4ce5881064f2bab3fa99",
            "placeholder": "​",
            "style": "IPY_MODEL_f3f1136da8ff481ebd8b4af00643f201",
            "value": "model-00001-of-00002.safetensors: 100%"
          }
        },
        "0b0ab05f84874804940f789cba9c096e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_313e3d3d10674873aa1c54987bbc5fd1",
            "max": 2039259008,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8216b6ddef934e31889e1fb880da8109",
            "value": 2039259008
          }
        },
        "6ae6f46786bb4314be0b9c9749ba9f77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0910491343314f0fb63ec63781255c20",
            "placeholder": "​",
            "style": "IPY_MODEL_4083454388f94e8491cdc2ab7de24a7a",
            "value": " 2.04G/2.04G [00:06&lt;00:00, 288MB/s]"
          }
        },
        "55f6524bd9a046cf98622683bd7d7b22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "182f0929a9ae4ce5881064f2bab3fa99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3f1136da8ff481ebd8b4af00643f201": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "313e3d3d10674873aa1c54987bbc5fd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8216b6ddef934e31889e1fb880da8109": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0910491343314f0fb63ec63781255c20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4083454388f94e8491cdc2ab7de24a7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "377ad608469c43ba856bddf03948da82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ec72afe044a946c0894bd864bbd485f9",
              "IPY_MODEL_32c3e7faf8014e0b8e64b78abe9e9694",
              "IPY_MODEL_f90fd36271f24a329ad1718300074a9e"
            ],
            "layout": "IPY_MODEL_bef4fa68c5194ee0a23a7fda69d71a1a"
          }
        },
        "ec72afe044a946c0894bd864bbd485f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d243db3a81e145bab723deeeb752a09c",
            "placeholder": "​",
            "style": "IPY_MODEL_5ef438958aca463eb0935865644fe9cc",
            "value": "model-00002-of-00002.safetensors: 100%"
          }
        },
        "32c3e7faf8014e0b8e64b78abe9e9694": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cb6460b19c84ebfb5878ebed2557637",
            "max": 1634419264,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_96b6925fd0704b589ded8987ee2788c0",
            "value": 1634419264
          }
        },
        "f90fd36271f24a329ad1718300074a9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b817617a2ff34666a75ae5e7d81b0c08",
            "placeholder": "​",
            "style": "IPY_MODEL_66989a7adaa14538ad3e1e297601e29d",
            "value": " 1.63G/1.63G [00:08&lt;00:00, 178MB/s]"
          }
        },
        "bef4fa68c5194ee0a23a7fda69d71a1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d243db3a81e145bab723deeeb752a09c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ef438958aca463eb0935865644fe9cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5cb6460b19c84ebfb5878ebed2557637": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96b6925fd0704b589ded8987ee2788c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b817617a2ff34666a75ae5e7d81b0c08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66989a7adaa14538ad3e1e297601e29d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7d05c2cf2af41e5b8ffaa277a6d493b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_abd4adc097934e8e961da426394bb767",
              "IPY_MODEL_93cfbfe2b5a546bb99bac9714f07e301",
              "IPY_MODEL_5e85061a740e40e88ae64ce2b523a89b"
            ],
            "layout": "IPY_MODEL_753b1063d7854b57b1e4778056183d12"
          }
        },
        "abd4adc097934e8e961da426394bb767": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8010ec298e94dfcb582e38b207ea0e3",
            "placeholder": "​",
            "style": "IPY_MODEL_943be4e1fa6a4634992e5f02c34981cb",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "93cfbfe2b5a546bb99bac9714f07e301": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41afc5080a6d4bf582cfac5ca0f4987e",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ffd48374d8de43128b93ea858932cf2f",
            "value": 2
          }
        },
        "5e85061a740e40e88ae64ce2b523a89b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7fee4ab30c16421fbb85cfc8858c03b6",
            "placeholder": "​",
            "style": "IPY_MODEL_cab882969fd944a0ac67f91635e135ad",
            "value": " 2/2 [00:02&lt;00:00,  1.12s/it]"
          }
        },
        "753b1063d7854b57b1e4778056183d12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8010ec298e94dfcb582e38b207ea0e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "943be4e1fa6a4634992e5f02c34981cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "41afc5080a6d4bf582cfac5ca0f4987e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffd48374d8de43128b93ea858932cf2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7fee4ab30c16421fbb85cfc8858c03b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cab882969fd944a0ac67f91635e135ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01751bb9f54043d29c8ad43f1b729702": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0186c10f4ec34c7182dfc182e3d66621",
              "IPY_MODEL_fba599da131246fa8c9c2c100050fa6a",
              "IPY_MODEL_8578e66792ca4d558f912e318e133e7c"
            ],
            "layout": "IPY_MODEL_a779a8371b6341c2921f9cac7c9c03e6"
          }
        },
        "0186c10f4ec34c7182dfc182e3d66621": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0db1ed9c83494c3899a3bb07146e2ae4",
            "placeholder": "​",
            "style": "IPY_MODEL_345b2519ee28469b9c9d06e39fa35722",
            "value": "generation_config.json: 100%"
          }
        },
        "fba599da131246fa8c9c2c100050fa6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e21298d8366849bfb394a673c116ed71",
            "max": 222,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b3cfa289291e425790348e79b3f8d0e5",
            "value": 222
          }
        },
        "8578e66792ca4d558f912e318e133e7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b677d8c9a9d4451e83b67cf6ccde3417",
            "placeholder": "​",
            "style": "IPY_MODEL_b6906f5221a54acc841044eb2d82a5d0",
            "value": " 222/222 [00:00&lt;00:00, 18.9kB/s]"
          }
        },
        "a779a8371b6341c2921f9cac7c9c03e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0db1ed9c83494c3899a3bb07146e2ae4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "345b2519ee28469b9c9d06e39fa35722": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e21298d8366849bfb394a673c116ed71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3cfa289291e425790348e79b3f8d0e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b677d8c9a9d4451e83b67cf6ccde3417": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6906f5221a54acc841044eb2d82a5d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d167de6fcfbc47458774ad929ea3c1f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_352d2d58616248ce95fdf7ad67439086",
              "IPY_MODEL_6d4427f4be7d4611ab81439f19099c1e",
              "IPY_MODEL_e400d1b4ded840c4a887a67c0b8a28dc"
            ],
            "layout": "IPY_MODEL_79079232fa49471eb49e0133ad96b4dc"
          }
        },
        "352d2d58616248ce95fdf7ad67439086": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a7b0a19b9494d0d879d266e96977b3f",
            "placeholder": "​",
            "style": "IPY_MODEL_b4ea205f4a574b348a6904ab186d4e0b",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "6d4427f4be7d4611ab81439f19099c1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_919edfdf181643bdafc335fafaa1e21a",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_84f3a883c1464738a4df0dd516ac6428",
            "value": 2
          }
        },
        "e400d1b4ded840c4a887a67c0b8a28dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a091b600a1b14820af88827fb0142e78",
            "placeholder": "​",
            "style": "IPY_MODEL_651bc6bc6fcc49bc98e6905627d52926",
            "value": " 2/2 [00:02&lt;00:00,  1.28s/it]"
          }
        },
        "79079232fa49471eb49e0133ad96b4dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a7b0a19b9494d0d879d266e96977b3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4ea205f4a574b348a6904ab186d4e0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "919edfdf181643bdafc335fafaa1e21a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84f3a883c1464738a4df0dd516ac6428": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a091b600a1b14820af88827fb0142e78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "651bc6bc6fcc49bc98e6905627d52926": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weedge/doraemon-nb/blob/main/qwen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Qwen\n",
        "- https://github.com/QwenLM/Qwen/blob/main/README_CN.md\n"
      ],
      "metadata": {
        "id": "_HfVTPTfUk80"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHw5xTCLrseK",
        "outputId": "1492f392-7add-40c4-c82b-e88d8fe1b071"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Qwen'...\n",
            "remote: Enumerating objects: 1458, done.\u001b[K\n",
            "remote: Counting objects: 100% (659/659), done.\u001b[K\n",
            "remote: Compressing objects: 100% (389/389), done.\u001b[K\n",
            "remote: Total 1458 (delta 484), reused 372 (delta 268), pack-reused 799\u001b[K\n",
            "Receiving objects: 100% (1458/1458), 35.31 MiB | 13.66 MiB/s, done.\n",
            "Resolving deltas: 100% (855/855), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/QwenLM/Qwen.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd Qwen/ && pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnaZyIZ1s9sP",
        "outputId": "90fa284d-25e1-4614-a0f5-3dd2bdaa67ef"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.32.0 (from -r requirements.txt (line 1))\n",
            "  Downloading transformers-4.32.0-py3-none-any.whl (7.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate (from -r requirements.txt (line 2))\n",
            "  Downloading accelerate-0.25.0-py3-none-any.whl (265 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken (from -r requirements.txt (line 3))\n",
            "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops (from -r requirements.txt (line 4))\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers_stream_generator==0.0.4 (from -r requirements.txt (line 5))\n",
            "  Downloading transformers-stream-generator-0.0.4.tar.gz (12 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (1.11.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.32.0->-r requirements.txt (line 1)) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.32.0->-r requirements.txt (line 1)) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.32.0->-r requirements.txt (line 1)) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.32.0->-r requirements.txt (line 1)) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.32.0->-r requirements.txt (line 1)) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.32.0->-r requirements.txt (line 1)) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.32.0->-r requirements.txt (line 1)) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.32.0->-r requirements.txt (line 1))\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.32.0->-r requirements.txt (line 1)) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.32.0->-r requirements.txt (line 1)) (4.66.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 2)) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 2)) (2.1.0+cu121)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.32.0->-r requirements.txt (line 1)) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.32.0->-r requirements.txt (line 1)) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.32.0->-r requirements.txt (line 1)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.32.0->-r requirements.txt (line 1)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.32.0->-r requirements.txt (line 1)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.32.0->-r requirements.txt (line 1)) (2023.11.17)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 2)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 2)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 2)) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 2)) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate->-r requirements.txt (line 2)) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate->-r requirements.txt (line 2)) (1.3.0)\n",
            "Building wheels for collected packages: transformers_stream_generator\n",
            "  Building wheel for transformers_stream_generator (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers_stream_generator: filename=transformers_stream_generator-0.0.4-py3-none-any.whl size=12316 sha256=4a68355f9149f3cef08feec16f6c33cb333553773ead72c6811c4785f05e9efd\n",
            "  Stored in directory: /root/.cache/pip/wheels/47/1d/3c/92d88493ed40c0d9be60a391eb76c9a56e9f9b7542cb789401\n",
            "Successfully built transformers_stream_generator\n",
            "Installing collected packages: tokenizers, einops, tiktoken, transformers, accelerate, transformers_stream_generator\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.15.0\n",
            "    Uninstalling tokenizers-0.15.0:\n",
            "      Successfully uninstalled tokenizers-0.15.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.35.2\n",
            "    Uninstalling transformers-4.35.2:\n",
            "      Successfully uninstalled transformers-4.35.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.25.0 einops-0.7.0 tiktoken-0.5.2 tokenizers-0.13.3 transformers-4.32.0 transformers_stream_generator-0.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 如果显卡支持fp16或bf16精度，推荐安装flash-attention（当前已支持flash attention 2）来提高你的运行效率以及降低显存占用。\n",
        "\n",
        "!git clone https://github.com/Dao-AILab/flash-attention\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6V6LOkKTuapl",
        "outputId": "be2b32cd-151f-4b75-9559-921a9286cc79"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'flash-attention'...\n",
            "remote: Enumerating objects: 4411, done.\u001b[K\n",
            "remote: Counting objects: 100% (2181/2181), done.\u001b[K\n",
            "remote: Compressing objects: 100% (323/323), done.\u001b[K\n",
            "remote: Total 4411 (delta 1958), reused 1871 (delta 1857), pack-reused 2230\u001b[K\n",
            "Receiving objects: 100% (4411/4411), 6.90 MiB | 12.76 MiB/s, done.\n",
            "Resolving deltas: 100% (3088/3088), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y flash-attn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIDThhzdzPha",
        "outputId": "2b1e3ff2-f21f-4a76-8ce8-2264600e8186"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: flash-attn 2.3.6\n",
            "Uninstalling flash-attn-2.3.6:\n",
            "  Successfully uninstalled flash-attn-2.3.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd flash-attention && pip install .\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bDP2BmFuoPF",
        "outputId": "594d8f03-8062-44ba-d30b-b216f4458106"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing /content/flash-attention\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from flash-attn==2.3.6) (2.1.0+cu121)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from flash-attn==2.3.6) (0.7.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from flash-attn==2.3.6) (23.2)\n",
            "Collecting ninja (from flash-attn==2.3.6)\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn==2.3.6) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn==2.3.6) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn==2.3.6) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn==2.3.6) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn==2.3.6) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn==2.3.6) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn==2.3.6) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->flash-attn==2.3.6) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->flash-attn==2.3.6) (1.3.0)\n",
            "Building wheels for collected packages: flash-attn\n",
            "  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flash-attn: filename=flash_attn-2.3.6-cp310-cp310-linux_x86_64.whl size=56477261 sha256=652ad256d0891cb2c6d7183f96f7f56ff61cdeee24388381abb35e7a0f2eeca1\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/cf/3b/d132219792be47c1a416734b31d5be638f6a6e282470b490c6\n",
            "Successfully built flash-attn\n",
            "Installing collected packages: ninja, flash-attn\n",
            "Successfully installed flash-attn-2.3.6 ninja-1.11.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/pytorch/pytorch/issues/107960\n",
        "!ldconfig -p | grep libcuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BfwWtBrxLVe",
        "outputId": "ca601645-69f8-4923-e37d-34f7f6174dba"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tlibcudart.so.12 (libc6,x86-64) => /usr/local/cuda/targets/x86_64-linux/lib/libcudart.so.12\n",
            "\tlibcudart.so (libc6,x86-64) => /usr/local/cuda/targets/x86_64-linux/lib/libcudart.so\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!find /usr -name 'libcuda.so'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKV_nymBxxoD",
        "outputId": "b38fa739-ac70-4980-fe12-400c97e4fe81"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/cuda-12.2/targets/x86_64-linux/lib/stubs/libcuda.so\n",
            "/usr/local/cuda-12.2/compat/libcuda.so\n",
            "/usr/lib64-nvidia/libcuda.so\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ldconfig /usr/lib64-nvidia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCW4she5x3F2",
        "outputId": "9f50967d-165f-4f7e-a745-ad8ead8fc4f1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ldconfig -p | grep libcuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rc2Hu3dpyHmr",
        "outputId": "8719c554-eba9-415d-8605-8b2ec52250c2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tlibcudart.so.12 (libc6,x86-64) => /usr/local/cuda/targets/x86_64-linux/lib/libcudart.so.12\n",
            "\tlibcudart.so (libc6,x86-64) => /usr/local/cuda/targets/x86_64-linux/lib/libcudart.so\n",
            "\tlibcudadebugger.so.1 (libc6,x86-64) => /usr/lib64-nvidia/libcudadebugger.so.1\n",
            "\tlibcuda.so.1 (libc6,x86-64) => /usr/lib64-nvidia/libcuda.so.1\n",
            "\tlibcuda.so (libc6,x86-64) => /usr/lib64-nvidia/libcuda.so\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding\n"
      ],
      "metadata": {
        "id": "bPKu6F4_6ibK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Qwen/Qwen-1.8B-Chat"
      ],
      "metadata": {
        "id": "JsA9nfxMJ3_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from transformers.generation import GenerationConfig\n",
        "model_path=\"./hf_models/Qwen/Qwen-1_8B-Chat\"\n",
        "# 可选的模型包括: \"Qwen/Qwen-1.8B-Chat\", \"Qwen/Qwen-7B-Chat\", \"Qwen/Qwen-14B-Chat\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen-1_8B-Chat\", trust_remote_code=True)\n",
        "print(tokenizer)\n",
        "tokenizer.save_pretrained(model_path,trust_remote_code=True,revision=\"main\")\n",
        "\n",
        "\n",
        "# 打开bf16精度，A100、H100、RTX3060、RTX3070等显卡建议启用以节省显存\n",
        "# model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen-1_8B-Chat\", device_map=\"auto\", trust_remote_code=True, bf16=True).eval()\n",
        "# 打开fp16精度，V100、P100、T4等显卡建议启用以节省显存\n",
        "# model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen-1_8B-Chat\", device_map=\"auto\", trust_remote_code=True, fp16=True).eval()\n",
        "# 使用CPU进行推理，需要约32GB内存\n",
        "# model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen-1_8B-Chat\", device_map=\"cpu\", trust_remote_code=True).eval()\n",
        "# 默认使用自动模式，根据设备自动选择精度\n",
        "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen-1_8B-Chat\", device_map=\"cuda\", trust_remote_code=True).eval()\n",
        "print(model)\n",
        "model.save_pretrained(model_path,trust_remote_code=True,revision=\"main\")\n",
        "\n",
        "\n",
        "# 可指定不同的生成长度、top_p等相关超参\n",
        "model.generation_config = GenerationConfig.from_pretrained(\"Qwen/Qwen-1_8B-Chat\", trust_remote_code=True)\n",
        "print(model)\n",
        "\n",
        "# 第一轮对话\n",
        "response, history = model.chat(tokenizer, \"你好\", history=None)\n",
        "print(response)\n",
        "# 你好！很高兴为你提供帮助。\n",
        "\n",
        "# 第二轮对话\n",
        "response, history = model.chat(tokenizer, \"给我讲一个年轻人奋斗创业最终取得成功的故事。\", history=history)\n",
        "print(response)\n",
        "# 这是一个关于一个年轻人奋斗创业最终取得成功的故事。\n",
        "# 故事的主人公叫李明，他来自一个普通的家庭，父母都是普通的工人。从小，李明就立下了一个目标：要成为一名成功的企业家。\n",
        "# 为了实现这个目标，李明勤奋学习，考上了大学。在大学期间，他积极参加各种创业比赛，获得了不少奖项。他还利用课余时间去实习，积累了宝贵的经验。\n",
        "# 毕业后，李明决定开始自己的创业之路。他开始寻找投资机会，但多次都被拒绝了。然而，他并没有放弃。他继续努力，不断改进自己的创业计划，并寻找新的投资机会。\n",
        "# 最终，李明成功地获得了一笔投资，开始了自己的创业之路。他成立了一家科技公司，专注于开发新型软件。在他的领导下，公司迅速发展起来，成为了一家成功的科技企业。\n",
        "# 李明的成功并不是偶然的。他勤奋、坚韧、勇于冒险，不断学习和改进自己。他的成功也证明了，只要努力奋斗，任何人都有可能取得成功。\n",
        "\n",
        "# 第三轮对话\n",
        "response, history = model.chat(tokenizer, \"给这个故事起一个标题\", history=history)\n",
        "print(response)\n",
        "# 《奋斗创业：一个年轻人的成功之路》"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7193533a1a124b1e951941d23d45f910",
            "27a6e13abf714c5eac1cfec5144535fe",
            "dd5e79ad07714da88073e835c06b9bf3",
            "b146187a268844bcbd70a6c6b804e459",
            "e80065ab941e484589aa70cf23e1ba8c",
            "586f4b9d9c8545aa9d72294031115b33",
            "9cb4396e8f544f92984dec7b6532c7df",
            "ae341ba0325a43b7b0994adb16f3bbf0",
            "05ba9945ecd648999b8a8e69cb960ad5",
            "7504921d27cf4f129692942e8d5c55ce",
            "472844d7558047289c773a8c9b71688b"
          ]
        },
        "id": "wBYwaEuuuy4u",
        "outputId": "a0cc6745-0360-4439-948e-1335c973e72d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QWenTokenizer(name_or_path='Qwen/Qwen-1_8B-Chat', vocab_size=151851, model_max_length=8192, is_fast=False, padding_side='right', truncation_side='right', special_tokens={}, clean_up_tokenization_spaces=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:transformers_modules.Qwen.Qwen-1_8B-Chat.1d0f68de57b88cfde81f3c3e537f24464d889081.modeling_qwen:The model is automatically converting to fp16 for faster inference. If you want to disable the automatic precision, please manually add bf16/fp16/fp32=True to \"AutoModelForCausalLM.from_pretrained\".\n",
            "WARNING:transformers_modules.Qwen.Qwen-1_8B-Chat.1d0f68de57b88cfde81f3c3e537f24464d889081.modeling_qwen:Try importing flash-attention for faster inference...\n",
            "WARNING:transformers_modules.Qwen.Qwen-1_8B-Chat.1d0f68de57b88cfde81f3c3e537f24464d889081.modeling_qwen:Warning: import flash_attn rotary fail, please install FlashAttention rotary to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/rotary\n",
            "WARNING:transformers_modules.Qwen.Qwen-1_8B-Chat.1d0f68de57b88cfde81f3c3e537f24464d889081.modeling_qwen:Warning: import flash_attn rms_norm fail, please install FlashAttention layer_norm to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/layer_norm\n",
            "WARNING:transformers_modules.Qwen.Qwen-1_8B-Chat.1d0f68de57b88cfde81f3c3e537f24464d889081.modeling_qwen:Warning: import flash_attn fail, please install FlashAttention to get higher efficiency https://github.com/Dao-AILab/flash-attention\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7193533a1a124b1e951941d23d45f910"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QWenLMHeadModel(\n",
            "  (transformer): QWenModel(\n",
            "    (wte): Embedding(151936, 2048)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (rotary_emb): RotaryEmbedding()\n",
            "    (h): ModuleList(\n",
            "      (0-23): 24 x QWenBlock(\n",
            "        (ln_1): RMSNorm()\n",
            "        (attn): QWenAttention(\n",
            "          (c_attn): Linear(in_features=2048, out_features=6144, bias=True)\n",
            "          (c_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
            "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ln_2): RMSNorm()\n",
            "        (mlp): QWenMLP(\n",
            "          (w1): Linear(in_features=2048, out_features=5504, bias=False)\n",
            "          (w2): Linear(in_features=2048, out_features=5504, bias=False)\n",
            "          (c_proj): Linear(in_features=5504, out_features=2048, bias=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ln_f): RMSNorm()\n",
            "  )\n",
            "  (lm_head): Linear(in_features=2048, out_features=151936, bias=False)\n",
            ")\n",
            "QWenLMHeadModel(\n",
            "  (transformer): QWenModel(\n",
            "    (wte): Embedding(151936, 2048)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (rotary_emb): RotaryEmbedding()\n",
            "    (h): ModuleList(\n",
            "      (0-23): 24 x QWenBlock(\n",
            "        (ln_1): RMSNorm()\n",
            "        (attn): QWenAttention(\n",
            "          (c_attn): Linear(in_features=2048, out_features=6144, bias=True)\n",
            "          (c_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
            "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ln_2): RMSNorm()\n",
            "        (mlp): QWenMLP(\n",
            "          (w1): Linear(in_features=2048, out_features=5504, bias=False)\n",
            "          (w2): Linear(in_features=2048, out_features=5504, bias=False)\n",
            "          (c_proj): Linear(in_features=5504, out_features=2048, bias=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ln_f): RMSNorm()\n",
            "  )\n",
            "  (lm_head): Linear(in_features=2048, out_features=151936, bias=False)\n",
            ")\n",
            "你好！有什么我可以帮助你的吗？\n",
            "有一个叫小杰的年轻人，他一直对科技有着浓厚的兴趣。毕业后，他决定创业，建立自己的科技公司。他的想法是利用互联网技术为用户提供更便捷、更高效的服务。\n",
            "\n",
            "然而，在创业的过程中，小杰遇到了许多困难和挑战。他需要克服资金短缺的问题，还需要找到合适的合作伙伴。此外，他还需要不断学习新技术，以便在激烈的竞争中保持领先。\n",
            "\n",
            "经过一段时间的努力，小杰终于建立了自己的科技公司，并在市场上取得了良好的反响。他通过不断改进产品和服务，吸引了大量的用户，使得公司的业务持续增长。\n",
            "\n",
            "最重要的是，小杰始终坚持不懈，勇于面对挫折，从失败中吸取经验教训。他相信只有这样，才能使自己不断成长，最终实现自己的梦想。\n",
            "\n",
            "小杰的故事告诉我们，只要有决心，有毅力，有勇气去追求自己的梦想，就一定能够实现自己的目标。只要我们不放弃，坚持不懈，我们就有可能在人生的旅途中取得成功。\n",
            "《用勇气照亮创业之路》\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -glh ./hf_models/Qwen/Qwen-1_8B-Chat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6C41Cn4QHaED",
        "outputId": "864d8960-015b-452f-d26b-0fba1db13835"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 3.5G\n",
            "-rw-r--r-- 1 root 1.1K Dec 17 13:51 config.json\n",
            "-rw-r--r-- 1 root  250 Dec 17 13:51 generation_config.json\n",
            "-rw-r--r-- 1 root 3.5G Dec 17 13:51 pytorch_model.bin\n",
            "-rw-r--r-- 1 root 2.5M Dec 17 13:51 qwen.tiktoken\n",
            "-rw-r--r-- 1 root    3 Dec 17 13:51 special_tokens_map.json\n",
            "-rw-r--r-- 1 root  232 Dec 17 13:51 tokenizer_config.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.cuda.memory_summary())\n",
        "torch.cuda.empty_cache()\n",
        "print(torch.cuda.memory_summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ek98o2gyMGwc",
        "outputId": "0fff98f1-7ce5-4f12-df2d-1a0d882816bc"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   3550 MiB |   7178 MiB | 151466 MiB | 147915 MiB |\n",
            "|       from large pool |   3548 MiB |   7162 MiB |  66055 MiB |  62507 MiB |\n",
            "|       from small pool |      2 MiB |    102 MiB |  85411 MiB |  85408 MiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   3550 MiB |   7178 MiB | 151466 MiB | 147915 MiB |\n",
            "|       from large pool |   3548 MiB |   7162 MiB |  66055 MiB |  62507 MiB |\n",
            "|       from small pool |      2 MiB |    102 MiB |  85411 MiB |  85408 MiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Requested memory      |   3513 MiB |   7098 MiB | 149172 MiB | 145659 MiB |\n",
            "|       from large pool |   3511 MiB |   7080 MiB |  63939 MiB |  60428 MiB |\n",
            "|       from small pool |      2 MiB |    102 MiB |  85233 MiB |  85230 MiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   3658 MiB |   7330 MiB |  20928 MiB |  17270 MiB |\n",
            "|       from large pool |   3648 MiB |   7224 MiB |  20504 MiB |  16856 MiB |\n",
            "|       from small pool |     10 MiB |    106 MiB |    424 MiB |    414 MiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory | 109973 KiB | 558928 KiB | 146205 MiB | 146097 MiB |\n",
            "|       from large pool | 102272 KiB | 551740 KiB |  51396 MiB |  51296 MiB |\n",
            "|       from small pool |   7701 KiB |  38209 KiB |  94808 MiB |  94800 MiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     253    |     613    |    1805 K  |    1804 K  |\n",
            "|       from large pool |     123    |     274    |      27 K  |      27 K  |\n",
            "|       from small pool |     130    |     368    |    1777 K  |    1777 K  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     253    |     613    |    1805 K  |    1804 K  |\n",
            "|       from large pool |     123    |     274    |      27 K  |      27 K  |\n",
            "|       from small pool |     130    |     368    |    1777 K  |    1777 K  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |     118    |     275    |     875    |     757    |\n",
            "|       from large pool |     113    |     222    |     663    |     550    |\n",
            "|       from small pool |       5    |      53    |     212    |     207    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      33    |      85    |     787 K  |     787 K  |\n",
            "|       from large pool |      17    |      32    |       6 K  |       6 K  |\n",
            "|       from small pool |      16    |      69    |     780 K  |     780 K  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
            "|===========================================================================|\n",
            "\n",
            "|===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   3550 MiB |   7178 MiB | 151466 MiB | 147915 MiB |\n",
            "|       from large pool |   3548 MiB |   7162 MiB |  66055 MiB |  62507 MiB |\n",
            "|       from small pool |      2 MiB |    102 MiB |  85411 MiB |  85408 MiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   3550 MiB |   7178 MiB | 151466 MiB | 147915 MiB |\n",
            "|       from large pool |   3548 MiB |   7162 MiB |  66055 MiB |  62507 MiB |\n",
            "|       from small pool |      2 MiB |    102 MiB |  85411 MiB |  85408 MiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Requested memory      |   3513 MiB |   7098 MiB | 149172 MiB | 145659 MiB |\n",
            "|       from large pool |   3511 MiB |   7080 MiB |  63939 MiB |  60428 MiB |\n",
            "|       from small pool |      2 MiB |    102 MiB |  85233 MiB |  85230 MiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   3658 MiB |   7330 MiB |  20928 MiB |  17270 MiB |\n",
            "|       from large pool |   3648 MiB |   7224 MiB |  20504 MiB |  16856 MiB |\n",
            "|       from small pool |     10 MiB |    106 MiB |    424 MiB |    414 MiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory | 109973 KiB | 558928 KiB | 146205 MiB | 146097 MiB |\n",
            "|       from large pool | 102272 KiB | 551740 KiB |  51396 MiB |  51296 MiB |\n",
            "|       from small pool |   7701 KiB |  38209 KiB |  94808 MiB |  94800 MiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     253    |     613    |    1805 K  |    1804 K  |\n",
            "|       from large pool |     123    |     274    |      27 K  |      27 K  |\n",
            "|       from small pool |     130    |     368    |    1777 K  |    1777 K  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     253    |     613    |    1805 K  |    1804 K  |\n",
            "|       from large pool |     123    |     274    |      27 K  |      27 K  |\n",
            "|       from small pool |     130    |     368    |    1777 K  |    1777 K  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |     118    |     275    |     875    |     757    |\n",
            "|       from large pool |     113    |     222    |     663    |     550    |\n",
            "|       from small pool |       5    |      53    |     212    |     207    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      33    |      85    |     787 K  |     787 K  |\n",
            "|       from large pool |      17    |      32    |       6 K  |       6 K  |\n",
            "|       from small pool |      16    |      69    |     780 K  |     780 K  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
            "|===========================================================================|\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Qwen/Qwen-1_8B"
      ],
      "metadata": {
        "id": "i7uJNu-kJx0A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from transformers.generation import GenerationConfig\n",
        "\n",
        "# 可选的模型包括: \"Qwen/Qwen-1_8B\",\"Qwen/Qwen-7B\", \"Qwen/Qwen-14B\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen-1_8B\", trust_remote_code=True)\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen-1_8B\", device_map=\"auto\", trust_remote_code=True).eval()\n",
        "\n",
        "# 可指定不同的生成长度、top_p等相关超参\n",
        "model.generation_config = GenerationConfig.from_pretrained(\"Qwen/Qwen-1_8B\", trust_remote_code=True)\n",
        "\n",
        "inputs = tokenizer('蒙古国的首都是乌兰巴托（Ulaanbaatar）\\n冰岛的首都是雷克雅未克（Reykjavik）\\n埃塞俄比亚的首都是', return_tensors='pt')\n",
        "inputs = inputs.to(model.device)\n",
        "pred = model.generate(**inputs)\n",
        "print(tokenizer.decode(pred.cpu()[0], skip_special_tokens=True))\n",
        "# 蒙古国的首都是乌兰巴托（Ulaanbaatar）\\n冰岛的首都是雷克雅未克（Reykjavik）\\n埃塞俄比亚的首都是亚的斯亚贝巴（Addis Ababa）..."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "11a8971605c244f4a3542ba2b5560ead",
            "b2c9c5dffbf443719c31e55e166a8656",
            "ca0a5ce00fe74d31bc06096ff27b5da9",
            "e50ab60d74c041028eb479a92ecd0d51",
            "070304130caf427bbd54569d6db952c7",
            "cc98556a237940a4aaf3e43ac9328fca",
            "635700942f94418e9033634954fc3c52",
            "e472a82438bb4c0daa98319201b3dcd2",
            "45613cc5db6b4acdb5aac39911515aea",
            "7292e3083a604496a04701e3b4bd6e5a",
            "36e8aa5d957b4eceb12a843180655acb",
            "129fe838c939464684cb18d1cf30a471",
            "a57e5c1c196348009ee7380457d9d2c8",
            "37a1398098d74b9c9d86f1969d087083",
            "b6b41bdc3d9b44c481ba92ea6a6759c7",
            "dd29b3cecb2f43e39a198293b41a88fb",
            "34c7d609365749bbab9ab9567cbbc28a",
            "3fddeafed0424f4db62a541c9ddbc394",
            "319971aad2404cef84f37ff24d5b46fd",
            "b5e64ee9970a4099aa3b399c826dda50",
            "077e17250f394d67953145135a1ae344",
            "0f2ecef152c044a68a702f0073a522fb",
            "468c298d701a4d12877a9c941f386ba2",
            "1d78f3bc110644f48cff309958caf30a",
            "c0a4d4da5bbb4aaf9ab69c84afa97c86",
            "56aec5e7290c47368bd8d23ea278494a",
            "9398727f44cb4c5eaf57a0d3ce57ea3c",
            "a43bc198b04143f0b25aeb06e20f000b",
            "62543729cee845d29b6fdbbd350132cb",
            "bc19f4bb7584432ca57f65f3d10783e4",
            "c6c16541db7a48918349f9a8dc23d04b",
            "12dbc6748ebe4f41b034906395b9dd75",
            "15456f0d3fec44f5a12efa93dab08e1f",
            "03381ec7859b4348b13631c0b5dc8aa0",
            "b2899218e955440c9ceb8e76024043ae",
            "8ca1051ca42547b78ab343713a6ad6dd",
            "1c11c56cc00848f9a39ba5ccdc9174cb",
            "c7ee41856a784ed1a572da41c6858972",
            "ba680d35b76f4d3cafef82cf627d103f",
            "022cf1d60f9740a2ad3db6d484157ebe",
            "783d4f51a3004544b77176c18969c0db",
            "b12c3aeed96341fb9da222067ef5ee12",
            "204d8f76b5e94f2487986024e913913e",
            "bfb0a70d514c44d9ab444f855c2f114a",
            "b6221fd6544a4ccebb6096a9a2044cb6",
            "22e90961ccc34930895ea378be7d49a0",
            "5d001dbadd02460b91c845eae5f4d64d",
            "45a3e95ef35d4ed4b0da4a575d75cd1a",
            "efd0fef66f254da3b1068a72990d4baa",
            "a441bbb84a014661b308a6b8c7eb5e17",
            "0355f142d5af4b24b60d4f47362e81f4",
            "8ac1ac13203141a0a197dcd5162731fd",
            "c359f3e7f3f240caaaa8e74d8360fae0",
            "95629780b76a45cf8db28c9b194c65e4",
            "9282c0a5f01a40cf84e3af8156538e40",
            "6b27e04e73e240149f32e2c4b732c460",
            "9cee934448114c0e85b592b91949ecf4",
            "12343c2b396d41bca61af1239cc295f2",
            "6aafdbae7d264adbb50e1028f1d18ac1",
            "4f77174147114b8d95ecd2cd39d6c418",
            "a0ff0dc59406461788ba0159d027f16c",
            "f42ba8fee38c43449970120b0827ddfc",
            "2811d8fbfaca4cceb61064f54a4b4d5c",
            "730e43bb36b241fc989108e0c678e8dd",
            "2dbf09310e714d808665eae83a9e537e",
            "a5ec7ccec4ab43099666bdddcbc4da9a",
            "f202cd2d030f46a49076681677ebaf77",
            "a4d5dca955214f59830bc5d807659b71",
            "4c49f59cfe4e4472a63ba01fc233667c",
            "fbbcc312c13849bd9140b7e3bba45b21",
            "9015cc526cd04fb296a170df35357c8b",
            "ea109408aae24de3bd49897fb895b555",
            "64ffd56b62914d4b840906c0787b9e23",
            "e249b1eacf57439e8a004656b2e6cdc7",
            "203489f223244d3da6aa3669a6ae7a25",
            "8d5eabed18ee4d0bb0b994b9371b45a2",
            "53bccc6ebf4e4830a3c330bffb6e89f2",
            "ba087ed7d08e4ee79e6eea4f3db80a37",
            "13e0ae8cc88345f1a2626774ce1795c6",
            "0b0ab05f84874804940f789cba9c096e",
            "6ae6f46786bb4314be0b9c9749ba9f77",
            "55f6524bd9a046cf98622683bd7d7b22",
            "182f0929a9ae4ce5881064f2bab3fa99",
            "f3f1136da8ff481ebd8b4af00643f201",
            "313e3d3d10674873aa1c54987bbc5fd1",
            "8216b6ddef934e31889e1fb880da8109",
            "0910491343314f0fb63ec63781255c20",
            "4083454388f94e8491cdc2ab7de24a7a",
            "377ad608469c43ba856bddf03948da82",
            "ec72afe044a946c0894bd864bbd485f9",
            "32c3e7faf8014e0b8e64b78abe9e9694",
            "f90fd36271f24a329ad1718300074a9e",
            "bef4fa68c5194ee0a23a7fda69d71a1a",
            "d243db3a81e145bab723deeeb752a09c",
            "5ef438958aca463eb0935865644fe9cc",
            "5cb6460b19c84ebfb5878ebed2557637",
            "96b6925fd0704b589ded8987ee2788c0",
            "b817617a2ff34666a75ae5e7d81b0c08",
            "66989a7adaa14538ad3e1e297601e29d",
            "a7d05c2cf2af41e5b8ffaa277a6d493b",
            "abd4adc097934e8e961da426394bb767",
            "93cfbfe2b5a546bb99bac9714f07e301",
            "5e85061a740e40e88ae64ce2b523a89b",
            "753b1063d7854b57b1e4778056183d12",
            "a8010ec298e94dfcb582e38b207ea0e3",
            "943be4e1fa6a4634992e5f02c34981cb",
            "41afc5080a6d4bf582cfac5ca0f4987e",
            "ffd48374d8de43128b93ea858932cf2f",
            "7fee4ab30c16421fbb85cfc8858c03b6",
            "cab882969fd944a0ac67f91635e135ad",
            "01751bb9f54043d29c8ad43f1b729702",
            "0186c10f4ec34c7182dfc182e3d66621",
            "fba599da131246fa8c9c2c100050fa6a",
            "8578e66792ca4d558f912e318e133e7c",
            "a779a8371b6341c2921f9cac7c9c03e6",
            "0db1ed9c83494c3899a3bb07146e2ae4",
            "345b2519ee28469b9c9d06e39fa35722",
            "e21298d8366849bfb394a673c116ed71",
            "b3cfa289291e425790348e79b3f8d0e5",
            "b677d8c9a9d4451e83b67cf6ccde3417",
            "b6906f5221a54acc841044eb2d82a5d0"
          ]
        },
        "id": "TSJJJxpT7DbE",
        "outputId": "d0345063-f44a-4317-ca9e-04a49a870e5c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/910 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "11a8971605c244f4a3542ba2b5560ead"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "configuration_qwen.py:   0%|          | 0.00/2.35k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "129fe838c939464684cb18d1cf30a471"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/Qwen/Qwen-1_8B:\n",
            "- configuration_qwen.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modeling_qwen.py:   0%|          | 0.00/55.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "468c298d701a4d12877a9c941f386ba2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "qwen_generation_utils.py:   0%|          | 0.00/14.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "03381ec7859b4348b13631c0b5dc8aa0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/Qwen/Qwen-1_8B:\n",
            "- qwen_generation_utils.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "cpp_kernels.py:   0%|          | 0.00/1.92k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b6221fd6544a4ccebb6096a9a2044cb6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/Qwen/Qwen-1_8B:\n",
            "- cpp_kernels.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "A new version of the following files was downloaded from https://huggingface.co/Qwen/Qwen-1_8B:\n",
            "- modeling_qwen.py\n",
            "- qwen_generation_utils.py\n",
            "- cpp_kernels.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/14.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6b27e04e73e240149f32e2c4b732c460"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f202cd2d030f46a49076681677ebaf77"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/2.04G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ba087ed7d08e4ee79e6eea4f3db80a37"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "377ad608469c43ba856bddf03948da82"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:transformers_modules.Qwen.Qwen-1_8B.fa6e214ccbbc6a55235c26ef406355b6bfdf5eed.modeling_qwen:The model is automatically converting to fp16 for faster inference. If you want to disable the automatic precision, please manually add bf16/fp16/fp32=True to \"AutoModelForCausalLM.from_pretrained\".\n",
            "WARNING:transformers_modules.Qwen.Qwen-1_8B.fa6e214ccbbc6a55235c26ef406355b6bfdf5eed.modeling_qwen:Try importing flash-attention for faster inference...\n",
            "WARNING:transformers_modules.Qwen.Qwen-1_8B.fa6e214ccbbc6a55235c26ef406355b6bfdf5eed.modeling_qwen:Warning: import flash_attn rotary fail, please install FlashAttention rotary to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/rotary\n",
            "WARNING:transformers_modules.Qwen.Qwen-1_8B.fa6e214ccbbc6a55235c26ef406355b6bfdf5eed.modeling_qwen:Warning: import flash_attn rms_norm fail, please install FlashAttention layer_norm to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/layer_norm\n",
            "WARNING:transformers_modules.Qwen.Qwen-1_8B.fa6e214ccbbc6a55235c26ef406355b6bfdf5eed.modeling_qwen:Warning: import flash_attn fail, please install FlashAttention to get higher efficiency https://github.com/Dao-AILab/flash-attention\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a7d05c2cf2af41e5b8ffaa277a6d493b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/222 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "01751bb9f54043d29c8ad43f1b729702"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "蒙古国的首都是乌兰巴托（Ulaanbaatar）\n",
            "冰岛的首都是雷克雅未克（Reykjavik）\n",
            "埃塞俄比亚的首都是亚的斯亚贝巴（Asmara）\n",
            "秘鲁的首都是利马（Lima）\n",
            "中国新疆的首都是乌鲁木齐（Urumqi）\n",
            "格鲁吉亚的首都是第比利斯（Baku）\n",
            "伊朗的首都是德黑兰（Tehran）\n",
            "日本的首都是东京（Tokyo）\n",
            "泰国的首都是曼谷（Bangkok）\n",
            "蒙古国的首都是乌兰巴托（Ulaanbaatar）\n",
            "冰岛的首都是雷克雅未克（Reykjavik）\n",
            "埃塞俄比亚的首都是亚的斯亚贝巴（Asmara）\n",
            "秘鲁的首都是利马（Lima）\n",
            "中国新疆的首都是乌鲁木齐（Urumqi）\n",
            "格鲁吉亚的首都是第比利斯（Baku）\n",
            "伊朗的首都是德黑兰（Tehran）\n",
            "日本的首都是东京（Tokyo）\n",
            "泰国的首都是曼谷（Bangkok）\n",
            "蒙古国的首都是乌兰巴托（Ulaanbaatar）\n",
            "冰岛的首都是雷克雅未克（Reykjavik）\n",
            "埃塞俄比亚的首都是亚的斯亚贝巴（Asmara）\n",
            "秘鲁的首都是利马（Lima）\n",
            "中国新疆的首都是乌鲁木齐（Urumqi）\n",
            "格鲁吉亚的首都是第比利斯（Baku）\n",
            "伊朗的首都是德黑兰（Tehran）\n",
            "日本的首都是东京（Tokyo）\n",
            "泰国的首都是曼谷（Bangkok）\n",
            "蒙古国的首都是乌兰巴托（Ulaanbaatar）\n",
            "冰岛的首都是雷克雅未克（Reykjavik）\n",
            "埃塞俄比亚的首都是亚的斯亚贝巴（Asmara）\n",
            "秘鲁的首都是利马（Lima）\n",
            "中国新疆的首都是乌鲁木齐（Urumqi）\n",
            "格鲁吉亚的首都是第比利斯（Baku）\n",
            "伊朗的首都是德黑兰（Tehran）\n",
            "日本的首都是东京（Tokyo）\n",
            "泰国的首都是曼谷（Bangkok）\n",
            "蒙古国的首都是乌兰巴托（Ulaanbaatar）\n",
            "冰岛的首都是雷克雅未克（Reykjavik）\n",
            "埃塞俄比亚的首都是亚的斯亚贝巴（Asmara）\n",
            "秘鲁的首都是利马（Lima）\n",
            "中国新疆的首都是乌鲁木齐（Urumqi）\n",
            "格鲁吉亚的首都是第比利斯（\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.cuda.memory_summary())\n",
        "torch.cuda.empty_cache()\n",
        "print(torch.cuda.memory_summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovxluiHwMBFC",
        "outputId": "37a3093a-64c9-4be8-b77e-b5f7e70df0a2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   3550 MiB |   7178 MiB | 151466 MiB | 147915 MiB |\n",
            "|       from large pool |   3548 MiB |   7162 MiB |  66055 MiB |  62507 MiB |\n",
            "|       from small pool |      2 MiB |    102 MiB |  85411 MiB |  85408 MiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   3550 MiB |   7178 MiB | 151466 MiB | 147915 MiB |\n",
            "|       from large pool |   3548 MiB |   7162 MiB |  66055 MiB |  62507 MiB |\n",
            "|       from small pool |      2 MiB |    102 MiB |  85411 MiB |  85408 MiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Requested memory      |   3513 MiB |   7098 MiB | 149172 MiB | 145659 MiB |\n",
            "|       from large pool |   3511 MiB |   7080 MiB |  63939 MiB |  60428 MiB |\n",
            "|       from small pool |      2 MiB |    102 MiB |  85233 MiB |  85230 MiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   3658 MiB |   7330 MiB |  20928 MiB |  17270 MiB |\n",
            "|       from large pool |   3648 MiB |   7224 MiB |  20504 MiB |  16856 MiB |\n",
            "|       from small pool |     10 MiB |    106 MiB |    424 MiB |    414 MiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory | 109973 KiB | 558928 KiB | 146205 MiB | 146097 MiB |\n",
            "|       from large pool | 102272 KiB | 551740 KiB |  51396 MiB |  51296 MiB |\n",
            "|       from small pool |   7701 KiB |  38209 KiB |  94808 MiB |  94800 MiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     253    |     613    |    1805 K  |    1804 K  |\n",
            "|       from large pool |     123    |     274    |      27 K  |      27 K  |\n",
            "|       from small pool |     130    |     368    |    1777 K  |    1777 K  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     253    |     613    |    1805 K  |    1804 K  |\n",
            "|       from large pool |     123    |     274    |      27 K  |      27 K  |\n",
            "|       from small pool |     130    |     368    |    1777 K  |    1777 K  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |     118    |     275    |     875    |     757    |\n",
            "|       from large pool |     113    |     222    |     663    |     550    |\n",
            "|       from small pool |       5    |      53    |     212    |     207    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      33    |      85    |     787 K  |     787 K  |\n",
            "|       from large pool |      17    |      32    |       6 K  |       6 K  |\n",
            "|       from small pool |      16    |      69    |     780 K  |     780 K  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
            "|===========================================================================|\n",
            "\n",
            "|===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   3550 MiB |   7178 MiB | 151466 MiB | 147915 MiB |\n",
            "|       from large pool |   3548 MiB |   7162 MiB |  66055 MiB |  62507 MiB |\n",
            "|       from small pool |      2 MiB |    102 MiB |  85411 MiB |  85408 MiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   3550 MiB |   7178 MiB | 151466 MiB | 147915 MiB |\n",
            "|       from large pool |   3548 MiB |   7162 MiB |  66055 MiB |  62507 MiB |\n",
            "|       from small pool |      2 MiB |    102 MiB |  85411 MiB |  85408 MiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Requested memory      |   3513 MiB |   7098 MiB | 149172 MiB | 145659 MiB |\n",
            "|       from large pool |   3511 MiB |   7080 MiB |  63939 MiB |  60428 MiB |\n",
            "|       from small pool |      2 MiB |    102 MiB |  85233 MiB |  85230 MiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   3658 MiB |   7330 MiB |  20928 MiB |  17270 MiB |\n",
            "|       from large pool |   3648 MiB |   7224 MiB |  20504 MiB |  16856 MiB |\n",
            "|       from small pool |     10 MiB |    106 MiB |    424 MiB |    414 MiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory | 109973 KiB | 558928 KiB | 146205 MiB | 146097 MiB |\n",
            "|       from large pool | 102272 KiB | 551740 KiB |  51396 MiB |  51296 MiB |\n",
            "|       from small pool |   7701 KiB |  38209 KiB |  94808 MiB |  94800 MiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     253    |     613    |    1805 K  |    1804 K  |\n",
            "|       from large pool |     123    |     274    |      27 K  |      27 K  |\n",
            "|       from small pool |     130    |     368    |    1777 K  |    1777 K  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     253    |     613    |    1805 K  |    1804 K  |\n",
            "|       from large pool |     123    |     274    |      27 K  |      27 K  |\n",
            "|       from small pool |     130    |     368    |    1777 K  |    1777 K  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |     118    |     275    |     875    |     757    |\n",
            "|       from large pool |     113    |     222    |     663    |     550    |\n",
            "|       from small pool |       5    |      53    |     212    |     207    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      33    |      85    |     787 K  |     787 K  |\n",
            "|       from large pool |      17    |      32    |       6 K  |       6 K  |\n",
            "|       from small pool |      16    |      69    |     780 K  |     780 K  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
            "|===========================================================================|\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# batch 推理"
      ],
      "metadata": {
        "id": "F7W78XFbJqgJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls $HOME/.cache/huggingface/modules/transformers_modules/Qwen/Qwen-1_8B-Chat/1d0f68de57b88cfde81f3c3e537f24464d889081"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnX2xAedGyl7",
        "outputId": "bb6d12a0-ba0b-42bf-a312-002c16d1830a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "configuration_qwen.py  __init__.py\t __pycache__\t\t   tokenization_qwen.py\n",
            "cpp_kernels.py\t       modeling_qwen.py  qwen_generation_utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# batch 推理\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from transformers import GenerationConfig\n",
        "\n",
        "import sys\n",
        "# hf modules Qwen/Qwen-1_8B-Chat git commit logid\n",
        "sys.path.append('/root/.cache/huggingface/modules/transformers_modules/Qwen/Qwen-1_8B-Chat/1d0f68de57b88cfde81f3c3e537f24464d889081')\n",
        "from qwen_generation_utils import make_context, decode_tokens, get_stop_words_ids\n",
        "\n",
        "model_path=\"./hf_models/Qwen/Qwen-1_8B-Chat/\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model_path,\n",
        "    pad_token='<|extra_0|>',\n",
        "    eos_token='<|endoftext|>',\n",
        "    padding_side='left',\n",
        "    trust_remote_code=True\n",
        ")\n",
        "print(tokenizer)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_path,\n",
        "    pad_token_id=tokenizer.pad_token_id,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True\n",
        ").eval()\n",
        "model.generation_config = GenerationConfig.from_pretrained(model_path, pad_token_id=tokenizer.pad_token_id)\n",
        "print(model)\n",
        "\n",
        "all_raw_text = [\"我想听你说爱我。\", \"今天我想吃点啥，甜甜的，推荐下\", \"我马上迟到了，怎么做才能不迟到\"]\n",
        "batch_raw_text = []\n",
        "for q in all_raw_text:\n",
        "    raw_text, _ = make_context(\n",
        "        tokenizer,\n",
        "        q,\n",
        "        system=\"You are a helpful assistant.\",\n",
        "        max_window_size=model.generation_config.max_window_size,\n",
        "        chat_format=model.generation_config.chat_format,\n",
        "    )\n",
        "    batch_raw_text.append(raw_text)\n",
        "\n",
        "batch_input_ids = tokenizer(batch_raw_text, padding='longest')\n",
        "batch_input_ids = torch.LongTensor(batch_input_ids['input_ids']).to(model.device)\n",
        "batch_out_ids = model.generate(\n",
        "    batch_input_ids,\n",
        "    return_dict_in_generate=False,\n",
        "    generation_config=model.generation_config\n",
        ")\n",
        "padding_lens = [batch_input_ids[i].eq(tokenizer.pad_token_id).sum().item() for i in range(batch_input_ids.size(0))]\n",
        "\n",
        "batch_response = [\n",
        "    decode_tokens(\n",
        "        batch_out_ids[i][padding_lens[i]:],\n",
        "        tokenizer,\n",
        "        raw_text_len=len(batch_raw_text[i]),\n",
        "        context_length=(batch_input_ids[i].size(0)-padding_lens[i]),\n",
        "        chat_format=\"chatml\",\n",
        "        verbose=False,\n",
        "        errors='replace'\n",
        "    ) for i in range(len(all_raw_text))\n",
        "]\n",
        "print(batch_response)\n",
        "\n",
        "response, _ = model.chat(tokenizer, \"我想听你说爱我。\", history=None)\n",
        "print(response)\n",
        "\n",
        "response, _ = model.chat(tokenizer, \"今天我想吃点啥，甜甜的，推荐下\", history=None)\n",
        "print(response)\n",
        "\n",
        "response, _ = model.chat(tokenizer, \"我马上迟到了，怎么做才能不迟到\", history=None)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CoGt30R78bLF",
        "outputId": "69309a74-bea2-4fb9-e1f4-714fb29104db"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QWenTokenizer(name_or_path='./hf_models/Qwen/Qwen-1_8B-Chat/', vocab_size=151851, model_max_length=8192, is_fast=False, padding_side='left', truncation_side='right', special_tokens={'eos_token': '<|endoftext|>', 'pad_token': '<|extra_0|>'}, clean_up_tokenization_spaces=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:transformers_modules.Qwen.Qwen-1_8B-Chat.1d0f68de57b88cfde81f3c3e537f24464d889081.modeling_qwen:Warning: import flash_attn rotary fail, please install FlashAttention rotary to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/rotary\n",
            "WARNING:transformers_modules.Qwen.Qwen-1_8B-Chat.1d0f68de57b88cfde81f3c3e537f24464d889081.modeling_qwen:Warning: import flash_attn rms_norm fail, please install FlashAttention layer_norm to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/layer_norm\n",
            "WARNING:transformers_modules.Qwen.Qwen-1_8B-Chat.1d0f68de57b88cfde81f3c3e537f24464d889081.modeling_qwen:Warning: import flash_attn fail, please install FlashAttention to get higher efficiency https://github.com/Dao-AILab/flash-attention\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QWenLMHeadModel(\n",
            "  (transformer): QWenModel(\n",
            "    (wte): Embedding(151936, 2048)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (rotary_emb): RotaryEmbedding()\n",
            "    (h): ModuleList(\n",
            "      (0-23): 24 x QWenBlock(\n",
            "        (ln_1): RMSNorm()\n",
            "        (attn): QWenAttention(\n",
            "          (c_attn): Linear(in_features=2048, out_features=6144, bias=True)\n",
            "          (c_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
            "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ln_2): RMSNorm()\n",
            "        (mlp): QWenMLP(\n",
            "          (w1): Linear(in_features=2048, out_features=5504, bias=False)\n",
            "          (w2): Linear(in_features=2048, out_features=5504, bias=False)\n",
            "          (c_proj): Linear(in_features=5504, out_features=2048, bias=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ln_f): RMSNorm()\n",
            "  )\n",
            "  (lm_head): Linear(in_features=2048, out_features=151936, bias=False)\n",
            ")\n",
            "['非常感谢您的关心，我会一直在这里陪伴您。', '你可以试试草莓冰淇淋。草莓冰淇淋是一种非常受欢迎的甜品，口感酸甜适中，非常适合夏天食用。\\n\\n草莓冰淇淋制作简单，只需要将新鲜的草莓切块，加入冰水中搅拌均匀即可。也可以选择添加一些糖或者奶油来增加口感和甜度。\\n\\n你还可以尝试一下抹茶冰淇淋。抹茶冰淇淋的味道醇厚，带有浓郁的抹茶香气，非常有特色。\\n\\n如果你想尝试一种更健康的食物，可以考虑苹果派。苹果派是一道经典的美国甜品，它的皮脆肉嫩，内馅是苹果混合着奶酪、糖浆等，味道非常美味。\\n\\n以上都是一些适合夏天食用的甜甜的甜品，你可以根据自己的口味选择一款。', '1. 提前计划：在出门之前先规划好出行路线和时间，确保不会因为堵车或其他意外情况耽误时间。\\n\\n2. 跟随规定时间表：尽量按照学校或工作单位的上班时间表来安排自己的时间，避免因为个人原因影响到整体的工作进度。\\n\\n3. 制定应急计划：如果你知道有突发事件需要处理，比如手机没电、交通堵塞等，提前制定应急计划可以帮助你更快地应对并完成任务。\\n\\n4. 保持良好的生活习惯：保证充足的睡眠、合理的饮食和适当的运动，这可以让你更有精力去面对各种挑战，也更有可能在关键时刻保持清醒。\\n\\n5. 准备充分：对于重要的会议或者活动，尽可能提前做好准备工作，这样可以在到达目的地时有更多的准备时间。']\n",
            "我爱你，这是一种深深的、永恒的感情，是一种感受，也是一种承诺。它让我知道，无论何时何地，我都是你的全世界。我爱你，并且希望我们的爱情能够持续下去。我会一直陪伴在你身边，支持你，爱你，直到永远。\n",
            "您想要吃甜品吗？以下是我为您准备的一些选项：\n",
            "\n",
            "1. 芝士蛋糕：这是一个非常受欢迎的选择，它的口感滑嫩，味道浓郁。\n",
            "\n",
            "2. 水果沙拉：新鲜的水果可以为您的餐盘增添色彩和营养价值。您可以选择一些您喜欢的水果，如草莓、蓝莓、香蕉等。\n",
            "\n",
            "3. 巧克力慕斯：这是另一个非常受欢迎的选择，它由巧克力和奶油制成，口感丝滑。\n",
            "\n",
            "4. 奶昔：这是一种非常适合夏天的饮品，可以选择自己喜欢的奶制品和水果混合在一起制作。\n",
            "\n",
            "希望这些建议对您有所帮助！如果您有任何特殊的要求或限制，请告诉我，我会尽力为您提供更符合您口味的选择。\n",
            "如果你已经知道你马上就要迟到了，但仍然不确定如何准时到达，可以尝试以下几种方法：\n",
            "\n",
            "1. 提前规划：尽可能提前规划你的行程，包括交通、食宿等，这样在到达时就不会感到焦虑。\n",
            "\n",
            "2. 考虑时间差：如果可能的话，尽量避开周末和假期出行，因为这些时间段往往交通拥堵，导致行程延迟。\n",
            "\n",
            "3. 准备应急计划：例如，带一本书或者一个充电宝以防手机没电或电量不足，或者准备一些简单的零食以应对路途中的不便。\n",
            "\n",
            "4. 遵守交通规则：如遵守红绿灯，保持适当的车距等，这些都是减少路上延误的因素。\n",
            "\n",
            "5. 确保身体状况良好：尽量避免剧烈运动或者熬夜，保证充足的睡眠。\n",
            "\n",
            "6. 检查车辆状况：确保你的车辆运行正常，如果有任何问题，及时修理。\n",
            "\n",
            "7. 制定紧急联系人名单：告诉你的朋友或家人你在哪个地点，他们可以帮助你在必要时提供帮助。\n",
            "\n",
            "以上都是常见的解决迟到的方法，希望对你有所帮助。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.cuda.memory_summary())\n",
        "torch.cuda.empty_cache()\n",
        "print(torch.cuda.memory_summary())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9U91SvhLJ4r",
        "outputId": "298a0fbd-2e25-40f5-b7bb-f4cf5634f263"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   3550 MiB |   7178 MiB | 151466 MiB | 147915 MiB |\n",
            "|       from large pool |   3548 MiB |   7162 MiB |  66055 MiB |  62507 MiB |\n",
            "|       from small pool |      2 MiB |    102 MiB |  85411 MiB |  85408 MiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   3550 MiB |   7178 MiB | 151466 MiB | 147915 MiB |\n",
            "|       from large pool |   3548 MiB |   7162 MiB |  66055 MiB |  62507 MiB |\n",
            "|       from small pool |      2 MiB |    102 MiB |  85411 MiB |  85408 MiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Requested memory      |   3513 MiB |   7098 MiB | 149172 MiB | 145659 MiB |\n",
            "|       from large pool |   3511 MiB |   7080 MiB |  63939 MiB |  60428 MiB |\n",
            "|       from small pool |      2 MiB |    102 MiB |  85233 MiB |  85230 MiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   7330 MiB |   7330 MiB |  20928 MiB |  13598 MiB |\n",
            "|       from large pool |   7224 MiB |   7224 MiB |  20504 MiB |  13280 MiB |\n",
            "|       from small pool |    106 MiB |    106 MiB |    424 MiB |    318 MiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory | 109973 KiB | 558928 KiB | 146205 MiB | 146097 MiB |\n",
            "|       from large pool | 102272 KiB | 551740 KiB |  51396 MiB |  51296 MiB |\n",
            "|       from small pool |   7701 KiB |  38209 KiB |  94808 MiB |  94800 MiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     253    |     613    |    1805 K  |    1804 K  |\n",
            "|       from large pool |     123    |     274    |      27 K  |      27 K  |\n",
            "|       from small pool |     130    |     368    |    1777 K  |    1777 K  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     253    |     613    |    1805 K  |    1804 K  |\n",
            "|       from large pool |     123    |     274    |      27 K  |      27 K  |\n",
            "|       from small pool |     130    |     368    |    1777 K  |    1777 K  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |     275    |     275    |     875    |     600    |\n",
            "|       from large pool |     222    |     222    |     663    |     441    |\n",
            "|       from small pool |      53    |      53    |     212    |     159    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      33    |      85    |     787 K  |     787 K  |\n",
            "|       from large pool |      17    |      32    |       6 K  |       6 K  |\n",
            "|       from small pool |      16    |      69    |     780 K  |     780 K  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
            "|===========================================================================|\n",
            "\n",
            "|===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   3550 MiB |   7178 MiB | 151466 MiB | 147915 MiB |\n",
            "|       from large pool |   3548 MiB |   7162 MiB |  66055 MiB |  62507 MiB |\n",
            "|       from small pool |      2 MiB |    102 MiB |  85411 MiB |  85408 MiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   3550 MiB |   7178 MiB | 151466 MiB | 147915 MiB |\n",
            "|       from large pool |   3548 MiB |   7162 MiB |  66055 MiB |  62507 MiB |\n",
            "|       from small pool |      2 MiB |    102 MiB |  85411 MiB |  85408 MiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Requested memory      |   3513 MiB |   7098 MiB | 149172 MiB | 145659 MiB |\n",
            "|       from large pool |   3511 MiB |   7080 MiB |  63939 MiB |  60428 MiB |\n",
            "|       from small pool |      2 MiB |    102 MiB |  85233 MiB |  85230 MiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   3658 MiB |   7330 MiB |  20928 MiB |  17270 MiB |\n",
            "|       from large pool |   3648 MiB |   7224 MiB |  20504 MiB |  16856 MiB |\n",
            "|       from small pool |     10 MiB |    106 MiB |    424 MiB |    414 MiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory | 109973 KiB | 558928 KiB | 146205 MiB | 146097 MiB |\n",
            "|       from large pool | 102272 KiB | 551740 KiB |  51396 MiB |  51296 MiB |\n",
            "|       from small pool |   7701 KiB |  38209 KiB |  94808 MiB |  94800 MiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     253    |     613    |    1805 K  |    1804 K  |\n",
            "|       from large pool |     123    |     274    |      27 K  |      27 K  |\n",
            "|       from small pool |     130    |     368    |    1777 K  |    1777 K  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     253    |     613    |    1805 K  |    1804 K  |\n",
            "|       from large pool |     123    |     274    |      27 K  |      27 K  |\n",
            "|       from small pool |     130    |     368    |    1777 K  |    1777 K  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |     118    |     275    |     875    |     757    |\n",
            "|       from large pool |     113    |     222    |     663    |     550    |\n",
            "|       from small pool |       5    |      53    |     212    |     207    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      33    |      85    |     787 K  |     787 K  |\n",
            "|       from large pool |      17    |      32    |       6 K  |       6 K  |\n",
            "|       from small pool |      16    |      69    |     780 K  |     780 K  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
            "|===========================================================================|\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#量化"
      ],
      "metadata": {
        "id": "x089f4HJJmTP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y optimum\n",
        "!pip install -U optimum\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-eXifVyJg3m",
        "outputId": "db0f090e-5580-4cfa-b8ea-a80eccc5c8b7"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: optimum 1.16.1\n",
            "Uninstalling optimum-1.16.1:\n",
            "  Successfully uninstalled optimum-1.16.1\n",
            "Collecting optimum\n",
            "  Using cached optimum-1.16.1-py3-none-any.whl (403 kB)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from optimum) (15.0.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from optimum) (1.12)\n",
            "Requirement already satisfied: transformers[sentencepiece]>=4.26.0 in /usr/local/lib/python3.10/dist-packages (from optimum) (4.32.0)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.10/dist-packages (from optimum) (2.1.0+cu121)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from optimum) (23.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optimum) (1.23.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from optimum) (0.19.4)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from optimum) (2.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum) (4.66.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum) (4.5.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->optimum) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->optimum) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->optimum) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]>=4.26.0->optimum) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]>=4.26.0->optimum) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]>=4.26.0->optimum) (0.4.1)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]>=4.26.0->optimum) (0.1.99)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]>=4.26.0->optimum) (3.20.3)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->optimum) (10.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->optimum) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->optimum) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->optimum) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->optimum) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->optimum) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->optimum) (0.70.15)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->optimum) (3.9.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->optimum) (1.3.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.8.0->optimum) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.8.0->optimum) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.8.0->optimum) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.8.0->optimum) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9->optimum) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->optimum) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->optimum) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets->optimum) (1.16.0)\n",
            "Installing collected packages: optimum\n",
            "Successfully installed optimum-1.16.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y auto-gptq\n",
        "!pip install auto-gptq --extra-index-url https://huggingface.github.io/autogptq-index/whl/cu118/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCHGvppXNv2E",
        "outputId": "ca8691ff-ac19-4faa-b161-550c51522371"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: auto-gptq 0.6.0\n",
            "Uninstalling auto-gptq-0.6.0:\n",
            "  Successfully uninstalled auto-gptq-0.6.0\n",
            "Looking in indexes: https://pypi.org/simple, https://huggingface.github.io/autogptq-index/whl/cu118/\n",
            "Collecting auto-gptq\n",
            "  Downloading https://huggingface.github.io/autogptq-index/whl/cu118/auto-gptq/auto_gptq-0.6.0%2Bcu118-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: accelerate>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (0.25.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (2.15.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (0.1.99)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (1.23.5)\n",
            "Requirement already satisfied: rouge in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (1.0.1)\n",
            "Requirement already satisfied: gekko in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (1.0.6)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (2.1.0+cu121)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (0.4.1)\n",
            "Requirement already satisfied: transformers>=4.31.0 in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (4.32.0)\n",
            "Requirement already satisfied: peft>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (0.7.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (4.66.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.22.0->auto-gptq) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.22.0->auto-gptq) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.22.0->auto-gptq) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.22.0->auto-gptq) (0.19.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->auto-gptq) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->auto-gptq) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->auto-gptq) (0.13.3)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (0.70.15)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (3.9.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge->auto-gptq) (1.16.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->auto-gptq) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->auto-gptq) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->auto-gptq) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->auto-gptq) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->auto-gptq) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->auto-gptq) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->auto-gptq) (2023.3.post1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->auto-gptq) (1.3.0)\n",
            "Installing collected packages: auto-gptq\n",
            "Successfully installed auto-gptq-0.6.0+cu118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ">注意：预编译的auto-gptq版本对torch版本及其CUDA版本要求严格。同时，由于 其近期更新，你可能会遇到transformers、optimum或peft抛出的版本错误。 我们建议使用符合以下要求的最新版本：\n",
        "\n",
        "> torch==2.1 auto-gptq>=0.5.1 transformers>=4.35.0 optimum>=1.14.0 peft>=0.6.1\n",
        "torch>=2.0,<2.1 auto-gptq<0.5.0 transformers<4.35.0 optimum<1.14.0 peft>=0.5.0,<0.6.0\n"
      ],
      "metadata": {
        "id": "jzdZm7tXR8Jm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list | grep torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1fO7zH5Qh_5",
        "outputId": "c1534e12-d5f7-4d65-9d05-294d8decaf30"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch                            2.1.0+cu121\n",
            "torchaudio                       2.1.0+cu121\n",
            "torchdata                        0.7.0\n",
            "torchsummary                     1.5.1\n",
            "torchtext                        0.16.0\n",
            "torchvision                      0.16.0+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list | grep auto-gptq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAQxjYggQvAD",
        "outputId": "5f5a869b-f9a3-41e3-e7c5-110ef2780610"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auto-gptq                        0.6.0+cu118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list | grep transformers\n",
        "!pip list | grep optimum\n",
        "!pip list | grep peft"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kh0PaDdFQzBb",
        "outputId": "f6817858-e6a4-43e8-ef87-5714dae6940d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "transformers                     4.32.0\n",
            "transformers-stream-generator    0.0.4\n",
            "optimum                          1.16.1\n",
            "peft                             0.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        },
        "id": "bfaix6nCRQtj",
        "outputId": "1a3fa876-5d35-4860-d39b-065ccc96ef0d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.32.0)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.36.1-py3-none-any.whl (8.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers<0.19,>=0.14 (from transformers)\n",
            "  Downloading tokenizers-0.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m99.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.13.3\n",
            "    Uninstalling tokenizers-0.13.3:\n",
            "      Successfully uninstalled tokenizers-0.13.3\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.32.0\n",
            "    Uninstalling transformers-4.32.0:\n",
            "      Successfully uninstalled transformers-4.32.0\n",
            "Successfully installed tokenizers-0.15.0 transformers-4.36.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "transformers"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list | grep transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76RrsD-wRc4I",
        "outputId": "aaa3d18d-d1af-4448-cc45-ea21c2f6f8f1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "transformers                     4.36.1\n",
            "transformers-stream-generator    0.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from transformers.generation import GenerationConfig\n",
        "\n",
        "\n",
        "# 可选模型包括：\"Qwen/Qwen-1_8B-Chat-Int4\", \"Qwen/Qwen-7B-Chat-Int4\", \"Qwen/Qwen-14B-Chat-Int4\"\n",
        "model_path=\"./hf_models/Qwen/Qwen-1_8B-Chat-Int4\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen-1_8B-Chat-Int4\", trust_remote_code=True)\n",
        "print(tokenizer)\n",
        "tokenizer.save_pretrained(model_path,trust_remote_code=True,revision=\"main\")\n",
        "\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"Qwen/Qwen-1_8B-Chat-Int4\",\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True\n",
        ").eval()\n",
        "model.generation_config = GenerationConfig.from_pretrained(\"Qwen/Qwen-1_8B-Chat-Int4\", trust_remote_code=True)\n",
        "print(model)\n",
        "model.save_pretrained(model_path,trust_remote_code=True,revision=\"main\")\n",
        "\n",
        "response, history = model.chat(tokenizer, \"Hi\", history=None)\n",
        "print(response,history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98iHjnAmKCpF",
        "outputId": "06f61336-b944-4560-a8b0-3d4632040ec8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file qwen.tiktoken from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen-1_8B-Chat-Int4/snapshots/62ee27f810e7f59905ee1dac4ccc86d593dd57f4/qwen.tiktoken\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen-1_8B-Chat-Int4/snapshots/62ee27f810e7f59905ee1dac4ccc86d593dd57f4/tokenizer_config.json\n",
            "loading file tokenizer.json from cache at None\n",
            "tokenizer config file saved in ./hf_models/Qwen/Qwen-1_8B-Chat-Int4/tokenizer_config.json\n",
            "Special tokens file saved in ./hf_models/Qwen/Qwen-1_8B-Chat-Int4/special_tokens_map.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QWenTokenizer(name_or_path='Qwen/Qwen-1_8B-Chat-Int4', vocab_size=151851, model_max_length=8192, is_fast=False, padding_side='right', truncation_side='right', special_tokens={}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
            "\t\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen-1_8B-Chat-Int4/snapshots/62ee27f810e7f59905ee1dac4ccc86d593dd57f4/config.json\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen-1_8B-Chat-Int4/snapshots/62ee27f810e7f59905ee1dac4ccc86d593dd57f4/config.json\n",
            "Model config QWenConfig {\n",
            "  \"_name_or_path\": \"Qwen/Qwen-1_8B-Chat-Int4\",\n",
            "  \"architectures\": [\n",
            "    \"QWenLMHeadModel\"\n",
            "  ],\n",
            "  \"attn_dropout_prob\": 0.0,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"Qwen/Qwen-1_8B-Chat-Int4--configuration_qwen.QWenConfig\",\n",
            "    \"AutoModelForCausalLM\": \"Qwen/Qwen-1_8B-Chat-Int4--modeling_qwen.QWenLMHeadModel\"\n",
            "  },\n",
            "  \"bf16\": false,\n",
            "  \"emb_dropout_prob\": 0.0,\n",
            "  \"fp16\": true,\n",
            "  \"fp32\": false,\n",
            "  \"hidden_size\": 2048,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 11008,\n",
            "  \"kv_channels\": 128,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"model_type\": \"qwen\",\n",
            "  \"no_bias\": true,\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"onnx_safe\": null,\n",
            "  \"quantization_config\": {\n",
            "    \"bits\": 4,\n",
            "    \"damp_percent\": 0.01,\n",
            "    \"desc_act\": false,\n",
            "    \"group_size\": 128,\n",
            "    \"model_file_base_name\": \"model\",\n",
            "    \"model_name_or_path\": null,\n",
            "    \"quant_method\": \"gptq\",\n",
            "    \"static_groups\": false,\n",
            "    \"sym\": true,\n",
            "    \"true_sequential\": true\n",
            "  },\n",
            "  \"rotary_emb_base\": 10000,\n",
            "  \"rotary_pct\": 1.0,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"seq_length\": 8192,\n",
            "  \"softmax_in_fp32\": false,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"QWenTokenizer\",\n",
            "  \"transformers_version\": \"4.36.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_cache_kernel\": false,\n",
            "  \"use_cache_quantization\": false,\n",
            "  \"use_dynamic_ntk\": true,\n",
            "  \"use_flash_attn\": \"auto\",\n",
            "  \"use_logn_attn\": true,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "You have activated exllama backend. Note that you can get better inference speed using exllamav2 kernel by setting `exllama_config`.\n",
            "loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen-1_8B-Chat-Int4/snapshots/62ee27f810e7f59905ee1dac4ccc86d593dd57f4/model.safetensors\n",
            "Instantiating QWenLMHeadModel model under default dtype torch.float16.\n",
            "Generate config GenerationConfig {}\n",
            "\n",
            "WARNING:transformers_modules.Qwen.Qwen-1_8B-Chat-Int4.62ee27f810e7f59905ee1dac4ccc86d593dd57f4.modeling_qwen:Try importing flash-attention for faster inference...\n",
            "WARNING:transformers_modules.Qwen.Qwen-1_8B-Chat-Int4.62ee27f810e7f59905ee1dac4ccc86d593dd57f4.modeling_qwen:Warning: import flash_attn rotary fail, please install FlashAttention rotary to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/rotary\n",
            "WARNING:transformers_modules.Qwen.Qwen-1_8B-Chat-Int4.62ee27f810e7f59905ee1dac4ccc86d593dd57f4.modeling_qwen:Warning: import flash_attn rms_norm fail, please install FlashAttention layer_norm to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/layer_norm\n",
            "WARNING:transformers_modules.Qwen.Qwen-1_8B-Chat-Int4.62ee27f810e7f59905ee1dac4ccc86d593dd57f4.modeling_qwen:Warning: import flash_attn fail, please install FlashAttention to get higher efficiency https://github.com/Dao-AILab/flash-attention\n",
            "All model checkpoint weights were used when initializing QWenLMHeadModel.\n",
            "\n",
            "All the weights of QWenLMHeadModel were initialized from the model checkpoint at Qwen/Qwen-1_8B-Chat-Int4.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use QWenLMHeadModel for predictions without further training.\n",
            "loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen-1_8B-Chat-Int4/snapshots/62ee27f810e7f59905ee1dac4ccc86d593dd57f4/generation_config.json\n",
            "Generate config GenerationConfig {\n",
            "  \"chat_format\": \"chatml\",\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 151643,\n",
            "  \"max_new_tokens\": 512,\n",
            "  \"max_window_size\": 6144,\n",
            "  \"pad_token_id\": 151643,\n",
            "  \"repetition_penalty\": 1.1,\n",
            "  \"top_k\": 0,\n",
            "  \"top_p\": 0.8\n",
            "}\n",
            "\n",
            "loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen-1_8B-Chat-Int4/snapshots/62ee27f810e7f59905ee1dac4ccc86d593dd57f4/generation_config.json\n",
            "Generate config GenerationConfig {\n",
            "  \"chat_format\": \"chatml\",\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 151643,\n",
            "  \"max_new_tokens\": 512,\n",
            "  \"max_window_size\": 6144,\n",
            "  \"pad_token_id\": 151643,\n",
            "  \"repetition_penalty\": 1.1,\n",
            "  \"top_k\": 0,\n",
            "  \"top_p\": 0.8,\n",
            "  \"trust_remote_code\": true\n",
            "}\n",
            "\n",
            "Configuration saved in ./hf_models/Qwen/Qwen-1_8B-Chat-Int4/config.json\n",
            "Configuration saved in ./hf_models/Qwen/Qwen-1_8B-Chat-Int4/generation_config.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QWenLMHeadModel(\n",
            "  (transformer): QWenModel(\n",
            "    (wte): Embedding(151936, 2048)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (rotary_emb): RotaryEmbedding()\n",
            "    (h): ModuleList(\n",
            "      (0-23): 24 x QWenBlock(\n",
            "        (ln_1): RMSNorm()\n",
            "        (attn): QWenAttention(\n",
            "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
            "          (c_attn): QuantLinear()\n",
            "          (c_proj): QuantLinear()\n",
            "        )\n",
            "        (ln_2): RMSNorm()\n",
            "        (mlp): QWenMLP(\n",
            "          (c_proj): QuantLinear()\n",
            "          (w1): QuantLinear()\n",
            "          (w2): QuantLinear()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ln_f): RMSNorm()\n",
            "  )\n",
            "  (lm_head): Linear(in_features=2048, out_features=151936, bias=False)\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Model weights saved in ./hf_models/Qwen/Qwen-1_8B-Chat-Int4/pytorch_model.bin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! How can I help you today? Is there something specific you would like to know or discuss? I'm here to answer any questions you might have. [('Hi', \"Hello! How can I help you today? Is there something specific you would like to know or discuss? I'm here to answer any questions you might have.\")]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "print(torch.cuda.memory_summary())\n",
        "torch.cuda.empty_cache()\n",
        "print(torch.cuda.memory_summary())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keAAA3fOU7li",
        "outputId": "8ea661e9-7f73-45ef-80f6-796fd218d5f8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   1826 MiB |   3643 MiB |   7343 MiB |   5517 MiB |\n",
            "|       from large pool |   1799 MiB |   3590 MiB |   5736 MiB |   3936 MiB |\n",
            "|       from small pool |     26 MiB |     53 MiB |   1607 MiB |   1580 MiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   1826 MiB |   3643 MiB |   7343 MiB |   5517 MiB |\n",
            "|       from large pool |   1799 MiB |   3590 MiB |   5736 MiB |   3936 MiB |\n",
            "|       from small pool |     26 MiB |     53 MiB |   1607 MiB |   1580 MiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Requested memory      |   1824 MiB |   3641 MiB |   7315 MiB |   5491 MiB |\n",
            "|       from large pool |   1798 MiB |   3588 MiB |   5718 MiB |   3920 MiB |\n",
            "|       from small pool |     26 MiB |     53 MiB |   1597 MiB |   1571 MiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   3778 MiB |   3778 MiB |   5042 MiB |   1264 MiB |\n",
            "|       from large pool |   3724 MiB |   3724 MiB |   4962 MiB |   1238 MiB |\n",
            "|       from small pool |     54 MiB |     58 MiB |     80 MiB |     26 MiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory | 108145 KiB | 237405 KiB |   4461 MiB |   4355 MiB |\n",
            "|       from large pool |  94464 KiB | 229376 KiB |   2700 MiB |   2608 MiB |\n",
            "|       from small pool |  13681 KiB |  21683 KiB |   1761 MiB |   1747 MiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     705    |    1407    |   93842    |   93137    |\n",
            "|       from large pool |     124    |     247    |     618    |     494    |\n",
            "|       from small pool |     581    |    1160    |   93224    |   92643    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     705    |    1407    |   93842    |   93137    |\n",
            "|       from large pool |     124    |     247    |     618    |     494    |\n",
            "|       from small pool |     581    |    1160    |   93224    |   92643    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      98    |      99    |     144    |      46    |\n",
            "|       from large pool |      71    |      71    |     104    |      33    |\n",
            "|       from small pool |      27    |      29    |      40    |      13    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      53    |      95    |   43983    |   43930    |\n",
            "|       from large pool |      35    |      69    |     326    |     291    |\n",
            "|       from small pool |      18    |      36    |   43657    |   43639    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
            "|===========================================================================|\n",
            "\n",
            "|===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   1826 MiB |   3643 MiB |   7343 MiB |   5517 MiB |\n",
            "|       from large pool |   1799 MiB |   3590 MiB |   5736 MiB |   3936 MiB |\n",
            "|       from small pool |     26 MiB |     53 MiB |   1607 MiB |   1580 MiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   1826 MiB |   3643 MiB |   7343 MiB |   5517 MiB |\n",
            "|       from large pool |   1799 MiB |   3590 MiB |   5736 MiB |   3936 MiB |\n",
            "|       from small pool |     26 MiB |     53 MiB |   1607 MiB |   1580 MiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Requested memory      |   1824 MiB |   3641 MiB |   7315 MiB |   5491 MiB |\n",
            "|       from large pool |   1798 MiB |   3588 MiB |   5718 MiB |   3920 MiB |\n",
            "|       from small pool |     26 MiB |     53 MiB |   1597 MiB |   1571 MiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   1932 MiB |   3778 MiB |   5042 MiB |   3110 MiB |\n",
            "|       from large pool |   1892 MiB |   3724 MiB |   4962 MiB |   3070 MiB |\n",
            "|       from small pool |     40 MiB |     58 MiB |     80 MiB |     40 MiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory | 108145 KiB | 237405 KiB |   4461 MiB |   4355 MiB |\n",
            "|       from large pool |  94464 KiB | 229376 KiB |   2700 MiB |   2608 MiB |\n",
            "|       from small pool |  13681 KiB |  21683 KiB |   1761 MiB |   1747 MiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     705    |    1407    |   93842    |   93137    |\n",
            "|       from large pool |     124    |     247    |     618    |     494    |\n",
            "|       from small pool |     581    |    1160    |   93224    |   92643    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     705    |    1407    |   93842    |   93137    |\n",
            "|       from large pool |     124    |     247    |     618    |     494    |\n",
            "|       from small pool |     581    |    1160    |   93224    |   92643    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      57    |      99    |     144    |      87    |\n",
            "|       from large pool |      37    |      71    |     104    |      67    |\n",
            "|       from small pool |      20    |      29    |      40    |      20    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      53    |      95    |   43983    |   43930    |\n",
            "|       from large pool |      35    |      69    |     326    |     291    |\n",
            "|       from small pool |      18    |      36    |   43657    |   43639    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
            "|===========================================================================|\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KV cache量化\n",
        "\n",
        "https://github.com/QwenLM/Qwen/blob/main/README_CN.md#kv-cache%E9%87%8F%E5%8C%96\n",
        "\n",
        "\n",
        "在模型推理时，我们可以将中间结果key以及value的值量化后压缩存储，这样便可以在相同的卡上存储更多的key以及value，增加样本吞吐。\n",
        "\n",
        "我们在config.json里提供了use_cache_quantization和use_cache_kernel两个参数来控制是否启用KV cache量化，具体使用方法如下：\n",
        "\n"
      ],
      "metadata": {
        "id": "R8VMNwIKSVZ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"Qwen/Qwen-1_8B-Chat\",\n",
        "     device_map=\"auto\",\n",
        "     trust_remote_code=True,\n",
        "     use_cache_quantization=True,\n",
        "     use_cache_kernel=True,\n",
        "     use_flash_attn=False\n",
        ")\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d167de6fcfbc47458774ad929ea3c1f0",
            "352d2d58616248ce95fdf7ad67439086",
            "6d4427f4be7d4611ab81439f19099c1e",
            "e400d1b4ded840c4a887a67c0b8a28dc",
            "79079232fa49471eb49e0133ad96b4dc",
            "4a7b0a19b9494d0d879d266e96977b3f",
            "b4ea205f4a574b348a6904ab186d4e0b",
            "919edfdf181643bdafc335fafaa1e21a",
            "84f3a883c1464738a4df0dd516ac6428",
            "a091b600a1b14820af88827fb0142e78",
            "651bc6bc6fcc49bc98e6905627d52926"
          ]
        },
        "id": "DuMK_PdZSU85",
        "outputId": "134990cc-d1b2-4603-d2ef-91cab77ac0a7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen-1_8B-Chat/snapshots/1d0f68de57b88cfde81f3c3e537f24464d889081/config.json\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen-1_8B-Chat/snapshots/1d0f68de57b88cfde81f3c3e537f24464d889081/config.json\n",
            "Model config QWenConfig {\n",
            "  \"_name_or_path\": \"Qwen/Qwen-1_8B-Chat\",\n",
            "  \"architectures\": [\n",
            "    \"QWenLMHeadModel\"\n",
            "  ],\n",
            "  \"attn_dropout_prob\": 0.0,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"Qwen/Qwen-1_8B-Chat--configuration_qwen.QWenConfig\",\n",
            "    \"AutoModelForCausalLM\": \"Qwen/Qwen-1_8B-Chat--modeling_qwen.QWenLMHeadModel\"\n",
            "  },\n",
            "  \"bf16\": false,\n",
            "  \"emb_dropout_prob\": 0.0,\n",
            "  \"fp16\": false,\n",
            "  \"fp32\": false,\n",
            "  \"hidden_size\": 2048,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 11008,\n",
            "  \"kv_channels\": 128,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"model_type\": \"qwen\",\n",
            "  \"no_bias\": true,\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"onnx_safe\": null,\n",
            "  \"rotary_emb_base\": 10000,\n",
            "  \"rotary_pct\": 1.0,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"seq_length\": 8192,\n",
            "  \"softmax_in_fp32\": false,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"QWenTokenizer\",\n",
            "  \"transformers_version\": \"4.36.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_cache_kernel\": true,\n",
            "  \"use_cache_quantization\": true,\n",
            "  \"use_dynamic_ntk\": true,\n",
            "  \"use_flash_attn\": false,\n",
            "  \"use_logn_attn\": true,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen-1_8B-Chat/snapshots/1d0f68de57b88cfde81f3c3e537f24464d889081/model.safetensors.index.json\n",
            "Generate config GenerationConfig {}\n",
            "\n",
            "WARNING:transformers_modules.Qwen.Qwen-1_8B-Chat.1d0f68de57b88cfde81f3c3e537f24464d889081.modeling_qwen:The model is automatically converting to fp16 for faster inference. If you want to disable the automatic precision, please manually add bf16/fp16/fp32=True to \"AutoModelForCausalLM.from_pretrained\".\n",
            "/root/.cache/huggingface/modules/transformers_modules/Qwen/Qwen-1_8B-Chat/1d0f68de57b88cfde81f3c3e537f24464d889081/modeling_qwen.py:313: UserWarning: KV cache kernel source files (.cpp and .cu) not found.\n",
            "  warnings.warn(\"KV cache kernel source files (.cpp and .cu) not found.\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d167de6fcfbc47458774ad929ea3c1f0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint weights were used when initializing QWenLMHeadModel.\n",
            "\n",
            "All the weights of QWenLMHeadModel were initialized from the model checkpoint at Qwen/Qwen-1_8B-Chat.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use QWenLMHeadModel for predictions without further training.\n",
            "loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen-1_8B-Chat/snapshots/1d0f68de57b88cfde81f3c3e537f24464d889081/generation_config.json\n",
            "Generate config GenerationConfig {\n",
            "  \"chat_format\": \"chatml\",\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 151643,\n",
            "  \"max_new_tokens\": 512,\n",
            "  \"max_window_size\": 6144,\n",
            "  \"pad_token_id\": 151643,\n",
            "  \"repetition_penalty\": 1.1,\n",
            "  \"top_k\": 0,\n",
            "  \"top_p\": 0.8\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QWenLMHeadModel(\n",
            "  (transformer): QWenModel(\n",
            "    (wte): Embedding(151936, 2048)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (rotary_emb): RotaryEmbedding()\n",
            "    (h): ModuleList(\n",
            "      (0-23): 24 x QWenBlock(\n",
            "        (ln_1): RMSNorm()\n",
            "        (attn): QWenAttention(\n",
            "          (c_attn): Linear(in_features=2048, out_features=6144, bias=True)\n",
            "          (c_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
            "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ln_2): RMSNorm()\n",
            "        (mlp): QWenMLP(\n",
            "          (w1): Linear(in_features=2048, out_features=5504, bias=False)\n",
            "          (w2): Linear(in_features=2048, out_features=5504, bias=False)\n",
            "          (c_proj): Linear(in_features=5504, out_features=2048, bias=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ln_f): RMSNorm()\n",
            "  )\n",
            "  (lm_head): Linear(in_features=2048, out_features=151936, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 开启了KV cache量化之后，模型在推理的时候可以开启更大的batch size (bs)。 而不会出现OOM\n",
        "\n",
        "- 开启了KV cache量化之后，模型在推理时可在生成更长的序列（sl，生成的token数）时，节约更多的显存。\n",
        "\n",
        "开启KV cache量化后，模型在推理时会将原始存进layer-past的float格式的key/value转换成int8格式，同时存储量化部分的参数。(Int8 KV Cache的使用对模型整体的精度指标基本无损)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RqoBfd2FWX47"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 推理性能\n"
      ],
      "metadata": {
        "id": "XBlFJgTtSX5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://qianwen-res.oss-cn-beijing.aliyuncs.com/profile.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1G0iAuBfXULs",
        "outputId": "56dac66e-fa71-4ea4-dc4f-1ad0a943980a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-17 15:39:23--  https://qianwen-res.oss-cn-beijing.aliyuncs.com/profile.py\n",
            "Resolving qianwen-res.oss-cn-beijing.aliyuncs.com (qianwen-res.oss-cn-beijing.aliyuncs.com)... 8.131.208.246\n",
            "Connecting to qianwen-res.oss-cn-beijing.aliyuncs.com (qianwen-res.oss-cn-beijing.aliyuncs.com)|8.131.208.246|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3150 (3.1K) [application/octet-stream]\n",
            "Saving to: ‘profile.py’\n",
            "\n",
            "profile.py          100%[===================>]   3.08K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-12-17 15:39:25 (1.09 GB/s) - ‘profile.py’ saved [3150/3150]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat profile.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayQk4ctEXbyA",
        "outputId": "9772fc64-4af0-4282-b20f-ec680fdc110b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# -*- coding: utf-8 -*-\n",
            "# Please pull the latest code to run the profiling.\n",
            "import time\n",
            "import torch\n",
            "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
            "from transformers.generation import GenerationConfig\n",
            "from transformers.trainer_utils import set_seed\n",
            "from tqdm import tqdm\n",
            "\n",
            "seed = 1024\n",
            "max_experiment_times = 1\n",
            "context_length_per_experiment = 1\n",
            "generate_length_per_experiment = 2048\n",
            "# context_length_per_experiment = 1\n",
            "# generate_length_per_experiment = 8192\n",
            "# context_length_per_experiment = 2048\n",
            "# generate_length_per_experiment = 1\n",
            "use_flash_attn = True\n",
            "# fp32 without quantization, bf16 without quantization or int4 quantization (updated on 8.28: we have updated the quantization strategy to AutoGPTQ in this script)\n",
            "quant_type = \"bf16\" # fp32, bf16 or int4\n",
            "\n",
            "set_seed(seed)\n",
            "\n",
            "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen-1_8B-Chat\", trust_remote_code=True)\n",
            "\n",
            "if quant_type == \"bf16\":\n",
            "    model = AutoModelForCausalLM.from_pretrained(\n",
            "        \"Qwen/Qwen-1_8B-Chat\", \n",
            "        device_map=\"cuda:0\", \n",
            "        trust_remote_code=True, \n",
            "        bf16=True, \n",
            "        use_flash_attn=use_flash_attn\n",
            "    ).eval()\n",
            "elif quant_type == \"fp32\":\n",
            "    assert use_flash_attn is False, \"FP32 profiling cannot be performed with Flash-Attention activated.\"\n",
            "    model = AutoModelForCausalLM.from_pretrained(\n",
            "        \"Qwen/Qwen-1_8B-Chat\", \n",
            "        device_map=\"cuda:0\", \n",
            "        trust_remote_code=True, \n",
            "        fp32=True, \n",
            "        use_flash_attn=False\n",
            "    ).eval()    \n",
            "elif quant_type == \"int4\":\n",
            "    # please install AutoGPTQ following the readme to use quantization\n",
            "    from auto_gptq import AutoGPTQForCausalLM\n",
            "    model = AutoGPTQForCausalLM.from_quantized(\n",
            "        \"Qwen/Qwen-1_8B-Chat-Int4\", \n",
            "        device=\"cuda:0\", \n",
            "        trust_remote_code=True, \n",
            "        use_safetensors=True, \n",
            "        use_flash_attn=use_flash_attn\n",
            "    ).eval()\n",
            "\n",
            "# Specify hyperparameters for generation\n",
            "config = GenerationConfig.from_pretrained(\"Qwen/Qwen-1_8B-Chat\", trust_remote_code=True)\n",
            "config.min_length = generate_length_per_experiment + context_length_per_experiment\n",
            "config.max_new_tokens = generate_length_per_experiment\n",
            "\n",
            "time_costs = []\n",
            "context_str = '我' * context_length_per_experiment\n",
            "max_gpu_memory_cost = 0\n",
            "for _ in tqdm(range(max_experiment_times)):\n",
            "    inputs = tokenizer(context_str, return_tensors='pt')\n",
            "    inputs = inputs.to(model.device)\n",
            "    t1 = time.time()\n",
            "    pred = model.generate(**inputs, generation_config=config)\n",
            "    time_costs.append(time.time() - t1)\n",
            "    assert pred.shape[1] == config.min_length\n",
            "    max_gpu_memory_cost = max(max_gpu_memory_cost, torch.cuda.max_memory_allocated())\n",
            "    torch.cuda.empty_cache()\n",
            "\n",
            "print(\"Average generate speed (tokens/s): {}\".format((max_experiment_times * generate_length_per_experiment) / sum(time_costs)))\n",
            "print(f\"GPU Memory cost: {max_gpu_memory_cost / 1024 / 1024 / 1024}GB\")\n",
            "print(\"Experiment setting: \")\n",
            "print(f\"seed = {seed}\")\n",
            "print(f\"max_experiment_times = {max_experiment_times}\")\n",
            "print(f\"context_length_per_experiment = {context_length_per_experiment}\")\n",
            "print(f\"generate_length_per_experiment = {generate_length_per_experiment}\")\n",
            "print(f\"use_flash_attn = {use_flash_attn}\")\n",
            "print(f\"quant_type = {quant_type}\")"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U transformers\n",
        "!pip install -U accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnfkM4IeZw3h",
        "outputId": "f98118db-933e-4c25-f774-3e07261946f8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.36.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.25.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.19.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list | grep transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rp3PIJtLaPDW",
        "outputId": "b8062974-ca6a-475d-8637-dc766a5b6347"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "transformers                     4.36.1\n",
            "transformers-stream-generator    0.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python profile.py"
      ],
      "metadata": {
        "id": "E6ncwsCJYUNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 微调\n",
        "\n",
        "我们提供了finetune.py这个脚本供用户实现在自己的数据上进行微调的功能，以接入下游任务。此外，我们还提供了shell脚本减少用户的工作量。这个脚本支持 [**DeepSpeed**](https://github.com/microsoft/DeepSpeed) 和 [**FSDP**](https://engineering.fb.com/2021/07/15/open-source/fsdp/) 。我们提供的shell脚本使用了DeepSpeed，因此建议您确保已经安装DeepSpeed和Peft（注意：DeepSpeed可能不兼容最新的pydantic版本，请确保pydantic<2.0）。你可以使用如下命令安装：\n",
        "\n"
      ],
      "metadata": {
        "id": "G4R6PbW4Sbef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install peft deepspeed\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C46DpqDoa5_Q",
        "outputId": "e6302ad2-4391-4a0e-e0dd-68f598643a24"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting peft\n",
            "  Downloading peft-0.7.1-py3-none-any.whl (168 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/168.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m153.6/168.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.3/168.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting deepspeed\n",
            "  Downloading deepspeed-0.12.5.tar.gz (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.1.0+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.36.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.25.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.19.4)\n",
            "Collecting hjson (from deepspeed)\n",
            "  Downloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from deepspeed) (1.11.1.1)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from deepspeed) (9.0.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from deepspeed) (1.10.13)\n",
            "Collecting pynvml (from deepspeed)\n",
            "  Downloading pynvml-11.5.0-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
            "Building wheels for collected packages: deepspeed\n",
            "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepspeed: filename=deepspeed-0.12.5-py3-none-any.whl size=1297451 sha256=6fac5d7c408038d9838867eee5bc47c2e7b9cb33b63348e1af36f832d18e9e88\n",
            "  Stored in directory: /root/.cache/pip/wheels/7d/4e/ca/24e93c09d21013b572826feb20cbef59b599f3d617bf075038\n",
            "Successfully built deepspeed\n",
            "Installing collected packages: hjson, pynvml, deepspeed, peft\n",
            "Successfully installed deepspeed-0.12.5 hjson-3.1.0 peft-0.7.1 pynvml-11.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 部署"
      ],
      "metadata": {
        "id": "sntCctM-jqOP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## vllm"
      ],
      "metadata": {
        "id": "b4cRA2OLj72d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "# pip install vllm  # 该方法安装较快，但官方版本不支持量化模型\n",
        "\n",
        "# 下面方法支持int4量化 (int8量化模型支持将近期更新)，但安装更慢 (约~10分钟)。\n",
        "git clone https://github.com/QwenLM/vllm-gptq\n",
        "cd vllm-gptq\n",
        "pip install -e .\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Q8kyhBGj-JG",
        "outputId": "b2d581b8-75fa-4d66-898f-3ab9c5f69960"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/vllm-gptq\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Checking if build backend supports build_editable: started\n",
            "  Checking if build backend supports build_editable: finished with status 'done'\n",
            "  Getting requirements to build editable: started\n",
            "  Getting requirements to build editable: finished with status 'done'\n",
            "  Preparing editable metadata (pyproject.toml): started\n",
            "  Preparing editable metadata (pyproject.toml): finished with status 'done'\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from vllm==0.2.2+cu122) (1.11.1.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from vllm==0.2.2+cu122) (5.9.5)\n",
            "Collecting ray>=2.5.1 (from vllm==0.2.2+cu122)\n",
            "  Downloading ray-2.8.1-cp310-cp310-manylinux2014_x86_64.whl (62.6 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.6/62.6 MB 23.3 MB/s eta 0:00:00\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from vllm==0.2.2+cu122) (1.5.3)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from vllm==0.2.2+cu122) (10.0.1)\n",
            "Collecting sentencepiece (from vllm==0.2.2+cu122)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 53.3 MB/s eta 0:00:00\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from vllm==0.2.2+cu122) (1.23.5)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from vllm==0.2.2+cu122) (0.7.0)\n",
            "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from vllm==0.2.2+cu122) (2.1.0+cu121)\n",
            "Requirement already satisfied: transformers>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from vllm==0.2.2+cu122) (4.36.1)\n",
            "Collecting xformers>=0.0.22.post7 (from vllm==0.2.2+cu122)\n",
            "  Downloading xformers-0.0.23.post1-cp310-cp310-manylinux2014_x86_64.whl (213.0 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 213.0/213.0 MB 3.6 MB/s eta 0:00:00\n",
            "Collecting fastapi (from vllm==0.2.2+cu122)\n",
            "  Downloading fastapi-0.105.0-py3-none-any.whl (93 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 93.1/93.1 kB 11.1 MB/s eta 0:00:00\n",
            "Collecting uvicorn[standard] (from vllm==0.2.2+cu122)\n",
            "  Downloading uvicorn-0.24.0.post1-py3-none-any.whl (59 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 59.7/59.7 kB 9.0 MB/s eta 0:00:00\n",
            "Requirement already satisfied: pydantic==1.10.13 in /usr/local/lib/python3.10/dist-packages (from vllm==0.2.2+cu122) (1.10.13)\n",
            "Collecting auto-gptq (from vllm==0.2.2+cu122)\n",
            "  Downloading auto_gptq-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.8/4.8 MB 93.1 MB/s eta 0:00:00\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic==1.10.13->vllm==0.2.2+cu122) (4.5.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray>=2.5.1->vllm==0.2.2+cu122) (8.1.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray>=2.5.1->vllm==0.2.2+cu122) (3.13.1)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray>=2.5.1->vllm==0.2.2+cu122) (4.19.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray>=2.5.1->vllm==0.2.2+cu122) (1.0.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ray>=2.5.1->vllm==0.2.2+cu122) (23.2)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray>=2.5.1->vllm==0.2.2+cu122) (3.20.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from ray>=2.5.1->vllm==0.2.2+cu122) (6.0.1)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray>=2.5.1->vllm==0.2.2+cu122) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray>=2.5.1->vllm==0.2.2+cu122) (1.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray>=2.5.1->vllm==0.2.2+cu122) (2.31.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->vllm==0.2.2+cu122) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->vllm==0.2.2+cu122) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->vllm==0.2.2+cu122) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->vllm==0.2.2+cu122) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->vllm==0.2.2+cu122) (2.1.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.34.0->vllm==0.2.2+cu122) (0.19.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.34.0->vllm==0.2.2+cu122) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.34.0->vllm==0.2.2+cu122) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.34.0->vllm==0.2.2+cu122) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.34.0->vllm==0.2.2+cu122) (4.66.1)\n",
            "Collecting torch>=2.1.0 (from vllm==0.2.2+cu122)\n",
            "  Using cached torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2.1.0->vllm==0.2.2+cu122)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2.1.0->vllm==0.2.2+cu122)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2.1.0->vllm==0.2.2+cu122)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2.1.0->vllm==0.2.2+cu122)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2.1.0->vllm==0.2.2+cu122)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2.1.0->vllm==0.2.2+cu122)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=2.1.0->vllm==0.2.2+cu122)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2.1.0->vllm==0.2.2+cu122)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2.1.0->vllm==0.2.2+cu122)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.18.1 (from torch>=2.1.0->vllm==0.2.2+cu122)\n",
            "  Using cached nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=2.1.0->vllm==0.2.2+cu122)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.1.0->vllm==0.2.2+cu122)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\n",
            "Requirement already satisfied: accelerate>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from auto-gptq->vllm==0.2.2+cu122) (0.25.0)\n",
            "Collecting datasets (from auto-gptq->vllm==0.2.2+cu122)\n",
            "  Downloading datasets-2.15.0-py3-none-any.whl (521 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 521.2/521.2 kB 51.6 MB/s eta 0:00:00\n",
            "Collecting rouge (from auto-gptq->vllm==0.2.2+cu122)\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Collecting gekko (from auto-gptq->vllm==0.2.2+cu122)\n",
            "  Downloading gekko-1.0.6-py3-none-any.whl (12.2 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.2/12.2 MB 101.7 MB/s eta 0:00:00\n",
            "Requirement already satisfied: peft>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from auto-gptq->vllm==0.2.2+cu122) (0.7.1)\n",
            "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi->vllm==0.2.2+cu122) (3.7.1)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi->vllm==0.2.2+cu122)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.0/67.0 kB 9.6 MB/s eta 0:00:00\n",
            "Collecting typing-extensions>=4.2.0 (from pydantic==1.10.13->vllm==0.2.2+cu122)\n",
            "  Using cached typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->vllm==0.2.2+cu122) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->vllm==0.2.2+cu122) (2023.3.post1)\n",
            "Collecting h11>=0.8 (from uvicorn[standard]->vllm==0.2.2+cu122)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.3/58.3 kB 8.6 MB/s eta 0:00:00\n",
            "Collecting httptools>=0.5.0 (from uvicorn[standard]->vllm==0.2.2+cu122)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 341.4/341.4 kB 38.8 MB/s eta 0:00:00\n",
            "Collecting python-dotenv>=0.13 (from uvicorn[standard]->vllm==0.2.2+cu122)\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]->vllm==0.2.2+cu122)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.4/3.4 MB 104.8 MB/s eta 0:00:00\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]->vllm==0.2.2+cu122)\n",
            "  Downloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 82.9 MB/s eta 0:00:00\n",
            "Collecting websockets>=10.4 (from uvicorn[standard]->vllm==0.2.2+cu122)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 130.2/130.2 kB 19.4 MB/s eta 0:00:00\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi->vllm==0.2.2+cu122) (3.6)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi->vllm==0.2.2+cu122) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi->vllm==0.2.2+cu122) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->vllm==0.2.2+cu122) (1.16.0)\n",
            "Collecting pyarrow-hotfix (from datasets->auto-gptq->vllm==0.2.2+cu122)\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets->auto-gptq->vllm==0.2.2+cu122)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 115.3/115.3 kB 17.6 MB/s eta 0:00:00\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq->vllm==0.2.2+cu122) (3.4.1)\n",
            "Collecting multiprocess (from datasets->auto-gptq->vllm==0.2.2+cu122)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.8/134.8 kB 19.1 MB/s eta 0:00:00\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq->vllm==0.2.2+cu122) (3.9.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ray>=2.5.1->vllm==0.2.2+cu122) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ray>=2.5.1->vllm==0.2.2+cu122) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray>=2.5.1->vllm==0.2.2+cu122) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.1.0->vllm==0.2.2+cu122) (2.1.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray>=2.5.1->vllm==0.2.2+cu122) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray>=2.5.1->vllm==0.2.2+cu122) (2023.11.2)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray>=2.5.1->vllm==0.2.2+cu122) (0.32.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray>=2.5.1->vllm==0.2.2+cu122) (0.13.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.1.0->vllm==0.2.2+cu122) (1.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq->vllm==0.2.2+cu122) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq->vllm==0.2.2+cu122) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq->vllm==0.2.2+cu122) (4.0.3)\n",
            "Building wheels for collected packages: vllm\n",
            "  Building editable for vllm (pyproject.toml): started\n",
            "  Building editable for vllm (pyproject.toml): finished with status 'done'\n",
            "  Created wheel for vllm: filename=vllm-0.2.2+cu122-0.editable-cp310-cp310-linux_x86_64.whl size=9945 sha256=dc2f1e11b0613c4ee45457388d08d2a5cea7f4d684ab8244b7df7347ee7fabfa\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-iyuw5o6p/wheels/69/cd/5f/f3c4a3d66e6c7a1be3c75d6a7b962e1c8989a2fdd47fcb83b5\n",
            "Successfully built vllm\n",
            "Installing collected packages: sentencepiece, websockets, uvloop, typing-extensions, rouge, python-dotenv, pyarrow-hotfix, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, httptools, h11, gekko, dill, watchfiles, uvicorn, starlette, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, nvidia-cusolver-cu12, fastapi, torch, ray, datasets, xformers, auto-gptq, vllm\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.0+cu121\n",
            "    Uninstalling torch-2.1.0+cu121:\n",
            "      Successfully uninstalled torch-2.1.0+cu121\n",
            "Successfully installed auto-gptq-0.6.0 datasets-2.15.0 dill-0.3.7 fastapi-0.105.0 gekko-1.0.6 h11-0.14.0 httptools-0.6.1 multiprocess-0.70.15 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.3.101 nvidia-nvtx-cu12-12.1.105 pyarrow-hotfix-0.6 python-dotenv-1.0.0 ray-2.8.1 rouge-1.0.1 sentencepiece-0.1.99 starlette-0.27.0 torch-2.1.2 typing-extensions-4.9.0 uvicorn-0.24.0.post1 uvloop-0.19.0 vllm-0.2.2+cu122 watchfiles-0.21.0 websockets-12.0 xformers-0.0.23.post1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Cloning into 'vllm-gptq'...\n",
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\n",
            "torchaudio 2.1.0+cu121 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\n",
            "torchvision 0.16.0+cu121 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# vLLM + 类Transformer接口\n",
        "\n",
        "import sys\n",
        "sys.path.append('./Qwen/examples')\n",
        "\n",
        "from vllm_wrapper import vLLMWrapper\n",
        "\n",
        "model = vLLMWrapper('Qwen/Qwen-1_8B-Chat', tensor_parallel_size=1)\n",
        "\n",
        "response, history = model.chat(query=\"你好\", history=None)\n",
        "print(response)\n",
        "response, history = model.chat(query=\"给我讲一个年轻人奋斗创业最终取得成功的故事。\", history=history)\n",
        "print(response)\n",
        "response, history = model.chat(query=\"给这个故事起一个标题\", history=history)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "t5vgie-YkjWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#vLLM + 网页Demo / 类OpenAI API\n",
        "\n",
        "!pip install \"fschat[model_worker,webui]\"\n"
      ],
      "metadata": {
        "id": "n70i4jlSlZa0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#使用vLLM和FastChat运行Qwen之前，首先启动一个controller：\n",
        "\n",
        "\n",
        "!python -m fastchat.serve.controller\n"
      ],
      "metadata": {
        "id": "0_7tBkRoljb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 然后启动model worker读取模型。如使用单卡推理，运行如下命令：\n",
        "\n",
        "!python -m fastchat.serve.vllm_worker --model-path $model_path --trust-remote-code --dtype bfloat16\n",
        "# python -m fastchat.serve.vllm_worker --model-path $model_path --trust-remote-code --dtype float16 # 运行int4模型\n"
      ],
      "metadata": {
        "id": "U3bcjVGslvvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Web UI Demo\n",
        "\n",
        "!python -m fastchat.serve.gradio_web_server\n"
      ],
      "metadata": {
        "id": "li5mxtOHmOvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🔥 系统指令 (System Prompt)\n",
        "Qwen-1.8-Chat 和 Qwen-72B-Chat 通义千问在多样且存在多轮复杂交互的系统指令上进行了充分训练，使模型可以跟随多样的系统指令，实现上下文(in-context)中的模型定制化，进一步提升了通义千问的可扩展性。\n",
        "\n",
        "通过系统指令，Qwen-Chat能够实现角色扮演，语言风格迁移，任务设定，和行为设定等能力agents。\n",
        "\n",
        "\n",
        "\n",
        "- https://github.com/QwenLM/Qwen/blob/main/examples/system_prompt.md\n",
        "\n"
      ],
      "metadata": {
        "id": "xWixFxzom3MC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "icBkaSaHm6ts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 工具调用\n",
        "https://github.com/QwenLM/Qwen/blob/main/README_CN.md#%E5%B7%A5%E5%85%B7%E8%B0%83%E7%94%A8\n",
        "\n",
        "\n",
        "Qwen-Chat针对工具使用、函数调用能力进行了优化。用户可以开发基于Qwen的Agent、LangChain应用、甚至Code Interpreter。\n",
        "\n",
        "为了考察Qwen使用Python Code Interpreter完成数学解题、数据可视化、及文件处理与爬虫等任务的能力，我们专门建设并开源了一个评测这方面能力的评测基准。 我们发现Qwen在生成代码的可执行率、结果正确性上均表现较好：\n",
        "\n",
        "\n",
        "- https://github.com/QwenLM/Qwen/blob/main/examples/react_prompt.md\n",
        "- https://github.com/QwenLM/Qwen-Agent/tree/main/benchmark\n"
      ],
      "metadata": {
        "id": "cdnXa3YFnS16"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 模型评估复现\n",
        "\n",
        "- https://github.com/QwenLM/Qwen/blob/main/eval/EVALUATION.md"
      ],
      "metadata": {
        "id": "iTm7me0joWJC"
      }
    }
  ]
}