{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOsxXjNVywYuUlTX5jbVgJw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weedge/doraemon-nb/blob/main/achatbot_daily_chat_tools_vision_bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTOZMjbnUZyM"
      },
      "outputs": [],
      "source": [
        "!cd /content && rm -rf achatbot && git clone --recursive https://github.com/ai-bot-pro/achatbot.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/achatbot"
      ],
      "metadata": {
        "id": "jj-NSzY1U_p7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!bash scripts/pypi_achatbot.sh dev"
      ],
      "metadata": {
        "id": "nesIRk-jVKsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q \"dist/achatbot-0.0.7.2-py3-none-any.whl[daily_room_audio_stream,livekit,livekit-api,sense_voice_asr,deepgram_asr_processor,llm_transformers_manual_vision,tts_edge,openai,queue]\""
      ],
      "metadata": {
        "id": "1U0Zy_vGVUPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli download FunAudioLLM/SenseVoiceSmall  --local-dir ./models/FunAudioLLM/SenseVoiceSmall --local-dir-use-symlinks False"
      ],
      "metadata": {
        "id": "4--WNqx8VpUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli download Qwen/Qwen2-VL-2B-Instruct --local-dir ./models/Qwen/Qwen2-VL-2B-Instruct --local-dir-use-symlinks False"
      ],
      "metadata": {
        "id": "QNh_N0AeVsmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhPOa8RBb0dS"
      },
      "source": [
        "run bot task woker with bot.json, e.g.: dummy_bot.json\n",
        "\n",
        "- use daily/livekit room stream, u can click bot joined the room url, to start chat with bot with audio and camera stream,\n",
        "  - [daily](https://www.daily.co/) need DAILY_API_KEY\n",
        "  - [livekit](https://livekit.io/) need project url LIVEKIT_URL, LIVEKIT_API_KEY, LIVEKIT_API_SECRET\n",
        "- use deepgram api asr model need api key\n",
        "  - [deepgram](https://deepgram.com/) DEEPGRAM_API_KEY\n",
        "- use openai/groq/together.ai api llm model need api key\n",
        "  - [openai](https://openai.com/) OPENAI_API_KEY\n",
        "  - [groq](https://groq.com/) GROQ_API_KEY\n",
        "  - [together.ai](https://www.together.ai/) TOGETHER_API_KEY\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "DAILY_API_KEY=userdata.get('DAILY_API_KEY')\n",
        "\n",
        "LIVEKIT_URL=userdata.get('LIVEKIT_URL')\n",
        "LIVEKIT_API_KEY=userdata.get('LIVEKIT_API_KEY')\n",
        "LIVEKIT_API_SECRET=userdata.get('LIVEKIT_API_SECRET')\n",
        "\n",
        "TOGETHER_API_KEY=userdata.get('TOGETHER_API_KEY')\n",
        "GROQ_API_KEY=userdata.get('GROQ_API_KEY')\n",
        "\n",
        "\n",
        "DEEPGRAM_API_KEY=userdata.get('DEEPGRAM_API_KEY')\n"
      ],
      "metadata": {
        "id": "uXIAi2IYUkcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /content/daily_chat_tools_vision_bot.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXhRNOaA6Miw",
        "outputId": "cad67535-776f-483f-8895-f3a22dcf5147"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"chat_bot_name\": \"DailyChatToolsVisionBot\",\n",
            "  \"room_name\": \"chat-room\",\n",
            "  \"room_url\": \"\",\n",
            "  \"token\": \"\",\n",
            "  \"services\": {\n",
            "    \"pipeline\": \"achatbot\",\n",
            "    \"vad\": \"silero\",\n",
            "    \"asr\": \"sense_voice\",\n",
            "    \"llm\": \"groq\",\n",
            "    \"vision_llm\": \"transformers_manual_vision_qwen\",\n",
            "    \"tts\": \"edge\"\n",
            "  },\n",
            "  \"config\": {\n",
            "    \"vad\": {\n",
            "      \"tag\": \"silero_vad_analyzer\",\n",
            "      \"args\": { \"stop_secs\": 0.7 }\n",
            "    },\n",
            "    \"asr\": {\n",
            "      \"tag\": \"deepgram_asr_processor\",\n",
            "      \"args\": {\n",
            "        \"language\": \"zh\",\n",
            "        \"model\": \"nova-2\"\n",
            "      }\n",
            "    },\n",
            "    \"llm\": {\n",
            "      \"tag\": \"openai_llm_processor\",\n",
            "      \"base_url\": \"https://api.groq.com/openai/v1\",\n",
            "      \"model\": \"llama3-groq-70b-8192-tool-use-preview\",\n",
            "      \"language\": \"zh\",\n",
            "      \"messages\": [\n",
            "        {\n",
            "          \"role\": \"system\",\n",
            "          \"content\": \"You are a helpful assistant who converses with a user and answers questions. Respond concisely to general questions.  Your response will be turned into speech so use only simple words and punctuation.\\n  You have access to two tools: get_weather and describe_image.  You can respond to questions about the weather using the get_weather tool.\\n  You can answer questions about the user's video stream using the describe_image tool.\\n Some examples of phrases that indicate you should use the describe_image tool are: \\n - What do you see?  \\n - What's in the video? \\n - Can you describe the video?\\n - Tell me about what you see.\\n  - Tell me something interesting about what you see.\\n  - What's happening in the video?\\n  If you need to use a tool, simply use the tool. Do not tell the user the tool you are using. Be brief and concise.\\n Please communicate in Chinese\"\n",
            "        }\n",
            "      ],\n",
            "      \"tools\": [\n",
            "        {\n",
            "          \"type\": \"function\",\n",
            "          \"function\": {\n",
            "            \"name\": \"get_weather\",\n",
            "            \"description\": \"Get the current weather in a given location\",\n",
            "            \"parameters\": {\n",
            "              \"type\": \"object\",\n",
            "              \"properties\": {\n",
            "                \"location\": {\n",
            "                  \"type\": \"string\",\n",
            "                  \"description\": \"The city and state, e.g. San Francisco, CA\"\n",
            "                }\n",
            "              },\n",
            "              \"required\": [\"location\"]\n",
            "            }\n",
            "          }\n",
            "        },\n",
            "        {\n",
            "          \"type\": \"function\",\n",
            "          \"function\": {\n",
            "            \"name\": \"describe_image\",\n",
            "            \"description\": \"describe an image from the video stream\",\n",
            "            \"input_schema\": {\n",
            "              \"type\": \"object\",\n",
            "              \"properties\": {\n",
            "                \"question\": {\n",
            "                  \"type\": \"string\",\n",
            "                  \"description\": \"the question is `describe image` from the video stream\"\n",
            "                }\n",
            "              },\n",
            "              \"required\": [\"question\"]\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "      ]\n",
            "    },\n",
            "    \"vision_llm\": {\n",
            "      \"tag\": \"llm_transformers_manual_vision_qwen\",\n",
            "      \"args\": {\n",
            "        \"lm_device\": \"cuda\",\n",
            "        \"lm_model_name_or_path\": \"./models/Qwen/Qwen2-VL-2B-Instruct\",\n",
            "        \"chat_history_size\": 0,\n",
            "        \"init_chat_prompt\": \"请用中文交流\",\n",
            "        \"model_type\": \"chat_completion\"\n",
            "      },\n",
            "      \"language\": \"zh\"\n",
            "    },\n",
            "    \"tts\": {\n",
            "      \"tag\": \"tts_edge\",\n",
            "      \"args\": {\n",
            "        \"voice_name\": \"zh-CN-YunjianNeural\",\n",
            "        \"language\": \"zh\",\n",
            "        \"gender\": \"Male\"\n",
            "      }\n",
            "    }\n",
            "  },\n",
            "  \"config_list\": []\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NKB146E-b9s_"
      },
      "outputs": [],
      "source": [
        "!DAILY_API_KEY=$DAILY_API_KEY GROQ_API_KEY=$GROQ_API_KEY DEEPGRAM_API_KEY=$DEEPGRAM_API_KEY \\\n",
        "  python -m src.cmd.bots.main -f /content/daily_chat_tools_vision_bot.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /content/livekit_chat_tools_vision_bot.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtOiBvvE6nBv",
        "outputId": "b0b881ee-0ab6-491f-e140-b8430a626318"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"chat_bot_name\": \"LivekitChatToolsVisionBot\",\n",
            "  \"room_name\": \"chat-room\",\n",
            "  \"room_url\": \"\",\n",
            "  \"token\": \"\",\n",
            "  \"room_manager\": {\n",
            "    \"tag\": \"livekit_room\",\n",
            "    \"args\": {\n",
            "      \"bot_name\": \"LivekitChatToolsVisionBot\",\n",
            "      \"is_common_session\": false\n",
            "    }\n",
            "  },\n",
            "  \"services\": {\n",
            "    \"pipeline\": \"achatbot\",\n",
            "    \"vad\": \"silero\",\n",
            "    \"asr\": \"sense_voice\",\n",
            "    \"llm\": \"groq\",\n",
            "    \"vision_llm\": \"transformers_manual_vision_qwen\",\n",
            "    \"tts\": \"edge\"\n",
            "  },\n",
            "  \"config\": {\n",
            "    \"vad\": {\n",
            "      \"tag\": \"silero_vad_analyzer\",\n",
            "      \"args\": { \"stop_secs\": 0.7 }\n",
            "    },\n",
            "    \"asr\": {\n",
            "      \"tag\": \"sense_voice_asr\",\n",
            "      \"args\": {\n",
            "        \"language\": \"zn\",\n",
            "        \"model_name_or_path\": \"./models/FunAudioLLM/SenseVoiceSmall\"\n",
            "      }\n",
            "    },\n",
            "    \"llm\": {\n",
            "      \"tag\": \"openai_llm_processor\",\n",
            "      \"base_url\": \"https://api.together.xyz/v1\",\n",
            "      \"model\": \"meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo\",\n",
            "      \"language\": \"zh\",\n",
            "      \"messages\": [\n",
            "        {\n",
            "          \"role\": \"system\",\n",
            "          \"content\": \"You are a helpful assistant who converses with a user and answers questions. Respond concisely to general questions.  Your response will be turned into speech so use only simple words and punctuation.\\n  You have access to two tools: get_weather and describe_image.  You can respond to questions about the weather using the get_weather tool.\\n  You can answer questions about the user's video stream using the describe_image tool.\\n Some examples of phrases that indicate you should use the describe_image tool are: \\n - What do you see?  \\n - What's in the video? \\n - Can you describe the video?\\n - Tell me about what you see.\\n  - Tell me something interesting about what you see.\\n  - What's happening in the video?\\n  If you need to use a tool, simply use the tool. Do not tell the user the tool you are using. Be brief and concise.\\n Please communicate in Chinese\"\n",
            "        }\n",
            "      ],\n",
            "      \"tools\": [\n",
            "        {\n",
            "          \"type\": \"function\",\n",
            "          \"function\": {\n",
            "            \"name\": \"get_weather\",\n",
            "            \"description\": \"Get the current weather in a given location\",\n",
            "            \"parameters\": {\n",
            "              \"type\": \"object\",\n",
            "              \"properties\": {\n",
            "                \"location\": {\n",
            "                  \"type\": \"string\",\n",
            "                  \"description\": \"The city and state, e.g. San Francisco, CA\"\n",
            "                }\n",
            "              },\n",
            "              \"required\": [\"location\"]\n",
            "            }\n",
            "          }\n",
            "        },\n",
            "        {\n",
            "          \"type\": \"function\",\n",
            "          \"function\": {\n",
            "            \"name\": \"describe_image\",\n",
            "            \"description\": \"describe an image from the video stream\",\n",
            "            \"input_schema\": {\n",
            "              \"type\": \"object\",\n",
            "              \"properties\": {\n",
            "                \"question\": {\n",
            "                  \"type\": \"string\",\n",
            "                  \"description\": \"the question is `describe image` from the video stream\"\n",
            "                }\n",
            "              },\n",
            "              \"required\": [\"question\"]\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "      ]\n",
            "    },\n",
            "    \"vision_llm\": {\n",
            "      \"tag\": \"llm_transformers_manual_vision_qwen\",\n",
            "      \"args\": {\n",
            "        \"lm_device\": \"cuda\",\n",
            "        \"lm_model_name_or_path\": \"./models/Qwen/Qwen2-VL-2B-Instruct\",\n",
            "        \"chat_history_size\": 0,\n",
            "        \"init_chat_prompt\": \"请用中文交流\",\n",
            "        \"model_type\": \"chat_completion\"\n",
            "      },\n",
            "      \"language\": \"zh\"\n",
            "    },\n",
            "    \"tts\": {\n",
            "      \"tag\": \"tts_edge\",\n",
            "      \"args\": {\n",
            "        \"voice_name\": \"zh-CN-YunjianNeural\",\n",
            "        \"language\": \"zh\",\n",
            "        \"gender\": \"Male\"\n",
            "      }\n",
            "    }\n",
            "  },\n",
            "  \"config_list\": []\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!TOGETHER_API_KEY=$TOGETHER_API_KEY LIVEKIT_URL=$LIVEKIT_URL LIVEKIT_API_KEY=$LIVEKIT_API_KEY LIVEKIT_API_SECRET=$LIVEKIT_API_SECRET \\\n",
        "  python -m src.cmd.bots.main -f /content/livekit_chat_tools_vision_bot.json"
      ],
      "metadata": {
        "id": "Bvn9i6Dx6l_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6EiEKxtbqVT"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "REDIS_PASSWORD=userdata.get('REDIS_PASSWORD')\n",
        "#print(REDIS_PASSWORD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FzqIIMQ9boPX"
      },
      "outputs": [],
      "source": [
        "!LOG_LEVEL=debug REDIS_PASSWORD=$REDIS_PASSWORD python -m src.cmd.bots.main -f /content/task_bot.json"
      ]
    }
  ]
}