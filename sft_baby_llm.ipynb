{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMKnoW9EKNwvSKnuf4BvjcZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8908ce4573974a2a8600b4a371342714": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fd5405520254406f839d44f9d22fb278",
              "IPY_MODEL_3118edb3b6ef4346819c9d0720613fe7",
              "IPY_MODEL_c35391111a2b4042a8406dea97af4988"
            ],
            "layout": "IPY_MODEL_77e5ba56111044aa810dece9c70d0597"
          }
        },
        "fd5405520254406f839d44f9d22fb278": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8242c55f7324dd3804fbe15870b29f6",
            "placeholder": "​",
            "style": "IPY_MODEL_b9e7efc8cdb341faba00e55f6003df80",
            "value": "Generating train split: "
          }
        },
        "3118edb3b6ef4346819c9d0720613fe7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4449f82383d74050a39a7188638a5339",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ffdcced6b14e42f883846d790d2e7670",
            "value": 1
          }
        },
        "c35391111a2b4042a8406dea97af4988": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1194042abdbc4c708d4345cca4dde604",
            "placeholder": "​",
            "style": "IPY_MODEL_e189ddcf03c0474a9d934cd70cc27f2a",
            "value": " 254547/0 [00:08&lt;00:00, 32239.41 examples/s]"
          }
        },
        "77e5ba56111044aa810dece9c70d0597": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8242c55f7324dd3804fbe15870b29f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9e7efc8cdb341faba00e55f6003df80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4449f82383d74050a39a7188638a5339": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "ffdcced6b14e42f883846d790d2e7670": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1194042abdbc4c708d4345cca4dde604": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e189ddcf03c0474a9d934cd70cc27f2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weedge/doraemon-nb/blob/main/sft_baby_llm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4__g4MnPbUg",
        "outputId": "756cb294-2fe9-4c2c-9593-fea0221a7e28"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: \n",
            "Add token as git credential? (Y/n) y\n",
            "Token is valid (permission: write).\n",
            "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
            "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
            "\n",
            "git config --global credential.helper store\n",
            "\n",
            "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
            "Token has not been saved to git credential helper.\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/DLLXW/baby-llama2-chinese.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VYdkXZp513t",
        "outputId": "97cf3db1-2313-403c-e13a-9e4f842d23b6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'baby-llama2-chinese'...\n",
            "remote: Enumerating objects: 162, done.\u001b[K\n",
            "remote: Counting objects: 100% (95/95), done.\u001b[K\n",
            "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
            "remote: Total 162 (delta 62), reused 57 (delta 57), pack-reused 67\u001b[K\n",
            "Receiving objects: 100% (162/162), 1.01 MiB | 15.46 MiB/s, done.\n",
            "Resolving deltas: 100% (86/86), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r  baby-llama2-chinese/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lWw_H0RB63Ly",
        "outputId": "315318ed-01f8-4e4c-f7ed-9eb7a44dbb1e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.23.5 (from -r baby-llama2-chinese/requirements.txt (line 1))\n",
            "  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytest==7.4.0 (from -r baby-llama2-chinese/requirements.txt (line 2))\n",
            "  Downloading pytest-7.4.0-py3-none-any.whl (323 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.6/323.6 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Requests==2.31.0 in /usr/local/lib/python3.10/dist-packages (from -r baby-llama2-chinese/requirements.txt (line 3)) (2.31.0)\n",
            "Requirement already satisfied: sentencepiece==0.1.99 in /usr/local/lib/python3.10/dist-packages (from -r baby-llama2-chinese/requirements.txt (line 4)) (0.1.99)\n",
            "Collecting torch==2.0.1 (from -r baby-llama2-chinese/requirements.txt (line 5))\n",
            "  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn==1.3.0 (from -r baby-llama2-chinese/requirements.txt (line 6))\n",
            "  Downloading scikit_learn-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m95.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm==4.64.1 (from -r baby-llama2-chinese/requirements.txt (line 7))\n",
            "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from -r baby-llama2-chinese/requirements.txt (line 8)) (0.42.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r baby-llama2-chinese/requirements.txt (line 9)) (1.5.3)\n",
            "Collecting transformers==4.33.2 (from -r baby-llama2-chinese/requirements.txt (line 10))\n",
            "  Downloading transformers-4.33.2-py3-none-any.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m117.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest==7.4.0->-r baby-llama2-chinese/requirements.txt (line 2)) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest==7.4.0->-r baby-llama2-chinese/requirements.txt (line 2)) (24.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest==7.4.0->-r baby-llama2-chinese/requirements.txt (line 2)) (1.4.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest==7.4.0->-r baby-llama2-chinese/requirements.txt (line 2)) (1.2.0)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest==7.4.0->-r baby-llama2-chinese/requirements.txt (line 2)) (2.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from Requests==2.31.0->-r baby-llama2-chinese/requirements.txt (line 3)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from Requests==2.31.0->-r baby-llama2-chinese/requirements.txt (line 3)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from Requests==2.31.0->-r baby-llama2-chinese/requirements.txt (line 3)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from Requests==2.31.0->-r baby-llama2-chinese/requirements.txt (line 3)) (2024.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r baby-llama2-chinese/requirements.txt (line 5)) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r baby-llama2-chinese/requirements.txt (line 5)) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r baby-llama2-chinese/requirements.txt (line 5)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r baby-llama2-chinese/requirements.txt (line 5)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r baby-llama2-chinese/requirements.txt (line 5)) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.1->-r baby-llama2-chinese/requirements.txt (line 5))\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.1->-r baby-llama2-chinese/requirements.txt (line 5))\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m70.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.1->-r baby-llama2-chinese/requirements.txt (line 5))\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m116.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.1->-r baby-llama2-chinese/requirements.txt (line 5))\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.1->-r baby-llama2-chinese/requirements.txt (line 5))\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.1->-r baby-llama2-chinese/requirements.txt (line 5))\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.1->-r baby-llama2-chinese/requirements.txt (line 5))\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.1->-r baby-llama2-chinese/requirements.txt (line 5))\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.1->-r baby-llama2-chinese/requirements.txt (line 5))\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.1->-r baby-llama2-chinese/requirements.txt (line 5))\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.1->-r baby-llama2-chinese/requirements.txt (line 5))\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==2.0.0 (from torch==2.0.1->-r baby-llama2-chinese/requirements.txt (line 5))\n",
            "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.3.0->-r baby-llama2-chinese/requirements.txt (line 6)) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.3.0->-r baby-llama2-chinese/requirements.txt (line 6)) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.3.0->-r baby-llama2-chinese/requirements.txt (line 6)) (3.4.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.33.2->-r baby-llama2-chinese/requirements.txt (line 10)) (0.20.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.33.2->-r baby-llama2-chinese/requirements.txt (line 10)) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.33.2->-r baby-llama2-chinese/requirements.txt (line 10)) (2023.12.25)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.33.2->-r baby-llama2-chinese/requirements.txt (line 10))\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m109.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.33.2->-r baby-llama2-chinese/requirements.txt (line 10)) (0.4.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->-r baby-llama2-chinese/requirements.txt (line 5)) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->-r baby-llama2-chinese/requirements.txt (line 5)) (0.43.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->-r baby-llama2-chinese/requirements.txt (line 5)) (3.27.9)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.1->-r baby-llama2-chinese/requirements.txt (line 5))\n",
            "  Downloading lit-18.1.2.tar.gz (161 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.0/161.0 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r baby-llama2-chinese/requirements.txt (line 9)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r baby-llama2-chinese/requirements.txt (line 9)) (2023.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.33.2->-r baby-llama2-chinese/requirements.txt (line 10)) (2023.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->-r baby-llama2-chinese/requirements.txt (line 9)) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1->-r baby-llama2-chinese/requirements.txt (line 5)) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->-r baby-llama2-chinese/requirements.txt (line 5)) (1.3.0)\n",
            "Building wheels for collected packages: lit\n",
            "  Building wheel for lit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lit: filename=lit-18.1.2-py3-none-any.whl size=96368 sha256=338b5210a322fbf2dd5b679cc989b870f02e050e9b90f876da3a1c1b5b11ca4d\n",
            "  Stored in directory: /root/.cache/pip/wheels/f4/4d/9c/3e28d23c2c6fc6a9bd89c91a7b7ff775fc71a41ac9a52563e9\n",
            "Successfully built lit\n",
            "Installing collected packages: tokenizers, lit, tqdm, pytest, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, numpy, nvidia-cusolver-cu11, nvidia-cudnn-cu11, transformers, scikit-learn, triton, torch\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.15.2\n",
            "    Uninstalling tokenizers-0.15.2:\n",
            "      Successfully uninstalled tokenizers-0.15.2\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.66.2\n",
            "    Uninstalling tqdm-4.66.2:\n",
            "      Successfully uninstalled tqdm-4.66.2\n",
            "  Attempting uninstall: pytest\n",
            "    Found existing installation: pytest 7.4.4\n",
            "    Uninstalling pytest-7.4.4:\n",
            "      Successfully uninstalled pytest-7.4.4\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.38.2\n",
            "    Uninstalling transformers-4.38.2:\n",
            "      Successfully uninstalled transformers-4.38.2\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.2.0\n",
            "    Uninstalling triton-2.2.0:\n",
            "      Successfully uninstalled triton-2.2.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.2.1+cu121\n",
            "    Uninstalling torch-2.2.1+cu121:\n",
            "      Successfully uninstalled torch-2.2.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "chex 0.1.86 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "torchaudio 2.2.1+cu121 requires torch==2.2.1, but you have torch 2.0.1 which is incompatible.\n",
            "torchtext 0.17.1 requires torch==2.2.1, but you have torch 2.0.1 which is incompatible.\n",
            "torchvision 0.17.1+cu121 requires torch==2.2.1, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed lit-18.1.2 numpy-1.23.5 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 pytest-7.4.0 scikit-learn-1.3.0 tokenizers-0.13.3 torch-2.0.1 tqdm-4.64.1 transformers-4.33.2 triton-2.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "bcc4034da4134a8892d95877c5559b25"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## pre-training 预训练模型\n",
        "\n",
        "使用 chatGLM tokenizer https://github.com/THUDM/ChatGLM2-6B"
      ],
      "metadata": {
        "id": "XXzAaDv_rcoO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 预训练模型数据集\n",
        "\n",
        "- pleisto/wikipedia-cn-20230720-filtered （524M）\n",
        "\n"
      ],
      "metadata": {
        "id": "8ozohy2lsiug"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHJSogtjOyA8",
        "outputId": "e8d0fbfa-0a1d-497b-bdcd-d8a906e5e915"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Consider using `hf_transfer` for faster downloads. This solution comes with some limitations. See https://huggingface.co/docs/huggingface_hub/hf_transfer for more details.\n",
            "Fetching 3 files:   0% 0/3 [00:00<?, ?it/s]downloading https://huggingface.co/datasets/pleisto/wikipedia-cn-20230720-filtered/resolve/4cef256a3f426ae1d3f6930c8cd59a32d785d99d/.gitattributes to /root/.cache/huggingface/hub/tmpx1xdj3_7\n",
            "downloading https://huggingface.co/datasets/pleisto/wikipedia-cn-20230720-filtered/resolve/4cef256a3f426ae1d3f6930c8cd59a32d785d99d/wikipedia-cn-20230720-filtered.json to /root/.cache/huggingface/hub/tmpitevcu1b\n",
            "\n",
            ".gitattributes: 100% 2.38k/2.38k [00:00<00:00, 15.5MB/s]\n",
            "Fetching 3 files:  33% 1/3 [00:00<00:00,  3.17it/s]downloading https://huggingface.co/datasets/pleisto/wikipedia-cn-20230720-filtered/resolve/4cef256a3f426ae1d3f6930c8cd59a32d785d99d/README.md to /root/.cache/huggingface/hub/tmp5e8caq_l\n",
            "\n",
            "README.md: 100% 1.36k/1.36k [00:00<00:00, 9.94MB/s]\n",
            "Fetching 3 files:  67% 2/3 [00:00<00:00,  3.88it/s]\n",
            "wikipedia-cn-20230720-filtered.json:   0% 0.00/524M [00:00<?, ?B/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:   2% 10.5M/524M [00:00<00:11, 43.9MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:   6% 31.5M/524M [00:00<00:05, 86.2MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:   8% 41.9M/524M [00:00<00:10, 46.0MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:  10% 52.4M/524M [00:00<00:08, 53.3MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:  14% 73.4M/524M [00:01<00:13, 33.2MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:  18% 94.4M/524M [00:01<00:08, 48.3MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:  20% 105M/524M [00:02<00:11, 37.5MB/s] \u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:  24% 126M/524M [00:02<00:07, 51.7MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:  28% 147M/524M [00:03<00:07, 51.0MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:  32% 168M/524M [00:03<00:05, 65.2MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:  34% 178M/524M [00:03<00:06, 52.8MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:  38% 199M/524M [00:03<00:04, 67.8MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:  40% 210M/524M [00:03<00:04, 68.0MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:  44% 231M/524M [00:04<00:03, 83.1MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:  48% 252M/524M [00:04<00:03, 76.6MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:  52% 273M/524M [00:04<00:02, 89.7MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:  54% 283M/524M [00:04<00:03, 71.7MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:  58% 304M/524M [00:04<00:02, 85.6MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:  60% 315M/524M [00:05<00:03, 56.0MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:  64% 336M/524M [00:05<00:02, 72.0MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:  66% 346M/524M [00:05<00:03, 54.2MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:  70% 367M/524M [00:06<00:02, 70.4MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:  74% 388M/524M [00:06<00:01, 69.8MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:  78% 409M/524M [00:06<00:01, 83.4MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:  80% 419M/524M [00:06<00:01, 55.4MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:  82% 430M/524M [00:07<00:01, 60.7MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:  86% 451M/524M [00:07<00:01, 55.0MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:  88% 461M/524M [00:07<00:01, 51.2MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:  90% 472M/524M [00:08<00:01, 47.1MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:  94% 493M/524M [00:08<00:00, 42.2MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:  98% 514M/524M [00:08<00:00, 56.5MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json: 100% 524M/524M [00:09<00:00, 55.4MB/s]\n",
            "Fetching 3 files: 100% 3/3 [00:10<00:00,  3.40s/it]\n",
            "/content/datas/datasets/pleisto/wikipedia-cn-20230720-filtered\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli download \\\n",
        "  --repo-type dataset pleisto/wikipedia-cn-20230720-filtered  \\\n",
        "  --local-dir ./datas/datasets/pleisto/wikipedia-cn-20230720-filtered \\\n",
        "  --local-dir-use-symlinks False"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "0Utteds8PxUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"./datas/datasets/pleisto/wikipedia-cn-20230720-filtered\")\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "8908ce4573974a2a8600b4a371342714",
            "fd5405520254406f839d44f9d22fb278",
            "3118edb3b6ef4346819c9d0720613fe7",
            "c35391111a2b4042a8406dea97af4988",
            "77e5ba56111044aa810dece9c70d0597",
            "a8242c55f7324dd3804fbe15870b29f6",
            "b9e7efc8cdb341faba00e55f6003df80",
            "4449f82383d74050a39a7188638a5339",
            "ffdcced6b14e42f883846d790d2e7670",
            "1194042abdbc4c708d4345cca4dde604",
            "e189ddcf03c0474a9d934cd70cc27f2a"
          ]
        },
        "id": "izMfVnFlP50m",
        "outputId": "6977ad4f-0e3f-401c-a78b-2225476ecfc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8908ce4573974a2a8600b4a371342714"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['source', 'completion'],\n",
              "        num_rows: 254547\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[\"train\"][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nt12B0tpQoac",
        "outputId": "091abbc5-407c-4632-e5fb-7bd48ca300f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'source': 'wikipedia.zh2307',\n",
              " 'completion': '昭通机场（ZPZT）是位于中国云南昭通的民用机场，始建于1935年，1960年3月开通往返航班“昆明－昭通”，原来属军民合用机场。1986年机场停止使用。1991年11月扩建，于1994年2月恢复通航。是西南地区「文明机场」，通航城市昆明。 机场占地1957亩，飞行区等级为4C，有一条跑道，长2720米，宽48米，可供波音737及以下机型起降。机坪面积6600平方米，停机位2个，航站楼面积1900平方米。位于城东6公里处，民航路与金鹰大道交叉处。\\n航点\\n客服电话\\n昭通机场客服电话：0870-2830004'}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 数据集预处理 - 对数据集分词"
      ],
      "metadata": {
        "id": "E3H9H1Db6O5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd baby-llama2-chinese && python data_process.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HJIs43H6SWo",
        "outputId": "f3aa90d8-a684-45d2-be67-243d454716ee"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
            "0it [00:00, ?it/s]\n",
            "100% 254547/254547 [09:10<00:00, 462.51it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 预训练"
      ],
      "metadata": {
        "id": "ZYlyKAm894ee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!cd baby-llama2-chinese && python pretrain.py --compile=False --eval_iters=2 --batch_size=8\n",
        "#!cd baby-llama2-chinese && python pretrain.py --compile=False --eval_iters=10 --batch_size=8\n",
        "!cd baby-llama2-chinese && torchrun --standalone --nproc_per_node=1 pretrain.py\n"
      ],
      "metadata": {
        "id": "h54qmMoN91yb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 评估-预训练模型\n",
        "使用 `BLEU` 评估方法"
      ],
      "metadata": {
        "id": "fd31QMftD9u-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd baby-llama2-chinese && python eval_pretrain.py"
      ],
      "metadata": {
        "id": "LX-8wqZmELdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Supervised Fine-tuning 有监督微调模型\n",
        "\n"
      ],
      "metadata": {
        "id": "TSRyQYuI1sB0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 数据准备\n",
        "\n",
        "[bell](https://huggingface.co/datasets/BelleGroup/train_1M_CN)、[MOSS](https://github.com/OpenLMLab/MOSS/tree/main/SFT_data)、[alpaca-zh](https://huggingface.co/datasets/shibing624/alpaca-zh)"
      ],
      "metadata": {
        "id": "NN1fcD9a4cWN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli download \\\n",
        "  --repo-type dataset shibing624/alpaca-zh  \\\n",
        "  --local-dir ./datas/datasets/shibing624/alpaca-zh \\\n",
        "  --local-dir-use-symlinks False"
      ],
      "metadata": {
        "id": "cCzlAbrC1v_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli download \\\n",
        "  --repo-type dataset BelleGroup/train_1M_CN  \\\n",
        "  --local-dir ./datas/datasets/BelleGroup/train_1M_CN \\\n",
        "  --local-dir-use-symlinks False"
      ],
      "metadata": {
        "id": "rH9mlLwg2Xuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli download \\\n",
        "  --repo-type dataset fnlp/moss-003-sft-data  \\\n",
        "  --local-dir ./datas/datasets/fnlp/moss-003-sft-data \\\n",
        "  --local-dir-use-symlinks False"
      ],
      "metadata": {
        "id": "2Ytj15n54GHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python baby-llama2-chinese/sft_data_process.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fIhhW8IqjEF",
        "outputId": "0d8e9f93-50b3-4a84-eca7-7ba8aac4a4f1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   prompt                                             answer\n",
            "0                                              保持健康的三个提示。  以下是保持健康的三个提示：\\n\\n1. 保持身体活动。每天做适当的身体运动，如散步、跑步或游...\n",
            "1                                      描述一次你不得不做出困难决定的经历。  作为一名人工智能助手，我是由程序控制的，没有感情和个人意识，我的一切决策都是基于我的算法和程...\n",
            "2                                  解释为什么以下分数等同于1/4输入：4/16  4/16等于1/4是因为我们可以约分分子分母都除以他们的最大公约数4，得到（4÷4）/ (1...\n",
            "3                                          朱利叶斯·凯撒是如何死亡的？  朱利叶斯·凯撒，又称尤利乌斯·恺撒（Julius Caesar）是古罗马的政治家、军事家和作...\n",
            "4                            将以下内容分类为动物、植物和矿物质：橡树、铜矿石、大象。                             植物: 橡树\\n动物:大象\\n矿物质:铜矿石\n",
            "...                                                   ...                                                ...\n",
            "802894               给出一组数据，预测下一次数据的值。\\n[1, 3, 5, 7, 9]\\n                                根据给定的数据，下一次预测的值是11。\n",
            "802895                                      提供制作荷包蛋的步骤。\\n  1. 准备好鸡蛋和调料（如盐、胡椒粉等）。\\n2. 把鸡蛋打在碗中，加入调料并搅拌均匀。\\n...\n",
            "802896  根据给定的文本，为每个段落创建一个摘要。\\n一篇新闻报道：一家新创公司新近推出了一款基于人工...  一家新创公司推出了一款基于人工智能技术的翻译软件。该软件能够识别和翻译多种语言，准确率高达9...\n",
            "802897  在此任务中，您需要编辑给定的句子并更正其中的语法错误。输出编辑过的句子。\\n这个学生他很聪明。\\n                                          这个学生非常聪明。\n",
            "802898           生成一个包含3个动物名字的列表，其中每个动物的名字都是至少4个字母长的单词。\\n  1. 企鹅 (penguin)\\n2. 犀牛 (rhinoceros)\\n3. 大猩猩 (g...\n",
            "\n",
            "[802899 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 有监督微调训练模型"
      ],
      "metadata": {
        "id": "sTqv26UiEBKi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd baby-llama2-chinese && python sft.py"
      ],
      "metadata": {
        "id": "DPqu8PfHqvAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 评估-有监督微调模型\n",
        "使用 `BLEU` 评估方法"
      ],
      "metadata": {
        "id": "hlgLAwUjDgPw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd baby-llama2-chinese && python eval.py"
      ],
      "metadata": {
        "id": "yMFeUquSDrK0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}