{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyN19cT9ag/Yv3SLVJP9l3sR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "caa716b12ad3483b9159d437281a2940": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ad9232648fef491887cefb5d065fd82c",
              "IPY_MODEL_b9679b9bb8724f30be810504176b117e",
              "IPY_MODEL_6ac64fac744c41b4aceed82b13d9aa73"
            ],
            "layout": "IPY_MODEL_d9a0bf708a8849a383b9900b4021ecfe"
          }
        },
        "ad9232648fef491887cefb5d065fd82c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca52df4633e04030b1db5fbe4e181185",
            "placeholder": "​",
            "style": "IPY_MODEL_b9d4f12cf3f64a9b8b096bd78e0497e2",
            "value": "config.json: 100%"
          }
        },
        "b9679b9bb8724f30be810504176b117e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ebf6e76a44a4eb9a1ce52a788fa4daa",
            "max": 571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b3a733030c4547eeacdef83a47751c87",
            "value": 571
          }
        },
        "6ac64fac744c41b4aceed82b13d9aa73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8349e742df564f30ba87290f36f16673",
            "placeholder": "​",
            "style": "IPY_MODEL_103fe095889049918d8d13f82a9165a2",
            "value": " 571/571 [00:00&lt;00:00, 48.9kB/s]"
          }
        },
        "d9a0bf708a8849a383b9900b4021ecfe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca52df4633e04030b1db5fbe4e181185": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9d4f12cf3f64a9b8b096bd78e0497e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ebf6e76a44a4eb9a1ce52a788fa4daa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3a733030c4547eeacdef83a47751c87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8349e742df564f30ba87290f36f16673": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "103fe095889049918d8d13f82a9165a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ca86f7cd1c1457f955d5cd50586e5d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_64e4e1b4e63a4ea4924d5038ea2f0edb",
              "IPY_MODEL_44fd3e2f471f4f6197d888b551d017cf",
              "IPY_MODEL_34059aee78c4456497565142c2ab80d8"
            ],
            "layout": "IPY_MODEL_bf0fe12ae121410989a09607206f8ad1"
          }
        },
        "64e4e1b4e63a4ea4924d5038ea2f0edb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_008c01d3fd044cd1bbb02f3f17fb0eb3",
            "placeholder": "​",
            "style": "IPY_MODEL_d3a79cab17c34dc59634cb5957815426",
            "value": "generation_config.json: 100%"
          }
        },
        "44fd3e2f471f4f6197d888b551d017cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60a14d9561424206804a8aa5cb99f534",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8ee80b47b6094fa1ae96e5e143a22030",
            "value": 116
          }
        },
        "34059aee78c4456497565142c2ab80d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34d1fcd20f694d5a90688c8866b4e888",
            "placeholder": "​",
            "style": "IPY_MODEL_fce8387721604a73b88af0afbff94b06",
            "value": " 116/116 [00:00&lt;00:00, 10.7kB/s]"
          }
        },
        "bf0fe12ae121410989a09607206f8ad1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "008c01d3fd044cd1bbb02f3f17fb0eb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3a79cab17c34dc59634cb5957815426": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60a14d9561424206804a8aa5cb99f534": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ee80b47b6094fa1ae96e5e143a22030": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "34d1fcd20f694d5a90688c8866b4e888": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fce8387721604a73b88af0afbff94b06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60b5dd19cda64ee38403df6eebe22bd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e60dc32a18524fa290ca9d68f673b87b",
              "IPY_MODEL_99963e7c84ca401f8a04b273bb51a37e",
              "IPY_MODEL_105ba53fb0fe4552a485a227fd24ced8"
            ],
            "layout": "IPY_MODEL_849be24c4861414e87b77ecee44d8b38"
          }
        },
        "e60dc32a18524fa290ca9d68f673b87b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2bbcd10ce494fe98420bf32d9bd2e21",
            "placeholder": "​",
            "style": "IPY_MODEL_954289896e864eafaa832a657730fede",
            "value": "Fetching 9 files: 100%"
          }
        },
        "99963e7c84ca401f8a04b273bb51a37e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8755522caff4d86b31adc96bd1cd94f",
            "max": 9,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_05ecadadab034564aa9a75e512fc6d83",
            "value": 9
          }
        },
        "105ba53fb0fe4552a485a227fd24ced8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54e77873c494490988397ee14eef66cf",
            "placeholder": "​",
            "style": "IPY_MODEL_9d5ac04a8a334268a8b9607c13ffc286",
            "value": " 9/9 [00:46&lt;00:00, 15.48s/it]"
          }
        },
        "849be24c4861414e87b77ecee44d8b38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2bbcd10ce494fe98420bf32d9bd2e21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "954289896e864eafaa832a657730fede": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8755522caff4d86b31adc96bd1cd94f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05ecadadab034564aa9a75e512fc6d83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "54e77873c494490988397ee14eef66cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d5ac04a8a334268a8b9607c13ffc286": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "815996c9d03144a0833d2d8960714532": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_44b9a739e98442ccbc0b1301a16a88d3",
              "IPY_MODEL_c1b33b8f4a71490ca75f28fee2241b9d",
              "IPY_MODEL_090c5aaba6ca4655a6c26e0febcf84bb"
            ],
            "layout": "IPY_MODEL_37a3fb6532934a1681e3368f07fc8ec0"
          }
        },
        "44b9a739e98442ccbc0b1301a16a88d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a4fc324634047338305108c31e38e5f",
            "placeholder": "​",
            "style": "IPY_MODEL_e44ddd248be94b489c5d73a9ddd24d2a",
            "value": "model-00001-of-00002.safetensors: 100%"
          }
        },
        "c1b33b8f4a71490ca75f28fee2241b9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5445894cf8e844fab3d56794108739d8",
            "max": 9942981696,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b232a8728e4d4f64b7719b6b15c706db",
            "value": 9942981696
          }
        },
        "090c5aaba6ca4655a6c26e0febcf84bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbfce62fa6214a518dc3b898dec966b7",
            "placeholder": "​",
            "style": "IPY_MODEL_851b0b6ade1b43d8a8e8b64e6635e011",
            "value": " 9.94G/9.94G [00:44&lt;00:00, 412MB/s]"
          }
        },
        "37a3fb6532934a1681e3368f07fc8ec0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a4fc324634047338305108c31e38e5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e44ddd248be94b489c5d73a9ddd24d2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5445894cf8e844fab3d56794108739d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b232a8728e4d4f64b7719b6b15c706db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cbfce62fa6214a518dc3b898dec966b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "851b0b6ade1b43d8a8e8b64e6635e011": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16d0204fd4cc442dbb850992e8bc912d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b807f72b7acd458c9dbd30e35cf93aac",
              "IPY_MODEL_2f1ac366b19848ae97bb5cede0191179",
              "IPY_MODEL_a0077fe17d09409b99a33d538ac245c7"
            ],
            "layout": "IPY_MODEL_3490bd753a1a45f7b76355276aa84508"
          }
        },
        "b807f72b7acd458c9dbd30e35cf93aac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1be16cd4a565460b8e6a78ba19903565",
            "placeholder": "​",
            "style": "IPY_MODEL_2608dff02aac4c27863b3a4f66ee666a",
            "value": "model-00002-of-00002.safetensors: 100%"
          }
        },
        "2f1ac366b19848ae97bb5cede0191179": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_adaebfa7fe8a4db59048dc9a6b47b74b",
            "max": 4540516344,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4655e0399cb04eed932c9610eb95f609",
            "value": 4540516344
          }
        },
        "a0077fe17d09409b99a33d538ac245c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1f05dd002ff4e6995aac4f73b78efc1",
            "placeholder": "​",
            "style": "IPY_MODEL_7300f68d2e4047418919acf4ae3b924d",
            "value": " 4.54G/4.54G [00:29&lt;00:00, 169MB/s]"
          }
        },
        "3490bd753a1a45f7b76355276aa84508": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1be16cd4a565460b8e6a78ba19903565": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2608dff02aac4c27863b3a4f66ee666a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "adaebfa7fe8a4db59048dc9a6b47b74b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4655e0399cb04eed932c9610eb95f609": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f1f05dd002ff4e6995aac4f73b78efc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7300f68d2e4047418919acf4ae3b924d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e48c166f533e41bb8d11236ceeb11a44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b2ffcd5c7c58477f94a98114c3142f18",
              "IPY_MODEL_27b219be62ee4202810c59a7f9112653",
              "IPY_MODEL_dd46e9c76ad8483bb3e735b39a463a71"
            ],
            "layout": "IPY_MODEL_fd4f6f3952fb436aa6a1e5bca6e76b4a"
          }
        },
        "b2ffcd5c7c58477f94a98114c3142f18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_525bacd6cd8446288f41623ff9d42d4a",
            "placeholder": "​",
            "style": "IPY_MODEL_d17ea2a5e62c4fd7b2051eccf70a1f66",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "27b219be62ee4202810c59a7f9112653": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b8d02d0495043bb9e5577ba05f4834a",
            "max": 967,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f029e455e0a24d4aa653fb4deb572eac",
            "value": 967
          }
        },
        "dd46e9c76ad8483bb3e735b39a463a71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bacaac16a3f04d42a885ec11a8a3b617",
            "placeholder": "​",
            "style": "IPY_MODEL_9ab50945556f4c9da39c2134ce347174",
            "value": " 967/967 [00:00&lt;00:00, 22.3kB/s]"
          }
        },
        "fd4f6f3952fb436aa6a1e5bca6e76b4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "525bacd6cd8446288f41623ff9d42d4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d17ea2a5e62c4fd7b2051eccf70a1f66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b8d02d0495043bb9e5577ba05f4834a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f029e455e0a24d4aa653fb4deb572eac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bacaac16a3f04d42a885ec11a8a3b617": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ab50945556f4c9da39c2134ce347174": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e49d3e89f36c4ab9abcd05a440d2e802": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_225f61d07fc1449996ec46b910d2dd4e",
              "IPY_MODEL_220b27b934514abc8426c22c53192a18",
              "IPY_MODEL_c3a2401529514557a2294901c244aec6"
            ],
            "layout": "IPY_MODEL_74682d70dca341a5af2917ac87a81b54"
          }
        },
        "225f61d07fc1449996ec46b910d2dd4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_320e51fc7e174991980147cd82193c30",
            "placeholder": "​",
            "style": "IPY_MODEL_c58bf29178464d8bac9b1e2baa29f4c5",
            "value": "pytorch_model.bin.index.json: 100%"
          }
        },
        "220b27b934514abc8426c22c53192a18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9dee19d6a4d74f6697af8e48bc56f611",
            "max": 23950,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ddfcf5e04a841f39428e1566c68ef3e",
            "value": 23950
          }
        },
        "c3a2401529514557a2294901c244aec6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22fb075d51c24f4aa0f9dd14df4c88b0",
            "placeholder": "​",
            "style": "IPY_MODEL_76b3de07c8a74122b3044b4409542f76",
            "value": " 23.9k/23.9k [00:00&lt;00:00, 427kB/s]"
          }
        },
        "74682d70dca341a5af2917ac87a81b54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "320e51fc7e174991980147cd82193c30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c58bf29178464d8bac9b1e2baa29f4c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9dee19d6a4d74f6697af8e48bc56f611": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ddfcf5e04a841f39428e1566c68ef3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "22fb075d51c24f4aa0f9dd14df4c88b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76b3de07c8a74122b3044b4409542f76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e786cd185ab4a0994037070bd023b99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0c1233485afa4d4e908c93e438ca9f57",
              "IPY_MODEL_895dc5292ce4439d819eddedc78a6a9d",
              "IPY_MODEL_f24f047d68524ea9981897b89e41df77"
            ],
            "layout": "IPY_MODEL_6638ab23a386452ea2cc8431a567d422"
          }
        },
        "0c1233485afa4d4e908c93e438ca9f57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e99945c02124a57a38aa8ef747fae37",
            "placeholder": "​",
            "style": "IPY_MODEL_a4fe170ca2744f54b857c0204f27d5ca",
            "value": "model.safetensors.index.json: 100%"
          }
        },
        "895dc5292ce4439d819eddedc78a6a9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd5cc23fc79246ebb9fc89b0dcff1cfb",
            "max": 25125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4bec94f4611c426888834535f6c29647",
            "value": 25125
          }
        },
        "f24f047d68524ea9981897b89e41df77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1328c6ef8f6243cd8d700c5375389265",
            "placeholder": "​",
            "style": "IPY_MODEL_5773edc93ebc403f8a68776fb26b96c5",
            "value": " 25.1k/25.1k [00:00&lt;00:00, 392kB/s]"
          }
        },
        "6638ab23a386452ea2cc8431a567d422": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e99945c02124a57a38aa8ef747fae37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4fe170ca2744f54b857c0204f27d5ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd5cc23fc79246ebb9fc89b0dcff1cfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bec94f4611c426888834535f6c29647": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1328c6ef8f6243cd8d700c5375389265": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5773edc93ebc403f8a68776fb26b96c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa6a8c6cf51e4cd89c2fbbcf2b93ff27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7801e8116853471d996ef05fbbdb1efc",
              "IPY_MODEL_6ab763ddc5464ec087df38ba058c093a",
              "IPY_MODEL_3eff858509e54bce83b84e6c06b6cc2d"
            ],
            "layout": "IPY_MODEL_e686d50944824468897041dfd1d93110"
          }
        },
        "7801e8116853471d996ef05fbbdb1efc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a6f478041ad495197e5d7c3bae9a2a5",
            "placeholder": "​",
            "style": "IPY_MODEL_91d6beb44c9541ab8929fa3e9c551889",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "6ab763ddc5464ec087df38ba058c093a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1443ac0e973440bab500076f4b224d1",
            "max": 72,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1da2fa1b294e45a7adfcb3930629ff7e",
            "value": 72
          }
        },
        "3eff858509e54bce83b84e6c06b6cc2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66c0df913905429982c41cb711854d66",
            "placeholder": "​",
            "style": "IPY_MODEL_5c968864b1e14980b3e521e0204283c5",
            "value": " 72.0/72.0 [00:00&lt;00:00, 1.71kB/s]"
          }
        },
        "e686d50944824468897041dfd1d93110": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a6f478041ad495197e5d7c3bae9a2a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91d6beb44c9541ab8929fa3e9c551889": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b1443ac0e973440bab500076f4b224d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1da2fa1b294e45a7adfcb3930629ff7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "66c0df913905429982c41cb711854d66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c968864b1e14980b3e521e0204283c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc37634d7b6b4ba68dd3fce0e7791342": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4ec1d0abf09c42c0a1424663f4ae445f",
              "IPY_MODEL_2f70e1a9e779469a997233a3e8c02d18",
              "IPY_MODEL_d9bd841ee881434287bd5a54702ae441"
            ],
            "layout": "IPY_MODEL_d059f5c2045c4c1da2114050f233267c"
          }
        },
        "4ec1d0abf09c42c0a1424663f4ae445f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab5b228a889e4e698229a3c563adc9d8",
            "placeholder": "​",
            "style": "IPY_MODEL_b7d8415503fc4d55a8f04cf21c0a2d30",
            "value": "tokenizer.json: 100%"
          }
        },
        "2f70e1a9e779469a997233a3e8c02d18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e585a5948fb49eda4dc1374cd4c14a4",
            "max": 1795303,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_956bd77eadcb47abb262f8b2e815a934",
            "value": 1795303
          }
        },
        "d9bd841ee881434287bd5a54702ae441": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9f8e8cc4c124266a6888e03349eb832",
            "placeholder": "​",
            "style": "IPY_MODEL_37838e53523049e9b64fb72fdf6f0151",
            "value": " 1.80M/1.80M [00:01&lt;00:00, 1.46MB/s]"
          }
        },
        "d059f5c2045c4c1da2114050f233267c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab5b228a889e4e698229a3c563adc9d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7d8415503fc4d55a8f04cf21c0a2d30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e585a5948fb49eda4dc1374cd4c14a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "956bd77eadcb47abb262f8b2e815a934": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b9f8e8cc4c124266a6888e03349eb832": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37838e53523049e9b64fb72fdf6f0151": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a54e937c2804694858a371b444aecb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d862dfc5d3cc45e5b10247c2b0510696",
              "IPY_MODEL_9aa5c2f1a88740b0be2caf218f1f31bb",
              "IPY_MODEL_d7939b5b64d44179a02d14bc0d02e189"
            ],
            "layout": "IPY_MODEL_01e57179edf448829574b7a04d7e79c8"
          }
        },
        "d862dfc5d3cc45e5b10247c2b0510696": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81ccc8b6c8e3465eb37fd60be81753f6",
            "placeholder": "​",
            "style": "IPY_MODEL_e9653782040c4497a246bd46edadbb97",
            "value": "tokenizer.model: 100%"
          }
        },
        "9aa5c2f1a88740b0be2caf218f1f31bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_699a7059e69d423d93fd90ecb388651d",
            "max": 493443,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0a5c03fbcd1a4f2f9d64f4824acac176",
            "value": 493443
          }
        },
        "d7939b5b64d44179a02d14bc0d02e189": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eff3427e0d2d49029320886de6602618",
            "placeholder": "​",
            "style": "IPY_MODEL_84f398c6388a4db6a944a0ac10165bb8",
            "value": " 493k/493k [00:00&lt;00:00, 523kB/s]"
          }
        },
        "01e57179edf448829574b7a04d7e79c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81ccc8b6c8e3465eb37fd60be81753f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9653782040c4497a246bd46edadbb97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "699a7059e69d423d93fd90ecb388651d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a5c03fbcd1a4f2f9d64f4824acac176": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eff3427e0d2d49029320886de6602618": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84f398c6388a4db6a944a0ac10165bb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5c19393cb7b4117b7bd688f47841854": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_af743e24883b4fcbb71dcf66eb93085a",
              "IPY_MODEL_bae633cf4dcb49e99c8d25523d3610e5",
              "IPY_MODEL_644ab2e3208c4b16995fceaa011b51b7"
            ],
            "layout": "IPY_MODEL_46251cd9b6424f7db36deab9304b7d6f"
          }
        },
        "af743e24883b4fcbb71dcf66eb93085a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f24376a0f88a4bd99f33c956f455d3b9",
            "placeholder": "​",
            "style": "IPY_MODEL_2799064976bb4770b4336a17121b3c2d",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "bae633cf4dcb49e99c8d25523d3610e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87dd4f8043364bbab0aa2351ef39ff0b",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f8b9a7fe2cf14cfda4dd0ee50e161293",
            "value": 3
          }
        },
        "644ab2e3208c4b16995fceaa011b51b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10d81750454a4f5cb04dc1c828c5a716",
            "placeholder": "​",
            "style": "IPY_MODEL_8487d042de104b8c84ff8557a1dff6f2",
            "value": " 3/3 [00:33&lt;00:00, 12.98s/it]"
          }
        },
        "46251cd9b6424f7db36deab9304b7d6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f24376a0f88a4bd99f33c956f455d3b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2799064976bb4770b4336a17121b3c2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87dd4f8043364bbab0aa2351ef39ff0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8b9a7fe2cf14cfda4dd0ee50e161293": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "10d81750454a4f5cb04dc1c828c5a716": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8487d042de104b8c84ff8557a1dff6f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d1205f4faf404c948a7401d068e7d2e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2adba48cf5264d5aaddd72c180574a87",
              "IPY_MODEL_5614398ae73141beb9be5ce378396562",
              "IPY_MODEL_473bbaf77f594a91a2fdf7a7407238e1"
            ],
            "layout": "IPY_MODEL_38f55f15bf41448581e3569d0ac6b4e5"
          }
        },
        "2adba48cf5264d5aaddd72c180574a87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fac98800ce24d49b7d16cbfd52fd186",
            "placeholder": "​",
            "style": "IPY_MODEL_d908ebff12c542a3ac4722cf9e6bacbd",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "5614398ae73141beb9be5ce378396562": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87ee759a9bed45d3ab0e23f0d05b5380",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5ed40000a5b149b8bcba39aabe1f08a7",
            "value": 3
          }
        },
        "473bbaf77f594a91a2fdf7a7407238e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_773e91d0e97a498a8178fe8ce8fa9e55",
            "placeholder": "​",
            "style": "IPY_MODEL_15fe3103f7004f1780ae34829bdc6000",
            "value": " 3/3 [00:04&lt;00:00,  1.61s/it]"
          }
        },
        "38f55f15bf41448581e3569d0ac6b4e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fac98800ce24d49b7d16cbfd52fd186": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d908ebff12c542a3ac4722cf9e6bacbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87ee759a9bed45d3ab0e23f0d05b5380": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ed40000a5b149b8bcba39aabe1f08a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "773e91d0e97a498a8178fe8ce8fa9e55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15fe3103f7004f1780ae34829bdc6000": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weedge/doraemon-nb/blob/main/deepspeed_MII.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "legacy\n",
        "- https://github.com/microsoft/DeepSpeed-MII/tree/main/mii/legacy\n",
        "- https://towardsdatascience.com/deepspeed-deep-dive-model-implementations-for-inference-mii-b02aa5d5e7f7\n",
        "- https://www.deepspeed.ai/2022/10/10/mii.html\n",
        "- [**DeepSpeed Inference: Enabling Efficient Inference of Transformer Models at Unprecedented Scale**](https://arxiv.org/abs/2207.00032)\n",
        "\n",
        "fastgen\n",
        "- https://github.com/microsoft/DeepSpeed/blob/master/blogs/deepspeed-fastgen/README.md\n",
        "- https://github.com/microsoft/DeepSpeed/blob/master/blogs/deepspeed-fastgen/chinese/README.md\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8SApMofRDid_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install tensorrt\n",
        "!ls /usr/local/lib/python3.10/dist-packages/tensorrt_libs/\n",
        "#!export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/lib/python3.10/dist-packages/tensorrt_libs/tensorrt_libs/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnU1_BfC4qG6",
        "outputId": "b2c5d192-95c2-40ac-acc6-5ad914bd47e7"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__init__.py\t\t\t      libnvinfer_plugin.so.9  libnvonnxparser.so.9\n",
            "libnvinfer_builder_resource.so.9.2.0  libnvinfer.so.9\t      __pycache__\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nki3tY8wCeSg",
        "outputId": "72a8bd5a-c7c1-4b1c-96d0-0bf753eeb429"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deepspeed-mii\n",
            "  Downloading deepspeed_mii-0.1.3-py3-none-any.whl (108 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/108.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/108.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.1/108.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Flask-RESTful (from deepspeed-mii)\n",
            "  Downloading Flask_RESTful-0.3.10-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from deepspeed-mii) (9.4.0)\n",
            "Requirement already satisfied: Werkzeug in /usr/local/lib/python3.10/dist-packages (from deepspeed-mii) (3.0.1)\n",
            "Collecting asyncio (from deepspeed-mii)\n",
            "  Downloading asyncio-3.4.3-py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.8/101.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting deepspeed-kernels (from deepspeed-mii)\n",
            "  Downloading deepspeed_kernels-0.0.1.dev1698255861-py3-none-manylinux1_x86_64.whl (44.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.5/44.5 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting deepspeed>=0.12.4 (from deepspeed-mii)\n",
            "  Downloading deepspeed-0.12.5.tar.gz (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: grpcio in /usr/local/lib/python3.10/dist-packages (from deepspeed-mii) (1.60.0)\n",
            "Collecting grpcio-tools (from deepspeed-mii)\n",
            "  Downloading grpcio_tools-1.60.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from deepspeed-mii) (1.10.13)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from deepspeed-mii) (0.4.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from deepspeed-mii) (2.1.0+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from deepspeed-mii) (4.35.2)\n",
            "Collecting ujson (from deepspeed-mii)\n",
            "  Downloading ujson-5.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.2/53.2 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting zmq (from deepspeed-mii)\n",
            "  Downloading zmq-0.0.0.zip (2.2 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting hjson (from deepspeed>=0.12.4->deepspeed-mii)\n",
            "  Downloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ninja (from deepspeed>=0.12.4->deepspeed-mii)\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deepspeed>=0.12.4->deepspeed-mii) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from deepspeed>=0.12.4->deepspeed-mii) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from deepspeed>=0.12.4->deepspeed-mii) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from deepspeed>=0.12.4->deepspeed-mii) (9.0.0)\n",
            "Collecting pynvml (from deepspeed>=0.12.4->deepspeed-mii)\n",
            "  Downloading pynvml-11.5.0-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from deepspeed>=0.12.4->deepspeed-mii) (4.66.1)\n",
            "Requirement already satisfied: cmake>=3.24 in /usr/local/lib/python3.10/dist-packages (from deepspeed-kernels->deepspeed-mii) (3.27.9)\n",
            "Collecting aniso8601>=0.82 (from Flask-RESTful->deepspeed-mii)\n",
            "  Downloading aniso8601-9.0.1-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.10/dist-packages (from Flask-RESTful->deepspeed-mii) (2.2.5)\n",
            "Requirement already satisfied: six>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from Flask-RESTful->deepspeed-mii) (1.16.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from Flask-RESTful->deepspeed-mii) (2023.3.post1)\n",
            "Collecting protobuf<5.0dev,>=4.21.6 (from grpcio-tools->deepspeed-mii)\n",
            "  Downloading protobuf-4.25.1-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from grpcio-tools->deepspeed-mii) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->deepspeed-mii) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed-mii) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed-mii) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed-mii) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed-mii) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed-mii) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed-mii) (2.1.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers->deepspeed-mii) (0.19.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->deepspeed-mii) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->deepspeed-mii) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->deepspeed-mii) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->deepspeed-mii) (0.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from Werkzeug->deepspeed-mii) (2.1.3)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.10/dist-packages (from zmq->deepspeed-mii) (23.2.1)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->Flask-RESTful->deepspeed-mii) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->Flask-RESTful->deepspeed-mii) (8.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->deepspeed-mii) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->deepspeed-mii) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->deepspeed-mii) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->deepspeed-mii) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->deepspeed-mii) (1.3.0)\n",
            "Building wheels for collected packages: deepspeed, zmq\n",
            "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepspeed: filename=deepspeed-0.12.5-py3-none-any.whl size=1297445 sha256=38a96169750e66dcaade739c06672aa526c9add95ab3777726a8548595c07007\n",
            "  Stored in directory: /root/.cache/pip/wheels/7d/4e/ca/24e93c09d21013b572826feb20cbef59b599f3d617bf075038\n",
            "  Building wheel for zmq (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for zmq: filename=zmq-0.0.0-py3-none-any.whl size=1264 sha256=cef529cd0bba68451433bf8d79ee999b998ef35adc7142b1557ad5d64cd73a04\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/c5/fe/d853f71843cae26c123d37a7a5934baac20fc66f35a913951d\n",
            "Successfully built deepspeed zmq\n",
            "Installing collected packages: ninja, hjson, asyncio, aniso8601, zmq, ujson, pynvml, protobuf, deepspeed-kernels, grpcio-tools, Flask-RESTful, deepspeed, deepspeed-mii\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorboard 2.15.1 requires protobuf<4.24,>=3.19.6, but you have protobuf 4.25.1 which is incompatible.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 4.25.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Flask-RESTful-0.3.10 aniso8601-9.0.1 asyncio-3.4.3 deepspeed-0.12.5 deepspeed-kernels-0.0.1.dev1698255861 deepspeed-mii-0.1.3 grpcio-tools-1.60.0 hjson-3.1.0 ninja-1.11.1.1 protobuf-4.25.1 pynvml-11.5.0 ujson-5.9.0 zmq-0.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "asyncio"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install deepspeed-mii\n",
        "!pip install -U transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ds_report"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLdzy63DJ2u-",
        "outputId": "21521741-9e32-4765-9976-4d89ecd40739"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-12-16 04:19:37,809] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "--------------------------------------------------\n",
            "DeepSpeed C++/CUDA extension op report\n",
            "--------------------------------------------------\n",
            "NOTE: Ops not installed will be just-in-time (JIT) compiled at\n",
            "      runtime if needed. Op compatibility means that your system\n",
            "      meet the required dependencies to JIT install the op.\n",
            "--------------------------------------------------\n",
            "JIT compiled ops requires ninja\n",
            "ninja .................. \u001b[92m[OKAY]\u001b[0m\n",
            "--------------------------------------------------\n",
            "op name ................ installed .. compatible\n",
            "--------------------------------------------------\n",
            "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
            "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
            "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
            "async_io ............... \u001b[93m[NO]\u001b[0m ....... \u001b[93m[NO]\u001b[0m\n",
            "fused_adam ............. \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "cpu_adam ............... \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "cpu_adagrad ............ \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "cpu_lion ............... \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
            "evoformer_attn ......... \u001b[93m[NO]\u001b[0m ....... \u001b[93m[NO]\u001b[0m\n",
            "fused_lamb ............. \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "fused_lion ............. \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "inference_core_ops ..... \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "cutlass_ops ............ \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "quantizer .............. \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "ragged_device_ops ...... \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "ragged_ops ............. \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "random_ltd ............. \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.1\n",
            "\u001b[93m [WARNING] \u001b[0m using untested triton version (2.1.0), only 1.0.0 is known to be compatible\n",
            "sparse_attn ............ \u001b[93m[NO]\u001b[0m ....... \u001b[93m[NO]\u001b[0m\n",
            "spatial_inference ...... \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "transformer ............ \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "stochastic_transformer . \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "transformer_inference .. \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "--------------------------------------------------\n",
            "DeepSpeed general environment info:\n",
            "torch install path ............... ['/usr/local/lib/python3.10/dist-packages/torch']\n",
            "torch version .................... 2.1.0+cu121\n",
            "deepspeed install path ........... ['/usr/local/lib/python3.10/dist-packages/deepspeed']\n",
            "deepspeed info ................... 0.12.5, unknown, unknown\n",
            "torch cuda version ............... 12.1\n",
            "torch hip version ................ None\n",
            "nvcc version ..................... 12.2\n",
            "deepspeed wheel compiled w. ...... torch 2.1, cuda 12.1\n",
            "shared memory (/dev/shm) size .... 40.75 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/microsoft/DeepSpeed-MII"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shaTH9qEYZsr",
        "outputId": "cef333fd-92bc-4816-f7ab-9534e1781d8b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DeepSpeed-MII'...\n",
            "remote: Enumerating objects: 3191, done.\u001b[K\n",
            "remote: Counting objects: 100% (1789/1789), done.\u001b[K\n",
            "remote: Compressing objects: 100% (674/674), done.\u001b[K\n",
            "remote: Total 3191 (delta 1359), reused 1309 (delta 1089), pack-reused 1402\u001b[K\n",
            "Receiving objects: 100% (3191/3191), 6.36 MiB | 22.08 MiB/s, done.\n",
            "Resolving deltas: 100% (2063/2063), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DeepSpeed-Legacy\n",
        "\n",
        "ds mii 以前的组件\n",
        "\n",
        "https://github.com/microsoft/DeepSpeed-MII/tree/main/mii/legacy\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "深度学习 (DL) 开源社区在过去几个月中出现了巨大的增长。极其强大的文本生成模型（如 Bloom 176B）或图像生成模型（如稳定扩散）现在可供通过 Hugging Face 等平台访问少量甚至单个 GPU 的任何人使用。尽管开源使人工智能功能的访问变得民主化，但其应用仍然受到两个关键因素的限制：推理延迟和成本。\n",
        "\n",
        "深度学习模型推理的系统优化已经取得了重大进展，可以大大减少延迟和成本，但这些进展并不容易实现。这种可访问性有限的主要原因是深度学习模型推理环境多种多样，模型的大小、架构、系统性能特征、硬件要求等各不相同。确定适用于给定模型的适当系统优化集并正确应用它们是很重要的。通常超出了大多数数据科学家的能力范围，导致低延迟和低成本推理几乎无法实现。\n",
        "\n",
        "DeepSpeed-MII 是 DeepSpeed 的一个新的开源 Python 库，旨在使强大模型的低延迟、低成本推理不仅可行，而且易于访问。\n",
        "\n",
        "- MII 提供对数千种广泛使用的深度学习模型的高度优化实现。\n",
        "- 与原始实施相比，MII 支持的模型可显着降低延迟和成本。例如，MII 将 Big-Science Bloom 176B 模型的延迟降低了 5.7 倍，同时将成本降低了 40 倍以上。同样，它将部署稳定扩散的延迟和成本降低了 1.9 倍。查看更多详细信息，[了解MII 的详尽延迟和成本分析](https://github.com/microsoft/DeepSpeed-MII/tree/main/mii/legacy#quantifying-latency-and-cost-reduction)。\n",
        "- 为了实现低延迟/成本推理，MII 利用 DeepSpeed-Inference 的一系列优化，例如transformer的深度融合、用于多 GPU 推理的自动张量切片、使用 ZeroQuant 进行动态量化以及其他几个（请参阅我们的博客文章[了解更多详细信息](https://www.deepspeed.ai/2022/10/10/mii.html)）。\n",
        "- 凭借最先进的性能，MII 只需几行代码即可通过 AML 在本地和 Azure 上低成本部署这些模型。\n",
        "\n",
        "\n",
        "![](https://github.com/microsoft/DeepSpeed-MII/blob/main/mii/legacy/docs/images/mii-arch.png?raw=true)\n",
        "MII 架构，显示 MII 如何使用 DS-Inference 自动优化 OSS 模型，然后使用 GRPC 在本地部署，或使用 AML Inference 在 Microsoft Azure 上部署。\n",
        "\n",
        "MII 的底层由DeepSpeed-Inference提供支持。根据模型类型、模型大小、批量大小和可用硬件资源，MII 自动应用 DeepSpeed-Inference 中的一组适当的系统优化，以最小化延迟并最大化吞吐量。它通过使用许多预先指定的模型注入策略之一来实现这一点，该策略允许 MII 和 DeepSpeed-Inference 识别底层 PyTorch 模型架构并用优化的实现替换它（见图A）。在此过程中，MII 使其 DeepSpeed-Inference 中的广泛优化自动可用于其支持的数千种流行模型。\n",
        "\n",
        "\n",
        "MII 可以使用 DeepSpeed-Inference 的两种变体。\n",
        "- 第一个称为 ds-public，包含此处讨论的大部分 DeepSpeed-Inference 优化，也可以通过我们的开源 DeepSpeed 库获得。\n",
        "- 第二个称为 ds-azure，提供与 Azure 更紧密的集成，并可通过 MII 向所有 Microsoft Azure 客户提供。我们将运行两个 DeepSpeed-Inference 变体的 MII 分别称为 MII-Public 和 MII-Azure。\n",
        "\n",
        "虽然这两种变体都比开源 PyTorch 基线提供了显着的延迟和成本降低，但后者为基于生成的工作负载提供了额外的性能优势。此处提供了与 PyTorch 基线以及这两个版本之间的完整延迟和成本优势比较。\n",
        "\n",
        "云服务部署方式大同小异，aws部署方式差不多\n",
        "\n",
        "这里介绍第一种方式\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "r4xJvVWnP_lz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 部署"
      ],
      "metadata": {
        "id": "nk-SjUbJV2cj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#MII-Public 可以部署在本地或任何云产品上，只需几行代码。MII 创建一个轻量级 GRPC 服务器来支持这种形式的部署，并为查询提供 GRPC 推理端点。\n",
        "\n",
        "# 作为示例，这里是Hugging Face 的bigscience/bloom-560m模型的部署：\n",
        "import mii\n",
        "mii_configs = {\"tensor_parallel\": 1, \"dtype\": \"fp16\"}\n",
        "mii.deploy(task=\"text-generation\",\n",
        "           model=\"bigscience/bloom-560m\",\n",
        "           deployment_name=\"bloom560m_deployment\",\n",
        "           mii_config=mii_configs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SguRnOWkVlEG",
        "outputId": "37411537-640f-4052-b633-0645ce9c00b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-12-13 09:11:19,436] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-13 09:12:42,722] [INFO] [deployment.py:75:deploy] ************* MII is using DeepSpeed Optimizations to accelerate your model *************\n",
            "[2023-12-13 09:12:42,722] [INFO] [deployment.py:75:deploy] ************* MII is using DeepSpeed Optimizations to accelerate your model *************\n",
            "[2023-12-13 09:12:42,727] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter hf_auth_token is deprecated. Parameter will be removed. Please use the `pipeline_kwargs` field to pass kwargs to the HuggingFace pipeline creation.\n",
            "[2023-12-13 09:12:42,728] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter trust_remote_code is deprecated. Parameter will be removed. Please use the `pipeline_kwargs` field to pass kwargs to the HuggingFace pipeline creation.\n",
            "[2023-12-13 09:12:42,735] [INFO] [server.py:38:__init__] Hostfile /job/hostfile not found, creating hostfile.\n",
            "[2023-12-13 09:12:42,735] [INFO] [server.py:38:__init__] Hostfile /job/hostfile not found, creating hostfile.\n",
            "[2023-12-13 09:12:42,738] [INFO] [server.py:103:_launch_server_process] MII server server launch: ['deepspeed', '-H', '/tmp/tmp30gbq06t', '-i', 'localhost:0', '--master_port', '29500', '--master_addr', 'localhost', '--no_ssh_check', '--no_local_rank', '--no_python', '/usr/bin/python3', '-m', 'mii.legacy.launch.multi_gpu_server', '--deployment-name', 'bloom560m_deployment', '--load-balancer-port', '50050', '--restful-gateway-port', '51080', '--server-port', '50051', '--model-config', 'eyJtb2RlbCI6ICJiaWdzY2llbmNlL2Jsb29tLTU2MG0iLCAidGFzayI6ICJ0ZXh0LWdlbmVyYXRpb24iLCAiZHR5cGUiOiAidG9yY2guZmxvYXQxNiIsICJtb2RlbF9wYXRoIjogIi90bXAvbWlpX21vZGVscyIsICJsb2FkX3dpdGhfc3lzX21lbSI6IGZhbHNlLCAibWV0YV90ZW5zb3IiOiBmYWxzZSwgImRlcGxveV9yYW5rIjogWzBdLCAidG9yY2hfZGlzdF9wb3J0IjogMjk1MDAsICJyZXBsaWNhX251bSI6IDEsICJyZXBsaWNhX2NvbmZpZ3MiOiBbeyJob3N0bmFtZSI6ICJsb2NhbGhvc3QiLCAidGVuc29yX3BhcmFsbGVsX3BvcnRzIjogWzUwMDUxXSwgInRvcmNoX2Rpc3RfcG9ydCI6IDI5NTAwLCAiZ3B1X2luZGljZXMiOiBbMF19XSwgInByb2ZpbGVfbW9kZWxfdGltZSI6IGZhbHNlLCAic2tpcF9tb2RlbF9jaGVjayI6IHRydWUsICJoZl9hdXRoX3Rva2VuIjogbnVsbCwgInRydXN0X3JlbW90ZV9jb2RlIjogZmFsc2UsICJwaXBlbGluZV9rd2FyZ3MiOiB7fSwgImVuYWJsZV9kZWVwc3BlZWQiOiB0cnVlLCAiZW5hYmxlX3plcm8iOiBmYWxzZSwgImRzX2NvbmZpZyI6IHt9LCAidGVuc29yX3BhcmFsbGVsIjogMSwgImVuYWJsZV9jdWRhX2dyYXBoIjogZmFsc2UsICJyZXBsYWNlX3dpdGhfa2VybmVsX2luamVjdCI6IHRydWUsICJjaGVja3BvaW50X2RpY3QiOiBudWxsLCAibWF4X3Rva2VucyI6IDEwMjR9']\n",
            "[2023-12-13 09:12:42,738] [INFO] [server.py:103:_launch_server_process] MII server server launch: ['deepspeed', '-H', '/tmp/tmp30gbq06t', '-i', 'localhost:0', '--master_port', '29500', '--master_addr', 'localhost', '--no_ssh_check', '--no_local_rank', '--no_python', '/usr/bin/python3', '-m', 'mii.legacy.launch.multi_gpu_server', '--deployment-name', 'bloom560m_deployment', '--load-balancer-port', '50050', '--restful-gateway-port', '51080', '--server-port', '50051', '--model-config', 'eyJtb2RlbCI6ICJiaWdzY2llbmNlL2Jsb29tLTU2MG0iLCAidGFzayI6ICJ0ZXh0LWdlbmVyYXRpb24iLCAiZHR5cGUiOiAidG9yY2guZmxvYXQxNiIsICJtb2RlbF9wYXRoIjogIi90bXAvbWlpX21vZGVscyIsICJsb2FkX3dpdGhfc3lzX21lbSI6IGZhbHNlLCAibWV0YV90ZW5zb3IiOiBmYWxzZSwgImRlcGxveV9yYW5rIjogWzBdLCAidG9yY2hfZGlzdF9wb3J0IjogMjk1MDAsICJyZXBsaWNhX251bSI6IDEsICJyZXBsaWNhX2NvbmZpZ3MiOiBbeyJob3N0bmFtZSI6ICJsb2NhbGhvc3QiLCAidGVuc29yX3BhcmFsbGVsX3BvcnRzIjogWzUwMDUxXSwgInRvcmNoX2Rpc3RfcG9ydCI6IDI5NTAwLCAiZ3B1X2luZGljZXMiOiBbMF19XSwgInByb2ZpbGVfbW9kZWxfdGltZSI6IGZhbHNlLCAic2tpcF9tb2RlbF9jaGVjayI6IHRydWUsICJoZl9hdXRoX3Rva2VuIjogbnVsbCwgInRydXN0X3JlbW90ZV9jb2RlIjogZmFsc2UsICJwaXBlbGluZV9rd2FyZ3MiOiB7fSwgImVuYWJsZV9kZWVwc3BlZWQiOiB0cnVlLCAiZW5hYmxlX3plcm8iOiBmYWxzZSwgImRzX2NvbmZpZyI6IHt9LCAidGVuc29yX3BhcmFsbGVsIjogMSwgImVuYWJsZV9jdWRhX2dyYXBoIjogZmFsc2UsICJyZXBsYWNlX3dpdGhfa2VybmVsX2luamVjdCI6IHRydWUsICJjaGVja3BvaW50X2RpY3QiOiBudWxsLCAibWF4X3Rva2VucyI6IDEwMjR9']\n",
            "[2023-12-13 09:12:42,741] [INFO] [server.py:103:_launch_server_process] load balancer server launch: ['/usr/bin/python3', '-m', 'mii.legacy.launch.multi_gpu_server', '--deployment-name', 'bloom560m_deployment', '--load-balancer-port', '50050', '--restful-gateway-port', '51080', '--load-balancer', '--model-config', 'eyJtb2RlbCI6ICJiaWdzY2llbmNlL2Jsb29tLTU2MG0iLCAidGFzayI6ICJ0ZXh0LWdlbmVyYXRpb24iLCAiZHR5cGUiOiAidG9yY2guZmxvYXQxNiIsICJtb2RlbF9wYXRoIjogIi90bXAvbWlpX21vZGVscyIsICJsb2FkX3dpdGhfc3lzX21lbSI6IGZhbHNlLCAibWV0YV90ZW5zb3IiOiBmYWxzZSwgImRlcGxveV9yYW5rIjogWzBdLCAidG9yY2hfZGlzdF9wb3J0IjogMjk1MDAsICJyZXBsaWNhX251bSI6IDEsICJyZXBsaWNhX2NvbmZpZ3MiOiBbeyJob3N0bmFtZSI6ICJsb2NhbGhvc3QiLCAidGVuc29yX3BhcmFsbGVsX3BvcnRzIjogWzUwMDUxXSwgInRvcmNoX2Rpc3RfcG9ydCI6IDI5NTAwLCAiZ3B1X2luZGljZXMiOiBbMF19XSwgInByb2ZpbGVfbW9kZWxfdGltZSI6IGZhbHNlLCAic2tpcF9tb2RlbF9jaGVjayI6IHRydWUsICJoZl9hdXRoX3Rva2VuIjogbnVsbCwgInRydXN0X3JlbW90ZV9jb2RlIjogZmFsc2UsICJwaXBlbGluZV9rd2FyZ3MiOiB7fSwgImVuYWJsZV9kZWVwc3BlZWQiOiB0cnVlLCAiZW5hYmxlX3plcm8iOiBmYWxzZSwgImRzX2NvbmZpZyI6IHt9LCAidGVuc29yX3BhcmFsbGVsIjogMSwgImVuYWJsZV9jdWRhX2dyYXBoIjogZmFsc2UsICJyZXBsYWNlX3dpdGhfa2VybmVsX2luamVjdCI6IHRydWUsICJjaGVja3BvaW50X2RpY3QiOiBudWxsLCAibWF4X3Rva2VucyI6IDEwMjR9']\n",
            "[2023-12-13 09:12:42,741] [INFO] [server.py:103:_launch_server_process] load balancer server launch: ['/usr/bin/python3', '-m', 'mii.legacy.launch.multi_gpu_server', '--deployment-name', 'bloom560m_deployment', '--load-balancer-port', '50050', '--restful-gateway-port', '51080', '--load-balancer', '--model-config', 'eyJtb2RlbCI6ICJiaWdzY2llbmNlL2Jsb29tLTU2MG0iLCAidGFzayI6ICJ0ZXh0LWdlbmVyYXRpb24iLCAiZHR5cGUiOiAidG9yY2guZmxvYXQxNiIsICJtb2RlbF9wYXRoIjogIi90bXAvbWlpX21vZGVscyIsICJsb2FkX3dpdGhfc3lzX21lbSI6IGZhbHNlLCAibWV0YV90ZW5zb3IiOiBmYWxzZSwgImRlcGxveV9yYW5rIjogWzBdLCAidG9yY2hfZGlzdF9wb3J0IjogMjk1MDAsICJyZXBsaWNhX251bSI6IDEsICJyZXBsaWNhX2NvbmZpZ3MiOiBbeyJob3N0bmFtZSI6ICJsb2NhbGhvc3QiLCAidGVuc29yX3BhcmFsbGVsX3BvcnRzIjogWzUwMDUxXSwgInRvcmNoX2Rpc3RfcG9ydCI6IDI5NTAwLCAiZ3B1X2luZGljZXMiOiBbMF19XSwgInByb2ZpbGVfbW9kZWxfdGltZSI6IGZhbHNlLCAic2tpcF9tb2RlbF9jaGVjayI6IHRydWUsICJoZl9hdXRoX3Rva2VuIjogbnVsbCwgInRydXN0X3JlbW90ZV9jb2RlIjogZmFsc2UsICJwaXBlbGluZV9rd2FyZ3MiOiB7fSwgImVuYWJsZV9kZWVwc3BlZWQiOiB0cnVlLCAiZW5hYmxlX3plcm8iOiBmYWxzZSwgImRzX2NvbmZpZyI6IHt9LCAidGVuc29yX3BhcmFsbGVsIjogMSwgImVuYWJsZV9jdWRhX2dyYXBoIjogZmFsc2UsICJyZXBsYWNlX3dpdGhfa2VybmVsX2luamVjdCI6IHRydWUsICJjaGVja3BvaW50X2RpY3QiOiBudWxsLCAibWF4X3Rva2VucyI6IDEwMjR9']\n",
            "[2023-12-13 09:12:47,749] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:12:47,749] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:12:52,756] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:12:52,756] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:12:57,764] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:12:57,764] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:13:02,768] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:13:02,768] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:13:07,775] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:13:07,775] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:13:12,782] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:13:12,782] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:13:17,789] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:13:17,789] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:13:22,796] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:13:22,796] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:13:27,803] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:13:27,803] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:13:32,809] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:13:32,809] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:13:37,815] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:13:37,815] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:13:42,822] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:13:42,822] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:13:47,830] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:13:47,830] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:13:52,838] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:13:52,838] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:13:57,845] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:13:57,845] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:14:02,852] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:14:02,852] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:14:07,859] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:14:07,859] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:14:12,865] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:14:12,865] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:14:17,873] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:14:17,873] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:14:22,879] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:14:22,879] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:14:27,887] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:14:27,887] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:14:32,896] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:14:32,896] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:14:37,904] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:14:37,904] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:14:42,913] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:14:42,913] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:14:47,921] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:14:47,921] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:14:52,928] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:14:52,928] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:14:57,935] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:14:57,935] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:15:02,942] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:15:02,942] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:15:07,950] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:15:07,950] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:15:07,952] [INFO] [server.py:64:_wait_until_server_is_live] server has started on ports [50051]\n",
            "[2023-12-13 09:15:07,952] [INFO] [server.py:64:_wait_until_server_is_live] server has started on ports [50051]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!lsof -i:50051"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DeGFUem0dYtS",
        "outputId": "667ef9e5-58da-4431-fe54-a9b7ea60c080"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COMMAND  PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\n",
            "python3 1480 root   40u  IPv4  62907      0t0  TCP *:50051 (LISTEN)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ps -ef | grep 1480"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Taw703dDddCF",
        "outputId": "a7cee095-dd7f-4482-9903-5d33f678edff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root        1480    1423 45 09:12 ?        00:01:21 /usr/bin/python3 -m mii.legacy.launch.multi_gpu_\n",
            "root        2486     392  0 09:15 ?        00:00:00 /bin/bash -c ps -ef | grep 1480\n",
            "root        2488    2486  0 09:15 ?        00:00:00 grep 1480\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 查询"
      ],
      "metadata": {
        "id": "K1qjbYn5V36j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 唯一需要的键是\"query\"，字典之外的所有其他项目都将作为generatekwargs 传递。对于 Hugging Face 提供的模型，您可以在其生成文档中找到所有可能的参数。\n",
        "#import nest_asyncio\n",
        "#nest_asyncio.apply()\n",
        "\n",
        "import mii\n",
        "generator = mii.mii_query_handle(\"bloom560m_deployment\")\n",
        "result = generator.query({\"query\": [\"DeepSpeed is\", \"Seattle is\"]}, do_sample=True, max_new_tokens=30)\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPmaQQ5EV8iY",
        "outputId": "926459aa-a6d1-483b-f9d5-3d62d81e41ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-12-13 09:24:59,842] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter hf_auth_token is deprecated. Parameter will be removed. Please use the `pipeline_kwargs` field to pass kwargs to the HuggingFace pipeline creation.\n",
            "[2023-12-13 09:24:59,843] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter trust_remote_code is deprecated. Parameter will be removed. Please use the `pipeline_kwargs` field to pass kwargs to the HuggingFace pipeline creation.\n",
            "response: \"DeepSpeed is [ ] \"\n",
            "response: \"Seattle is The Crown:\\n The...\\n...\\n...\\n.........\\n...\\n...\\n...\\n...\\n...\\n...\\n......\\n...\\n......\\n...\\n......\\n...\\n...\\n...\\n...\\n......\\n\"\n",
            "time_taken: 0.654122353\n",
            "model_time_taken: -1\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 负载均衡\n",
        "\n",
        "您可以启动负载平衡器和 MII 服务器的多个副本。当您指定 的值时replica_num，mii.deploy()启动负载均衡器服务器和replica_num副本数。请注意，每个副本均由部署在同一服务器上的tensor_parallel服务器进程组成。\n",
        "```\n",
        "mii_configs = {\n",
        "...\n",
        "    \"tensor_parallel\": tensor_parallel,\n",
        "    \"replica_num\": replica_num,\n",
        "    \"hostfile\": hostfile\n",
        "}\n",
        "mii.deploy(...\n",
        "           mii_config=mii_configs,\n",
        "           ...)\n",
        "```\n",
        "\n",
        "客户端将请求发送到负载均衡器，负载均衡器将请求转发到副本，而不是将请求发送到各个 MII 服务器。目前，负载均衡器实现了简单的循环算法。replica_num当设置为 1 时，负载均衡器充当简单代理。\n",
        "\n",
        "hostfile是 DeepSpeed 启动器使用的主机文件的路径。当未指定 hostfile 时，DeepSpeed-MII 使用/job/hostfile为 DeepSpeed 定义的默认路径。有关详细信息，请参阅DeepSpeed 的文档。\n",
        "\n",
        "\n",
        "https://www.deepspeed.ai/getting-started/#resource-configuration-multi-node"
      ],
      "metadata": {
        "id": "uhNXb6HCdGhY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 关闭服务"
      ],
      "metadata": {
        "id": "C-QBdUiJWo2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import mii\n",
        "mii.terminate(\"bloom560m_deployment\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftp-NJ4aWsHe",
        "outputId": "a3c8848e-4ddb-4769-e431-602908448ff6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-12-13 09:25:31,531] [INFO] [terminate.py:12:terminate] Terminating server for bloom560m_deployment\n",
            "[2023-12-13 09:25:31,531] [INFO] [terminate.py:12:terminate] Terminating server for bloom560m_deployment\n",
            "[2023-12-13 09:25:31,535] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter hf_auth_token is deprecated. Parameter will be removed. Please use the `pipeline_kwargs` field to pass kwargs to the HuggingFace pipeline creation.\n",
            "[2023-12-13 09:25:31,536] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter trust_remote_code is deprecated. Parameter will be removed. Please use the `pipeline_kwargs` field to pass kwargs to the HuggingFace pipeline creation.\n",
            "[2023-12-13 09:25:31,550] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter hf_auth_token is deprecated. Parameter will be removed. Please use the `pipeline_kwargs` field to pass kwargs to the HuggingFace pipeline creation.\n",
            "[2023-12-13 09:25:31,551] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter trust_remote_code is deprecated. Parameter will be removed. Please use the `pipeline_kwargs` field to pass kwargs to the HuggingFace pipeline creation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## chat\n",
        "\n",
        "https://github.com/microsoft/DeepSpeed-MII/blob/main/mii/legacy/examples/local/chat/README.md\n",
        "\n",
        "\n",
        "**训练笔记：https://github.com/weedge/doraemon-nb/blob/main/ds_examples_chatbot.ipynb**\n",
        "\n",
        "\n",
        "使用[DeepSpeed-Chat](https://github.com/microsoft/DeepSpeedExamples/blob/master/applications/DeepSpeed-Chat/README.md)通过RLHF训练的模型，已经上传至huggingface:\n",
        "\n",
        "https://huggingface.co/AdamG012/chat-opt-1.3b-rlhf-actor-deepspeed"
      ],
      "metadata": {
        "id": "1YFj5Ck3Zr2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# deploy start server\n",
        "!cd DeepSpeed-MII/mii/legacy/examples/local/chat && (nohup python chat-server-example.py &)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XY6YhwXJZMgl",
        "outputId": "f866cb4f-7eda-42da-b327-f78d51f45018"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: appending output to 'nohup.out'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat DeepSpeed-MII/mii/legacy/examples/local/chat/nohup.out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUTAidYMkMjl",
        "outputId": "1689415c-6b1d-4710-e052-b2a1a731fe0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-12-13 09:45:03,835] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "2023-12-13 09:45:05.726142: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-13 09:45:05.726202: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-13 09:45:05.726229: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-13 09:45:06.874407: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Deploying AdamG012/chat-opt-1.3b-rlhf-actor-deepspeed...\n",
            "[2023-12-13 09:45:44,816] [INFO] [deployment.py:75:deploy] ************* MII is using DeepSpeed Optimizations to accelerate your model *************\n",
            "[2023-12-13 09:45:44,816] [INFO] [deployment.py:75:deploy] ************* MII is using DeepSpeed Optimizations to accelerate your model *************\n",
            "[2023-12-13 09:45:44,818] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter hf_auth_token is deprecated. Parameter will be removed. Please use the `pipeline_kwargs` field to pass kwargs to the HuggingFace pipeline creation.\n",
            "[2023-12-13 09:45:44,818] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter trust_remote_code is deprecated. Parameter will be removed. Please use the `pipeline_kwargs` field to pass kwargs to the HuggingFace pipeline creation.\n",
            "[2023-12-13 09:45:44,824] [INFO] [server.py:38:__init__] Hostfile /job/hostfile not found, creating hostfile.\n",
            "[2023-12-13 09:45:44,824] [INFO] [server.py:38:__init__] Hostfile /job/hostfile not found, creating hostfile.\n",
            "[2023-12-13 09:45:44,825] [INFO] [server.py:103:_launch_server_process] MII server server launch: ['deepspeed', '-H', '/tmp/tmp0staojpq', '-i', 'localhost:0', '--master_port', '29500', '--master_addr', 'localhost', '--no_ssh_check', '--no_local_rank', '--no_python', '/usr/bin/python3', '-m', 'mii.legacy.launch.multi_gpu_server', '--deployment-name', 'chat_example_deployment', '--load-balancer-port', '50050', '--restful-gateway-port', '51080', '--server-port', '50051', '--model-config', 'eyJtb2RlbCI6ICJBZGFtRzAxMi9jaGF0LW9wdC0xLjNiLXJsaGYtYWN0b3ItZGVlcHNwZWVkIiwgInRhc2siOiAidGV4dC1nZW5lcmF0aW9uIiwgImR0eXBlIjogInRvcmNoLmZsb2F0MzIiLCAibW9kZWxfcGF0aCI6ICIvdG1wL21paV9tb2RlbHMiLCAibG9hZF93aXRoX3N5c19tZW0iOiBmYWxzZSwgIm1ldGFfdGVuc29yIjogZmFsc2UsICJkZXBsb3lfcmFuayI6IFswXSwgInRvcmNoX2Rpc3RfcG9ydCI6IDI5NTAwLCAicmVwbGljYV9udW0iOiAxLCAicmVwbGljYV9jb25maWdzIjogW3siaG9zdG5hbWUiOiAibG9jYWxob3N0IiwgInRlbnNvcl9wYXJhbGxlbF9wb3J0cyI6IFs1MDA1MV0sICJ0b3JjaF9kaXN0X3BvcnQiOiAyOTUwMCwgImdwdV9pbmRpY2VzIjogWzBdfV0sICJwcm9maWxlX21vZGVsX3RpbWUiOiBmYWxzZSwgInNraXBfbW9kZWxfY2hlY2siOiB0cnVlLCAiaGZfYXV0aF90b2tlbiI6IG51bGwsICJ0cnVzdF9yZW1vdGVfY29kZSI6IGZhbHNlLCAicGlwZWxpbmVfa3dhcmdzIjoge30sICJlbmFibGVfZGVlcHNwZWVkIjogdHJ1ZSwgImVuYWJsZV96ZXJvIjogZmFsc2UsICJkc19jb25maWciOiB7fSwgInRlbnNvcl9wYXJhbGxlbCI6IDEsICJlbmFibGVfY3VkYV9ncmFwaCI6IGZhbHNlLCAicmVwbGFjZV93aXRoX2tlcm5lbF9pbmplY3QiOiB0cnVlLCAiY2hlY2twb2ludF9kaWN0IjogbnVsbCwgIm1heF90b2tlbnMiOiAxMDI0fQ==']\n",
            "[2023-12-13 09:45:44,825] [INFO] [server.py:103:_launch_server_process] MII server server launch: ['deepspeed', '-H', '/tmp/tmp0staojpq', '-i', 'localhost:0', '--master_port', '29500', '--master_addr', 'localhost', '--no_ssh_check', '--no_local_rank', '--no_python', '/usr/bin/python3', '-m', 'mii.legacy.launch.multi_gpu_server', '--deployment-name', 'chat_example_deployment', '--load-balancer-port', '50050', '--restful-gateway-port', '51080', '--server-port', '50051', '--model-config', 'eyJtb2RlbCI6ICJBZGFtRzAxMi9jaGF0LW9wdC0xLjNiLXJsaGYtYWN0b3ItZGVlcHNwZWVkIiwgInRhc2siOiAidGV4dC1nZW5lcmF0aW9uIiwgImR0eXBlIjogInRvcmNoLmZsb2F0MzIiLCAibW9kZWxfcGF0aCI6ICIvdG1wL21paV9tb2RlbHMiLCAibG9hZF93aXRoX3N5c19tZW0iOiBmYWxzZSwgIm1ldGFfdGVuc29yIjogZmFsc2UsICJkZXBsb3lfcmFuayI6IFswXSwgInRvcmNoX2Rpc3RfcG9ydCI6IDI5NTAwLCAicmVwbGljYV9udW0iOiAxLCAicmVwbGljYV9jb25maWdzIjogW3siaG9zdG5hbWUiOiAibG9jYWxob3N0IiwgInRlbnNvcl9wYXJhbGxlbF9wb3J0cyI6IFs1MDA1MV0sICJ0b3JjaF9kaXN0X3BvcnQiOiAyOTUwMCwgImdwdV9pbmRpY2VzIjogWzBdfV0sICJwcm9maWxlX21vZGVsX3RpbWUiOiBmYWxzZSwgInNraXBfbW9kZWxfY2hlY2siOiB0cnVlLCAiaGZfYXV0aF90b2tlbiI6IG51bGwsICJ0cnVzdF9yZW1vdGVfY29kZSI6IGZhbHNlLCAicGlwZWxpbmVfa3dhcmdzIjoge30sICJlbmFibGVfZGVlcHNwZWVkIjogdHJ1ZSwgImVuYWJsZV96ZXJvIjogZmFsc2UsICJkc19jb25maWciOiB7fSwgInRlbnNvcl9wYXJhbGxlbCI6IDEsICJlbmFibGVfY3VkYV9ncmFwaCI6IGZhbHNlLCAicmVwbGFjZV93aXRoX2tlcm5lbF9pbmplY3QiOiB0cnVlLCAiY2hlY2twb2ludF9kaWN0IjogbnVsbCwgIm1heF90b2tlbnMiOiAxMDI0fQ==']\n",
            "[2023-12-13 09:45:44,827] [INFO] [server.py:103:_launch_server_process] load balancer server launch: ['/usr/bin/python3', '-m', 'mii.legacy.launch.multi_gpu_server', '--deployment-name', 'chat_example_deployment', '--load-balancer-port', '50050', '--restful-gateway-port', '51080', '--load-balancer', '--model-config', 'eyJtb2RlbCI6ICJBZGFtRzAxMi9jaGF0LW9wdC0xLjNiLXJsaGYtYWN0b3ItZGVlcHNwZWVkIiwgInRhc2siOiAidGV4dC1nZW5lcmF0aW9uIiwgImR0eXBlIjogInRvcmNoLmZsb2F0MzIiLCAibW9kZWxfcGF0aCI6ICIvdG1wL21paV9tb2RlbHMiLCAibG9hZF93aXRoX3N5c19tZW0iOiBmYWxzZSwgIm1ldGFfdGVuc29yIjogZmFsc2UsICJkZXBsb3lfcmFuayI6IFswXSwgInRvcmNoX2Rpc3RfcG9ydCI6IDI5NTAwLCAicmVwbGljYV9udW0iOiAxLCAicmVwbGljYV9jb25maWdzIjogW3siaG9zdG5hbWUiOiAibG9jYWxob3N0IiwgInRlbnNvcl9wYXJhbGxlbF9wb3J0cyI6IFs1MDA1MV0sICJ0b3JjaF9kaXN0X3BvcnQiOiAyOTUwMCwgImdwdV9pbmRpY2VzIjogWzBdfV0sICJwcm9maWxlX21vZGVsX3RpbWUiOiBmYWxzZSwgInNraXBfbW9kZWxfY2hlY2siOiB0cnVlLCAiaGZfYXV0aF90b2tlbiI6IG51bGwsICJ0cnVzdF9yZW1vdGVfY29kZSI6IGZhbHNlLCAicGlwZWxpbmVfa3dhcmdzIjoge30sICJlbmFibGVfZGVlcHNwZWVkIjogdHJ1ZSwgImVuYWJsZV96ZXJvIjogZmFsc2UsICJkc19jb25maWciOiB7fSwgInRlbnNvcl9wYXJhbGxlbCI6IDEsICJlbmFibGVfY3VkYV9ncmFwaCI6IGZhbHNlLCAicmVwbGFjZV93aXRoX2tlcm5lbF9pbmplY3QiOiB0cnVlLCAiY2hlY2twb2ludF9kaWN0IjogbnVsbCwgIm1heF90b2tlbnMiOiAxMDI0fQ==']\n",
            "[2023-12-13 09:45:44,827] [INFO] [server.py:103:_launch_server_process] load balancer server launch: ['/usr/bin/python3', '-m', 'mii.legacy.launch.multi_gpu_server', '--deployment-name', 'chat_example_deployment', '--load-balancer-port', '50050', '--restful-gateway-port', '51080', '--load-balancer', '--model-config', 'eyJtb2RlbCI6ICJBZGFtRzAxMi9jaGF0LW9wdC0xLjNiLXJsaGYtYWN0b3ItZGVlcHNwZWVkIiwgInRhc2siOiAidGV4dC1nZW5lcmF0aW9uIiwgImR0eXBlIjogInRvcmNoLmZsb2F0MzIiLCAibW9kZWxfcGF0aCI6ICIvdG1wL21paV9tb2RlbHMiLCAibG9hZF93aXRoX3N5c19tZW0iOiBmYWxzZSwgIm1ldGFfdGVuc29yIjogZmFsc2UsICJkZXBsb3lfcmFuayI6IFswXSwgInRvcmNoX2Rpc3RfcG9ydCI6IDI5NTAwLCAicmVwbGljYV9udW0iOiAxLCAicmVwbGljYV9jb25maWdzIjogW3siaG9zdG5hbWUiOiAibG9jYWxob3N0IiwgInRlbnNvcl9wYXJhbGxlbF9wb3J0cyI6IFs1MDA1MV0sICJ0b3JjaF9kaXN0X3BvcnQiOiAyOTUwMCwgImdwdV9pbmRpY2VzIjogWzBdfV0sICJwcm9maWxlX21vZGVsX3RpbWUiOiBmYWxzZSwgInNraXBfbW9kZWxfY2hlY2siOiB0cnVlLCAiaGZfYXV0aF90b2tlbiI6IG51bGwsICJ0cnVzdF9yZW1vdGVfY29kZSI6IGZhbHNlLCAicGlwZWxpbmVfa3dhcmdzIjoge30sICJlbmFibGVfZGVlcHNwZWVkIjogdHJ1ZSwgImVuYWJsZV96ZXJvIjogZmFsc2UsICJkc19jb25maWciOiB7fSwgInRlbnNvcl9wYXJhbGxlbCI6IDEsICJlbmFibGVfY3VkYV9ncmFwaCI6IGZhbHNlLCAicmVwbGFjZV93aXRoX2tlcm5lbF9pbmplY3QiOiB0cnVlLCAiY2hlY2twb2ludF9kaWN0IjogbnVsbCwgIm1heF90b2tlbnMiOiAxMDI0fQ==']\n",
            "[2023-12-13 09:45:47,160] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-13 09:45:47,233] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-13 09:45:48,991] [INFO] [runner.py:570:main] cmd = /usr/bin/python3 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=localhost --master_port=29500 --no_python --no_local_rank --enable_each_rank_log=None /usr/bin/python3 -m mii.legacy.launch.multi_gpu_server --deployment-name chat_example_deployment --load-balancer-port 50050 --restful-gateway-port 51080 --server-port 50051 --model-config eyJtb2RlbCI6ICJBZGFtRzAxMi9jaGF0LW9wdC0xLjNiLXJsaGYtYWN0b3ItZGVlcHNwZWVkIiwgInRhc2siOiAidGV4dC1nZW5lcmF0aW9uIiwgImR0eXBlIjogInRvcmNoLmZsb2F0MzIiLCAibW9kZWxfcGF0aCI6ICIvdG1wL21paV9tb2RlbHMiLCAibG9hZF93aXRoX3N5c19tZW0iOiBmYWxzZSwgIm1ldGFfdGVuc29yIjogZmFsc2UsICJkZXBsb3lfcmFuayI6IFswXSwgInRvcmNoX2Rpc3RfcG9ydCI6IDI5NTAwLCAicmVwbGljYV9udW0iOiAxLCAicmVwbGljYV9jb25maWdzIjogW3siaG9zdG5hbWUiOiAibG9jYWxob3N0IiwgInRlbnNvcl9wYXJhbGxlbF9wb3J0cyI6IFs1MDA1MV0sICJ0b3JjaF9kaXN0X3BvcnQiOiAyOTUwMCwgImdwdV9pbmRpY2VzIjogWzBdfV0sICJwcm9maWxlX21vZGVsX3RpbWUiOiBmYWxzZSwgInNraXBfbW9kZWxfY2hlY2siOiB0cnVlLCAiaGZfYXV0aF90b2tlbiI6IG51bGwsICJ0cnVzdF9yZW1vdGVfY29kZSI6IGZhbHNlLCAicGlwZWxpbmVfa3dhcmdzIjoge30sICJlbmFibGVfZGVlcHNwZWVkIjogdHJ1ZSwgImVuYWJsZV96ZXJvIjogZmFsc2UsICJkc19jb25maWciOiB7fSwgInRlbnNvcl9wYXJhbGxlbCI6IDEsICJlbmFibGVfY3VkYV9ncmFwaCI6IGZhbHNlLCAicmVwbGFjZV93aXRoX2tlcm5lbF9pbmplY3QiOiB0cnVlLCAiY2hlY2twb2ludF9kaWN0IjogbnVsbCwgIm1heF90b2tlbnMiOiAxMDI0fQ==\n",
            "2023-12-13 09:45:49.299986: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-13 09:45:49.300052: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-13 09:45:49.300079: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "[2023-12-13 09:45:49,829] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:45:49,829] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "2023-12-13 09:45:50.496774: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "[2023-12-13 09:45:51,242] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-13 09:45:51,666] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter hf_auth_token is deprecated. Parameter will be removed. Please use the `pipeline_kwargs` field to pass kwargs to the HuggingFace pipeline creation.\n",
            "[2023-12-13 09:45:51,666] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter trust_remote_code is deprecated. Parameter will be removed. Please use the `pipeline_kwargs` field to pass kwargs to the HuggingFace pipeline creation.\n",
            "[2023-12-13 09:45:52,923] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE=libnccl-dev=2.15.5-1+cuda11.8\n",
            "[2023-12-13 09:45:52,923] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE_VERSION=2.15.5-1\n",
            "[2023-12-13 09:45:52,923] [INFO] [launch.py:138:main] 0 NCCL_VERSION=2.15.5-1\n",
            "[2023-12-13 09:45:52,923] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE_NAME=libnccl-dev\n",
            "[2023-12-13 09:45:52,923] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE=libnccl2=2.15.5-1+cuda11.8\n",
            "[2023-12-13 09:45:52,923] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE_NAME=libnccl2\n",
            "[2023-12-13 09:45:52,923] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE_VERSION=2.15.5-1\n",
            "[2023-12-13 09:45:52,923] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0]}\n",
            "[2023-12-13 09:45:52,923] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=1, node_rank=0\n",
            "[2023-12-13 09:45:52,923] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})\n",
            "[2023-12-13 09:45:52,923] [INFO] [launch.py:163:main] dist_world_size=1\n",
            "[2023-12-13 09:45:52,923] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0\n",
            "[2023-12-13 09:45:54,833] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:45:54,833] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:45:55,196] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "2023-12-13 09:45:57.061922: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-13 09:45:57.061972: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-13 09:45:57.062006: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-13 09:45:58.164593: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "[2023-12-13 09:45:59,267] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter hf_auth_token is deprecated. Parameter will be removed. Please use the `pipeline_kwargs` field to pass kwargs to the HuggingFace pipeline creation.\n",
            "[2023-12-13 09:45:59,267] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter trust_remote_code is deprecated. Parameter will be removed. Please use the `pipeline_kwargs` field to pass kwargs to the HuggingFace pipeline creation.\n",
            "\rconfig.json:   0%|          | 0.00/800 [00:00<?, ?B/s]\rconfig.json: 100%|██████████| 800/800 [00:00<00:00, 4.31MB/s]\n",
            "[2023-12-13 09:45:59,838] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:45:59,838] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "\rpytorch_model.bin:   0%|          | 0.00/3.24G [00:00<?, ?B/s]\rpytorch_model.bin:   0%|          | 10.5M/3.24G [00:00<04:18, 12.5MB/s]\rpytorch_model.bin:   1%|          | 21.0M/3.24G [00:01<02:36, 20.5MB/s]\rpytorch_model.bin:   1%|          | 31.5M/3.24G [00:01<02:16, 23.5MB/s]\rpytorch_model.bin:   1%|▏         | 41.9M/3.24G [00:01<01:55, 27.8MB/s]\rpytorch_model.bin:   2%|▏         | 52.4M/3.24G [00:02<01:43, 30.7MB/s]\rpytorch_model.bin:   2%|▏         | 62.9M/3.24G [00:02<01:45, 30.2MB/s]\rpytorch_model.bin:   2%|▏         | 73.4M/3.24G [00:02<01:38, 32.2MB/s]\rpytorch_model.bin:   3%|▎         | 83.9M/3.24G [00:02<01:35, 33.0MB/s]\rpytorch_model.bin:   3%|▎         | 94.4M/3.24G [00:03<01:31, 34.4MB/s]\rpytorch_model.bin:   3%|▎         | 105M/3.24G [00:03<01:28, 35.4MB/s] \rpytorch_model.bin:   4%|▎         | 115M/3.24G [00:03<01:26, 36.1MB/s][2023-12-13 09:46:04,843] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:46:04,843] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "\rpytorch_model.bin:   4%|▍         | 126M/3.24G [00:04<01:25, 36.4MB/s]\rpytorch_model.bin:   4%|▍         | 136M/3.24G [00:04<01:24, 36.7MB/s]\rpytorch_model.bin:   5%|▍         | 147M/3.24G [00:04<01:23, 36.8MB/s]\rpytorch_model.bin:   5%|▍         | 157M/3.24G [00:04<01:28, 34.8MB/s]\rpytorch_model.bin:   5%|▌         | 168M/3.24G [00:05<01:26, 35.7MB/s]\rpytorch_model.bin:   6%|▌         | 178M/3.24G [00:05<01:22, 37.2MB/s]\rpytorch_model.bin:   6%|▌         | 189M/3.24G [00:05<01:29, 34.2MB/s]\rpytorch_model.bin:   6%|▌         | 199M/3.24G [00:06<01:26, 35.2MB/s]\rpytorch_model.bin:   6%|▋         | 210M/3.24G [00:06<01:20, 37.5MB/s]\rpytorch_model.bin:   7%|▋         | 220M/3.24G [00:06<01:17, 38.7MB/s]\rpytorch_model.bin:   7%|▋         | 231M/3.24G [00:06<01:17, 39.0MB/s]\rpytorch_model.bin:   7%|▋         | 241M/3.24G [00:07<01:23, 36.0MB/s]\rpytorch_model.bin:   8%|▊         | 252M/3.24G [00:07<01:21, 36.5MB/s]\rpytorch_model.bin:   8%|▊         | 262M/3.24G [00:07<01:15, 39.4MB/s]\rpytorch_model.bin:   8%|▊         | 273M/3.24G [00:08<01:29, 33.3MB/s]\rpytorch_model.bin:   9%|▊         | 283M/3.24G [00:08<01:26, 34.3MB/s]\rpytorch_model.bin:   9%|▉         | 294M/3.24G [00:08<01:29, 32.7MB/s][2023-12-13 09:46:09,847] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:46:09,847] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "\rpytorch_model.bin:   9%|▉         | 304M/3.24G [00:09<01:26, 34.0MB/s]\rpytorch_model.bin:  10%|▉         | 315M/3.24G [00:09<01:30, 32.5MB/s]\rpytorch_model.bin:  10%|█         | 325M/3.24G [00:09<01:26, 33.7MB/s]\rpytorch_model.bin:  10%|█         | 336M/3.24G [00:10<01:23, 34.8MB/s]\rpytorch_model.bin:  11%|█         | 346M/3.24G [00:10<01:26, 33.3MB/s]\rpytorch_model.bin:  11%|█         | 357M/3.24G [00:10<01:24, 33.9MB/s]\rpytorch_model.bin:  11%|█▏        | 367M/3.24G [00:11<01:45, 27.1MB/s]\rpytorch_model.bin:  12%|█▏        | 377M/3.24G [00:11<01:41, 28.3MB/s]\rpytorch_model.bin:  12%|█▏        | 388M/3.24G [00:11<01:33, 30.6MB/s]\rpytorch_model.bin:  12%|█▏        | 398M/3.24G [00:12<01:27, 32.4MB/s]\rpytorch_model.bin:  13%|█▎        | 409M/3.24G [00:12<01:26, 32.6MB/s]\rpytorch_model.bin:  13%|█▎        | 419M/3.24G [00:12<01:26, 32.6MB/s]\rpytorch_model.bin:  13%|█▎        | 430M/3.24G [00:13<01:24, 33.1MB/s]\rpytorch_model.bin:  14%|█▎        | 440M/3.24G [00:13<01:23, 33.3MB/s]\rpytorch_model.bin:  14%|█▍        | 451M/3.24G [00:13<01:20, 34.6MB/s]\rpytorch_model.bin:  14%|█▍        | 461M/3.24G [00:13<01:18, 35.5MB/s][2023-12-13 09:46:14,852] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:46:14,852] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "\rpytorch_model.bin:  15%|█▍        | 472M/3.24G [00:14<01:17, 35.6MB/s]\rpytorch_model.bin:  15%|█▍        | 482M/3.24G [00:14<01:20, 34.0MB/s]\rpytorch_model.bin:  15%|█▌        | 493M/3.24G [00:14<01:18, 35.1MB/s]\rpytorch_model.bin:  16%|█▌        | 503M/3.24G [00:15<01:16, 35.8MB/s]\rpytorch_model.bin:  16%|█▌        | 514M/3.24G [00:15<01:14, 36.4MB/s]\rpytorch_model.bin:  16%|█▌        | 524M/3.24G [00:15<01:20, 33.8MB/s]\rpytorch_model.bin:  17%|█▋        | 535M/3.24G [00:16<01:17, 34.9MB/s]\rpytorch_model.bin:  17%|█▋        | 545M/3.24G [00:16<01:15, 35.7MB/s]\rpytorch_model.bin:  17%|█▋        | 556M/3.24G [00:16<01:13, 36.3MB/s]\rpytorch_model.bin:  17%|█▋        | 566M/3.24G [00:16<01:14, 35.6MB/s]\rpytorch_model.bin:  18%|█▊        | 577M/3.24G [00:17<01:19, 33.5MB/s]\rpytorch_model.bin:  18%|█▊        | 587M/3.24G [00:17<01:16, 34.7MB/s]\rpytorch_model.bin:  18%|█▊        | 598M/3.24G [00:17<01:14, 35.6MB/s]\rpytorch_model.bin:  19%|█▉        | 608M/3.24G [00:18<01:13, 35.8MB/s]\rpytorch_model.bin:  19%|█▉        | 619M/3.24G [00:18<01:18, 33.3MB/s]\rpytorch_model.bin:  19%|█▉        | 629M/3.24G [00:18<01:21, 31.8MB/s][2023-12-13 09:46:19,856] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:46:19,856] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "\rpytorch_model.bin:  20%|█▉        | 640M/3.24G [00:19<01:24, 30.8MB/s]\rpytorch_model.bin:  20%|██        | 650M/3.24G [00:19<01:25, 30.1MB/s]\rpytorch_model.bin:  20%|██        | 661M/3.24G [00:19<01:20, 31.9MB/s]\rpytorch_model.bin:  21%|██        | 671M/3.24G [00:20<01:22, 31.0MB/s]\rpytorch_model.bin:  21%|██        | 682M/3.24G [00:20<01:23, 30.4MB/s]\rpytorch_model.bin:  21%|██▏       | 692M/3.24G [00:20<01:19, 32.1MB/s]\rpytorch_model.bin:  22%|██▏       | 703M/3.24G [00:21<01:20, 31.3MB/s]\rpytorch_model.bin:  22%|██▏       | 713M/3.24G [00:21<01:17, 32.7MB/s]\rpytorch_model.bin:  22%|██▏       | 724M/3.24G [00:21<01:18, 31.9MB/s]\rpytorch_model.bin:  23%|██▎       | 734M/3.24G [00:22<01:15, 33.0MB/s]\rpytorch_model.bin:  23%|██▎       | 744M/3.24G [00:22<01:12, 34.2MB/s]\rpytorch_model.bin:  23%|██▎       | 755M/3.24G [00:22<01:14, 33.2MB/s]\rpytorch_model.bin:  24%|██▎       | 765M/3.24G [00:23<01:13, 33.7MB/s]\rpytorch_model.bin:  24%|██▍       | 776M/3.24G [00:23<01:10, 34.8MB/s]\rpytorch_model.bin:  24%|██▍       | 786M/3.24G [00:23<01:14, 32.7MB/s]\rpytorch_model.bin:  25%|██▍       | 797M/3.24G [00:23<01:11, 34.1MB/s][2023-12-13 09:46:24,861] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:46:24,861] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "\rpytorch_model.bin:  25%|██▍       | 807M/3.24G [00:24<01:09, 35.1MB/s]\rpytorch_model.bin:  25%|██▌       | 818M/3.24G [00:24<01:07, 35.8MB/s]\rpytorch_model.bin:  26%|██▌       | 828M/3.24G [00:24<01:06, 36.3MB/s]\rpytorch_model.bin:  26%|██▌       | 839M/3.24G [00:25<01:11, 33.6MB/s]\rpytorch_model.bin:  26%|██▌       | 849M/3.24G [00:25<01:13, 32.5MB/s]\rpytorch_model.bin:  27%|██▋       | 860M/3.24G [00:25<01:10, 33.9MB/s]\rpytorch_model.bin:  27%|██▋       | 870M/3.24G [00:26<01:17, 30.4MB/s]\rpytorch_model.bin:  27%|██▋       | 881M/3.24G [00:26<01:13, 31.9MB/s]\rpytorch_model.bin:  28%|██▊       | 891M/3.24G [00:26<01:15, 31.2MB/s]\rpytorch_model.bin:  28%|██▊       | 902M/3.24G [00:27<01:17, 30.1MB/s]\rpytorch_model.bin:  28%|██▊       | 912M/3.24G [00:27<01:12, 32.1MB/s]\rpytorch_model.bin:  29%|██▊       | 923M/3.24G [00:28<01:32, 25.0MB/s]\rpytorch_model.bin:  29%|██▉       | 933M/3.24G [00:28<01:22, 27.9MB/s]\rpytorch_model.bin:  29%|██▉       | 944M/3.24G [00:28<01:20, 28.6MB/s][2023-12-13 09:46:29,866] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:46:29,866] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "\rpytorch_model.bin:  29%|██▉       | 954M/3.24G [00:29<01:14, 30.5MB/s]\rpytorch_model.bin:  30%|██▉       | 965M/3.24G [00:29<01:10, 32.3MB/s]\rpytorch_model.bin:  30%|███       | 975M/3.24G [00:29<01:10, 32.3MB/s]\rpytorch_model.bin:  30%|███       | 986M/3.24G [00:29<01:07, 33.6MB/s]\rpytorch_model.bin:  31%|███       | 996M/3.24G [00:30<01:14, 30.2MB/s]\rpytorch_model.bin:  31%|███       | 1.01G/3.24G [00:30<01:09, 32.1MB/s]\rpytorch_model.bin:  31%|███▏      | 1.02G/3.24G [00:30<01:06, 33.5MB/s]\rpytorch_model.bin:  32%|███▏      | 1.03G/3.24G [00:31<01:09, 31.8MB/s]\rpytorch_model.bin:  32%|███▏      | 1.04G/3.24G [00:31<01:11, 30.8MB/s]\rpytorch_model.bin:  32%|███▏      | 1.05G/3.24G [00:32<01:12, 30.1MB/s]\rpytorch_model.bin:  33%|███▎      | 1.06G/3.24G [00:32<01:13, 29.7MB/s]\rpytorch_model.bin:  33%|███▎      | 1.07G/3.24G [00:32<01:13, 29.5MB/s]\rpytorch_model.bin:  33%|███▎      | 1.08G/3.24G [00:33<01:13, 29.4MB/s]\rpytorch_model.bin:  34%|███▎      | 1.09G/3.24G [00:33<01:08, 31.3MB/s]\rpytorch_model.bin:  34%|███▍      | 1.10G/3.24G [00:33<01:10, 30.1MB/s][2023-12-13 09:46:34,870] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:46:34,870] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "\rpytorch_model.bin:  34%|███▍      | 1.11G/3.24G [00:34<01:09, 30.5MB/s]\rpytorch_model.bin:  35%|███▍      | 1.12G/3.24G [00:34<01:07, 31.5MB/s]\rpytorch_model.bin:  35%|███▍      | 1.13G/3.24G [00:34<01:10, 29.9MB/s]\rpytorch_model.bin:  35%|███▌      | 1.14G/3.24G [00:35<01:05, 31.8MB/s]\rpytorch_model.bin:  36%|███▌      | 1.15G/3.24G [00:35<01:02, 33.3MB/s]\rpytorch_model.bin:  36%|███▌      | 1.16G/3.24G [00:35<01:04, 32.3MB/s]\rpytorch_model.bin:  36%|███▋      | 1.17G/3.24G [00:36<01:01, 33.3MB/s]\rpytorch_model.bin:  37%|███▋      | 1.18G/3.24G [00:36<01:04, 32.0MB/s]\rpytorch_model.bin:  37%|███▋      | 1.20G/3.24G [00:36<01:00, 33.5MB/s]\rpytorch_model.bin:  37%|███▋      | 1.21G/3.24G [00:37<01:11, 28.4MB/s]\rpytorch_model.bin:  38%|███▊      | 1.22G/3.24G [00:37<01:05, 30.7MB/s]\rpytorch_model.bin:  38%|███▊      | 1.23G/3.24G [00:37<01:01, 32.5MB/s]\rpytorch_model.bin:  38%|███▊      | 1.24G/3.24G [00:38<00:59, 33.8MB/s]\rpytorch_model.bin:  39%|███▊      | 1.25G/3.24G [00:38<01:00, 32.7MB/s]\rpytorch_model.bin:  39%|███▉      | 1.26G/3.24G [00:38<01:06, 29.7MB/s][2023-12-13 09:46:39,875] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:46:39,875] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "\rpytorch_model.bin:  39%|███▉      | 1.27G/3.24G [00:39<01:02, 31.7MB/s]\rpytorch_model.bin:  40%|███▉      | 1.28G/3.24G [00:39<00:58, 33.3MB/s]\rpytorch_model.bin:  40%|███▉      | 1.29G/3.24G [00:39<00:59, 32.5MB/s]\rpytorch_model.bin:  40%|████      | 1.30G/3.24G [00:39<00:57, 33.9MB/s]\rpytorch_model.bin:  41%|████      | 1.31G/3.24G [00:40<01:24, 22.7MB/s]\rpytorch_model.bin:  41%|████      | 1.32G/3.24G [00:41<01:18, 24.5MB/s]\rpytorch_model.bin:  41%|████      | 1.33G/3.24G [00:41<01:09, 27.4MB/s]\rpytorch_model.bin:  41%|████▏     | 1.34G/3.24G [00:41<01:03, 29.9MB/s]\rpytorch_model.bin:  42%|████▏     | 1.35G/3.24G [00:41<01:01, 30.5MB/s]\rpytorch_model.bin:  42%|████▏     | 1.36G/3.24G [00:42<01:04, 29.2MB/s]\rpytorch_model.bin:  42%|████▏     | 1.37G/3.24G [00:42<01:01, 30.4MB/s]\rpytorch_model.bin:  43%|████▎     | 1.38G/3.24G [00:42<00:57, 32.2MB/s]\rpytorch_model.bin:  43%|████▎     | 1.39G/3.24G [00:43<00:59, 30.9MB/s]\rpytorch_model.bin:  43%|████▎     | 1.41G/3.24G [00:43<00:55, 32.7MB/s]\rpytorch_model.bin:  44%|████▎     | 1.42G/3.24G [00:43<00:53, 34.1MB/s][2023-12-13 09:46:44,877] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:46:44,877] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "\rpytorch_model.bin:  44%|████▍     | 1.43G/3.24G [00:44<00:51, 35.0MB/s]\rpytorch_model.bin:  44%|████▍     | 1.44G/3.24G [00:44<00:50, 35.8MB/s]\rpytorch_model.bin:  45%|████▍     | 1.45G/3.24G [00:44<00:49, 35.9MB/s]\rpytorch_model.bin:  45%|████▌     | 1.46G/3.24G [00:45<00:48, 36.4MB/s]\rpytorch_model.bin:  45%|████▌     | 1.47G/3.24G [00:45<00:59, 29.9MB/s]\rpytorch_model.bin:  46%|████▌     | 1.48G/3.24G [00:46<01:04, 27.2MB/s]\rpytorch_model.bin:  46%|████▌     | 1.49G/3.24G [00:46<01:07, 25.9MB/s]\rpytorch_model.bin:  46%|████▋     | 1.50G/3.24G [00:46<01:13, 23.5MB/s]\rpytorch_model.bin:  47%|████▋     | 1.51G/3.24G [00:47<01:14, 23.3MB/s]\rpytorch_model.bin:  47%|████▋     | 1.52G/3.24G [00:47<01:18, 22.0MB/s]\rpytorch_model.bin:  47%|████▋     | 1.53G/3.24G [00:48<01:16, 22.2MB/s]\rpytorch_model.bin:  48%|████▊     | 1.54G/3.24G [00:48<01:15, 22.4MB/s][2023-12-13 09:46:49,882] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:46:49,882] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "\rpytorch_model.bin:  48%|████▊     | 1.55G/3.24G [00:49<01:14, 22.6MB/s]\rpytorch_model.bin:  48%|████▊     | 1.56G/3.24G [00:49<01:13, 22.7MB/s]\rpytorch_model.bin:  49%|████▊     | 1.57G/3.24G [00:50<01:12, 22.8MB/s]\rpytorch_model.bin:  49%|████▉     | 1.58G/3.24G [00:50<01:12, 22.9MB/s]\rpytorch_model.bin:  49%|████▉     | 1.59G/3.24G [00:51<01:11, 22.9MB/s]\rpytorch_model.bin:  50%|████▉     | 1.60G/3.24G [00:51<01:11, 23.0MB/s]\rpytorch_model.bin:  50%|████▉     | 1.61G/3.24G [00:52<01:10, 23.0MB/s]\rpytorch_model.bin:  50%|█████     | 1.63G/3.24G [00:52<01:09, 23.0MB/s]\rpytorch_model.bin:  51%|█████     | 1.64G/3.24G [00:53<01:09, 23.0MB/s]\rpytorch_model.bin:  51%|█████     | 1.65G/3.24G [00:53<01:09, 23.0MB/s]\rpytorch_model.bin:  51%|█████     | 1.66G/3.24G [00:53<01:08, 23.0MB/s][2023-12-13 09:46:54,886] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:46:54,886] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "\rpytorch_model.bin:  52%|█████▏    | 1.67G/3.24G [00:54<01:07, 23.1MB/s]\rpytorch_model.bin:  52%|█████▏    | 1.68G/3.24G [00:54<01:07, 23.1MB/s]\rpytorch_model.bin:  52%|█████▏    | 1.69G/3.24G [00:55<01:07, 23.1MB/s]\rpytorch_model.bin:  52%|█████▏    | 1.70G/3.24G [00:55<01:03, 24.4MB/s]\rpytorch_model.bin:  53%|█████▎    | 1.71G/3.24G [00:56<01:11, 21.3MB/s]\rpytorch_model.bin:  53%|█████▎    | 1.72G/3.24G [00:56<01:13, 20.6MB/s]\rpytorch_model.bin:  53%|█████▎    | 1.73G/3.24G [00:57<01:14, 20.2MB/s]\rpytorch_model.bin:  54%|█████▍    | 1.74G/3.24G [00:57<01:15, 19.9MB/s]\rpytorch_model.bin:  54%|█████▍    | 1.75G/3.24G [00:58<01:15, 19.7MB/s]\rpytorch_model.bin:  54%|█████▍    | 1.76G/3.24G [00:58<01:11, 20.5MB/s][2023-12-13 09:46:59,891] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:46:59,891] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "\rpytorch_model.bin:  55%|█████▍    | 1.77G/3.24G [00:59<01:12, 20.2MB/s]\rpytorch_model.bin:  55%|█████▌    | 1.78G/3.24G [00:59<01:09, 20.9MB/s]\rpytorch_model.bin:  55%|█████▌    | 1.79G/3.24G [01:00<01:07, 21.5MB/s]\rpytorch_model.bin:  56%|█████▌    | 1.80G/3.24G [01:00<01:08, 20.9MB/s]\rpytorch_model.bin:  56%|█████▌    | 1.81G/3.24G [01:01<01:06, 21.4MB/s]\rpytorch_model.bin:  56%|█████▋    | 1.82G/3.24G [01:01<01:04, 21.9MB/s]\rpytorch_model.bin:  57%|█████▋    | 1.84G/3.24G [01:02<01:03, 22.2MB/s]\rpytorch_model.bin:  57%|█████▋    | 1.85G/3.24G [01:02<01:01, 22.5MB/s]\rpytorch_model.bin:  57%|█████▋    | 1.86G/3.24G [01:03<01:00, 22.6MB/s]\rpytorch_model.bin:  58%|█████▊    | 1.87G/3.24G [01:03<01:00, 22.8MB/s][2023-12-13 09:47:04,896] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:47:04,896] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "\rpytorch_model.bin:  58%|█████▊    | 1.88G/3.24G [01:04<00:59, 22.9MB/s]\rpytorch_model.bin:  58%|█████▊    | 1.89G/3.24G [01:04<00:55, 24.1MB/s]\rpytorch_model.bin:  59%|█████▊    | 1.90G/3.24G [01:04<00:56, 23.8MB/s]\rpytorch_model.bin:  59%|█████▉    | 1.91G/3.24G [01:05<00:56, 23.6MB/s]\rpytorch_model.bin:  59%|█████▉    | 1.92G/3.24G [01:05<00:56, 23.4MB/s]\rpytorch_model.bin:  60%|█████▉    | 1.93G/3.24G [01:06<00:55, 23.4MB/s]\rpytorch_model.bin:  60%|█████▉    | 1.94G/3.24G [01:06<00:55, 23.3MB/s]\rpytorch_model.bin:  60%|██████    | 1.95G/3.24G [01:07<00:55, 23.2MB/s]\rpytorch_model.bin:  61%|██████    | 1.96G/3.24G [01:07<00:54, 23.2MB/s]\rpytorch_model.bin:  61%|██████    | 1.97G/3.24G [01:08<00:54, 23.2MB/s]\rpytorch_model.bin:  61%|██████    | 1.98G/3.24G [01:08<00:54, 23.1MB/s]\rpytorch_model.bin:  62%|██████▏   | 1.99G/3.24G [01:08<00:51, 24.3MB/s][2023-12-13 09:47:09,900] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:47:09,900] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "\rpytorch_model.bin:  62%|██████▏   | 2.00G/3.24G [01:09<00:51, 24.0MB/s]\rpytorch_model.bin:  62%|██████▏   | 2.01G/3.24G [01:09<00:51, 23.7MB/s]\rpytorch_model.bin:  63%|██████▎   | 2.02G/3.24G [01:10<00:51, 23.5MB/s]\rpytorch_model.bin:  63%|██████▎   | 2.03G/3.24G [01:10<00:51, 23.5MB/s]\rpytorch_model.bin:  63%|██████▎   | 2.04G/3.24G [01:11<00:50, 23.4MB/s]\rpytorch_model.bin:  64%|██████▎   | 2.06G/3.24G [01:11<00:48, 24.5MB/s]\rpytorch_model.bin:  64%|██████▍   | 2.07G/3.24G [01:12<00:48, 24.2MB/s]\rpytorch_model.bin:  64%|██████▍   | 2.08G/3.24G [01:12<00:48, 24.0MB/s]\rpytorch_model.bin:  64%|██████▍   | 2.09G/3.24G [01:12<00:46, 25.0MB/s]\rpytorch_model.bin:  65%|██████▍   | 2.10G/3.24G [01:13<00:48, 23.6MB/s]\rpytorch_model.bin:  65%|██████▌   | 2.11G/3.24G [01:13<00:49, 23.0MB/s][2023-12-13 09:47:14,905] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:47:14,905] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "\rpytorch_model.bin:  65%|██████▌   | 2.12G/3.24G [01:14<00:45, 24.4MB/s]\rpytorch_model.bin:  66%|██████▌   | 2.13G/3.24G [01:14<00:46, 24.1MB/s]\rpytorch_model.bin:  66%|██████▌   | 2.14G/3.24G [01:15<00:43, 25.3MB/s]\rpytorch_model.bin:  66%|██████▋   | 2.15G/3.24G [01:15<00:49, 21.9MB/s]\rpytorch_model.bin:  67%|██████▋   | 2.16G/3.24G [01:16<00:47, 22.7MB/s]\rpytorch_model.bin:  67%|██████▋   | 2.17G/3.24G [01:16<00:44, 24.2MB/s]\rpytorch_model.bin:  67%|██████▋   | 2.18G/3.24G [01:16<00:41, 25.4MB/s]\rpytorch_model.bin:  68%|██████▊   | 2.19G/3.24G [01:17<00:37, 27.5MB/s]\rpytorch_model.bin:  68%|██████▊   | 2.20G/3.24G [01:17<00:37, 27.9MB/s]\rpytorch_model.bin:  68%|██████▊   | 2.21G/3.24G [01:17<00:36, 28.3MB/s]\rpytorch_model.bin:  69%|██████▊   | 2.22G/3.24G [01:18<00:33, 30.5MB/s]\rpytorch_model.bin:  69%|██████▉   | 2.23G/3.24G [01:18<00:33, 30.0MB/s]\rpytorch_model.bin:  69%|██████▉   | 2.24G/3.24G [01:18<00:32, 30.1MB/s][2023-12-13 09:47:19,910] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:47:19,910] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "\rpytorch_model.bin:  70%|██████▉   | 2.25G/3.24G [01:19<00:31, 31.6MB/s]\rpytorch_model.bin:  70%|██████▉   | 2.26G/3.24G [01:19<00:29, 33.2MB/s]\rpytorch_model.bin:  70%|███████   | 2.28G/3.24G [01:19<00:27, 34.4MB/s]\rpytorch_model.bin:  71%|███████   | 2.29G/3.24G [01:20<00:30, 31.1MB/s]\rpytorch_model.bin:  71%|███████   | 2.30G/3.24G [01:20<00:28, 32.8MB/s]\rpytorch_model.bin:  71%|███████▏  | 2.31G/3.24G [01:20<00:27, 34.1MB/s]\rpytorch_model.bin:  72%|███████▏  | 2.32G/3.24G [01:20<00:26, 35.2MB/s]\rpytorch_model.bin:  72%|███████▏  | 2.33G/3.24G [01:21<00:25, 36.0MB/s]\rpytorch_model.bin:  72%|███████▏  | 2.34G/3.24G [01:21<00:37, 23.9MB/s]\rpytorch_model.bin:  73%|███████▎  | 2.35G/3.24G [01:22<00:32, 27.0MB/s]\rpytorch_model.bin:  73%|███████▎  | 2.36G/3.24G [01:22<00:31, 27.5MB/s]\rpytorch_model.bin:  73%|███████▎  | 2.37G/3.24G [01:22<00:29, 29.3MB/s]\rpytorch_model.bin:  74%|███████▎  | 2.38G/3.24G [01:23<00:28, 29.8MB/s]\rpytorch_model.bin:  74%|███████▍  | 2.39G/3.24G [01:23<00:32, 26.4MB/s]\rpytorch_model.bin:  74%|███████▍  | 2.40G/3.24G [01:24<00:28, 28.8MB/s][2023-12-13 09:47:24,914] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:47:24,914] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "\rpytorch_model.bin:  75%|███████▍  | 2.41G/3.24G [01:24<00:28, 29.1MB/s]\rpytorch_model.bin:  75%|███████▍  | 2.42G/3.24G [01:24<00:26, 31.0MB/s]\rpytorch_model.bin:  75%|███████▌  | 2.43G/3.24G [01:25<00:28, 27.8MB/s]\rpytorch_model.bin:  76%|███████▌  | 2.44G/3.24G [01:25<00:25, 31.5MB/s]\rpytorch_model.bin:  76%|███████▌  | 2.45G/3.24G [01:25<00:23, 33.2MB/s]\rpytorch_model.bin:  76%|███████▌  | 2.46G/3.24G [01:25<00:22, 33.8MB/s]\rpytorch_model.bin:  76%|███████▋  | 2.47G/3.24G [01:26<00:22, 34.6MB/s]\rpytorch_model.bin:  77%|███████▋  | 2.49G/3.24G [01:26<00:22, 33.9MB/s]\rpytorch_model.bin:  77%|███████▋  | 2.50G/3.24G [01:27<00:37, 19.9MB/s]\rpytorch_model.bin:  77%|███████▋  | 2.51G/3.24G [01:27<00:31, 23.2MB/s]\rpytorch_model.bin:  78%|███████▊  | 2.52G/3.24G [01:28<00:27, 26.1MB/s]\rpytorch_model.bin:  78%|███████▊  | 2.53G/3.24G [01:28<00:24, 28.8MB/s]\rpytorch_model.bin:  78%|███████▊  | 2.54G/3.24G [01:28<00:22, 31.0MB/s]\rpytorch_model.bin:  79%|███████▊  | 2.55G/3.24G [01:29<00:21, 32.7MB/s][2023-12-13 09:47:29,919] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:47:29,919] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "\rpytorch_model.bin:  79%|███████▉  | 2.56G/3.24G [01:29<00:19, 33.9MB/s]\rpytorch_model.bin:  79%|███████▉  | 2.57G/3.24G [01:29<00:19, 34.8MB/s]\rpytorch_model.bin:  80%|███████▉  | 2.58G/3.24G [01:30<00:24, 27.0MB/s]\rpytorch_model.bin:  80%|████████  | 2.59G/3.24G [01:30<00:22, 29.0MB/s]\rpytorch_model.bin:  80%|████████  | 2.60G/3.24G [01:30<00:23, 26.9MB/s]\rpytorch_model.bin:  81%|████████  | 2.61G/3.24G [01:31<00:19, 31.5MB/s]\rpytorch_model.bin:  81%|████████  | 2.62G/3.24G [01:31<00:20, 29.4MB/s]\rpytorch_model.bin:  81%|████████▏ | 2.63G/3.24G [01:31<00:20, 29.2MB/s]\rpytorch_model.bin:  82%|████████▏ | 2.64G/3.24G [01:32<00:20, 29.1MB/s]\rpytorch_model.bin:  82%|████████▏ | 2.65G/3.24G [01:32<00:19, 29.2MB/s]\rpytorch_model.bin:  82%|████████▏ | 2.66G/3.24G [01:32<00:18, 31.0MB/s]\rpytorch_model.bin:  83%|████████▎ | 2.67G/3.24G [01:33<00:18, 30.4MB/s]\rpytorch_model.bin:  83%|████████▎ | 2.68G/3.24G [01:33<00:18, 30.0MB/s]\rpytorch_model.bin:  83%|████████▎ | 2.69G/3.24G [01:33<00:16, 31.9MB/s][2023-12-13 09:47:34,923] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:47:34,923] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "\rpytorch_model.bin:  84%|████████▎ | 2.71G/3.24G [01:34<00:17, 31.0MB/s]\rpytorch_model.bin:  84%|████████▍ | 2.72G/3.24G [01:34<00:16, 30.6MB/s]\rpytorch_model.bin:  84%|████████▍ | 2.73G/3.24G [01:34<00:15, 32.1MB/s]\rpytorch_model.bin:  85%|████████▍ | 2.74G/3.24G [01:35<00:15, 31.4MB/s]\rpytorch_model.bin:  85%|████████▍ | 2.75G/3.24G [01:35<00:14, 32.8MB/s]\rpytorch_model.bin:  85%|████████▌ | 2.76G/3.24G [01:35<00:15, 31.9MB/s]\rpytorch_model.bin:  86%|████████▌ | 2.77G/3.24G [01:36<00:14, 33.1MB/s]\rpytorch_model.bin:  86%|████████▌ | 2.78G/3.24G [01:36<00:15, 29.6MB/s]\rpytorch_model.bin:  86%|████████▌ | 2.79G/3.24G [01:36<00:15, 29.5MB/s]\rpytorch_model.bin:  87%|████████▋ | 2.80G/3.24G [01:37<00:14, 30.8MB/s]\rpytorch_model.bin:  87%|████████▋ | 2.81G/3.24G [01:37<00:13, 31.1MB/s]\rpytorch_model.bin:  87%|████████▋ | 2.82G/3.24G [01:37<00:13, 31.0MB/s]\rpytorch_model.bin:  87%|████████▋ | 2.83G/3.24G [01:38<00:14, 28.8MB/s]\rpytorch_model.bin:  88%|████████▊ | 2.84G/3.24G [01:38<00:13, 29.0MB/s][2023-12-13 09:47:39,928] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:47:39,928] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "\rpytorch_model.bin:  88%|████████▊ | 2.85G/3.24G [01:39<00:14, 26.6MB/s]\rpytorch_model.bin:  88%|████████▊ | 2.86G/3.24G [01:39<00:15, 24.0MB/s]\rpytorch_model.bin:  89%|████████▉ | 2.87G/3.24G [01:40<00:17, 21.1MB/s]\rpytorch_model.bin:  89%|████████▉ | 2.88G/3.24G [01:40<00:17, 20.5MB/s]\rpytorch_model.bin:  89%|████████▉ | 2.89G/3.24G [01:41<00:17, 20.0MB/s]\rpytorch_model.bin:  90%|████████▉ | 2.90G/3.24G [01:42<00:18, 17.9MB/s]\rpytorch_model.bin:  90%|█████████ | 2.92G/3.24G [01:42<00:19, 16.7MB/s]\rpytorch_model.bin:  90%|█████████ | 2.93G/3.24G [01:43<00:19, 16.0MB/s][2023-12-13 09:47:44,932] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:47:44,932] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "\rpytorch_model.bin:  91%|█████████ | 2.94G/3.24G [01:44<00:18, 16.1MB/s]\rpytorch_model.bin:  91%|█████████ | 2.95G/3.24G [01:45<00:18, 15.6MB/s]\rpytorch_model.bin:  91%|█████████▏| 2.96G/3.24G [01:45<00:17, 15.8MB/s]\rpytorch_model.bin:  92%|█████████▏| 2.97G/3.24G [01:46<00:16, 16.0MB/s]\rpytorch_model.bin:  92%|█████████▏| 2.98G/3.24G [01:47<00:17, 14.9MB/s]\rpytorch_model.bin:  92%|█████████▏| 2.99G/3.24G [01:47<00:17, 14.2MB/s]\rpytorch_model.bin:  93%|█████████▎| 3.00G/3.24G [01:48<00:17, 13.7MB/s][2023-12-13 09:47:49,937] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:47:49,937] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "\rpytorch_model.bin:  93%|█████████▎| 3.01G/3.24G [01:49<00:16, 13.5MB/s]\rpytorch_model.bin:  93%|█████████▎| 3.02G/3.24G [01:50<00:16, 13.3MB/s]\rpytorch_model.bin:  94%|█████████▎| 3.03G/3.24G [01:51<00:15, 13.6MB/s]\rpytorch_model.bin:  94%|█████████▍| 3.04G/3.24G [01:51<00:14, 13.4MB/s]\rpytorch_model.bin:  94%|█████████▍| 3.05G/3.24G [01:52<00:13, 13.6MB/s]\rpytorch_model.bin:  95%|█████████▍| 3.06G/3.24G [01:53<00:12, 13.7MB/s][2023-12-13 09:47:54,941] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:47:54,941] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "\rpytorch_model.bin:  95%|█████████▍| 3.07G/3.24G [01:54<00:12, 13.6MB/s]\rpytorch_model.bin:  95%|█████████▌| 3.08G/3.24G [01:54<00:11, 13.8MB/s]\rpytorch_model.bin:  96%|█████████▌| 3.09G/3.24G [01:55<00:10, 13.7MB/s]\rpytorch_model.bin:  96%|█████████▌| 3.10G/3.24G [01:56<00:09, 13.7MB/s]\rpytorch_model.bin:  96%|█████████▌| 3.11G/3.24G [01:57<00:08, 13.9MB/s]\rpytorch_model.bin:  97%|█████████▋| 3.12G/3.24G [01:57<00:08, 13.8MB/s]\rpytorch_model.bin:  97%|█████████▋| 3.14G/3.24G [01:58<00:07, 14.0MB/s][2023-12-13 09:47:59,945] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:47:59,945] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "\rpytorch_model.bin:  97%|█████████▋| 3.15G/3.24G [01:59<00:06, 14.1MB/s]\rpytorch_model.bin:  98%|█████████▊| 3.16G/3.24G [02:00<00:05, 14.5MB/s]\rpytorch_model.bin:  98%|█████████▊| 3.17G/3.24G [02:00<00:04, 14.5MB/s]\rpytorch_model.bin:  98%|█████████▊| 3.18G/3.24G [02:01<00:03, 15.0MB/s]\rpytorch_model.bin:  99%|█████████▊| 3.19G/3.24G [02:02<00:03, 15.4MB/s]\rpytorch_model.bin:  99%|█████████▉| 3.20G/3.24G [02:02<00:02, 16.3MB/s]\rpytorch_model.bin:  99%|█████████▉| 3.21G/3.24G [02:03<00:01, 16.5MB/s]\rpytorch_model.bin:  99%|█████████▉| 3.22G/3.24G [02:03<00:00, 17.2MB/s][2023-12-13 09:48:04,950] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:48:04,950] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "\rpytorch_model.bin: 100%|█████████▉| 3.23G/3.24G [02:04<00:00, 18.5MB/s]\rpytorch_model.bin: 100%|██████████| 3.24G/3.24G [02:04<00:00, 18.7MB/s]\rpytorch_model.bin: 100%|██████████| 3.24G/3.24G [02:04<00:00, 26.0MB/s]\n",
            "[2023-12-13 09:48:09,954] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:48:09,954] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:48:14,959] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:48:14,959] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "\rvocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]\rvocab.json: 100%|██████████| 798k/798k [00:00<00:00, 2.43MB/s]\rvocab.json: 100%|██████████| 798k/798k [00:00<00:00, 2.42MB/s]\n",
            "\rmerges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]\rmerges.txt: 100%|██████████| 456k/456k [00:00<00:00, 1.89MB/s]\rmerges.txt: 100%|██████████| 456k/456k [00:00<00:00, 1.88MB/s]\n",
            "[2023-12-13 09:48:19,964] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:48:19,964] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "> --------- MII Settings: ds_optimize=True, replace_with_kernel_inject=True, enable_cuda_graph=False \n",
            "[2023-12-13 09:48:23,355] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.12.4, git-hash=unknown, git-branch=unknown\n",
            "[2023-12-13 09:48:23,356] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter replace_method is deprecated. This parameter is no longer needed, please remove from your call to DeepSpeed-inference\n",
            "[2023-12-13 09:48:23,356] [INFO] [logging.py:96:log_dist] [Rank -1] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1\n",
            "Using /root/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
            "Detected CUDA files, patching ldflags\n",
            "Emitting ninja build file /root/.cache/torch_extensions/py310_cu118/transformer_inference/build.ninja...\n",
            "Building extension module transformer_inference...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "ninja: no work to do.\n",
            "Loading extension module transformer_inference...\n",
            "Time to load transformer_inference op: 0.09351205825805664 seconds\n",
            "[2023-12-13 09:48:23,831] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed-Inference config: {'layer_id': 0, 'hidden_size': 2048, 'intermediate_size': 8192, 'heads': 32, 'num_hidden_layers': -1, 'dtype': torch.float32, 'pre_layer_norm': True, 'norm_type': <NormType.LayerNorm: 1>, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-05, 'mp_size': 1, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'rotary_dim': -1, 'rotate_half': False, 'rotate_every_two': True, 'return_tuple': True, 'mlp_after_attn': True, 'mlp_act_func_type': <ActivationFuncType.ReLU: 2>, 'specialized_mode': False, 'training_mp_size': 1, 'bigscience_bloom': False, 'max_out_tokens': 1024, 'min_out_tokens': 1024, 'scale_attn_by_inverse_layer_idx': False, 'enable_qkv_quantization': False, 'use_mup': False, 'return_single_tuple': False, 'set_empty_params': False, 'transposed_mode': False, 'use_triton': False, 'triton_autotune': False, 'num_kv': -1, 'rope_theta': 10000}\n",
            "[2023-12-13 09:48:24,965] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:48:24,965] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:48:29,970] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:48:29,970] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:48:29,970] [INFO] [server.py:64:_wait_until_server_is_live] server has started on ports [50051]\n",
            "[2023-12-13 09:48:29,970] [INFO] [server.py:64:_wait_until_server_is_live] server has started on ports [50051]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!lsof -i:50051"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_w1nkfndkjKw",
        "outputId": "e4459a1f-70ef-4adc-f8c8-b8d4edd601ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COMMAND   PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\n",
            "python3 10919 root   40u  IPv4 262091      0t0  TCP *:50051 (LISTEN)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cliet chat\n",
        "!cd DeepSpeed-MII/mii/legacy/examples/local/chat && python chat-client-example.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8snvrDj9are-",
        "outputId": "52efcf48-e2d0-4c08-9df0-8e6318da5c03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-12-13 09:59:01,271] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "2023-12-13 09:59:03.188707: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-13 09:59:03.188760: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-13 09:59:03.188785: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-13 09:59:04.323178: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "[2023-12-13 09:59:05,180] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter hf_auth_token is deprecated. Parameter will be removed. Please use the `pipeline_kwargs` field to pass kwargs to the HuggingFace pipeline creation.\n",
            "[2023-12-13 09:59:05,180] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter trust_remote_code is deprecated. Parameter will be removed. Please use the `pipeline_kwargs` field to pass kwargs to the HuggingFace pipeline creation.\n",
            "# Start a conversation session. Type 'q' to exit.\n",
            "You: hello , are u a bot?\n",
            "Bot: Yes, I am a bot.  Yes, I am programmed to provide information.\n",
            "You: Can you tell me about deep learning?\n",
            "Bot: Yes, it is a form of deep learning.  It is a technique for developing artificial intelligence that learns from data.  It allows computers to develop their own intelligence.\n",
            "You: I want to try it.\n",
            "Bot: Yes, it is a good idea to try deep learning.  It can help you develop your own intelligence.\n",
            "You: Is it hard to learn?\n",
            "Bot: Yes, it is hard to learn.  It requires a lot of practice and practice is necessary to develop an effective deep learning system.\n",
            "You: Where can I start?\n",
            "Bot: Yes, it is a good idea to start with deep learning.  It can help you develop your own intelligence.  You should start with simple tasks and gradually increase the complexity of the tasks as you become more proficient with the system.\n",
            "You: thank you\n",
            "Bot: You are welcome\n",
            "You: bye\n",
            "Bot: \n",
            "You: 88\n",
            "Bot: \n",
            "You: 拜\n",
            "Bot: \n",
            "You: q\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mii\n",
        "mii.terminate(\"chat_example_deployment\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbNiSkexkJcR",
        "outputId": "4a01a0fb-51f2-435d-ac02-feb76ce535d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-12-13 10:01:33,497] [INFO] [terminate.py:12:terminate] Terminating server for chat_example_deployment\n",
            "[2023-12-13 10:01:33,497] [INFO] [terminate.py:12:terminate] Terminating server for chat_example_deployment\n",
            "[2023-12-13 10:01:33,501] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter hf_auth_token is deprecated. Parameter will be removed. Please use the `pipeline_kwargs` field to pass kwargs to the HuggingFace pipeline creation.\n",
            "[2023-12-13 10:01:33,502] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter trust_remote_code is deprecated. Parameter will be removed. Please use the `pipeline_kwargs` field to pass kwargs to the HuggingFace pipeline creation.\n",
            "[2023-12-13 10:01:33,540] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter hf_auth_token is deprecated. Parameter will be removed. Please use the `pipeline_kwargs` field to pass kwargs to the HuggingFace pipeline creation.\n",
            "[2023-12-13 10:01:33,541] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter trust_remote_code is deprecated. Parameter will be removed. Please use the `pipeline_kwargs` field to pass kwargs to the HuggingFace pipeline creation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!lsof -i:50051"
      ],
      "metadata": {
        "id": "4XkEGm4ooAOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## more\n",
        "更多示例：\n",
        "https://github.com/microsoft/DeepSpeed-MII/tree/main/mii/legacy/examples/local"
      ],
      "metadata": {
        "id": "0-zJ_kwkYPp_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh DeepSpeed-MII/mii/legacy/examples/local"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T40MpO32gcKw",
        "outputId": "012bc6f4-0702-4c7a-fcce-88ff3bc8e4ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 64K\n",
            "drwxr-xr-x 2 root root 4.0K Dec 13 09:11 chat\n",
            "-rw-r--r-- 1 root root  302 Dec 13 09:11 conversational-example.py\n",
            "-rw-r--r-- 1 root root  757 Dec 13 09:11 conversational-query-example.py\n",
            "-rw-r--r-- 1 root root  677 Dec 13 09:11 fill-mask-example.py\n",
            "-rw-r--r-- 1 root root  351 Dec 13 09:11 question-answering-example.py\n",
            "-rw-r--r-- 1 root root  386 Dec 13 09:11 question-answering-query-example.py\n",
            "-rw-r--r-- 1 root root  317 Dec 13 09:11 text-classification-example.py\n",
            "-rw-r--r-- 1 root root  410 Dec 13 09:11 text-classification-query-example.py\n",
            "-rw-r--r-- 1 root root  324 Dec 13 09:11 text-generation-bloom560m-example.py\n",
            "-rw-r--r-- 1 root root  456 Dec 13 09:11 text-generation-bloom-example.py\n",
            "-rw-r--r-- 1 root root  721 Dec 13 09:11 text-generation-fbopt-example.py\n",
            "-rw-r--r-- 1 root root  568 Dec 13 09:11 text-generation-query-example.py\n",
            "-rw-r--r-- 1 root root 1.4K Dec 13 09:11 text-generation-zero-example.py\n",
            "-rw-r--r-- 1 root root  288 Dec 13 09:11 token-classification-example.py\n",
            "-rw-r--r-- 1 root root  403 Dec 13 09:11 token-classification-query-example.py\n",
            "-rw-r--r-- 1 root root 1.3K Dec 13 09:11 txt2img-example.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd DeepSpeed-MII/mii/legacy/examples/local && (nohup python conversational-example.py &)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jd5oPp6ChEAk",
        "outputId": "11270784-6871-4083-d676-315572f46163"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: appending output to 'nohup.out'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat DeepSpeed-MII/mii/legacy/examples/local/nohup.out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3YOtxtqYQob",
        "outputId": "0f4597e6-c3c1-4c54-8105-b5647d3d079f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-12-13 09:34:21,814] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "2023-12-13 09:34:23.741561: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-13 09:34:23.741615: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-13 09:34:23.741646: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-13 09:34:24.887416: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Deploying microsoft/DialoGPT-large...\n",
            "[2023-12-13 09:35:02,358] [INFO] [deployment.py:75:deploy] ************* MII is using DeepSpeed Optimizations to accelerate your model *************\n",
            "[2023-12-13 09:35:02,358] [INFO] [deployment.py:75:deploy] ************* MII is using DeepSpeed Optimizations to accelerate your model *************\n",
            "[2023-12-13 09:35:02,360] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter hf_auth_token is deprecated. Parameter will be removed. Please use the `pipeline_kwargs` field to pass kwargs to the HuggingFace pipeline creation.\n",
            "[2023-12-13 09:35:02,360] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter trust_remote_code is deprecated. Parameter will be removed. Please use the `pipeline_kwargs` field to pass kwargs to the HuggingFace pipeline creation.\n",
            "[2023-12-13 09:35:02,365] [INFO] [server.py:38:__init__] Hostfile /job/hostfile not found, creating hostfile.\n",
            "[2023-12-13 09:35:02,365] [INFO] [server.py:38:__init__] Hostfile /job/hostfile not found, creating hostfile.\n",
            "[2023-12-13 09:35:02,367] [INFO] [server.py:103:_launch_server_process] MII server server launch: ['deepspeed', '-H', '/tmp/tmp_tzqzbzl', '-i', 'localhost:0', '--master_port', '29500', '--master_addr', 'localhost', '--no_ssh_check', '--no_local_rank', '--no_python', '/usr/bin/python3', '-m', 'mii.legacy.launch.multi_gpu_server', '--deployment-name', 'microsoft/DialoGPT-large_deployment', '--load-balancer-port', '50050', '--restful-gateway-port', '51080', '--server-port', '50051', '--model-config', 'eyJtb2RlbCI6ICJtaWNyb3NvZnQvRGlhbG9HUFQtbGFyZ2UiLCAidGFzayI6ICJjb252ZXJzYXRpb25hbCIsICJkdHlwZSI6ICJ0b3JjaC5mbG9hdDMyIiwgIm1vZGVsX3BhdGgiOiAiL3RtcC9taWlfbW9kZWxzIiwgImxvYWRfd2l0aF9zeXNfbWVtIjogZmFsc2UsICJtZXRhX3RlbnNvciI6IGZhbHNlLCAiZGVwbG95X3JhbmsiOiBbMF0sICJ0b3JjaF9kaXN0X3BvcnQiOiAyOTUwMCwgInJlcGxpY2FfbnVtIjogMSwgInJlcGxpY2FfY29uZmlncyI6IFt7Imhvc3RuYW1lIjogImxvY2FsaG9zdCIsICJ0ZW5zb3JfcGFyYWxsZWxfcG9ydHMiOiBbNTAwNTFdLCAidG9yY2hfZGlzdF9wb3J0IjogMjk1MDAsICJncHVfaW5kaWNlcyI6IFswXX1dLCAicHJvZmlsZV9tb2RlbF90aW1lIjogZmFsc2UsICJza2lwX21vZGVsX2NoZWNrIjogdHJ1ZSwgImhmX2F1dGhfdG9rZW4iOiBudWxsLCAidHJ1c3RfcmVtb3RlX2NvZGUiOiBmYWxzZSwgInBpcGVsaW5lX2t3YXJncyI6IHt9LCAiZW5hYmxlX2RlZXBzcGVlZCI6IHRydWUsICJlbmFibGVfemVybyI6IGZhbHNlLCAiZHNfY29uZmlnIjoge30sICJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAiZW5hYmxlX2N1ZGFfZ3JhcGgiOiBmYWxzZSwgInJlcGxhY2Vfd2l0aF9rZXJuZWxfaW5qZWN0IjogdHJ1ZSwgImNoZWNrcG9pbnRfZGljdCI6IG51bGwsICJtYXhfdG9rZW5zIjogMTAyNH0=']\n",
            "[2023-12-13 09:35:02,367] [INFO] [server.py:103:_launch_server_process] MII server server launch: ['deepspeed', '-H', '/tmp/tmp_tzqzbzl', '-i', 'localhost:0', '--master_port', '29500', '--master_addr', 'localhost', '--no_ssh_check', '--no_local_rank', '--no_python', '/usr/bin/python3', '-m', 'mii.legacy.launch.multi_gpu_server', '--deployment-name', 'microsoft/DialoGPT-large_deployment', '--load-balancer-port', '50050', '--restful-gateway-port', '51080', '--server-port', '50051', '--model-config', 'eyJtb2RlbCI6ICJtaWNyb3NvZnQvRGlhbG9HUFQtbGFyZ2UiLCAidGFzayI6ICJjb252ZXJzYXRpb25hbCIsICJkdHlwZSI6ICJ0b3JjaC5mbG9hdDMyIiwgIm1vZGVsX3BhdGgiOiAiL3RtcC9taWlfbW9kZWxzIiwgImxvYWRfd2l0aF9zeXNfbWVtIjogZmFsc2UsICJtZXRhX3RlbnNvciI6IGZhbHNlLCAiZGVwbG95X3JhbmsiOiBbMF0sICJ0b3JjaF9kaXN0X3BvcnQiOiAyOTUwMCwgInJlcGxpY2FfbnVtIjogMSwgInJlcGxpY2FfY29uZmlncyI6IFt7Imhvc3RuYW1lIjogImxvY2FsaG9zdCIsICJ0ZW5zb3JfcGFyYWxsZWxfcG9ydHMiOiBbNTAwNTFdLCAidG9yY2hfZGlzdF9wb3J0IjogMjk1MDAsICJncHVfaW5kaWNlcyI6IFswXX1dLCAicHJvZmlsZV9tb2RlbF90aW1lIjogZmFsc2UsICJza2lwX21vZGVsX2NoZWNrIjogdHJ1ZSwgImhmX2F1dGhfdG9rZW4iOiBudWxsLCAidHJ1c3RfcmVtb3RlX2NvZGUiOiBmYWxzZSwgInBpcGVsaW5lX2t3YXJncyI6IHt9LCAiZW5hYmxlX2RlZXBzcGVlZCI6IHRydWUsICJlbmFibGVfemVybyI6IGZhbHNlLCAiZHNfY29uZmlnIjoge30sICJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAiZW5hYmxlX2N1ZGFfZ3JhcGgiOiBmYWxzZSwgInJlcGxhY2Vfd2l0aF9rZXJuZWxfaW5qZWN0IjogdHJ1ZSwgImNoZWNrcG9pbnRfZGljdCI6IG51bGwsICJtYXhfdG9rZW5zIjogMTAyNH0=']\n",
            "[2023-12-13 09:35:02,368] [INFO] [server.py:103:_launch_server_process] load balancer server launch: ['/usr/bin/python3', '-m', 'mii.legacy.launch.multi_gpu_server', '--deployment-name', 'microsoft/DialoGPT-large_deployment', '--load-balancer-port', '50050', '--restful-gateway-port', '51080', '--load-balancer', '--model-config', 'eyJtb2RlbCI6ICJtaWNyb3NvZnQvRGlhbG9HUFQtbGFyZ2UiLCAidGFzayI6ICJjb252ZXJzYXRpb25hbCIsICJkdHlwZSI6ICJ0b3JjaC5mbG9hdDMyIiwgIm1vZGVsX3BhdGgiOiAiL3RtcC9taWlfbW9kZWxzIiwgImxvYWRfd2l0aF9zeXNfbWVtIjogZmFsc2UsICJtZXRhX3RlbnNvciI6IGZhbHNlLCAiZGVwbG95X3JhbmsiOiBbMF0sICJ0b3JjaF9kaXN0X3BvcnQiOiAyOTUwMCwgInJlcGxpY2FfbnVtIjogMSwgInJlcGxpY2FfY29uZmlncyI6IFt7Imhvc3RuYW1lIjogImxvY2FsaG9zdCIsICJ0ZW5zb3JfcGFyYWxsZWxfcG9ydHMiOiBbNTAwNTFdLCAidG9yY2hfZGlzdF9wb3J0IjogMjk1MDAsICJncHVfaW5kaWNlcyI6IFswXX1dLCAicHJvZmlsZV9tb2RlbF90aW1lIjogZmFsc2UsICJza2lwX21vZGVsX2NoZWNrIjogdHJ1ZSwgImhmX2F1dGhfdG9rZW4iOiBudWxsLCAidHJ1c3RfcmVtb3RlX2NvZGUiOiBmYWxzZSwgInBpcGVsaW5lX2t3YXJncyI6IHt9LCAiZW5hYmxlX2RlZXBzcGVlZCI6IHRydWUsICJlbmFibGVfemVybyI6IGZhbHNlLCAiZHNfY29uZmlnIjoge30sICJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAiZW5hYmxlX2N1ZGFfZ3JhcGgiOiBmYWxzZSwgInJlcGxhY2Vfd2l0aF9rZXJuZWxfaW5qZWN0IjogdHJ1ZSwgImNoZWNrcG9pbnRfZGljdCI6IG51bGwsICJtYXhfdG9rZW5zIjogMTAyNH0=']\n",
            "[2023-12-13 09:35:02,368] [INFO] [server.py:103:_launch_server_process] load balancer server launch: ['/usr/bin/python3', '-m', 'mii.legacy.launch.multi_gpu_server', '--deployment-name', 'microsoft/DialoGPT-large_deployment', '--load-balancer-port', '50050', '--restful-gateway-port', '51080', '--load-balancer', '--model-config', 'eyJtb2RlbCI6ICJtaWNyb3NvZnQvRGlhbG9HUFQtbGFyZ2UiLCAidGFzayI6ICJjb252ZXJzYXRpb25hbCIsICJkdHlwZSI6ICJ0b3JjaC5mbG9hdDMyIiwgIm1vZGVsX3BhdGgiOiAiL3RtcC9taWlfbW9kZWxzIiwgImxvYWRfd2l0aF9zeXNfbWVtIjogZmFsc2UsICJtZXRhX3RlbnNvciI6IGZhbHNlLCAiZGVwbG95X3JhbmsiOiBbMF0sICJ0b3JjaF9kaXN0X3BvcnQiOiAyOTUwMCwgInJlcGxpY2FfbnVtIjogMSwgInJlcGxpY2FfY29uZmlncyI6IFt7Imhvc3RuYW1lIjogImxvY2FsaG9zdCIsICJ0ZW5zb3JfcGFyYWxsZWxfcG9ydHMiOiBbNTAwNTFdLCAidG9yY2hfZGlzdF9wb3J0IjogMjk1MDAsICJncHVfaW5kaWNlcyI6IFswXX1dLCAicHJvZmlsZV9tb2RlbF90aW1lIjogZmFsc2UsICJza2lwX21vZGVsX2NoZWNrIjogdHJ1ZSwgImhmX2F1dGhfdG9rZW4iOiBudWxsLCAidHJ1c3RfcmVtb3RlX2NvZGUiOiBmYWxzZSwgInBpcGVsaW5lX2t3YXJncyI6IHt9LCAiZW5hYmxlX2RlZXBzcGVlZCI6IHRydWUsICJlbmFibGVfemVybyI6IGZhbHNlLCAiZHNfY29uZmlnIjoge30sICJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAiZW5hYmxlX2N1ZGFfZ3JhcGgiOiBmYWxzZSwgInJlcGxhY2Vfd2l0aF9rZXJuZWxfaW5qZWN0IjogdHJ1ZSwgImNoZWNrcG9pbnRfZGljdCI6IG51bGwsICJtYXhfdG9rZW5zIjogMTAyNH0=']\n",
            "[2023-12-13 09:35:04,701] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-13 09:35:04,792] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-13 09:35:06,441] [INFO] [runner.py:570:main] cmd = /usr/bin/python3 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=localhost --master_port=29500 --no_python --no_local_rank --enable_each_rank_log=None /usr/bin/python3 -m mii.legacy.launch.multi_gpu_server --deployment-name microsoft/DialoGPT-large_deployment --load-balancer-port 50050 --restful-gateway-port 51080 --server-port 50051 --model-config eyJtb2RlbCI6ICJtaWNyb3NvZnQvRGlhbG9HUFQtbGFyZ2UiLCAidGFzayI6ICJjb252ZXJzYXRpb25hbCIsICJkdHlwZSI6ICJ0b3JjaC5mbG9hdDMyIiwgIm1vZGVsX3BhdGgiOiAiL3RtcC9taWlfbW9kZWxzIiwgImxvYWRfd2l0aF9zeXNfbWVtIjogZmFsc2UsICJtZXRhX3RlbnNvciI6IGZhbHNlLCAiZGVwbG95X3JhbmsiOiBbMF0sICJ0b3JjaF9kaXN0X3BvcnQiOiAyOTUwMCwgInJlcGxpY2FfbnVtIjogMSwgInJlcGxpY2FfY29uZmlncyI6IFt7Imhvc3RuYW1lIjogImxvY2FsaG9zdCIsICJ0ZW5zb3JfcGFyYWxsZWxfcG9ydHMiOiBbNTAwNTFdLCAidG9yY2hfZGlzdF9wb3J0IjogMjk1MDAsICJncHVfaW5kaWNlcyI6IFswXX1dLCAicHJvZmlsZV9tb2RlbF90aW1lIjogZmFsc2UsICJza2lwX21vZGVsX2NoZWNrIjogdHJ1ZSwgImhmX2F1dGhfdG9rZW4iOiBudWxsLCAidHJ1c3RfcmVtb3RlX2NvZGUiOiBmYWxzZSwgInBpcGVsaW5lX2t3YXJncyI6IHt9LCAiZW5hYmxlX2RlZXBzcGVlZCI6IHRydWUsICJlbmFibGVfemVybyI6IGZhbHNlLCAiZHNfY29uZmlnIjoge30sICJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAiZW5hYmxlX2N1ZGFfZ3JhcGgiOiBmYWxzZSwgInJlcGxhY2Vfd2l0aF9rZXJuZWxfaW5qZWN0IjogdHJ1ZSwgImNoZWNrcG9pbnRfZGljdCI6IG51bGwsICJtYXhfdG9rZW5zIjogMTAyNH0=\n",
            "2023-12-13 09:35:06.733281: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-13 09:35:06.733335: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-13 09:35:06.733361: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "[2023-12-13 09:35:07,373] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:35:07,373] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "2023-12-13 09:35:07.945468: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "[2023-12-13 09:35:08,670] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-13 09:35:09,107] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter hf_auth_token is deprecated. Parameter will be removed. Please use the `pipeline_kwargs` field to pass kwargs to the HuggingFace pipeline creation.\n",
            "[2023-12-13 09:35:09,107] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter trust_remote_code is deprecated. Parameter will be removed. Please use the `pipeline_kwargs` field to pass kwargs to the HuggingFace pipeline creation.\n",
            "[2023-12-13 09:35:10,326] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE=libnccl-dev=2.15.5-1+cuda11.8\n",
            "[2023-12-13 09:35:10,326] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE_VERSION=2.15.5-1\n",
            "[2023-12-13 09:35:10,326] [INFO] [launch.py:138:main] 0 NCCL_VERSION=2.15.5-1\n",
            "[2023-12-13 09:35:10,326] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE_NAME=libnccl-dev\n",
            "[2023-12-13 09:35:10,326] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE=libnccl2=2.15.5-1+cuda11.8\n",
            "[2023-12-13 09:35:10,326] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE_NAME=libnccl2\n",
            "[2023-12-13 09:35:10,326] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE_VERSION=2.15.5-1\n",
            "[2023-12-13 09:35:10,326] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0]}\n",
            "[2023-12-13 09:35:10,326] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=1, node_rank=0\n",
            "[2023-12-13 09:35:10,326] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})\n",
            "[2023-12-13 09:35:10,326] [INFO] [launch.py:163:main] dist_world_size=1\n",
            "[2023-12-13 09:35:10,326] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0\n",
            "[2023-12-13 09:35:12,378] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:35:12,378] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:35:12,590] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "2023-12-13 09:35:14.450109: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-13 09:35:14.450168: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-13 09:35:14.450206: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-13 09:35:15.559751: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "[2023-12-13 09:35:16,710] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter hf_auth_token is deprecated. Parameter will be removed. Please use the `pipeline_kwargs` field to pass kwargs to the HuggingFace pipeline creation.\n",
            "[2023-12-13 09:35:16,710] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter trust_remote_code is deprecated. Parameter will be removed. Please use the `pipeline_kwargs` field to pass kwargs to the HuggingFace pipeline creation.\n",
            "[2023-12-13 09:35:17,382] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:35:17,382] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:35:22,387] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:35:22,387] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:35:27,392] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:35:27,392] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "> --------- MII Settings: ds_optimize=True, replace_with_kernel_inject=True, enable_cuda_graph=False \n",
            "[2023-12-13 09:35:28,542] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.12.4, git-hash=unknown, git-branch=unknown\n",
            "[2023-12-13 09:35:28,542] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter replace_method is deprecated. This parameter is no longer needed, please remove from your call to DeepSpeed-inference\n",
            "[2023-12-13 09:35:28,543] [INFO] [logging.py:96:log_dist] [Rank -1] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1\n",
            "Using /root/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
            "Detected CUDA files, patching ldflags\n",
            "Emitting ninja build file /root/.cache/torch_extensions/py310_cu118/transformer_inference/build.ninja...\n",
            "Building extension module transformer_inference...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "ninja: no work to do.\n",
            "Loading extension module transformer_inference...\n",
            "Time to load transformer_inference op: 0.09584593772888184 seconds\n",
            "[2023-12-13 09:35:29,007] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed-Inference config: {'layer_id': 0, 'hidden_size': 1280, 'intermediate_size': 5120, 'heads': 20, 'num_hidden_layers': -1, 'dtype': torch.float32, 'pre_layer_norm': True, 'norm_type': <NormType.LayerNorm: 1>, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-05, 'mp_size': 1, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'rotary_dim': -1, 'rotate_half': False, 'rotate_every_two': True, 'return_tuple': True, 'mlp_after_attn': True, 'mlp_act_func_type': <ActivationFuncType.GELU: 1>, 'specialized_mode': False, 'training_mp_size': 1, 'bigscience_bloom': False, 'max_out_tokens': 1024, 'min_out_tokens': 1024, 'scale_attn_by_inverse_layer_idx': False, 'enable_qkv_quantization': False, 'use_mup': False, 'return_single_tuple': False, 'set_empty_params': False, 'transposed_mode': False, 'use_triton': False, 'triton_autotune': False, 'num_kv': -1, 'rope_theta': 10000}\n",
            "[2023-12-13 09:35:32,397] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:35:32,397] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:35:37,402] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:35:37,402] [INFO] [server.py:63:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-13 09:35:37,402] [INFO] [server.py:64:_wait_until_server_is_live] server has started on ports [50051]\n",
            "[2023-12-13 09:35:37,402] [INFO] [server.py:64:_wait_until_server_is_live] server has started on ports [50051]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd DeepSpeed-MII/mii/legacy/examples/local && python conversational-query-example.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkEnx0FLgyrr",
        "outputId": "796ea767-bf9c-4e16-abd6-bd3b641ae302"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-12-13 09:41:57,043] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "2023-12-13 09:41:58.932739: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-13 09:41:58.932786: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-13 09:41:58.932813: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-13 09:42:00.069422: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Querying microsoft/DialoGPT-large...\n",
            "[2023-12-13 09:42:00,919] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter hf_auth_token is deprecated. Parameter will be removed. Please use the `pipeline_kwargs` field to pass kwargs to the HuggingFace pipeline creation.\n",
            "[2023-12-13 09:42:00,919] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter trust_remote_code is deprecated. Parameter will be removed. Please use the `pipeline_kwargs` field to pass kwargs to the HuggingFace pipeline creation.\n",
            "conversation_id: \"6af613b6-569c-5c22-9c37-2ed93f31d3af\"\n",
            "past_user_inputs: \"DeepSpeed is the greatest\"\n",
            "generated_responses: \"I love it. It\\'s so much fun.\"\n",
            "time_taken: 0.218658924\n",
            "model_time_taken: -1\n",
            "\n",
            "time_taken: 0.2186589241027832\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/DeepSpeed-MII/mii/legacy/examples/local/conversational-query-example.py\", line 30, in <module>\n",
            "    result = generator.query({\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mii/legacy/client.py\", line 77, in query\n",
            "    return self.asyncio_loop.run_until_complete(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/nest_asyncio.py\", line 99, in run_until_complete\n",
            "    return f.result()\n",
            "  File \"/usr/lib/python3.10/asyncio/futures.py\", line 201, in result\n",
            "    raise self._exception.with_traceback(self._exception_tb)\n",
            "  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 232, in __step\n",
            "    result = coro.send(None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mii/legacy/client.py\", line 72, in _request_async_response\n",
            "    proto_request = task_methods.pack_request_to_proto(request_dict, **query_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mii/legacy/method_table.py\", line 227, in pack_request_to_proto\n",
            "    return modelresponse_pb2.ConversationRequest(\n",
            "TypeError: bad argument type for built-in operation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!lsof -i:50051"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GnJmsWViIPY",
        "outputId": "01e749fc-ad0c-4e93-82c6-36ec6a0babed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COMMAND  PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\n",
            "python3 7710 root   23u  IPv4 190929      0t0  TCP localhost:45268->localhost:50051 (ESTABLISHED)\n",
            "python3 7844 root   39u  IPv4 185094      0t0  TCP *:50051 (LISTEN)\n",
            "python3 7844 root   40u  IPv4 189060      0t0  TCP localhost:50051->localhost:45268 (ESTABLISHED)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mii\n",
        "mii.terminate(\"microsoft/DialoGPT-large_deployment\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ob07Ri3Cj37Z",
        "outputId": "ce45648d-049f-417c-bfdf-71892d92d8f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-12-13 09:43:59,850] [INFO] [terminate.py:12:terminate] Terminating server for microsoft/DialoGPT-large_deployment\n",
            "[2023-12-13 09:43:59,850] [INFO] [terminate.py:12:terminate] Terminating server for microsoft/DialoGPT-large_deployment\n",
            "[2023-12-13 09:43:59,854] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter hf_auth_token is deprecated. Parameter will be removed. Please use the `pipeline_kwargs` field to pass kwargs to the HuggingFace pipeline creation.\n",
            "[2023-12-13 09:43:59,855] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter trust_remote_code is deprecated. Parameter will be removed. Please use the `pipeline_kwargs` field to pass kwargs to the HuggingFace pipeline creation.\n",
            "[2023-12-13 09:43:59,861] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter hf_auth_token is deprecated. Parameter will be removed. Please use the `pipeline_kwargs` field to pass kwargs to the HuggingFace pipeline creation.\n",
            "[2023-12-13 09:43:59,862] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter trust_remote_code is deprecated. Parameter will be removed. Please use the `pipeline_kwargs` field to pass kwargs to the HuggingFace pipeline creation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!lsof -i:50051"
      ],
      "metadata": {
        "id": "9Hc1PHeij-p9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DeepSpeed-FastGen\n",
        "\n",
        "https://github.com/microsoft/DeepSpeed/blob/master/blogs/deepspeed-fastgen/chinese/README.md\n",
        "\n",
        "ds-mii-fastgen 是为了解决LLMs推理加速，提高推理吞吐，以及长prompt问题(llm已经支持长token,树万token)。\n",
        "\n",
        "GPT-4 和 LLaMA 这样的大型语言模型（LLMs）已在各个层次上成为了集成 AI 的主流服务应用。从常规聊天模型到文档摘要，从自动驾驶到各个软件中的Copilot功能，这些模型的部署和服务需求正在迅速增加。像 DeepSpeed、PyTorch 和其他几个框架可以在 LLM 训练期间实现良好的硬件利用率。但它们在与用户互动及处理开放式文本生成等任务时，受限于这些操作的计算密集度相对较低，现有系统往往在推理吞吐量上遇到瓶颈。\n",
        "\n",
        "为了解决这一问题， vLLM 这样由 PagedAttention 驱动的框架和 [Orca](https://www.usenix.org/system/files/osdi22-yu.pdf) 这样的系统显著提高了 LLM 推理的性能。然而，这些系统在面对长提示的工作负载时，依旧难以提供良好的服务质量。随着越来越多的模型（例如 MPT-StoryWriter）和系统（例如DeepSpeed Ulysses）支持延伸到数万个令牌的上下文窗口，这些长提示工作负载变得越来越重要。为了更好地理解问题，我们在下文中提供了详细的示例来说明 LLM 的文本生成是如何在“提示处理”和“生成”的这两个阶段中工作的。当系统将它们视为不同的阶段时，生成阶段将被提示处理所抢占，这可能会破坏服务级别协议（SLAs）。\n",
        "\n",
        "tips:\n",
        "- vllm 跟进 https://github.com/vllm-project/vllm/issues/1562\n",
        "\n",
        "DeepSpeed-FastGen 框架，它通过采用动态 SplitFuse 技术，能够提供比vLLM 等先进系统高出多达 2.3 倍的有效吞吐量。DeepSpeed-FastGen 是 DeepSpeed-MII 和 DeepSpeed-Inference 的结合，提供了一个易于使用的服务系统\n",
        "\n",
        "\n",
        "\n",
        "DeepSpeed-FastGen 是 [DeepSpeed-MII](https://github.com/microsoft/DeepSpeed-MII) 和 [DeepSpeed-Inference](https://github.com/microsoft/DeepSpeed) 的协同组合，如下图所示。这两个软件包共同提供了系统的各个组成部分，包括前端 API、用于使用动态 SplitFuse 调度批次的主机和设备基础设施、优化的内核实现，以及构建新模型实现的工具。\n",
        "![](https://github.com/microsoft/DeepSpeed/blob/master/blogs/deepspeed-fastgen/assets/images/fastgen-arch-light.png?raw=true)\n"
      ],
      "metadata": {
        "id": "OqJfbV1oPadS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 现有 LLM 服务技术\n",
        "\n",
        "单个序列的文本生成工作负载包含两个阶段：1）提示处理，此阶段系统处理用户输入的文本，将其转换成一系列令牌并构建用于注意力机制的键值（KV）缓存；2）生成令牌，即向缓存中添加单个令牌并产生新的令牌。在生成文本序列的过程中，系统将对模型进行多次前向调用以生成完整的文本序列。现有文献和系统中已经提出了两种主要技术，它们解决了这些阶段中可能出现的各种限制和瓶颈。\n",
        "\n",
        "分块 KV 缓存：\n",
        "\n",
        "vLLM识别出大型单体KV缓存导致的内存碎片化显著降低了大型语言模型服务系统的并发性，并提出了“分页注意力”Paged Attention 机制来实现非连续KV缓存，并增加整个系统的总吞吐量。此技术采用分页缓存机制，从而提升了系统的整体吞吐量。不同于之前分配各个不同大小的连续内存块的做法，分块 KV 缓存中的底层存储是固定大小的块（也称为页面）。分块 KV 缓存通过消除 KV 缓存引起的内存碎片化，增加了潜在的序列并发量，从而增加了系统吞吐量。非连续 KV 缓存也被 HuggingFace TGI 和 NVIDIA TensorRT-LLM 等框架所实现。\n",
        "\n",
        "连续批处理：\n",
        "\n",
        "过去，动态批处理（服务器等待多个请求以同步处理）被用来提高 GPU 利用率。然而，这种方法有缺点，因为它通常需要将输入填充到相同长度或使系统等待以构建更大的批次（batch）。\n",
        "\n",
        "近期大型语言模型（LLM）推理和服务的优化一直专注于细粒度调度和优化内存效率。例如，Orca 提出了 迭代级调度（也称为连续批处理），它在模型的每次前向传递时作出独特的调度决策。这允许请求根据需要加入/离开批次，从而消除了填充请求的需要，提高了总体吞吐量。除了 Orca，NVIDIA TRT-LLM、HuggingFace TGI 和 vLLM 也实现了连续批处理。\n",
        "\n",
        "在当前系统中，有两种主要方法来实现连续批处理。在 TGI 和 vLLM 中，生成阶段被抢占以执行提示处理（在 TGI 中称为填充）然后继续生成。在 Orca 中，这些阶段不被区分；相反，只要总序列数没有达到固定限制，Orca 就会将提示加入正在运行的批次中。这两种方法都在不同程度上需要暂停生成以处理长提示\n",
        "\n",
        "为了解决这些缺点，我们提出了一种新颖的提示和生成组合策略，动态 SplitFuse。\n",
        "\n"
      ],
      "metadata": {
        "id": "hSrI8HhrabUL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 动态 SplitFuse：一种新颖的提示和生成组合策略\n",
        "\n",
        "类似于现有的框架如 TRT-LLM、TGI 和 vLLM，DeepSpeed-FastGen 的目标是利用连续批处理和非连续 KV 缓存技术，以提升数据中心服务大型语言模型（LLM）的硬件利用率和响应速度。为了实现更高的性能，DeepSpeed-FastGen 提出了 SplitFuse 技术，它利用动态提示和生成分解, 统一来进一步改善连续批处理和系统吞吐量。\n",
        "\n",
        "\n",
        "### 动态分割融合（Dynamic SplitFuse）\n",
        "动态分割融合是一种用于提示处理和令牌生成的新型令牌组成策略。DeepSpeed-FastGen 利用动态分割融合策略，通过从提示中取出部分令牌并与生成过程相结合，使得模型可以保持一致的前向传递大小（forward size）。具体来说，动态分割融合执行两个关键行为：\n",
        "\n",
        "1. 将长提示分解成更小的块，并在多个前向传递（迭代）中进行调度，只有在最后一个传递中才执行生成。\n",
        "2. 短提示将被组合以精确填满目标令牌预算。即使是短提示也可能被分解，以确保预算被精确满足，前向大小（forward sizes）保持良好对齐。\n",
        "\n",
        "动态分割融合（Dynamic SplitFuse）提升了以下性能指标：\n",
        "\n",
        "1. 更好的响应性： 由于长提示不再需要极长的前向传递来处理，模型将提供更低的客户端延迟。在同一时间窗口内执行的前向传递更多。\n",
        "2. 更高的效率： 短提示的融合到更大的令牌预算使模型能够持续运行在高吞吐量状态。\n",
        "3. 更低的波动和更好的一致性： 由于前向传递的大小一致，且前向传递大小是性能的主要决定因素，每个前向传递的延迟比其他系统更加一致。生成频率也是如此，因为DeepSpeed-FastGen不需要像其他先前的系统那样抢占或长时间运行提示，因此延迟会更低。\n",
        "因此，与现有最先进的服务系统相比，DeepSpeed-FastGen 将以允许快速、持续生成的速率消耗来自提示的令牌，同时向系统添加令牌，提高系统利用率，提供更低的延迟和更高的吞吐量流式生成给所有客户端。\n",
        "\n"
      ],
      "metadata": {
        "id": "I8hGJn6Zam5H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  性能评估\n",
        "\n",
        "DeepSpeed-FastGen 利用分块 KV 缓存和动态分割融合连续批处理，提供了最先进的 LLM 服务性能。我们以下述的基准测试方法对 DeepSpeed-FastGen 和 vLLM 在一系列模型和硬件配置上进行评估。\n",
        "\n",
        "我们采用两种主要的定量方法来衡量性能。\n",
        "\n",
        "吞吐量-延迟曲线： 生产环境的两个关键指标是吞吐量（以每秒请求计）和延迟（每个请求的响应性）。为了衡量这一点，我们模拟了多个客户端（数量从 1 到 32 不等）同时向服务器发送请求（总计 512 个）的情况。每个请求的结果延迟在端点测量，吞吐量通过完成实验的端到端时间来测量。\n",
        "\n",
        "有效吞吐量（用户体验SLA）： 诸如聊天应用程序之类的交互式应用程序可能有比上述指标（如端到端延迟）更严格和复杂的要求。以越来越受欢迎的聊天应用为例：\n",
        "\n",
        "用户通过发送提示（输入）来开始对话。\n",
        "系统处理提示并返回第一个令牌。\n",
        "随着生成的进行，后续令牌被流式传输给用户。\n",
        "在这个过程的每个阶段，系统都有可能提供不利的用户体验；例如，第一个令牌到达得太慢；或生成似乎停止了一段时间。我们提出了一个考虑这两个维度的 SLA 框架。\n",
        "\n",
        "由于提示和生成文本的长度差异很大，影响计算成本，因此设定同一个 SLA 值对于吞吐量和延迟是不切实际的。因此，我们将提示延迟的 SLA 定义为 “|提示中的令牌|/512” 秒（= 512 令牌/秒）。此外，考虑到人类的阅读速度，我们将生成延迟的 SLA 设置在指数移动平均（EMA）上为 2、4 或 6 令牌/秒。能够达到这些 SLA 的请求被认为是成功的，这些成功请求的吞吐量被称为有效吞吐量。\n",
        "\n",
        "我们通过在 NVIDIA A100、H100 和 A6000 上运行 Llama-2 7B、Llama-2 13B 和 Llama-2 70B 对 vLLM 和 DeepSpeed-FastGen进行了评估。\n",
        "\n",
        "DeepSpeed-FastGen 提供了副本级负载均衡，可以将请求均匀分布在多个服务器上，轻松扩展应用程序。\n",
        "\n",
        "Tips:\n",
        "\n",
        "在评估使用推理服务成本的时候，需要结合当前用户请求峰值进行评估，结合A100-40/80G卡作为基础卡来部署，需要评估整体算力成本； gpu利用率上去了，性能可以水平扩展，吞吐线性增长就更好了。\n",
        "\n"
      ],
      "metadata": {
        "id": "qU7ZBXbLeW3Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 部署选项\n",
        "示例均可在 DeepSpeedExamples 中运行。安装后，有两种部署方式：交互式非持久管道或持久化服务部署："
      ],
      "metadata": {
        "id": "EqMkpc3OORnE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 非持久管道\n",
        "非持久管道部署是快速入门的好方法，只需几行代码即可完成。非持久模型只在您运行的 python 脚本期间存在，适用于临时交互式会话。\n",
        "\n"
      ],
      "metadata": {
        "id": "joIQE6ufOaR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/microsoft/DeepSpeed-MII/issues/273 need SM>=8.0 (Ampere+) A100\n",
        "# if use T4 GPU , need use https://github.com/microsoft/DeepSpeed-MII/tree/main/mii/legacy\n",
        "from mii import pipeline\n",
        "pipe = pipeline(\"mistralai/Mistral-7B-v0.1\")\n",
        "output = pipe([\"Hello, my name is\", \"DeepSpeed is\"], max_new_tokens=128)\n",
        "print(output)\n"
      ],
      "metadata": {
        "id": "C-Gkv5ZAHgBy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "caa716b12ad3483b9159d437281a2940",
            "ad9232648fef491887cefb5d065fd82c",
            "b9679b9bb8724f30be810504176b117e",
            "6ac64fac744c41b4aceed82b13d9aa73",
            "d9a0bf708a8849a383b9900b4021ecfe",
            "ca52df4633e04030b1db5fbe4e181185",
            "b9d4f12cf3f64a9b8b096bd78e0497e2",
            "5ebf6e76a44a4eb9a1ce52a788fa4daa",
            "b3a733030c4547eeacdef83a47751c87",
            "8349e742df564f30ba87290f36f16673",
            "103fe095889049918d8d13f82a9165a2",
            "2ca86f7cd1c1457f955d5cd50586e5d5",
            "64e4e1b4e63a4ea4924d5038ea2f0edb",
            "44fd3e2f471f4f6197d888b551d017cf",
            "34059aee78c4456497565142c2ab80d8",
            "bf0fe12ae121410989a09607206f8ad1",
            "008c01d3fd044cd1bbb02f3f17fb0eb3",
            "d3a79cab17c34dc59634cb5957815426",
            "60a14d9561424206804a8aa5cb99f534",
            "8ee80b47b6094fa1ae96e5e143a22030",
            "34d1fcd20f694d5a90688c8866b4e888",
            "fce8387721604a73b88af0afbff94b06",
            "60b5dd19cda64ee38403df6eebe22bd8",
            "e60dc32a18524fa290ca9d68f673b87b",
            "99963e7c84ca401f8a04b273bb51a37e",
            "105ba53fb0fe4552a485a227fd24ced8",
            "849be24c4861414e87b77ecee44d8b38",
            "a2bbcd10ce494fe98420bf32d9bd2e21",
            "954289896e864eafaa832a657730fede",
            "d8755522caff4d86b31adc96bd1cd94f",
            "05ecadadab034564aa9a75e512fc6d83",
            "54e77873c494490988397ee14eef66cf",
            "9d5ac04a8a334268a8b9607c13ffc286",
            "815996c9d03144a0833d2d8960714532",
            "44b9a739e98442ccbc0b1301a16a88d3",
            "c1b33b8f4a71490ca75f28fee2241b9d",
            "090c5aaba6ca4655a6c26e0febcf84bb",
            "37a3fb6532934a1681e3368f07fc8ec0",
            "1a4fc324634047338305108c31e38e5f",
            "e44ddd248be94b489c5d73a9ddd24d2a",
            "5445894cf8e844fab3d56794108739d8",
            "b232a8728e4d4f64b7719b6b15c706db",
            "cbfce62fa6214a518dc3b898dec966b7",
            "851b0b6ade1b43d8a8e8b64e6635e011",
            "16d0204fd4cc442dbb850992e8bc912d",
            "b807f72b7acd458c9dbd30e35cf93aac",
            "2f1ac366b19848ae97bb5cede0191179",
            "a0077fe17d09409b99a33d538ac245c7",
            "3490bd753a1a45f7b76355276aa84508",
            "1be16cd4a565460b8e6a78ba19903565",
            "2608dff02aac4c27863b3a4f66ee666a",
            "adaebfa7fe8a4db59048dc9a6b47b74b",
            "4655e0399cb04eed932c9610eb95f609",
            "f1f05dd002ff4e6995aac4f73b78efc1",
            "7300f68d2e4047418919acf4ae3b924d",
            "e48c166f533e41bb8d11236ceeb11a44",
            "b2ffcd5c7c58477f94a98114c3142f18",
            "27b219be62ee4202810c59a7f9112653",
            "dd46e9c76ad8483bb3e735b39a463a71",
            "fd4f6f3952fb436aa6a1e5bca6e76b4a",
            "525bacd6cd8446288f41623ff9d42d4a",
            "d17ea2a5e62c4fd7b2051eccf70a1f66",
            "3b8d02d0495043bb9e5577ba05f4834a",
            "f029e455e0a24d4aa653fb4deb572eac",
            "bacaac16a3f04d42a885ec11a8a3b617",
            "9ab50945556f4c9da39c2134ce347174",
            "e49d3e89f36c4ab9abcd05a440d2e802",
            "225f61d07fc1449996ec46b910d2dd4e",
            "220b27b934514abc8426c22c53192a18",
            "c3a2401529514557a2294901c244aec6",
            "74682d70dca341a5af2917ac87a81b54",
            "320e51fc7e174991980147cd82193c30",
            "c58bf29178464d8bac9b1e2baa29f4c5",
            "9dee19d6a4d74f6697af8e48bc56f611",
            "7ddfcf5e04a841f39428e1566c68ef3e",
            "22fb075d51c24f4aa0f9dd14df4c88b0",
            "76b3de07c8a74122b3044b4409542f76",
            "7e786cd185ab4a0994037070bd023b99",
            "0c1233485afa4d4e908c93e438ca9f57",
            "895dc5292ce4439d819eddedc78a6a9d",
            "f24f047d68524ea9981897b89e41df77",
            "6638ab23a386452ea2cc8431a567d422",
            "5e99945c02124a57a38aa8ef747fae37",
            "a4fe170ca2744f54b857c0204f27d5ca",
            "cd5cc23fc79246ebb9fc89b0dcff1cfb",
            "4bec94f4611c426888834535f6c29647",
            "1328c6ef8f6243cd8d700c5375389265",
            "5773edc93ebc403f8a68776fb26b96c5",
            "aa6a8c6cf51e4cd89c2fbbcf2b93ff27",
            "7801e8116853471d996ef05fbbdb1efc",
            "6ab763ddc5464ec087df38ba058c093a",
            "3eff858509e54bce83b84e6c06b6cc2d",
            "e686d50944824468897041dfd1d93110",
            "7a6f478041ad495197e5d7c3bae9a2a5",
            "91d6beb44c9541ab8929fa3e9c551889",
            "b1443ac0e973440bab500076f4b224d1",
            "1da2fa1b294e45a7adfcb3930629ff7e",
            "66c0df913905429982c41cb711854d66",
            "5c968864b1e14980b3e521e0204283c5",
            "cc37634d7b6b4ba68dd3fce0e7791342",
            "4ec1d0abf09c42c0a1424663f4ae445f",
            "2f70e1a9e779469a997233a3e8c02d18",
            "d9bd841ee881434287bd5a54702ae441",
            "d059f5c2045c4c1da2114050f233267c",
            "ab5b228a889e4e698229a3c563adc9d8",
            "b7d8415503fc4d55a8f04cf21c0a2d30",
            "4e585a5948fb49eda4dc1374cd4c14a4",
            "956bd77eadcb47abb262f8b2e815a934",
            "b9f8e8cc4c124266a6888e03349eb832",
            "37838e53523049e9b64fb72fdf6f0151",
            "2a54e937c2804694858a371b444aecb9",
            "d862dfc5d3cc45e5b10247c2b0510696",
            "9aa5c2f1a88740b0be2caf218f1f31bb",
            "d7939b5b64d44179a02d14bc0d02e189",
            "01e57179edf448829574b7a04d7e79c8",
            "81ccc8b6c8e3465eb37fd60be81753f6",
            "e9653782040c4497a246bd46edadbb97",
            "699a7059e69d423d93fd90ecb388651d",
            "0a5c03fbcd1a4f2f9d64f4824acac176",
            "eff3427e0d2d49029320886de6602618",
            "84f398c6388a4db6a944a0ac10165bb8"
          ]
        },
        "outputId": "bb4c91f2-74c5-4724-c293-e4ada25b8bc8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-12-16 04:20:35,306] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 04:20:40,245] [INFO] [comm.py:637:init_distributed] cdb=None\n",
            "[2023-12-16 04:20:40,246] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "caa716b12ad3483b9159d437281a2940"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ca86f7cd1c1457f955d5cd50586e5d5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 9 files:   0%|          | 0/9 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "60b5dd19cda64ee38403df6eebe22bd8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "815996c9d03144a0833d2d8960714532"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "16d0204fd4cc442dbb850992e8bc912d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/967 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e48c166f533e41bb8d11236ceeb11a44"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e49d3e89f36c4ab9abcd05a440d2e802"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7e786cd185ab4a0994037070bd023b99"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa6a8c6cf51e4cd89c2fbbcf2b93ff27"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc37634d7b6b4ba68dd3fce0e7791342"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-12-16 04:21:28,463] [INFO] [engine_v2.py:82:__init__] Building model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\n",
            "Creating extension directory /root/.cache/torch_extensions/py310_cu121/inference_core_ops...\n",
            "Detected CUDA files, patching ldflags\n",
            "Emitting ninja build file /root/.cache/torch_extensions/py310_cu121/inference_core_ops/build.ninja...\n",
            "Building extension module inference_core_ops...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "Loading extension module inference_core_ops...\n",
            "Using /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\n",
            "Creating extension directory /root/.cache/torch_extensions/py310_cu121/ragged_device_ops...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time to load inference_core_ops op: 37.377023458480835 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Detected CUDA files, patching ldflags\n",
            "Emitting ninja build file /root/.cache/torch_extensions/py310_cu121/ragged_device_ops/build.ninja...\n",
            "Building extension module ragged_device_ops...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time to load ragged_device_ops op: 51.90882420539856 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading extension module ragged_device_ops...\n",
            "Using /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\n",
            "Creating extension directory /root/.cache/torch_extensions/py310_cu121/ragged_ops...\n",
            "Detected CUDA files, patching ldflags\n",
            "Emitting ninja build file /root/.cache/torch_extensions/py310_cu121/ragged_ops/build.ninja...\n",
            "Building extension module ragged_ops...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time to load ragged_ops op: 32.21213245391846 seconds\n",
            "[2023-12-16 04:23:30,759] [INFO] [huggingface_engine.py:112:parameters] Loading checkpoint: /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-v0.1/snapshots/26bca36bde8333b5d7f72e9ed20ccda6a618af24/model-00002-of-00002.safetensors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading extension module ragged_ops...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-12-16 04:23:31,258] [INFO] [huggingface_engine.py:112:parameters] Loading checkpoint: /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-v0.1/snapshots/26bca36bde8333b5d7f72e9ed20ccda6a618af24/model-00001-of-00002.safetensors\n",
            "[2023-12-16 04:23:36,569] [INFO] [engine_v2.py:84:__init__] Model built.\n",
            "[2023-12-16 04:23:36,594] [INFO] [kv_cache.py:135:__init__] Allocating KV-cache 0 with shape: (32, 3134, 64, 2, 8, 128) consisting of 3134 blocks.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2a54e937c2804694858a371b444aecb9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Yana,\n",
            "\n",
            "It’s been a long time since I posted here and I thought it was time I updated you on my life. My family and I are living in Vienna, Austria and we love it. We have a terrace, a garden and a wonderful view on the landscape from our apartment.\n",
            "\n",
            "I joined a hiking group, which goes on long and short walks. I enjoy both very much. Here I am on a hike to Vienna, Austria. I am enjoying the camaraderie of the group, which has 20 – 25 people in it.\n",
            "\n",
            "Here is a, an open source ML framework that simplifies distributed model training with GPUs and CPUs. This high performance library allows developers to train larger models with limited hardware resources.\n",
            "\n",
            "DeepSpeed now adds two new features to expand the capability of this framework:\n",
            "\n",
            "- Checkpointing can reduce the length of training runs by reusing training jobs across GPUs.\n",
            "- Optimizing data transfer allows you to compress data and transfer it between machines using standard filesystems, which reduces the amount of memory used and eliminates the need for SSDs.\n",
            "\n",
            "## Checkpointing\n",
            "\n",
            "Checkpointing is a feature that DeepSpeed]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 持久部署\n",
        "持久部署非常适合用于长时间运行和生产的应用。持久部署使用了轻量级的 GRPC 服务器，可以使用以下两行代码创建：\n",
        "\n"
      ],
      "metadata": {
        "id": "VmbRsaW7OdGD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import mii\n",
        "#mii.serve(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
        "\n",
        "mii.serve(\"mistralai/Mistral-7B-v0.1\")\n"
      ],
      "metadata": {
        "id": "UdH3NCrBOfjq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9890580b-bf9e-42a5-d204-2dd2e97cc61f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-12-16 04:44:01,915] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 04:44:06,594] [INFO] [server.py:38:__init__] Hostfile /job/hostfile not found, creating hostfile.\n",
            "[2023-12-16 04:44:06,594] [INFO] [server.py:38:__init__] Hostfile /job/hostfile not found, creating hostfile.\n",
            "[2023-12-16 04:44:06,603] [INFO] [server.py:107:_launch_server_process] msg_server launch: ['deepspeed', '-i', 'localhost:0', '--master_port', '29500', '--master_addr', 'localhost', '--no_ssh_check', '--no_local_rank', '--no_python', '/usr/bin/python3', '-m', 'mii.launch.multi_gpu_server', '--deployment-name', 'mistralai/Mistral-7B-v0.1-mii-deployment', '--load-balancer-port', '50050', '--restful-gateway-port', '51080', '--restful-gateway-procs', '32', '--server-port', '50051', '--zmq-port', '25555', '--model-config', 'eyJtb2RlbF9uYW1lX29yX3BhdGgiOiAibWlzdHJhbGFpL01pc3RyYWwtN0ItdjAuMSIsICJ0b2tlbml6ZXIiOiAibWlzdHJhbGFpL01pc3RyYWwtN0ItdjAuMSIsICJ0YXNrIjogInRleHQtZ2VuZXJhdGlvbiIsICJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAiaW5mZXJlbmNlX2VuZ2luZV9jb25maWciOiB7InRlbnNvcl9wYXJhbGxlbCI6IHsidHBfc2l6ZSI6IDF9LCAic3RhdGVfbWFuYWdlciI6IHsibWF4X3RyYWNrZWRfc2VxdWVuY2VzIjogMjA0OCwgIm1heF9yYWdnZWRfYmF0Y2hfc2l6ZSI6IDc2OCwgIm1heF9yYWdnZWRfc2VxdWVuY2VfY291bnQiOiA1MTIsICJtYXhfY29udGV4dCI6IDgxOTIsICJtZW1vcnlfY29uZmlnIjogeyJtb2RlIjogInJlc2VydmUiLCAic2l6ZSI6IDEwMDAwMDAwMDB9LCAib2ZmbG9hZCI6IGZhbHNlfX0sICJ0b3JjaF9kaXN0X3BvcnQiOiAyOTUwMCwgInptcV9wb3J0X251bWJlciI6IDI1NTU1LCAicmVwbGljYV9udW0iOiAxLCAicmVwbGljYV9jb25maWdzIjogW3siaG9zdG5hbWUiOiAibG9jYWxob3N0IiwgInRlbnNvcl9wYXJhbGxlbF9wb3J0cyI6IFs1MDA1MV0sICJ0b3JjaF9kaXN0X3BvcnQiOiAyOTUwMCwgImdwdV9pbmRpY2VzIjogWzBdLCAiem1xX3BvcnQiOiAyNTU1NX1dLCAiZGV2aWNlX21hcCI6ICJhdXRvIiwgIm1heF9sZW5ndGgiOiBudWxsLCAiYWxsX3Jhbmtfb3V0cHV0IjogZmFsc2UsICJzeW5jX2RlYnVnIjogZmFsc2UsICJwcm9maWxlX21vZGVsX3RpbWUiOiBmYWxzZX0=']\n",
            "[2023-12-16 04:44:06,603] [INFO] [server.py:107:_launch_server_process] msg_server launch: ['deepspeed', '-i', 'localhost:0', '--master_port', '29500', '--master_addr', 'localhost', '--no_ssh_check', '--no_local_rank', '--no_python', '/usr/bin/python3', '-m', 'mii.launch.multi_gpu_server', '--deployment-name', 'mistralai/Mistral-7B-v0.1-mii-deployment', '--load-balancer-port', '50050', '--restful-gateway-port', '51080', '--restful-gateway-procs', '32', '--server-port', '50051', '--zmq-port', '25555', '--model-config', 'eyJtb2RlbF9uYW1lX29yX3BhdGgiOiAibWlzdHJhbGFpL01pc3RyYWwtN0ItdjAuMSIsICJ0b2tlbml6ZXIiOiAibWlzdHJhbGFpL01pc3RyYWwtN0ItdjAuMSIsICJ0YXNrIjogInRleHQtZ2VuZXJhdGlvbiIsICJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAiaW5mZXJlbmNlX2VuZ2luZV9jb25maWciOiB7InRlbnNvcl9wYXJhbGxlbCI6IHsidHBfc2l6ZSI6IDF9LCAic3RhdGVfbWFuYWdlciI6IHsibWF4X3RyYWNrZWRfc2VxdWVuY2VzIjogMjA0OCwgIm1heF9yYWdnZWRfYmF0Y2hfc2l6ZSI6IDc2OCwgIm1heF9yYWdnZWRfc2VxdWVuY2VfY291bnQiOiA1MTIsICJtYXhfY29udGV4dCI6IDgxOTIsICJtZW1vcnlfY29uZmlnIjogeyJtb2RlIjogInJlc2VydmUiLCAic2l6ZSI6IDEwMDAwMDAwMDB9LCAib2ZmbG9hZCI6IGZhbHNlfX0sICJ0b3JjaF9kaXN0X3BvcnQiOiAyOTUwMCwgInptcV9wb3J0X251bWJlciI6IDI1NTU1LCAicmVwbGljYV9udW0iOiAxLCAicmVwbGljYV9jb25maWdzIjogW3siaG9zdG5hbWUiOiAibG9jYWxob3N0IiwgInRlbnNvcl9wYXJhbGxlbF9wb3J0cyI6IFs1MDA1MV0sICJ0b3JjaF9kaXN0X3BvcnQiOiAyOTUwMCwgImdwdV9pbmRpY2VzIjogWzBdLCAiem1xX3BvcnQiOiAyNTU1NX1dLCAiZGV2aWNlX21hcCI6ICJhdXRvIiwgIm1heF9sZW5ndGgiOiBudWxsLCAiYWxsX3Jhbmtfb3V0cHV0IjogZmFsc2UsICJzeW5jX2RlYnVnIjogZmFsc2UsICJwcm9maWxlX21vZGVsX3RpbWUiOiBmYWxzZX0=']\n",
            "[2023-12-16 04:44:06,607] [INFO] [server.py:107:_launch_server_process] msg_server launch: ['/usr/bin/python3', '-m', 'mii.launch.multi_gpu_server', '--deployment-name', 'mistralai/Mistral-7B-v0.1-mii-deployment', '--load-balancer-port', '50050', '--restful-gateway-port', '51080', '--restful-gateway-procs', '32', '--load-balancer', '--model-config', 'eyJtb2RlbF9uYW1lX29yX3BhdGgiOiAibWlzdHJhbGFpL01pc3RyYWwtN0ItdjAuMSIsICJ0b2tlbml6ZXIiOiAibWlzdHJhbGFpL01pc3RyYWwtN0ItdjAuMSIsICJ0YXNrIjogInRleHQtZ2VuZXJhdGlvbiIsICJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAiaW5mZXJlbmNlX2VuZ2luZV9jb25maWciOiB7InRlbnNvcl9wYXJhbGxlbCI6IHsidHBfc2l6ZSI6IDF9LCAic3RhdGVfbWFuYWdlciI6IHsibWF4X3RyYWNrZWRfc2VxdWVuY2VzIjogMjA0OCwgIm1heF9yYWdnZWRfYmF0Y2hfc2l6ZSI6IDc2OCwgIm1heF9yYWdnZWRfc2VxdWVuY2VfY291bnQiOiA1MTIsICJtYXhfY29udGV4dCI6IDgxOTIsICJtZW1vcnlfY29uZmlnIjogeyJtb2RlIjogInJlc2VydmUiLCAic2l6ZSI6IDEwMDAwMDAwMDB9LCAib2ZmbG9hZCI6IGZhbHNlfX0sICJ0b3JjaF9kaXN0X3BvcnQiOiAyOTUwMCwgInptcV9wb3J0X251bWJlciI6IDI1NTU1LCAicmVwbGljYV9udW0iOiAxLCAicmVwbGljYV9jb25maWdzIjogW3siaG9zdG5hbWUiOiAibG9jYWxob3N0IiwgInRlbnNvcl9wYXJhbGxlbF9wb3J0cyI6IFs1MDA1MV0sICJ0b3JjaF9kaXN0X3BvcnQiOiAyOTUwMCwgImdwdV9pbmRpY2VzIjogWzBdLCAiem1xX3BvcnQiOiAyNTU1NX1dLCAiZGV2aWNlX21hcCI6ICJhdXRvIiwgIm1heF9sZW5ndGgiOiBudWxsLCAiYWxsX3Jhbmtfb3V0cHV0IjogZmFsc2UsICJzeW5jX2RlYnVnIjogZmFsc2UsICJwcm9maWxlX21vZGVsX3RpbWUiOiBmYWxzZX0=']\n",
            "[2023-12-16 04:44:06,607] [INFO] [server.py:107:_launch_server_process] msg_server launch: ['/usr/bin/python3', '-m', 'mii.launch.multi_gpu_server', '--deployment-name', 'mistralai/Mistral-7B-v0.1-mii-deployment', '--load-balancer-port', '50050', '--restful-gateway-port', '51080', '--restful-gateway-procs', '32', '--load-balancer', '--model-config', 'eyJtb2RlbF9uYW1lX29yX3BhdGgiOiAibWlzdHJhbGFpL01pc3RyYWwtN0ItdjAuMSIsICJ0b2tlbml6ZXIiOiAibWlzdHJhbGFpL01pc3RyYWwtN0ItdjAuMSIsICJ0YXNrIjogInRleHQtZ2VuZXJhdGlvbiIsICJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAiaW5mZXJlbmNlX2VuZ2luZV9jb25maWciOiB7InRlbnNvcl9wYXJhbGxlbCI6IHsidHBfc2l6ZSI6IDF9LCAic3RhdGVfbWFuYWdlciI6IHsibWF4X3RyYWNrZWRfc2VxdWVuY2VzIjogMjA0OCwgIm1heF9yYWdnZWRfYmF0Y2hfc2l6ZSI6IDc2OCwgIm1heF9yYWdnZWRfc2VxdWVuY2VfY291bnQiOiA1MTIsICJtYXhfY29udGV4dCI6IDgxOTIsICJtZW1vcnlfY29uZmlnIjogeyJtb2RlIjogInJlc2VydmUiLCAic2l6ZSI6IDEwMDAwMDAwMDB9LCAib2ZmbG9hZCI6IGZhbHNlfX0sICJ0b3JjaF9kaXN0X3BvcnQiOiAyOTUwMCwgInptcV9wb3J0X251bWJlciI6IDI1NTU1LCAicmVwbGljYV9udW0iOiAxLCAicmVwbGljYV9jb25maWdzIjogW3siaG9zdG5hbWUiOiAibG9jYWxob3N0IiwgInRlbnNvcl9wYXJhbGxlbF9wb3J0cyI6IFs1MDA1MV0sICJ0b3JjaF9kaXN0X3BvcnQiOiAyOTUwMCwgImdwdV9pbmRpY2VzIjogWzBdLCAiem1xX3BvcnQiOiAyNTU1NX1dLCAiZGV2aWNlX21hcCI6ICJhdXRvIiwgIm1heF9sZW5ndGgiOiBudWxsLCAiYWxsX3Jhbmtfb3V0cHV0IjogZmFsc2UsICJzeW5jX2RlYnVnIjogZmFsc2UsICJwcm9maWxlX21vZGVsX3RpbWUiOiBmYWxzZX0=']\n",
            "[2023-12-16 04:44:11,614] [INFO] [server.py:65:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-16 04:44:11,614] [INFO] [server.py:65:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-16 04:44:16,622] [INFO] [server.py:65:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-16 04:44:16,622] [INFO] [server.py:65:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-16 04:44:21,629] [INFO] [server.py:65:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-16 04:44:21,629] [INFO] [server.py:65:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-16 04:44:26,636] [INFO] [server.py:65:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-16 04:44:26,636] [INFO] [server.py:65:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-16 04:44:31,644] [INFO] [server.py:65:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-16 04:44:31,644] [INFO] [server.py:65:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-16 04:44:36,651] [INFO] [server.py:65:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-16 04:44:36,651] [INFO] [server.py:65:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-16 04:44:41,658] [INFO] [server.py:65:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-16 04:44:41,658] [INFO] [server.py:65:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-16 04:44:41,660] [INFO] [server.py:70:_wait_until_server_is_live] server has started on ports [50051]\n",
            "[2023-12-16 04:44:41,660] [INFO] [server.py:70:_wait_until_server_is_live] server has started on ports [50051]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<mii.backend.client.MIIClient at 0x7bb3e2cc5840>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!lsof -i:29500\n",
        "!lsof -i:50050\n",
        "!lsof -i:51080"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jy7xe6_V5icd",
        "outputId": "0e64896c-630a-4f5d-aafb-6cc5f258957e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COMMAND  PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\n",
            "python3 8608 root   15u  IPv6 193369      0t0  TCP *:29500 (LISTEN)\n",
            "python3 8608 root   18u  IPv6 193371      0t0  TCP localhost:33198->localhost:29500 (ESTABLISHED)\n",
            "python3 8608 root   19u  IPv6 188293      0t0  TCP localhost:29500->localhost:33198 (ESTABLISHED)\n",
            "COMMAND  PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\n",
            "python3 8440 root   22u  IPv4 190022      0t0  TCP *:50050 (LISTEN)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ps -ef | grep python3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHNG1BR275ob",
        "outputId": "bdc25908-bafb-4773-b305-ec24dfaa1c8f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root          68       7  0 04:16 ?        00:00:07 [python3] <defunct>\n",
            "root          69       7  0 04:16 ?        00:00:00 python3 /usr/local/bin/colab-fileshim.py\n",
            "root         125       7  0 04:16 ?        00:00:06 /usr/bin/python3 /usr/local/bin/jupyter-notebook\n",
            "root        7473     125  4 04:40 ?        00:00:12 /usr/bin/python3 -m colab_kernel_launcher -f /ro\n",
            "root        7511       1  0 04:40 ?        00:00:00 /usr/bin/python3 /usr/local/lib/python3.10/dist-\n",
            "root        8439    7473  9 04:44 ?        00:00:06 /usr/bin/python3 /usr/local/bin/deepspeed -i loc\n",
            "root        8440    7473 13 04:44 ?        00:00:09 /usr/bin/python3 -m mii.launch.multi_gpu_server \n",
            "root        8531    8439 10 04:44 ?        00:00:06 /usr/bin/python3 -u -m deepspeed.launcher.launch\n",
            "root        8608    8531 99 04:44 ?        00:01:07 /usr/bin/python3 -m mii.launch.multi_gpu_server \n",
            "root        8992    7473  0 04:45 ?        00:00:00 /bin/bash -c ps -ef | grep python3\n",
            "root        8994    8992  0 04:45 ?        00:00:00 grep python3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 上述服务器可以同时被多个客户端查询，这要归功于 DeepSpeed-MII 内置的负载平衡器。创建客户端也只需要两行代码：\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "#client = mii.client(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
        "client = mii.client(\"mistralai/Mistral-7B-v0.1\")\n",
        "output = client.generate(\"Deepspeed is\", max_new_tokens=128)\n",
        "print(output)\n"
      ],
      "metadata": {
        "id": "KruNB7amO1Z0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cd73be3-2eb5-44b0-aa82-05bc3a20f5f3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[an open-source, Nvidia-backed machine learning tool designed to make training deep learning models faster and more efficient. Deepspeed specializes in scaling deep learning models across different machines and GPU types. Deepspeed’s popularity has recently surged as Nvidia continues to push deep learning applications at scale.\n",
            "\n",
            "With the tool, engineers can train and scale models more efficiently, cutting down their training time and speeding up their model execution.\n",
            "\n",
            "Nvidia’s Deepspeed uses popular open source frameworks, including PyTorch, MPI, and Apex, to implement horizontal scaling]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# 使用 mistralai-7b mistral-tiny模型， 对中文支持不够，详情见 https://docs.mistral.ai/models/\n",
        "#\n",
        "#client = mii.client(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
        "client = mii.client(\"mistralai/Mistral-7B-v0.1\")\n",
        "output = client.generate(\"深度学习是\", max_new_tokens=128)\n",
        "print(output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ta10F1in8o26",
        "outputId": "6bc502ee-1837-4e07-dc98-8c42c76b11f2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[什么？\n",
            "\n",
            "1.作为一个主题，深度学习又被广泛地应用于计算机视觉、自然语言处理、人工智能、机器学习、凡是需要解决复杂问题的领域。\n",
            "\n",
            "2.深度学习依赖人工智能的基础学习。\n",
            "\n",
            "3.深度学习算法所使用的模型可以把复杂任务分解为一系列的任务，每个任务可以由不同]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#持久部署可以在不再需要时终止：\n",
        "\n",
        "client.terminate_server()\n"
      ],
      "metadata": {
        "id": "1DzeTAl4O9Vg"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!lsof -i:29500\n",
        "!lsof -i:50050\n",
        "!lsof -i:51080"
      ],
      "metadata": {
        "id": "6lsbYyb89dGB"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ps -ef | grep benchmark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WZhXjSN9hFy",
        "outputId": "60c8d891-60f0-41b1-884a-845bd3a95764"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root       80726    7473  0 09:22 ?        00:00:00 /bin/bash -c ps -ef | grep benchmark\n",
            "root       80728   80726  0 09:22 ?        00:00:00 grep benchmark\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ps -ef | grep run_benchmark | awk '{print $2}' | xargs kill"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhvdrNfS7m3v",
        "outputId": "d6c1e677-73e5-45b5-a2b2-7a9d2f3cd78e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kill: (80706): No such process\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MII-example"
      ],
      "metadata": {
        "id": "KVlzFqnp4oa7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/microsoft/DeepSpeedExamples.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9b7IFXY4oE8",
        "outputId": "c2aa313c-f86f-4712-c713-d0f838a12892"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DeepSpeedExamples'...\n",
            "remote: Enumerating objects: 9729, done.\u001b[K\n",
            "remote: Total 9729 (delta 0), reused 0 (delta 0), pack-reused 9729\u001b[K\n",
            "Receiving objects: 100% (9729/9729), 119.27 MiB | 16.49 MiB/s, done.\n",
            "Resolving deltas: 100% (5442/5442), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## benchmark-FasteGen"
      ],
      "metadata": {
        "id": "gk2XUKYI-eqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "print(locale.getpreferredencoding())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qe-LadfAKi3R",
        "outputId": "3396f68c-358d-4feb-cc5c-ca9406f92697"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UTF-8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding\n"
      ],
      "metadata": {
        "id": "vnX2XDymK0H8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4CeKfoE97xQ",
        "outputId": "2a624010-d45b-4112-ac6b-dba7182c8f5e"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: \n",
            "Add token as git credential? (Y/n) y\n",
            "Token is valid (permission: read).\n",
            "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
            "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
            "\n",
            "git config --global credential.helper store\n",
            "\n",
            "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
            "Token has not been saved to git credential helper.\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd DeepSpeedExamples/benchmarks/inference/mii \\\n",
        "  && python server.py -h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kQvcFiG-eKs",
        "outputId": "79a98f00-e397-466b-879d-b96d513a14ee"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-12-16 04:57:19,334] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "2023-12-16 04:57:21.470522: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 04:57:21.470583: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 04:57:21.472252: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 04:57:22.703255: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "usage: server.py [-h] [--model_name MODEL_NAME] [-d DEPLOYMENT_NAME] [-t TASK]\n",
            "                 [-m TENSOR_PARALLEL] [-b RAGGED_BATCH_SIZE] [-r REPLICA_NUM]\n",
            "                 cmd\n",
            "\n",
            "positional arguments:\n",
            "  cmd                   start, stop, or restart\n",
            "\n",
            "options:\n",
            "  -h, --help            show this help message and exit\n",
            "  --model_name MODEL_NAME\n",
            "                        Name of the model in the model_files to benchmark\n",
            "  -d DEPLOYMENT_NAME, --deployment_name DEPLOYMENT_NAME\n",
            "  -t TASK, --task TASK  Task type. Currently only text-generation is supported\n",
            "  -m TENSOR_PARALLEL, --tensor_parallel TENSOR_PARALLEL\n",
            "                        Degree of tensor (model) parallelism\n",
            "  -b RAGGED_BATCH_SIZE, --ragged_batch_size RAGGED_BATCH_SIZE\n",
            "                        Max batch size for ragged batching\n",
            "  -r REPLICA_NUM, --replica_num REPLICA_NUM\n",
            "                        Number of replicas for load balancing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd DeepSpeedExamples/benchmarks/inference/mii \\\n",
        "  && python server.py --model_name meta-llama/Llama-2-7b-hf -d llama2-7b-tp1-b768 -m 1 -b 768 start"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XB3aSLwr778Z",
        "outputId": "6023195f-d0b9-4c02-d3ef-49bc7375067b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-12-16 12:19:03,415] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "2023-12-16 12:19:05.592081: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 12:19:05.592139: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 12:19:05.593966: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 12:19:06.842722: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "[2023-12-16 12:19:08,002] [INFO] [server.py:38:__init__] Hostfile /job/hostfile not found, creating hostfile.\n",
            "[2023-12-16 12:19:08,002] [INFO] [server.py:38:__init__] Hostfile /job/hostfile not found, creating hostfile.\n",
            "[2023-12-16 12:19:08,009] [INFO] [server.py:107:_launch_server_process] msg_server launch: ['deepspeed', '-i', 'localhost:0', '--master_port', '29500', '--master_addr', 'localhost', '--no_ssh_check', '--no_local_rank', '--no_python', '/usr/bin/python3', '-m', 'mii.launch.multi_gpu_server', '--deployment-name', 'llama2-7b-tp1-b768', '--load-balancer-port', '50050', '--restful-gateway-port', '51080', '--restful-gateway-procs', '32', '--server-port', '50051', '--zmq-port', '25555', '--model-config', 'eyJtb2RlbF9uYW1lX29yX3BhdGgiOiAibWV0YS1sbGFtYS9MbGFtYS0yLTdiLWhmIiwgInRva2VuaXplciI6ICJtZXRhLWxsYW1hL0xsYW1hLTItN2ItaGYiLCAidGFzayI6ICJ0ZXh0LWdlbmVyYXRpb24iLCAidGVuc29yX3BhcmFsbGVsIjogMSwgImluZmVyZW5jZV9lbmdpbmVfY29uZmlnIjogeyJ0ZW5zb3JfcGFyYWxsZWwiOiB7InRwX3NpemUiOiAxfSwgInN0YXRlX21hbmFnZXIiOiB7Im1heF90cmFja2VkX3NlcXVlbmNlcyI6IDIwNDgsICJtYXhfcmFnZ2VkX2JhdGNoX3NpemUiOiA3NjgsICJtYXhfcmFnZ2VkX3NlcXVlbmNlX2NvdW50IjogNzY4LCAibWF4X2NvbnRleHQiOiA4MTkyLCAibWVtb3J5X2NvbmZpZyI6IHsibW9kZSI6ICJyZXNlcnZlIiwgInNpemUiOiAxMDAwMDAwMDAwfSwgIm9mZmxvYWQiOiBmYWxzZX19LCAidG9yY2hfZGlzdF9wb3J0IjogMjk1MDAsICJ6bXFfcG9ydF9udW1iZXIiOiAyNTU1NSwgInJlcGxpY2FfbnVtIjogMSwgInJlcGxpY2FfY29uZmlncyI6IFt7Imhvc3RuYW1lIjogImxvY2FsaG9zdCIsICJ0ZW5zb3JfcGFyYWxsZWxfcG9ydHMiOiBbNTAwNTFdLCAidG9yY2hfZGlzdF9wb3J0IjogMjk1MDAsICJncHVfaW5kaWNlcyI6IFswXSwgInptcV9wb3J0IjogMjU1NTV9XSwgImRldmljZV9tYXAiOiAiYXV0byIsICJtYXhfbGVuZ3RoIjogbnVsbCwgImFsbF9yYW5rX291dHB1dCI6IGZhbHNlLCAic3luY19kZWJ1ZyI6IGZhbHNlLCAicHJvZmlsZV9tb2RlbF90aW1lIjogZmFsc2V9']\n",
            "[2023-12-16 12:19:08,009] [INFO] [server.py:107:_launch_server_process] msg_server launch: ['deepspeed', '-i', 'localhost:0', '--master_port', '29500', '--master_addr', 'localhost', '--no_ssh_check', '--no_local_rank', '--no_python', '/usr/bin/python3', '-m', 'mii.launch.multi_gpu_server', '--deployment-name', 'llama2-7b-tp1-b768', '--load-balancer-port', '50050', '--restful-gateway-port', '51080', '--restful-gateway-procs', '32', '--server-port', '50051', '--zmq-port', '25555', '--model-config', 'eyJtb2RlbF9uYW1lX29yX3BhdGgiOiAibWV0YS1sbGFtYS9MbGFtYS0yLTdiLWhmIiwgInRva2VuaXplciI6ICJtZXRhLWxsYW1hL0xsYW1hLTItN2ItaGYiLCAidGFzayI6ICJ0ZXh0LWdlbmVyYXRpb24iLCAidGVuc29yX3BhcmFsbGVsIjogMSwgImluZmVyZW5jZV9lbmdpbmVfY29uZmlnIjogeyJ0ZW5zb3JfcGFyYWxsZWwiOiB7InRwX3NpemUiOiAxfSwgInN0YXRlX21hbmFnZXIiOiB7Im1heF90cmFja2VkX3NlcXVlbmNlcyI6IDIwNDgsICJtYXhfcmFnZ2VkX2JhdGNoX3NpemUiOiA3NjgsICJtYXhfcmFnZ2VkX3NlcXVlbmNlX2NvdW50IjogNzY4LCAibWF4X2NvbnRleHQiOiA4MTkyLCAibWVtb3J5X2NvbmZpZyI6IHsibW9kZSI6ICJyZXNlcnZlIiwgInNpemUiOiAxMDAwMDAwMDAwfSwgIm9mZmxvYWQiOiBmYWxzZX19LCAidG9yY2hfZGlzdF9wb3J0IjogMjk1MDAsICJ6bXFfcG9ydF9udW1iZXIiOiAyNTU1NSwgInJlcGxpY2FfbnVtIjogMSwgInJlcGxpY2FfY29uZmlncyI6IFt7Imhvc3RuYW1lIjogImxvY2FsaG9zdCIsICJ0ZW5zb3JfcGFyYWxsZWxfcG9ydHMiOiBbNTAwNTFdLCAidG9yY2hfZGlzdF9wb3J0IjogMjk1MDAsICJncHVfaW5kaWNlcyI6IFswXSwgInptcV9wb3J0IjogMjU1NTV9XSwgImRldmljZV9tYXAiOiAiYXV0byIsICJtYXhfbGVuZ3RoIjogbnVsbCwgImFsbF9yYW5rX291dHB1dCI6IGZhbHNlLCAic3luY19kZWJ1ZyI6IGZhbHNlLCAicHJvZmlsZV9tb2RlbF90aW1lIjogZmFsc2V9']\n",
            "[2023-12-16 12:19:08,010] [INFO] [server.py:107:_launch_server_process] msg_server launch: ['/usr/bin/python3', '-m', 'mii.launch.multi_gpu_server', '--deployment-name', 'llama2-7b-tp1-b768', '--load-balancer-port', '50050', '--restful-gateway-port', '51080', '--restful-gateway-procs', '32', '--load-balancer', '--model-config', 'eyJtb2RlbF9uYW1lX29yX3BhdGgiOiAibWV0YS1sbGFtYS9MbGFtYS0yLTdiLWhmIiwgInRva2VuaXplciI6ICJtZXRhLWxsYW1hL0xsYW1hLTItN2ItaGYiLCAidGFzayI6ICJ0ZXh0LWdlbmVyYXRpb24iLCAidGVuc29yX3BhcmFsbGVsIjogMSwgImluZmVyZW5jZV9lbmdpbmVfY29uZmlnIjogeyJ0ZW5zb3JfcGFyYWxsZWwiOiB7InRwX3NpemUiOiAxfSwgInN0YXRlX21hbmFnZXIiOiB7Im1heF90cmFja2VkX3NlcXVlbmNlcyI6IDIwNDgsICJtYXhfcmFnZ2VkX2JhdGNoX3NpemUiOiA3NjgsICJtYXhfcmFnZ2VkX3NlcXVlbmNlX2NvdW50IjogNzY4LCAibWF4X2NvbnRleHQiOiA4MTkyLCAibWVtb3J5X2NvbmZpZyI6IHsibW9kZSI6ICJyZXNlcnZlIiwgInNpemUiOiAxMDAwMDAwMDAwfSwgIm9mZmxvYWQiOiBmYWxzZX19LCAidG9yY2hfZGlzdF9wb3J0IjogMjk1MDAsICJ6bXFfcG9ydF9udW1iZXIiOiAyNTU1NSwgInJlcGxpY2FfbnVtIjogMSwgInJlcGxpY2FfY29uZmlncyI6IFt7Imhvc3RuYW1lIjogImxvY2FsaG9zdCIsICJ0ZW5zb3JfcGFyYWxsZWxfcG9ydHMiOiBbNTAwNTFdLCAidG9yY2hfZGlzdF9wb3J0IjogMjk1MDAsICJncHVfaW5kaWNlcyI6IFswXSwgInptcV9wb3J0IjogMjU1NTV9XSwgImRldmljZV9tYXAiOiAiYXV0byIsICJtYXhfbGVuZ3RoIjogbnVsbCwgImFsbF9yYW5rX291dHB1dCI6IGZhbHNlLCAic3luY19kZWJ1ZyI6IGZhbHNlLCAicHJvZmlsZV9tb2RlbF90aW1lIjogZmFsc2V9']\n",
            "[2023-12-16 12:19:08,010] [INFO] [server.py:107:_launch_server_process] msg_server launch: ['/usr/bin/python3', '-m', 'mii.launch.multi_gpu_server', '--deployment-name', 'llama2-7b-tp1-b768', '--load-balancer-port', '50050', '--restful-gateway-port', '51080', '--restful-gateway-procs', '32', '--load-balancer', '--model-config', 'eyJtb2RlbF9uYW1lX29yX3BhdGgiOiAibWV0YS1sbGFtYS9MbGFtYS0yLTdiLWhmIiwgInRva2VuaXplciI6ICJtZXRhLWxsYW1hL0xsYW1hLTItN2ItaGYiLCAidGFzayI6ICJ0ZXh0LWdlbmVyYXRpb24iLCAidGVuc29yX3BhcmFsbGVsIjogMSwgImluZmVyZW5jZV9lbmdpbmVfY29uZmlnIjogeyJ0ZW5zb3JfcGFyYWxsZWwiOiB7InRwX3NpemUiOiAxfSwgInN0YXRlX21hbmFnZXIiOiB7Im1heF90cmFja2VkX3NlcXVlbmNlcyI6IDIwNDgsICJtYXhfcmFnZ2VkX2JhdGNoX3NpemUiOiA3NjgsICJtYXhfcmFnZ2VkX3NlcXVlbmNlX2NvdW50IjogNzY4LCAibWF4X2NvbnRleHQiOiA4MTkyLCAibWVtb3J5X2NvbmZpZyI6IHsibW9kZSI6ICJyZXNlcnZlIiwgInNpemUiOiAxMDAwMDAwMDAwfSwgIm9mZmxvYWQiOiBmYWxzZX19LCAidG9yY2hfZGlzdF9wb3J0IjogMjk1MDAsICJ6bXFfcG9ydF9udW1iZXIiOiAyNTU1NSwgInJlcGxpY2FfbnVtIjogMSwgInJlcGxpY2FfY29uZmlncyI6IFt7Imhvc3RuYW1lIjogImxvY2FsaG9zdCIsICJ0ZW5zb3JfcGFyYWxsZWxfcG9ydHMiOiBbNTAwNTFdLCAidG9yY2hfZGlzdF9wb3J0IjogMjk1MDAsICJncHVfaW5kaWNlcyI6IFswXSwgInptcV9wb3J0IjogMjU1NTV9XSwgImRldmljZV9tYXAiOiAiYXV0byIsICJtYXhfbGVuZ3RoIjogbnVsbCwgImFsbF9yYW5rX291dHB1dCI6IGZhbHNlLCAic3luY19kZWJ1ZyI6IGZhbHNlLCAicHJvZmlsZV9tb2RlbF90aW1lIjogZmFsc2V9']\n",
            "[2023-12-16 12:19:10,559] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 12:19:10,607] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 12:19:12,458] [WARNING] [runner.py:202:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n",
            "[2023-12-16 12:19:12,464] [INFO] [runner.py:570:main] cmd = /usr/bin/python3 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29500 --no_python --no_local_rank --enable_each_rank_log=None /usr/bin/python3 -m mii.launch.multi_gpu_server --deployment-name llama2-7b-tp1-b768 --load-balancer-port 50050 --restful-gateway-port 51080 --restful-gateway-procs 32 --server-port 50051 --zmq-port 25555 --model-config eyJtb2RlbF9uYW1lX29yX3BhdGgiOiAibWV0YS1sbGFtYS9MbGFtYS0yLTdiLWhmIiwgInRva2VuaXplciI6ICJtZXRhLWxsYW1hL0xsYW1hLTItN2ItaGYiLCAidGFzayI6ICJ0ZXh0LWdlbmVyYXRpb24iLCAidGVuc29yX3BhcmFsbGVsIjogMSwgImluZmVyZW5jZV9lbmdpbmVfY29uZmlnIjogeyJ0ZW5zb3JfcGFyYWxsZWwiOiB7InRwX3NpemUiOiAxfSwgInN0YXRlX21hbmFnZXIiOiB7Im1heF90cmFja2VkX3NlcXVlbmNlcyI6IDIwNDgsICJtYXhfcmFnZ2VkX2JhdGNoX3NpemUiOiA3NjgsICJtYXhfcmFnZ2VkX3NlcXVlbmNlX2NvdW50IjogNzY4LCAibWF4X2NvbnRleHQiOiA4MTkyLCAibWVtb3J5X2NvbmZpZyI6IHsibW9kZSI6ICJyZXNlcnZlIiwgInNpemUiOiAxMDAwMDAwMDAwfSwgIm9mZmxvYWQiOiBmYWxzZX19LCAidG9yY2hfZGlzdF9wb3J0IjogMjk1MDAsICJ6bXFfcG9ydF9udW1iZXIiOiAyNTU1NSwgInJlcGxpY2FfbnVtIjogMSwgInJlcGxpY2FfY29uZmlncyI6IFt7Imhvc3RuYW1lIjogImxvY2FsaG9zdCIsICJ0ZW5zb3JfcGFyYWxsZWxfcG9ydHMiOiBbNTAwNTFdLCAidG9yY2hfZGlzdF9wb3J0IjogMjk1MDAsICJncHVfaW5kaWNlcyI6IFswXSwgInptcV9wb3J0IjogMjU1NTV9XSwgImRldmljZV9tYXAiOiAiYXV0byIsICJtYXhfbGVuZ3RoIjogbnVsbCwgImFsbF9yYW5rX291dHB1dCI6IGZhbHNlLCAic3luY19kZWJ1ZyI6IGZhbHNlLCAicHJvZmlsZV9tb2RlbF90aW1lIjogZmFsc2V9\n",
            "2023-12-16 12:19:12.780686: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 12:19:12.780737: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 12:19:12.781966: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "[2023-12-16 12:19:13,015] [INFO] [server.py:65:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-16 12:19:13,015] [INFO] [server.py:65:_wait_until_server_is_live] waiting for server to start...\n",
            "2023-12-16 12:19:14.093846: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "[2023-12-16 12:19:14,935] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "Starting load balancer on port: 50050\n",
            "About to start server\n",
            "Started\n",
            "[2023-12-16 12:19:16,801] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE=libnccl-dev=2.19.3-1+cuda12.2\n",
            "[2023-12-16 12:19:16,801] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE_VERSION=2.19.3-1\n",
            "[2023-12-16 12:19:16,801] [INFO] [launch.py:138:main] 0 NCCL_VERSION=2.19.3-1\n",
            "[2023-12-16 12:19:16,801] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE_NAME=libnccl-dev\n",
            "[2023-12-16 12:19:16,801] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE=libnccl2=2.19.3-1+cuda12.2\n",
            "[2023-12-16 12:19:16,801] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE_NAME=libnccl2\n",
            "[2023-12-16 12:19:16,801] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE_VERSION=2.19.3-1\n",
            "[2023-12-16 12:19:16,801] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0]}\n",
            "[2023-12-16 12:19:16,801] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=1, node_rank=0\n",
            "[2023-12-16 12:19:16,801] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})\n",
            "[2023-12-16 12:19:16,801] [INFO] [launch.py:163:main] dist_world_size=1\n",
            "[2023-12-16 12:19:16,801] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0\n",
            "[2023-12-16 12:19:18,019] [INFO] [server.py:65:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-16 12:19:18,019] [INFO] [server.py:65:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-16 12:19:19,306] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "2023-12-16 12:19:21.408712: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 12:19:21.408766: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 12:19:21.409981: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 12:19:22.627492: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "[2023-12-16 12:19:23,023] [INFO] [server.py:65:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-16 12:19:23,023] [INFO] [server.py:65:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-16 12:19:23,822] [INFO] [comm.py:637:init_distributed] cdb=None\n",
            "[2023-12-16 12:19:23,823] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
            "config.json: 100% 609/609 [00:00<00:00, 3.35MB/s]\n",
            "generation_config.json: 100% 188/188 [00:00<00:00, 1.02MB/s]\n",
            "Fetching 9 files:   0% 0/9 [00:00<?, ?it/s]\n",
            "model-00001-of-00002.safetensors:   0% 0.00/9.98G [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   0% 0.00/3.50G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   0% 10.5M/9.98G [00:00<02:29, 66.8MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   1% 31.5M/3.50G [00:00<00:12, 271MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "special_tokens_map.json: 100% 414/414 [00:00<00:00, 2.25MB/s]\n",
            "\n",
            "\n",
            "\n",
            "tokenizer_config.json: 100% 776/776 [00:00<00:00, 3.26MB/s]\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin.index.json: 100% 26.8k/26.8k [00:00<00:00, 77.0MB/s]\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors.index.json: 100% 26.8k/26.8k [00:00<00:00, 51.5MB/s]\n",
            "\n",
            "\n",
            "\n",
            "tokenizer.json:   0% 0.00/1.84M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   0% 31.5M/9.98G [00:00<01:17, 129MB/s] \u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   2% 83.9M/3.50G [00:00<00:09, 370MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 73.4M/9.98G [00:00<00:46, 214MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   4% 126M/3.50G [00:00<00:09, 356MB/s] \u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 105M/9.98G [00:00<00:41, 238MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 147M/9.98G [00:00<00:38, 256MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   5% 168M/3.50G [00:00<00:12, 260MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 189M/9.98G [00:00<00:32, 300MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   6% 199M/3.50G [00:00<00:12, 265MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 231M/9.98G [00:00<00:29, 327MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   7% 241M/3.50G [00:00<00:11, 279MB/s]\u001b[A\u001b[A[2023-12-16 12:19:28,027] [INFO] [server.py:65:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-16 12:19:28,027] [INFO] [server.py:65:_wait_until_server_is_live] waiting for server to start...\n",
            "\n",
            "model-00001-of-00002.safetensors:   3% 273M/9.98G [00:01<00:31, 311MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   8% 273M/3.50G [00:00<00:12, 256MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 315M/9.98G [00:01<00:34, 276MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   9% 304M/3.50G [00:01<00:13, 237MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 357M/9.98G [00:01<00:35, 273MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  10% 336M/3.50G [00:01<00:14, 215MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 398M/9.98G [00:01<00:33, 290MB/s]\u001b[A\n",
            "\n",
            "\n",
            "tokenizer.json: 100% 1.84M/1.84M [00:01<00:00, 1.48MB/s]\n",
            "\n",
            "\n",
            "model-00002-of-00002.safetensors:  10% 367M/3.50G [00:01<00:14, 221MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 430M/9.98G [00:01<00:32, 292MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  11% 398M/3.50G [00:01<00:13, 232MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 472M/9.98G [00:01<00:30, 309MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  12% 430M/3.50G [00:01<00:12, 246MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 514M/9.98G [00:01<00:30, 315MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  13% 461M/3.50G [00:01<00:13, 221MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 556M/9.98G [00:01<00:30, 311MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  14% 493M/3.50G [00:01<00:13, 231MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 587M/9.98G [00:02<00:30, 303MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  15% 535M/3.50G [00:02<00:11, 254MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 629M/9.98G [00:02<00:28, 325MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  16% 566M/3.50G [00:02<00:10, 268MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 671M/9.98G [00:02<00:27, 336MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  17% 598M/3.50G [00:02<00:13, 223MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 713M/9.98G [00:02<00:33, 274MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  18% 629M/3.50G [00:02<00:12, 233MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 755M/9.98G [00:02<00:30, 300MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  19% 661M/3.50G [00:02<00:11, 246MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 797M/9.98G [00:02<00:29, 313MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  20% 703M/3.50G [00:02<00:10, 278MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 839M/9.98G [00:02<00:27, 334MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 881M/9.98G [00:02<00:26, 346MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  21% 734M/3.50G [00:02<00:10, 256MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 923M/9.98G [00:03<00:27, 333MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  22% 765M/3.50G [00:03<00:11, 247MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 965M/9.98G [00:03<00:27, 331MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  23% 797M/3.50G [00:03<00:11, 228MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 1.01G/9.98G [00:03<00:28, 320MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  24% 828M/3.50G [00:03<00:11, 242MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 1.05G/9.98G [00:03<00:27, 325MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  25% 860M/3.50G [00:03<00:11, 239MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 1.09G/9.98G [00:03<00:27, 327MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  25% 891M/3.50G [00:03<00:10, 239MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  26% 923M/3.50G [00:03<00:10, 248MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 1.13G/9.98G [00:03<00:28, 308MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  27% 954M/3.50G [00:03<00:09, 258MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 1.17G/9.98G [00:03<00:27, 323MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 1.22G/9.98G [00:04<00:26, 334MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  28% 986M/3.50G [00:03<00:09, 253MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 1.26G/9.98G [00:04<00:25, 338MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  29% 1.02G/3.50G [00:04<00:10, 227MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 1.30G/9.98G [00:04<00:25, 337MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 1.34G/9.98G [00:04<00:25, 334MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  30% 1.05G/3.50G [00:04<00:12, 201MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 1.38G/9.98G [00:04<00:26, 330MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  31% 1.09G/3.50G [00:04<00:10, 230MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  32% 1.12G/3.50G [00:04<00:09, 241MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 1.43G/9.98G [00:04<00:26, 317MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  33% 1.15G/3.50G [00:04<00:09, 240MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 1.47G/9.98G [00:04<00:28, 301MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 1.50G/9.98G [00:04<00:27, 304MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  34% 1.18G/3.50G [00:04<00:10, 223MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 1.53G/9.98G [00:05<00:29, 289MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  35% 1.22G/3.50G [00:05<00:10, 228MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 1.56G/9.98G [00:05<00:30, 273MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  36% 1.25G/3.50G [00:05<00:10, 221MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 1.59G/9.98G [00:05<00:30, 275MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  37% 1.28G/3.50G [00:05<00:09, 233MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 1.63G/9.98G [00:05<00:30, 273MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  37% 1.31G/3.50G [00:05<00:10, 216MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 1.67G/9.98G [00:05<00:28, 296MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  38% 1.34G/3.50G [00:05<00:09, 231MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 1.70G/9.98G [00:05<00:29, 280MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  39% 1.37G/3.50G [00:05<00:09, 233MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 1.73G/9.98G [00:05<00:34, 239MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  40% 1.41G/3.50G [00:05<00:09, 233MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 1.77G/9.98G [00:05<00:29, 275MB/s]\u001b[A[2023-12-16 12:19:33,032] [INFO] [server.py:65:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-16 12:19:33,032] [INFO] [server.py:65:_wait_until_server_is_live] waiting for server to start...\n",
            "\n",
            "model-00001-of-00002.safetensors:  18% 1.80G/9.98G [00:06<00:40, 202MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  41% 1.44G/3.50G [00:06<00:14, 147MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 1.84G/9.98G [00:06<00:39, 207MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  42% 1.46G/3.50G [00:06<00:13, 146MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 1.87G/9.98G [00:06<00:41, 196MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  43% 1.49G/3.50G [00:06<00:11, 170MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  43% 1.51G/3.50G [00:06<00:11, 167MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 1.90G/9.98G [00:06<00:45, 178MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  44% 1.53G/3.50G [00:06<00:11, 165MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 1.92G/9.98G [00:06<00:44, 180MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  44% 1.55G/3.50G [00:06<00:12, 159MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 1.94G/9.98G [00:07<00:47, 171MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  45% 1.57G/3.50G [00:07<00:12, 155MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 1.96G/9.98G [00:07<00:48, 165MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  46% 1.59G/3.50G [00:07<00:11, 161MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 1.98G/9.98G [00:07<00:47, 169MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  46% 1.61G/3.50G [00:07<00:12, 156MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 2.00G/9.98G [00:07<00:50, 159MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  47% 1.64G/3.50G [00:07<00:11, 161MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 2.02G/9.98G [00:07<00:48, 165MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  47% 1.66G/3.50G [00:07<00:11, 157MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 2.04G/9.98G [00:07<00:50, 157MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  48% 1.68G/3.50G [00:07<00:11, 152MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 2.07G/9.98G [00:07<00:48, 162MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  49% 1.70G/3.50G [00:07<00:12, 149MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 2.09G/9.98G [00:07<00:50, 156MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  49% 1.72G/3.50G [00:07<00:11, 156MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 2.11G/9.98G [00:08<00:51, 153MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  50% 1.74G/3.50G [00:08<00:11, 151MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 2.13G/9.98G [00:08<00:52, 149MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  50% 1.76G/3.50G [00:08<00:11, 148MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 2.15G/9.98G [00:08<00:53, 146MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  51% 1.78G/3.50G [00:08<00:12, 135MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 2.17G/9.98G [00:08<00:55, 142MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  52% 1.80G/3.50G [00:08<00:12, 133MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 2.19G/9.98G [00:08<01:00, 129MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  52% 1.82G/3.50G [00:08<00:14, 120MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 2.21G/9.98G [00:08<01:04, 120MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  53% 1.85G/3.50G [00:09<00:15, 108MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 2.23G/9.98G [00:09<01:14, 104MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  53% 1.87G/3.50G [00:09<00:18, 88.4MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 2.25G/9.98G [00:09<01:28, 87.1MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  54% 1.88G/3.50G [00:09<00:21, 77.2MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 2.26G/9.98G [00:09<01:40, 76.5MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  54% 1.89G/3.50G [00:09<00:21, 74.2MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 2.28G/9.98G [00:09<01:48, 71.3MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  54% 1.90G/3.50G [00:09<00:22, 71.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  55% 1.91G/3.50G [00:10<00:20, 77.1MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 2.29G/9.98G [00:10<02:18, 55.4MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  55% 1.93G/3.50G [00:10<00:17, 90.6MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 2.31G/9.98G [00:10<01:40, 76.0MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  56% 1.95G/3.50G [00:10<00:14, 108MB/s] \u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 2.33G/9.98G [00:10<01:20, 95.3MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  57% 1.98G/3.50G [00:10<00:10, 143MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 2.37G/9.98G [00:10<00:50, 152MB/s] \u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  57% 2.00G/3.50G [00:10<00:09, 153MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 2.40G/9.98G [00:10<00:43, 173MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  58% 2.02G/3.50G [00:10<00:09, 154MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 2.42G/9.98G [00:10<00:47, 158MB/s]\u001b[A[2023-12-16 12:19:38,036] [INFO] [server.py:65:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-16 12:19:38,036] [INFO] [server.py:65:_wait_until_server_is_live] waiting for server to start...\n",
            "\n",
            "\n",
            "model-00002-of-00002.safetensors:  58% 2.04G/3.50G [00:10<00:09, 149MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 2.44G/9.98G [00:11<00:45, 164MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  59% 2.07G/3.50G [00:11<00:10, 141MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 2.46G/9.98G [00:11<00:50, 150MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  60% 2.09G/3.50G [00:11<00:10, 137MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 2.49G/9.98G [00:11<00:54, 137MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  60% 2.11G/3.50G [00:11<00:10, 127MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 2.51G/9.98G [00:11<00:57, 131MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  61% 2.13G/3.50G [00:11<00:11, 119MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 2.53G/9.98G [00:11<01:02, 120MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  61% 2.15G/3.50G [00:11<00:11, 114MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 2.55G/9.98G [00:12<01:05, 113MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  62% 2.17G/3.50G [00:12<00:11, 116MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 2.57G/9.98G [00:12<00:59, 125MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  63% 2.19G/3.50G [00:12<00:10, 128MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 2.59G/9.98G [00:12<00:54, 135MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  63% 2.21G/3.50G [00:12<00:09, 141MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 2.61G/9.98G [00:12<00:50, 145MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  64% 2.23G/3.50G [00:12<00:08, 150MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 2.63G/9.98G [00:12<00:46, 156MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  64% 2.25G/3.50G [00:12<00:07, 161MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 2.65G/9.98G [00:12<00:43, 169MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  65% 2.29G/3.50G [00:12<00:06, 182MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 2.68G/9.98G [00:12<00:38, 188MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  66% 2.32G/3.50G [00:12<00:06, 190MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 2.71G/9.98G [00:12<00:37, 192MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 2.73G/9.98G [00:12<00:38, 189MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  67% 2.35G/3.50G [00:12<00:05, 193MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 2.75G/9.98G [00:13<00:45, 160MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  68% 2.37G/3.50G [00:13<00:09, 119MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 2.77G/9.98G [00:15<04:11, 28.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 2.81G/9.98G [00:15<02:26, 48.8MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  68% 2.39G/3.50G [00:15<00:36, 30.1MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 2.85G/9.98G [00:15<01:40, 71.0MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  69% 2.41G/3.50G [00:15<00:29, 37.3MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 2.88G/9.98G [00:15<01:20, 88.3MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  69% 2.43G/3.50G [00:15<00:22, 47.5MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 2.90G/9.98G [00:15<01:13, 96.0MB/s]\u001b[A[2023-12-16 12:19:43,041] [INFO] [server.py:65:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-16 12:19:43,041] [INFO] [server.py:65:_wait_until_server_is_live] waiting for server to start...\n",
            "\n",
            "\n",
            "model-00002-of-00002.safetensors:  70% 2.45G/3.50G [00:15<00:17, 59.2MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 2.93G/9.98G [00:16<01:06, 106MB/s] \u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  71% 2.47G/3.50G [00:16<00:14, 72.4MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 2.95G/9.98G [00:16<01:03, 110MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  71% 2.50G/3.50G [00:16<00:11, 85.7MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 2.97G/9.98G [00:16<00:59, 118MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  72% 2.52G/3.50G [00:16<00:10, 97.2MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 2.99G/9.98G [00:16<00:56, 124MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  72% 2.54G/3.50G [00:16<00:08, 108MB/s] \u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 3.01G/9.98G [00:16<00:53, 130MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  73% 2.56G/3.50G [00:16<00:08, 112MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 3.03G/9.98G [00:16<00:51, 136MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  74% 2.58G/3.50G [00:16<00:07, 121MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 3.05G/9.98G [00:16<00:51, 134MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  74% 2.60G/3.50G [00:16<00:07, 127MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 3.07G/9.98G [00:17<00:49, 139MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  75% 2.62G/3.50G [00:17<00:06, 134MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 3.09G/9.98G [00:17<00:47, 144MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  75% 2.64G/3.50G [00:17<00:06, 139MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 3.11G/9.98G [00:17<00:46, 147MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  76% 2.66G/3.50G [00:17<00:05, 143MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 3.14G/9.98G [00:17<00:46, 148MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  77% 2.68G/3.50G [00:17<00:05, 144MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 3.16G/9.98G [00:17<00:46, 148MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  77% 2.71G/3.50G [00:17<00:05, 144MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 3.18G/9.98G [00:17<00:46, 147MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  78% 2.73G/3.50G [00:17<00:05, 144MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 3.20G/9.98G [00:17<00:48, 140MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  78% 2.75G/3.50G [00:17<00:05, 137MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 3.22G/9.98G [00:18<00:49, 138MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  79% 2.77G/3.50G [00:18<00:05, 134MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 3.24G/9.98G [00:18<00:52, 130MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  80% 2.79G/3.50G [00:18<00:05, 121MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 3.26G/9.98G [00:18<00:57, 117MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  80% 2.81G/3.50G [00:18<00:06, 108MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 3.28G/9.98G [00:18<01:05, 102MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  81% 2.83G/3.50G [00:18<00:07, 92.5MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 3.30G/9.98G [00:19<01:21, 81.6MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  81% 2.84G/3.50G [00:19<00:08, 79.7MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 3.31G/9.98G [00:19<01:30, 73.7MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  81% 2.85G/3.50G [00:19<00:09, 71.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  82% 2.86G/3.50G [00:19<00:09, 69.5MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 3.32G/9.98G [00:19<01:36, 69.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 3.34G/9.98G [00:19<01:14, 89.2MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  82% 2.88G/3.50G [00:19<00:07, 81.2MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 3.37G/9.98G [00:19<01:06, 99.6MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  83% 2.92G/3.50G [00:19<00:05, 110MB/s] \u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 3.40G/9.98G [00:20<00:51, 129MB/s] \u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  84% 2.94G/3.50G [00:19<00:04, 120MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 3.42G/9.98G [00:20<00:46, 141MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  85% 2.97G/3.50G [00:20<00:04, 125MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 3.44G/9.98G [00:20<00:52, 125MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  85% 2.99G/3.50G [00:20<00:03, 139MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 3.46G/9.98G [00:20<00:46, 139MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  86% 3.01G/3.50G [00:20<00:03, 145MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 3.48G/9.98G [00:20<00:44, 146MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  87% 3.03G/3.50G [00:20<00:03, 151MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 3.50G/9.98G [00:20<00:45, 142MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  87% 3.05G/3.50G [00:20<00:02, 164MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  88% 3.08G/3.50G [00:20<00:02, 188MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 3.52G/9.98G [00:20<00:49, 131MB/s]\u001b[A[2023-12-16 12:19:48,045] [INFO] [server.py:65:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-16 12:19:48,045] [INFO] [server.py:65:_wait_until_server_is_live] waiting for server to start...\n",
            "\n",
            "\n",
            "model-00002-of-00002.safetensors:  89% 3.10G/3.50G [00:20<00:02, 189MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 3.54G/9.98G [00:21<00:45, 143MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  89% 3.12G/3.50G [00:21<00:02, 165MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 3.57G/9.98G [00:21<00:50, 128MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  90% 3.15G/3.50G [00:21<00:02, 144MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 3.59G/9.98G [00:21<00:50, 127MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  90% 3.17G/3.50G [00:21<00:02, 145MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 3.61G/9.98G [00:21<00:47, 135MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  91% 3.19G/3.50G [00:21<00:02, 148MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 3.63G/9.98G [00:21<00:45, 140MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  92% 3.21G/3.50G [00:21<00:01, 155MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 3.65G/9.98G [00:21<00:41, 152MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  92% 3.23G/3.50G [00:21<00:01, 161MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 3.67G/9.98G [00:21<00:38, 162MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 3.69G/9.98G [00:22<00:36, 172MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  93% 3.26G/3.50G [00:21<00:01, 179MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 3.72G/9.98G [00:22<00:31, 196MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  94% 3.29G/3.50G [00:22<00:01, 199MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 3.75G/9.98G [00:22<00:31, 197MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  95% 3.32G/3.50G [00:22<00:00, 181MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 3.77G/9.98G [00:25<04:12, 24.5MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  96% 3.34G/3.50G [00:25<00:06, 25.6MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 3.80G/9.98G [00:25<03:13, 32.0MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  96% 3.37G/3.50G [00:25<00:04, 32.7MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 3.82G/9.98G [00:25<02:31, 40.6MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  97% 3.39G/3.50G [00:25<00:02, 42.0MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 3.84G/9.98G [00:25<01:59, 51.2MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  97% 3.41G/3.50G [00:25<00:01, 52.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  98% 3.43G/3.50G [00:25<00:01, 64.4MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 3.86G/9.98G [00:25<01:37, 62.5MB/s]\u001b[A[2023-12-16 12:19:53,050] [INFO] [server.py:65:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-16 12:19:53,050] [INFO] [server.py:65:_wait_until_server_is_live] waiting for server to start...\n",
            "\n",
            "model-00001-of-00002.safetensors:  39% 3.88G/9.98G [00:26<01:21, 74.7MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  99% 3.45G/3.50G [00:25<00:00, 75.6MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 3.90G/9.98G [00:26<01:10, 85.7MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  99% 3.47G/3.50G [00:26<00:00, 86.6MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 3.92G/9.98G [00:26<01:04, 94.5MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors: 100% 3.50G/3.50G [00:26<00:00, 132MB/s] \n",
            "\n",
            "model-00001-of-00002.safetensors:  40% 3.94G/9.98G [00:26<01:01, 98.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 3.96G/9.98G [00:26<00:58, 103MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 3.98G/9.98G [00:26<00:57, 105MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 4.01G/9.98G [00:27<00:56, 106MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 4.03G/9.98G [00:27<01:05, 90.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 4.06G/9.98G [00:27<00:50, 117MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 4.08G/9.98G [00:27<00:49, 120MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 4.10G/9.98G [00:27<00:45, 128MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 4.12G/9.98G [00:28<00:42, 136MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 4.14G/9.98G [00:28<00:38, 151MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 4.18G/9.98G [00:28<00:29, 200MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 4.23G/9.98G [00:28<00:23, 250MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 4.26G/9.98G [00:28<00:21, 264MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 4.29G/9.98G [00:28<00:21, 269MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 4.33G/9.98G [00:28<00:18, 299MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 4.37G/9.98G [00:28<00:18, 295MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 4.42G/9.98G [00:28<00:17, 314MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 4.47G/9.98G [00:29<00:20, 268MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 4.51G/9.98G [00:29<00:18, 297MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 4.56G/9.98G [00:29<00:15, 339MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 4.60G/9.98G [00:29<00:15, 352MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 4.65G/9.98G [00:29<00:15, 353MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 4.69G/9.98G [00:29<00:14, 362MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 4.73G/9.98G [00:29<00:14, 350MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 4.77G/9.98G [00:29<00:14, 354MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 4.81G/9.98G [00:30<00:15, 335MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 4.85G/9.98G [00:30<00:17, 296MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 4.90G/9.98G [00:30<00:15, 323MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 4.94G/9.98G [00:30<00:14, 336MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 4.98G/9.98G [00:30<00:14, 335MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 5.02G/9.98G [00:30<00:15, 320MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 5.06G/9.98G [00:30<00:14, 336MB/s]\u001b[A[2023-12-16 12:19:58,054] [INFO] [server.py:65:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-16 12:19:58,054] [INFO] [server.py:65:_wait_until_server_is_live] waiting for server to start...\n",
            "\n",
            "model-00001-of-00002.safetensors:  51% 5.11G/9.98G [00:31<00:14, 336MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 5.15G/9.98G [00:31<00:17, 284MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 5.20G/9.98G [00:31<00:15, 308MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 5.24G/9.98G [00:31<00:14, 325MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 5.28G/9.98G [00:31<00:13, 339MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 5.33G/9.98G [00:31<00:13, 339MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 5.37G/9.98G [00:31<00:13, 346MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 5.41G/9.98G [00:31<00:13, 341MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 5.45G/9.98G [00:32<00:13, 347MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 5.49G/9.98G [00:32<00:12, 352MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 5.54G/9.98G [00:32<00:12, 369MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 5.58G/9.98G [00:32<00:12, 341MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 5.62G/9.98G [00:32<00:13, 322MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 5.66G/9.98G [00:32<00:13, 326MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 5.70G/9.98G [00:32<00:13, 328MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 5.75G/9.98G [00:32<00:13, 315MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 5.79G/9.98G [00:33<00:13, 312MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 5.83G/9.98G [00:33<00:12, 324MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 5.87G/9.98G [00:33<00:12, 316MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 5.91G/9.98G [00:33<00:12, 317MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 5.96G/9.98G [00:33<00:13, 293MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 6.00G/9.98G [00:33<00:13, 305MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 6.04G/9.98G [00:33<00:12, 311MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 6.07G/9.98G [00:34<00:13, 300MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 6.11G/9.98G [00:34<00:12, 313MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 6.16G/9.98G [00:34<00:11, 332MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 6.20G/9.98G [00:34<00:11, 320MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 6.24G/9.98G [00:34<00:10, 341MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 6.28G/9.98G [00:34<00:10, 355MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 6.32G/9.98G [00:34<00:10, 345MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 6.36G/9.98G [00:34<00:10, 330MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 6.41G/9.98G [00:35<00:11, 322MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 6.45G/9.98G [00:35<00:10, 329MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 6.49G/9.98G [00:35<00:10, 339MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 6.54G/9.98G [00:35<00:09, 365MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 6.59G/9.98G [00:35<00:09, 372MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 6.63G/9.98G [00:35<00:09, 342MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 6.67G/9.98G [00:35<00:10, 330MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 6.72G/9.98G [00:35<00:09, 356MB/s]\u001b[A[2023-12-16 12:20:03,058] [INFO] [server.py:65:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-16 12:20:03,058] [INFO] [server.py:65:_wait_until_server_is_live] waiting for server to start...\n",
            "\n",
            "model-00001-of-00002.safetensors:  68% 6.76G/9.98G [00:36<00:09, 352MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 6.81G/9.98G [00:36<00:08, 358MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 6.86G/9.98G [00:36<00:08, 380MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 6.91G/9.98G [00:36<00:07, 401MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 6.96G/9.98G [00:36<00:07, 417MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 7.00G/9.98G [00:36<00:07, 386MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 7.05G/9.98G [00:36<00:07, 388MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 7.10G/9.98G [00:36<00:07, 400MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 7.14G/9.98G [00:36<00:07, 391MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 7.18G/9.98G [00:37<00:07, 384MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 7.22G/9.98G [00:37<00:07, 392MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 7.27G/9.98G [00:37<00:07, 361MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 7.31G/9.98G [00:37<00:12, 221MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 7.35G/9.98G [00:37<00:10, 254MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 7.39G/9.98G [00:37<00:09, 260MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 7.42G/9.98G [00:38<00:09, 265MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 7.48G/9.98G [00:38<00:08, 312MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 7.52G/9.98G [00:38<00:07, 309MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 7.56G/9.98G [00:38<00:07, 328MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 7.60G/9.98G [00:38<00:07, 335MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 7.65G/9.98G [00:38<00:06, 364MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 7.71G/9.98G [00:38<00:05, 384MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 7.75G/9.98G [00:38<00:05, 373MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 7.79G/9.98G [00:39<00:05, 373MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 7.83G/9.98G [00:39<00:05, 374MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 7.87G/9.98G [00:39<00:05, 352MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 7.92G/9.98G [00:39<00:06, 314MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 7.96G/9.98G [00:39<00:06, 316MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 8.00G/9.98G [00:39<00:06, 327MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 8.05G/9.98G [00:39<00:05, 352MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 8.10G/9.98G [00:39<00:05, 365MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 8.14G/9.98G [00:40<00:05, 354MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 8.18G/9.98G [00:40<00:05, 317MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 8.22G/9.98G [00:40<00:05, 334MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 8.26G/9.98G [00:40<00:04, 350MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 8.30G/9.98G [00:40<00:04, 362MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 8.35G/9.98G [00:40<00:04, 371MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 8.39G/9.98G [00:40<00:04, 375MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 8.43G/9.98G [00:40<00:05, 269MB/s]\u001b[A[2023-12-16 12:20:08,063] [INFO] [server.py:65:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-16 12:20:08,063] [INFO] [server.py:65:_wait_until_server_is_live] waiting for server to start...\n",
            "\n",
            "model-00001-of-00002.safetensors:  85% 8.47G/9.98G [00:41<00:04, 301MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 8.51G/9.98G [00:41<00:04, 299MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 8.56G/9.98G [00:41<00:04, 315MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 8.60G/9.98G [00:41<00:04, 319MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 8.64G/9.98G [00:41<00:04, 316MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 8.68G/9.98G [00:41<00:04, 316MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 8.73G/9.98G [00:41<00:03, 361MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 8.79G/9.98G [00:41<00:03, 396MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 8.84G/9.98G [00:42<00:02, 422MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 8.89G/9.98G [00:42<00:02, 385MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 8.93G/9.98G [00:42<00:02, 369MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 8.98G/9.98G [00:42<00:02, 342MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 9.02G/9.98G [00:42<00:02, 340MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 9.06G/9.98G [00:42<00:02, 351MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 9.10G/9.98G [00:42<00:02, 351MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 9.15G/9.98G [00:42<00:02, 381MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 9.20G/9.98G [00:43<00:02, 370MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 9.25G/9.98G [00:43<00:01, 397MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 9.29G/9.98G [00:43<00:01, 383MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 9.33G/9.98G [00:43<00:01, 377MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 9.37G/9.98G [00:43<00:01, 357MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 9.42G/9.98G [00:43<00:01, 356MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 9.46G/9.98G [00:43<00:01, 350MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 9.50G/9.98G [00:43<00:01, 348MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 9.54G/9.98G [00:44<00:01, 348MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 9.58G/9.98G [00:44<00:01, 249MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 9.62G/9.98G [00:44<00:01, 255MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 9.67G/9.98G [00:44<00:01, 299MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 9.71G/9.98G [00:44<00:00, 308MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 9.75G/9.98G [00:44<00:00, 326MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 9.80G/9.98G [00:44<00:00, 363MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 9.85G/9.98G [00:45<00:00, 374MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 9.89G/9.98G [00:45<00:00, 362MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 9.93G/9.98G [00:45<00:00, 328MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 9.98G/9.98G [00:45<00:00, 220MB/s]\n",
            "Fetching 9 files: 100% 9/9 [00:46<00:00,  5.21s/it]\n",
            "[2023-12-16 12:20:12,506] [INFO] [engine_v2.py:82:__init__] Building model...\n",
            "Using /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\n",
            "Detected CUDA files, patching ldflags\n",
            "Emitting ninja build file /root/.cache/torch_extensions/py310_cu121/inference_core_ops/build.ninja...\n",
            "Building extension module inference_core_ops...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "ninja: no work to do.\n",
            "Loading extension module inference_core_ops...\n",
            "Time to load inference_core_ops op: 0.09584236145019531 seconds\n",
            "[2023-12-16 12:20:13,067] [INFO] [server.py:65:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-16 12:20:13,067] [INFO] [server.py:65:_wait_until_server_is_live] waiting for server to start...\n",
            "Using /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\n",
            "Detected CUDA files, patching ldflags\n",
            "Emitting ninja build file /root/.cache/torch_extensions/py310_cu121/ragged_device_ops/build.ninja...\n",
            "Building extension module ragged_device_ops...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "ninja: no work to do.\n",
            "Loading extension module ragged_device_ops...\n",
            "Time to load ragged_device_ops op: 0.09783768653869629 seconds\n",
            "Using /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\n",
            "Detected CUDA files, patching ldflags\n",
            "Emitting ninja build file /root/.cache/torch_extensions/py310_cu121/ragged_ops/build.ninja...\n",
            "Building extension module ragged_ops...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "ninja: no work to do.\n",
            "Loading extension module ragged_ops...\n",
            "Time to load ragged_ops op: 0.09635734558105469 seconds\n",
            "[2023-12-16 12:20:13,312] [INFO] [huggingface_engine.py:112:parameters] Loading checkpoint: /root/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-hf/snapshots/8cca527612d856d7d32bd94f8103728d614eb852/model-00001-of-00002.safetensors\n",
            "[2023-12-16 12:20:14,138] [INFO] [huggingface_engine.py:112:parameters] Loading checkpoint: /root/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-hf/snapshots/8cca527612d856d7d32bd94f8103728d614eb852/model-00002-of-00002.safetensors\n",
            "[2023-12-16 12:20:18,072] [INFO] [server.py:65:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-16 12:20:18,072] [INFO] [server.py:65:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-16 12:20:18,428] [INFO] [engine_v2.py:84:__init__] Model built.\n",
            "[2023-12-16 12:20:18,438] [INFO] [kv_cache.py:135:__init__] Allocating KV-cache 0 with shape: (32, 813, 64, 2, 32, 128) consisting of 813 blocks.\n",
            "tokenizer.model: 100% 500k/500k [00:01<00:00, 402kB/s]\n",
            "Starting server on port: 50051\n",
            "About to start server\n",
            "Started\n",
            "[2023-12-16 12:20:23,076] [INFO] [server.py:65:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-16 12:20:23,076] [INFO] [server.py:65:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-16 12:20:28,081] [INFO] [server.py:65:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-16 12:20:28,081] [INFO] [server.py:65:_wait_until_server_is_live] waiting for server to start...\n",
            "[2023-12-16 12:20:28,081] [INFO] [server.py:70:_wait_until_server_is_live] server has started on ports [50051]\n",
            "[2023-12-16 12:20:28,081] [INFO] [server.py:70:_wait_until_server_is_live] server has started on ports [50051]\n",
            "[2023-12-16 12:42:15,225] [INFO] [launch.py:347:main] Process 126382 exits successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd DeepSpeedExamples/benchmarks/inference/mii && python server.py -d llama2-7b-tp1-b768 stop"
      ],
      "metadata": {
        "id": "ccNmb5atplcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!lsof -i:50051\n"
      ],
      "metadata": {
        "id": "5_YhhTmvpve1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Deployment: llama2-7b-tp1-b768 Clients: 1, Prompt (mean): 2600 tokens, Generation (mean): 60 tokens, Query throughput: 0.791 queries/s, Token throughput (total): 2225.653 tokens/s, Query latency: 1.265 s, Token generation latency: 0.018 s/token, First token received: 0.204 s\n",
        "#Namespace(max_new_tokens=60, deployment_name='llama2-7b-tp1-b768', num_queries=512, warmup=1, client_num=2, prompt_length=2600, use_thread=False, stream=True, vllm=False, out_json_path=PosixPath('logs.llama2-7b-tp1-b768/llama2-7b-tp1-b768_c2_p2600_g60.json'))\n",
        "\n",
        "!cd DeepSpeedExamples/benchmarks/inference/mii \\\n",
        "  && bash -x run_example.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvJys7z9Apyj",
        "outputId": "13794109-5f96-4dc6-ce72-5c58de52e509"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m流式输出内容被截断，只能显示最后 5000 行内容。\u001b[0m\n",
            "queue size: 354 (140712)\n",
            "queue size: 353 (140708)\n",
            "queue size: 352 (140713)\n",
            "queue size: 351 (140711)\n",
            "queue size: 350 (140710)\n",
            "queue size: 349 (140709)\n",
            "queue size: 348 (140712)\n",
            "queue size: 347 (140713)\n",
            "queue size: 346 (140708)\n",
            "queue size: 345 (140710)\n",
            "queue size: 344 (140709)\n",
            "queue size: 343 (140711)\n",
            "queue size: 342 (140712)\n",
            "queue size: 341 (140713)\n",
            "queue size: 340 (140709)\n",
            "queue size: 339 (140708)\n",
            "queue size: 338 (140710)\n",
            "queue size: 337 (140711)\n",
            "queue size: 336 (140712)\n",
            "queue size: 335 (140708)\n",
            "queue size: 334 (140713)\n",
            "queue size: 333 (140709)\n",
            "queue size: 332 (140711)\n",
            "queue size: 331 (140712)\n",
            "queue size: 330 (140713)\n",
            "queue size: 329 (140709)\n",
            "queue size: 328 (140710)\n",
            "queue size: 327 (140708)\n",
            "queue size: 326 (140711)\n",
            "queue size: 325 (140710)\n",
            "queue size: 324 (140713)\n",
            "queue size: 323 (140712)\n",
            "queue size: 322 (140713)\n",
            "queue size: 321 (140709)\n",
            "queue size: 320 (140711)\n",
            "queue size: 319 (140710)\n",
            "queue size: 318 (140708)\n",
            "queue size: 317 (140712)\n",
            "queue size: 316 (140713)\n",
            "queue size: 315 (140710)\n",
            "queue size: 314 (140711)\n",
            "queue size: 313 (140708)\n",
            "queue size: 312 (140709)\n",
            "queue size: 311 (140710)\n",
            "queue size: 310 (140712)\n",
            "queue size: 309 (140711)\n",
            "queue size: 308 (140713)\n",
            "queue size: 307 (140709)\n",
            "queue size: 306 (140708)\n",
            "queue size: 305 (140710)\n",
            "queue size: 304 (140712)\n",
            "queue size: 303 (140713)\n",
            "queue size: 302 (140711)\n",
            "queue size: 301 (140709)\n",
            "queue size: 300 (140710)\n",
            "queue size: 299 (140713)\n",
            "queue size: 298 (140710)\n",
            "queue size: 297 (140708)\n",
            "queue size: 296 (140712)\n",
            "queue size: 295 (140711)\n",
            "queue size: 294 (140709)\n",
            "queue size: 293 (140712)\n",
            "queue size: 292 (140713)\n",
            "queue size: 291 (140708)\n",
            "queue size: 290 (140711)\n",
            "queue size: 289 (140710)\n",
            "queue size: 288 (140709)\n",
            "queue size: 287 (140712)\n",
            "queue size: 286 (140708)\n",
            "queue size: 285 (140710)\n",
            "queue size: 284 (140713)\n",
            "queue size: 283 (140711)\n",
            "queue size: 282 (140709)\n",
            "queue size: 281 (140712)\n",
            "queue size: 280 (140708)\n",
            "queue size: 279 (140710)\n",
            "queue size: 278 (140713)\n",
            "queue size: 277 (140709)\n",
            "queue size: 276 (140711)\n",
            "queue size: 275 (140713)\n",
            "queue size: 274 (140708)\n",
            "queue size: 274 (140710)\n",
            "queue size: 272 (140712)\n",
            "queue size: 271 (140709)\n",
            "queue size: 270 (140711)\n",
            "queue size: 269 (140713)\n",
            "queue size: 268 (140708)\n",
            "queue size: 267 (140709)\n",
            "queue size: 266 (140712)\n",
            "queue size: 265 (140711)\n",
            "queue size: 264 (140710)\n",
            "queue size: 263 (140708)\n",
            "queue size: 262 (140713)\n",
            "queue size: 261 (140711)\n",
            "queue size: 260 (140709)\n",
            "queue size: 259 (140712)\n",
            "queue size: 258 (140710)\n",
            "queue size: 257 (140708)\n",
            "queue size: 256 (140711)\n",
            "queue size: 255 (140709)\n",
            "queue size: 254 (140713)\n",
            "queue size: 253 (140712)\n",
            "queue size: 252 (140710)\n",
            "queue size: 251 (140711)\n",
            "queue size: 250 (140709)\n",
            "queue size: 249 (140708)\n",
            "queue size: 248 (140713)\n",
            "queue size: 247 (140712)\n",
            "queue size: 246 (140710)\n",
            "queue size: 245 (140709)\n",
            "queue size: 244 (140708)\n",
            "queue size: 243 (140711)\n",
            "queue size: 242 (140712)\n",
            "queue size: 241 (140713)\n",
            "queue size: 240 (140712)\n",
            "queue size: 239 (140711)\n",
            "queue size: 238 (140710)\n",
            "queue size: 237 (140708)\n",
            "queue size: 236 (140709)\n",
            "queue size: 235 (140712)\n",
            "queue size: 234 (140713)\n",
            "queue size: 233 (140710)\n",
            "queue size: 232 (140711)\n",
            "queue size: 231 (140708)\n",
            "queue size: 230 (140712)\n",
            "queue size: 229 (140709)\n",
            "queue size: 228 (140713)\n",
            "queue size: 227 (140710)\n",
            "queue size: 226 (140711)\n",
            "queue size: 225 (140708)\n",
            "queue size: 224 (140709)\n",
            "queue size: 223 (140710)\n",
            "queue size: 222 (140712)\n",
            "queue size: 221 (140711)\n",
            "queue size: 220 (140708)\n",
            "queue size: 219 (140713)\n",
            "queue size: 218 (140711)\n",
            "queue size: 217 (140710)\n",
            "queue size: 216 (140709)\n",
            "queue size: 215 (140712)\n",
            "queue size: 214 (140708)\n",
            "queue size: 213 (140710)\n",
            "queue size: 212 (140711)\n",
            "queue size: 211 (140713)\n",
            "queue size: 210 (140709)\n",
            "queue size: 209 (140710)\n",
            "queue size: 208 (140712)\n",
            "queue size: 207 (140711)\n",
            "queue size: 206 (140713)\n",
            "queue size: 205 (140708)\n",
            "queue size: 204 (140710)\n",
            "queue size: 203 (140709)\n",
            "queue size: 202 (140712)\n",
            "queue size: 201 (140713)\n",
            "queue size: 200 (140711)\n",
            "queue size: 199 (140708)\n",
            "queue size: 198 (140710)\n",
            "queue size: 197 (140709)\n",
            "queue size: 196 (140712)\n",
            "queue size: 195 (140713)\n",
            "queue size: 194 (140708)\n",
            "queue size: 193 (140711)\n",
            "queue size: 192 (140709)\n",
            "queue size: 191 (140708)\n",
            "queue size: 190 (140710)\n",
            "queue size: 189 (140712)\n",
            "queue size: 188 (140713)\n",
            "queue size: 187 (140711)\n",
            "queue size: 186 (140709)\n",
            "queue size: 185 (140708)\n",
            "queue size: 184 (140710)\n",
            "queue size: 183 (140713)\n",
            "queue size: 182 (140711)\n",
            "queue size: 181 (140709)\n",
            "queue size: 180 (140712)\n",
            "queue size: 179 (140708)\n",
            "queue size: 178 (140710)\n",
            "queue size: 177 (140709)\n",
            "queue size: 176 (140713)\n",
            "queue size: 175 (140712)\n",
            "queue size: 174 (140710)\n",
            "queue size: 173 (140711)\n",
            "queue size: 172 (140708)\n",
            "queue size: 171 (140712)\n",
            "queue size: 170 (140713)\n",
            "queue size: 169 (140709)\n",
            "queue size: 168 (140708)\n",
            "queue size: 167 (140712)\n",
            "queue size: 166 (140710)\n",
            "queue size: 165 (140711)\n",
            "queue size: 164 (140713)\n",
            "queue size: 163 (140709)\n",
            "queue size: 162 (140708)\n",
            "queue size: 161 (140710)\n",
            "queue size: 160 (140711)\n",
            "queue size: 159 (140713)\n",
            "queue size: 158 (140709)\n",
            "queue size: 157 (140712)\n",
            "queue size: 156 (140708)\n",
            "queue size: 155 (140711)\n",
            "queue size: 154 (140713)\n",
            "queue size: 153 (140709)\n",
            "queue size: 152 (140710)\n",
            "queue size: 151 (140711)\n",
            "queue size: 150 (140712)\n",
            "queue size: 149 (140713)\n",
            "queue size: 148 (140708)\n",
            "queue size: 147 (140709)\n",
            "queue size: 146 (140710)\n",
            "queue size: 145 (140713)\n",
            "queue size: 144 (140712)\n",
            "queue size: 143 (140711)\n",
            "queue size: 142 (140708)\n",
            "queue size: 141 (140709)\n",
            "queue size: 140 (140710)\n",
            "queue size: 139 (140713)\n",
            "queue size: 138 (140712)\n",
            "queue size: 137 (140711)\n",
            "queue size: 136 (140710)\n",
            "queue size: 135 (140708)\n",
            "queue size: 134 (140709)\n",
            "queue size: 133 (140713)\n",
            "queue size: 132 (140711)\n",
            "queue size: 131 (140712)\n",
            "queue size: 130 (140708)\n",
            "queue size: 129 (140710)\n",
            "queue size: 128 (140709)\n",
            "queue size: 127 (140711)\n",
            "queue size: 126 (140708)\n",
            "queue size: 125 (140713)\n",
            "queue size: 124 (140712)\n",
            "queue size: 123 (140710)\n",
            "queue size: 122 (140709)\n",
            "queue size: 121 (140708)\n",
            "queue size: 120 (140713)\n",
            "queue size: 119 (140712)\n",
            "queue size: 118 (140711)\n",
            "queue size: 117 (140709)\n",
            "queue size: 116 (140708)\n",
            "queue size: 115 (140710)\n",
            "queue size: 114 (140713)\n",
            "queue size: 113 (140711)\n",
            "queue size: 112 (140712)\n",
            "queue size: 111 (140709)\n",
            "queue size: 110 (140710)\n",
            "queue size: 109 (140711)\n",
            "queue size: 108 (140713)\n",
            "queue size: 108 (140708)\n",
            "queue size: 106 (140709)\n",
            "queue size: 105 (140710)\n",
            "queue size: 104 (140712)\n",
            "queue size: 103 (140709)\n",
            "queue size: 102 (140711)\n",
            "queue size: 101 (140713)\n",
            "queue size: 100 (140712)\n",
            "queue size: 99 (140709)\n",
            "queue size: 98 (140708)\n",
            "queue size: 97 (140712)\n",
            "queue size: 96 (140713)\n",
            "queue size: 95 (140710)\n",
            "queue size: 94 (140711)\n",
            "queue size: 93 (140709)\n",
            "queue size: 92 (140713)\n",
            "queue size: 91 (140708)\n",
            "queue size: 90 (140712)\n",
            "queue size: 89 (140710)\n",
            "queue size: 88 (140712)\n",
            "queue size: 87 (140711)\n",
            "queue size: 86 (140708)\n",
            "queue size: 85 (140709)\n",
            "queue size: 84 (140710)\n",
            "queue size: 83 (140713)\n",
            "queue size: 82 (140712)\n",
            "queue size: 81 (140708)\n",
            "queue size: 80 (140711)\n",
            "queue size: 79 (140709)\n",
            "queue size: 78 (140710)\n",
            "queue size: 77 (140712)\n",
            "queue size: 76 (140711)\n",
            "queue size: 75 (140713)\n",
            "queue size: 74 (140708)\n",
            "queue size: 73 (140709)\n",
            "queue size: 72 (140710)\n",
            "queue size: 71 (140712)\n",
            "queue size: 70 (140711)\n",
            "queue size: 69 (140708)\n",
            "queue size: 68 (140710)\n",
            "queue size: 67 (140713)\n",
            "queue size: 66 (140709)\n",
            "queue size: 65 (140711)\n",
            "queue size: 64 (140713)\n",
            "queue size: 63 (140710)\n",
            "queue size: 62 (140712)\n",
            "queue size: 61 (140709)\n",
            "queue size: 60 (140708)\n",
            "queue size: 59 (140711)\n",
            "queue size: 58 (140709)\n",
            "queue size: 57 (140711)\n",
            "queue size: 56 (140710)\n",
            "queue size: 55 (140712)\n",
            "queue size: 54 (140713)\n",
            "queue size: 53 (140708)\n",
            "queue size: 52 (140709)\n",
            "queue size: 51 (140713)\n",
            "queue size: 50 (140711)\n",
            "queue size: 49 (140710)\n",
            "queue size: 48 (140712)\n",
            "queue size: 47 (140708)\n",
            "queue size: 46 (140709)\n",
            "queue size: 45 (140713)\n",
            "queue size: 44 (140713)\n",
            "queue size: 43 (140712)\n",
            "queue size: 42 (140708)\n",
            "queue size: 41 (140709)\n",
            "queue size: 40 (140710)\n",
            "queue size: 39 (140711)\n",
            "queue size: 38 (140713)\n",
            "queue size: 37 (140712)\n",
            "queue size: 36 (140708)\n",
            "queue size: 35 (140709)\n",
            "queue size: 34 (140711)\n",
            "queue size: 33 (140713)\n",
            "queue size: 32 (140710)\n",
            "queue size: 31 (140712)\n",
            "queue size: 30 (140708)\n",
            "queue size: 29 (140709)\n",
            "queue size: 28 (140713)\n",
            "queue size: 27 (140711)\n",
            "queue size: 26 (140710)\n",
            "queue size: 25 (140712)\n",
            "queue size: 24 (140711)\n",
            "queue size: 23 (140708)\n",
            "queue size: 22 (140712)\n",
            "queue size: 21 (140709)\n",
            "queue size: 20 (140713)\n",
            "queue size: 19 (140708)\n",
            "queue size: 18 (140710)\n",
            "queue size: 17 (140713)\n",
            "queue size: 16 (140709)\n",
            "queue size: 15 (140711)\n",
            "queue size: 14 (140712)\n",
            "queue size: 13 (140708)\n",
            "queue size: 12 (140710)\n",
            "queue size: 11 (140713)\n",
            "queue size: 10 (140709)\n",
            "queue size: 9 (140711)\n",
            "queue size: 8 (140712)\n",
            "queue size: 7 (140708)\n",
            "queue size: 6 (140713)\n",
            "queue size: 5 (140710)\n",
            "queue size: 4 (140709)\n",
            "queue size: 3 (140711)\n",
            "queue size: 2 (140712)\n",
            "queue size: 1 (140710)\n",
            "Worker (140708) finished. session_id: test_session_p140708_t139058077733504\n",
            "Worker (140713) finished. session_id: test_session_p140713_t139058077733504\n",
            "Worker (140709) finished. session_id: test_session_p140709_t139058077733504\n",
            "Worker (140711) finished. session_id: test_session_p140711_t139058077733504\n",
            "Worker (140712) finished. session_id: test_session_p140712_t139058077733504\n",
            "Worker (140710) finished. session_id: test_session_p140710_t139058077733504\n",
            "Deployment: llama2-7b-tp1-b768 Clients: 6, Prompt (mean): 2600 tokens, Generation (mean): 60 tokens, Query throughput: 2.465 queries/s, Token throughput (total): 1175.761 tokens/s, Query latency: 2.434 s, Token generation latency: 0.036 s/token, First token received: 0.313 s\n",
            "Namespace(max_new_tokens=60, deployment_name='llama2-7b-tp1-b768', num_queries=512, warmup=1, client_num=8, prompt_length=2600, use_thread=False, stream=True, vllm=False, out_json_path=PosixPath('logs.llama2-7b-tp1-b768/llama2-7b-tp1-b768_c8_p2600_g60.json'))\n",
            "[2023-12-16 13:10:14,427] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:10:14,434] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:10:14,590] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:10:14,607] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:10:14,618] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:10:14,650] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:10:14,658] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:10:14,662] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "2023-12-16 13:10:16.636760: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:10:16.636763: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:10:16.636795: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:10:16.636801: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:10:16.638438: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:10:16.638455: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:10:16.909434: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:10:16.909473: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:10:16.910706: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:10:16.963545: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:10:16.963599: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:10:16.965278: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:10:17.022494: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:10:17.022545: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:10:17.024191: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:10:17.192245: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:10:17.192262: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:10:17.192297: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:10:17.192298: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:10:17.194001: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:10:17.194009: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:10:17.226407: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:10:17.226463: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:10:17.228175: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:10:17.976904: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:10:18.002244: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:10:18.455026: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:10:18.829088: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:10:18.913507: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:10:18.968248: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:10:19.140188: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:10:19.156145: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "warmup queue size: 520 (142477)\n",
            "warmup queue size: 520 (142479)\n",
            "warmup queue size: 520 (142481)\n",
            "warmup queue size: 520 (142482)\n",
            "warmup queue size: 519 (142476)\n",
            "warmup queue size: 519 (142478)\n",
            "warmup queue size: 519 (142480)\n",
            "warmup queue size: 518 (142475)\n",
            "queue size: 512 (142479)\n",
            "queue size: 511 (142476)\n",
            "queue size: 510 (142477)\n",
            "queue size: 509 (142478)\n",
            "queue size: 508 (142481)\n",
            "queue size: 507 (142475)\n",
            "queue size: 506 (142480)\n",
            "queue size: 505 (142482)\n",
            "queue size: 504 (142478)\n",
            "queue size: 503 (142476)\n",
            "queue size: 502 (142475)\n",
            "queue size: 501 (142479)\n",
            "queue size: 500 (142480)\n",
            "queue size: 499 (142481)\n",
            "queue size: 498 (142477)\n",
            "queue size: 497 (142482)\n",
            "queue size: 496 (142478)\n",
            "queue size: 495 (142478)\n",
            "queue size: 494 (142476)\n",
            "queue size: 493 (142479)\n",
            "queue size: 492 (142481)\n",
            "queue size: 491 (142475)\n",
            "queue size: 490 (142480)\n",
            "queue size: 489 (142477)\n",
            "queue size: 488 (142478)\n",
            "queue size: 487 (142482)\n",
            "queue size: 486 (142479)\n",
            "queue size: 485 (142476)\n",
            "queue size: 484 (142481)\n",
            "queue size: 483 (142475)\n",
            "queue size: 482 (142480)\n",
            "queue size: 481 (142477)\n",
            "queue size: 480 (142482)\n",
            "queue size: 479 (142476)\n",
            "queue size: 478 (142478)\n",
            "queue size: 477 (142481)\n",
            "queue size: 476 (142475)\n",
            "queue size: 475 (142479)\n",
            "queue size: 474 (142477)\n",
            "queue size: 473 (142480)\n",
            "queue size: 472 (142477)\n",
            "queue size: 471 (142481)\n",
            "queue size: 470 (142482)\n",
            "queue size: 469 (142479)\n",
            "queue size: 468 (142478)\n",
            "queue size: 467 (142477)\n",
            "queue size: 466 (142480)\n",
            "queue size: 465 (142475)\n",
            "queue size: 464 (142476)\n",
            "queue size: 463 (142475)\n",
            "queue size: 462 (142481)\n",
            "queue size: 461 (142482)\n",
            "queue size: 460 (142477)\n",
            "queue size: 459 (142478)\n",
            "queue size: 458 (142481)\n",
            "queue size: 457 (142479)\n",
            "queue size: 456 (142476)\n",
            "queue size: 455 (142480)\n",
            "queue size: 454 (142475)\n",
            "queue size: 453 (142478)\n",
            "queue size: 452 (142482)\n",
            "queue size: 451 (142477)\n",
            "queue size: 450 (142481)\n",
            "queue size: 449 (142476)\n",
            "queue size: 448 (142480)\n",
            "queue size: 447 (142475)\n",
            "queue size: 446 (142478)\n",
            "queue size: 445 (142477)\n",
            "queue size: 444 (142479)\n",
            "queue size: 443 (142475)\n",
            "queue size: 442 (142476)\n",
            "queue size: 441 (142482)\n",
            "queue size: 440 (142481)\n",
            "queue size: 439 (142480)\n",
            "queue size: 438 (142477)\n",
            "queue size: 437 (142475)\n",
            "queue size: 436 (142479)\n",
            "queue size: 435 (142478)\n",
            "queue size: 434 (142476)\n",
            "queue size: 433 (142480)\n",
            "queue size: 432 (142482)\n",
            "queue size: 431 (142481)\n",
            "queue size: 430 (142482)\n",
            "queue size: 429 (142479)\n",
            "queue size: 428 (142477)\n",
            "queue size: 427 (142476)\n",
            "queue size: 426 (142480)\n",
            "queue size: 425 (142475)\n",
            "queue size: 424 (142478)\n",
            "queue size: 423 (142476)\n",
            "queue size: 422 (142479)\n",
            "queue size: 421 (142481)\n",
            "queue size: 420 (142482)\n",
            "queue size: 419 (142477)\n",
            "queue size: 418 (142475)\n",
            "queue size: 417 (142478)\n",
            "queue size: 416 (142480)\n",
            "queue size: 415 (142482)\n",
            "queue size: 414 (142476)\n",
            "queue size: 413 (142481)\n",
            "queue size: 413 (142479)\n",
            "queue size: 411 (142477)\n",
            "queue size: 410 (142475)\n",
            "queue size: 409 (142476)\n",
            "queue size: 408 (142482)\n",
            "queue size: 407 (142478)\n",
            "queue size: 406 (142481)\n",
            "queue size: 405 (142479)\n",
            "queue size: 404 (142475)\n",
            "queue size: 403 (142480)\n",
            "queue size: 402 (142477)\n",
            "queue size: 401 (142479)\n",
            "queue size: 400 (142482)\n",
            "queue size: 400 (142481)\n",
            "queue size: 398 (142478)\n",
            "queue size: 397 (142476)\n",
            "queue size: 396 (142477)\n",
            "queue size: 395 (142480)\n",
            "queue size: 394 (142479)\n",
            "queue size: 393 (142475)\n",
            "queue size: 392 (142479)\n",
            "queue size: 391 (142476)\n",
            "queue size: 390 (142482)\n",
            "queue size: 389 (142478)\n",
            "queue size: 388 (142477)\n",
            "queue size: 387 (142481)\n",
            "queue size: 386 (142480)\n",
            "queue size: 385 (142475)\n",
            "queue size: 384 (142479)\n",
            "queue size: 383 (142476)\n",
            "queue size: 382 (142481)\n",
            "queue size: 381 (142477)\n",
            "queue size: 380 (142478)\n",
            "queue size: 379 (142482)\n",
            "queue size: 378 (142475)\n",
            "queue size: 377 (142479)\n",
            "queue size: 376 (142476)\n",
            "queue size: 375 (142478)\n",
            "queue size: 374 (142481)\n",
            "queue size: 373 (142477)\n",
            "queue size: 372 (142480)\n",
            "queue size: 371 (142482)\n",
            "queue size: 370 (142479)\n",
            "queue size: 369 (142480)\n",
            "queue size: 368 (142475)\n",
            "queue size: 367 (142476)\n",
            "queue size: 366 (142480)\n",
            "queue size: 365 (142481)\n",
            "queue size: 364 (142478)\n",
            "queue size: 363 (142475)\n",
            "queue size: 362 (142480)\n",
            "queue size: 361 (142482)\n",
            "queue size: 361 (142477)\n",
            "queue size: 359 (142476)\n",
            "queue size: 358 (142481)\n",
            "queue size: 357 (142479)\n",
            "queue size: 356 (142478)\n",
            "queue size: 355 (142476)\n",
            "queue size: 354 (142478)\n",
            "queue size: 353 (142481)\n",
            "queue size: 352 (142482)\n",
            "queue size: 351 (142480)\n",
            "queue size: 350 (142475)\n",
            "queue size: 349 (142477)\n",
            "queue size: 348 (142479)\n",
            "queue size: 347 (142478)\n",
            "queue size: 346 (142476)\n",
            "queue size: 345 (142481)\n",
            "queue size: 344 (142479)\n",
            "queue size: 343 (142475)\n",
            "queue size: 342 (142480)\n",
            "queue size: 341 (142482)\n",
            "queue size: 340 (142477)\n",
            "queue size: 339 (142475)\n",
            "queue size: 338 (142481)\n",
            "queue size: 337 (142478)\n",
            "queue size: 336 (142476)\n",
            "queue size: 335 (142479)\n",
            "queue size: 334 (142482)\n",
            "queue size: 333 (142480)\n",
            "queue size: 332 (142477)\n",
            "queue size: 331 (142478)\n",
            "queue size: 330 (142476)\n",
            "queue size: 329 (142481)\n",
            "queue size: 328 (142476)\n",
            "queue size: 327 (142482)\n",
            "queue size: 326 (142477)\n",
            "queue size: 325 (142475)\n",
            "queue size: 324 (142479)\n",
            "queue size: 323 (142476)\n",
            "queue size: 322 (142481)\n",
            "queue size: 321 (142477)\n",
            "queue size: 320 (142482)\n",
            "queue size: 319 (142480)\n",
            "queue size: 318 (142478)\n",
            "queue size: 317 (142479)\n",
            "queue size: 316 (142475)\n",
            "queue size: 315 (142480)\n",
            "queue size: 314 (142481)\n",
            "queue size: 313 (142476)\n",
            "queue size: 312 (142478)\n",
            "queue size: 311 (142477)\n",
            "queue size: 310 (142482)\n",
            "queue size: 309 (142475)\n",
            "queue size: 308 (142480)\n",
            "queue size: 307 (142479)\n",
            "queue size: 306 (142478)\n",
            "queue size: 305 (142481)\n",
            "queue size: 304 (142477)\n",
            "queue size: 303 (142476)\n",
            "queue size: 302 (142479)\n",
            "queue size: 301 (142482)\n",
            "queue size: 300 (142475)\n",
            "queue size: 299 (142480)\n",
            "queue size: 298 (142475)\n",
            "queue size: 297 (142477)\n",
            "queue size: 296 (142481)\n",
            "queue size: 295 (142478)\n",
            "queue size: 294 (142476)\n",
            "queue size: 293 (142480)\n",
            "queue size: 292 (142477)\n",
            "queue size: 291 (142482)\n",
            "queue size: 290 (142475)\n",
            "queue size: 289 (142479)\n",
            "queue size: 288 (142478)\n",
            "queue size: 287 (142481)\n",
            "queue size: 286 (142480)\n",
            "queue size: 285 (142482)\n",
            "queue size: 284 (142476)\n",
            "queue size: 283 (142477)\n",
            "queue size: 282 (142479)\n",
            "queue size: 281 (142475)\n",
            "queue size: 280 (142478)\n",
            "queue size: 279 (142480)\n",
            "queue size: 278 (142479)\n",
            "queue size: 277 (142481)\n",
            "queue size: 276 (142477)\n",
            "queue size: 275 (142476)\n",
            "queue size: 274 (142478)\n",
            "queue size: 273 (142475)\n",
            "queue size: 272 (142480)\n",
            "queue size: 271 (142482)\n",
            "queue size: 270 (142476)\n",
            "queue size: 269 (142481)\n",
            "queue size: 268 (142478)\n",
            "queue size: 267 (142477)\n",
            "queue size: 266 (142480)\n",
            "queue size: 265 (142479)\n",
            "queue size: 264 (142475)\n",
            "queue size: 263 (142481)\n",
            "queue size: 262 (142479)\n",
            "queue size: 261 (142476)\n",
            "queue size: 260 (142482)\n",
            "queue size: 259 (142478)\n",
            "queue size: 258 (142475)\n",
            "queue size: 257 (142480)\n",
            "queue size: 256 (142477)\n",
            "queue size: 255 (142481)\n",
            "queue size: 254 (142476)\n",
            "queue size: 253 (142478)\n",
            "queue size: 252 (142479)\n",
            "queue size: 251 (142482)\n",
            "queue size: 250 (142475)\n",
            "queue size: 249 (142480)\n",
            "queue size: 248 (142482)\n",
            "queue size: 247 (142477)\n",
            "queue size: 246 (142479)\n",
            "queue size: 245 (142478)\n",
            "queue size: 244 (142481)\n",
            "queue size: 243 (142476)\n",
            "queue size: 242 (142477)\n",
            "queue size: 241 (142479)\n",
            "queue size: 240 (142475)\n",
            "queue size: 239 (142480)\n",
            "queue size: 238 (142482)\n",
            "queue size: 237 (142481)\n",
            "queue size: 236 (142478)\n",
            "queue size: 235 (142476)\n",
            "queue size: 234 (142477)\n",
            "queue size: 233 (142479)\n",
            "queue size: 232 (142480)\n",
            "queue size: 231 (142482)\n",
            "queue size: 230 (142481)\n",
            "queue size: 229 (142475)\n",
            "queue size: 228 (142478)\n",
            "queue size: 227 (142476)\n",
            "queue size: 226 (142477)\n",
            "queue size: 225 (142479)\n",
            "queue size: 224 (142482)\n",
            "queue size: 223 (142475)\n",
            "queue size: 222 (142481)\n",
            "queue size: 221 (142480)\n",
            "queue size: 220 (142479)\n",
            "queue size: 219 (142476)\n",
            "queue size: 218 (142478)\n",
            "queue size: 217 (142482)\n",
            "queue size: 216 (142477)\n",
            "queue size: 215 (142481)\n",
            "queue size: 214 (142479)\n",
            "queue size: 213 (142475)\n",
            "queue size: 212 (142480)\n",
            "queue size: 211 (142482)\n",
            "queue size: 210 (142477)\n",
            "queue size: 209 (142476)\n",
            "queue size: 208 (142475)\n",
            "queue size: 207 (142480)\n",
            "queue size: 206 (142477)\n",
            "queue size: 205 (142478)\n",
            "queue size: 204 (142481)\n",
            "queue size: 203 (142479)\n",
            "queue size: 202 (142476)\n",
            "queue size: 201 (142482)\n",
            "queue size: 200 (142475)\n",
            "queue size: 199 (142480)\n",
            "queue size: 198 (142479)\n",
            "queue size: 197 (142477)\n",
            "queue size: 196 (142478)\n",
            "queue size: 195 (142482)\n",
            "queue size: 194 (142475)\n",
            "queue size: 193 (142476)\n",
            "queue size: 192 (142481)\n",
            "queue size: 191 (142479)\n",
            "queue size: 190 (142480)\n",
            "queue size: 189 (142477)\n",
            "queue size: 188 (142478)\n",
            "queue size: 187 (142482)\n",
            "queue size: 186 (142481)\n",
            "queue size: 185 (142475)\n",
            "queue size: 184 (142479)\n",
            "queue size: 183 (142480)\n",
            "queue size: 182 (142477)\n",
            "queue size: 181 (142478)\n",
            "queue size: 180 (142476)\n",
            "queue size: 179 (142479)\n",
            "queue size: 178 (142475)\n",
            "queue size: 177 (142482)\n",
            "queue size: 176 (142477)\n",
            "queue size: 175 (142481)\n",
            "queue size: 174 (142479)\n",
            "queue size: 173 (142480)\n",
            "queue size: 172 (142478)\n",
            "queue size: 171 (142476)\n",
            "queue size: 170 (142477)\n",
            "queue size: 169 (142481)\n",
            "queue size: 168 (142475)\n",
            "queue size: 167 (142479)\n",
            "queue size: 166 (142480)\n",
            "queue size: 165 (142482)\n",
            "queue size: 164 (142478)\n",
            "queue size: 163 (142475)\n",
            "queue size: 162 (142481)\n",
            "queue size: 161 (142477)\n",
            "queue size: 160 (142479)\n",
            "queue size: 159 (142476)\n",
            "queue size: 158 (142480)\n",
            "queue size: 157 (142478)\n",
            "queue size: 156 (142475)\n",
            "queue size: 155 (142481)\n",
            "queue size: 154 (142482)\n",
            "queue size: 153 (142476)\n",
            "queue size: 152 (142480)\n",
            "queue size: 151 (142477)\n",
            "queue size: 150 (142479)\n",
            "queue size: 149 (142478)\n",
            "queue size: 148 (142476)\n",
            "queue size: 147 (142475)\n",
            "queue size: 146 (142482)\n",
            "queue size: 145 (142480)\n",
            "queue size: 144 (142481)\n",
            "queue size: 143 (142477)\n",
            "queue size: 142 (142478)\n",
            "queue size: 141 (142479)\n",
            "queue size: 140 (142476)\n",
            "queue size: 139 (142481)\n",
            "queue size: 138 (142475)\n",
            "queue size: 137 (142480)\n",
            "queue size: 136 (142482)\n",
            "queue size: 135 (142477)\n",
            "queue size: 134 (142479)\n",
            "queue size: 133 (142481)\n",
            "queue size: 132 (142476)\n",
            "queue size: 131 (142478)\n",
            "queue size: 130 (142475)\n",
            "queue size: 129 (142479)\n",
            "queue size: 128 (142482)\n",
            "queue size: 127 (142477)\n",
            "queue size: 126 (142480)\n",
            "queue size: 125 (142475)\n",
            "queue size: 124 (142481)\n",
            "queue size: 123 (142476)\n",
            "queue size: 122 (142479)\n",
            "queue size: 121 (142482)\n",
            "queue size: 120 (142480)\n",
            "queue size: 119 (142478)\n",
            "queue size: 118 (142477)\n",
            "queue size: 117 (142475)\n",
            "queue size: 116 (142479)\n",
            "queue size: 115 (142481)\n",
            "queue size: 114 (142476)\n",
            "queue size: 113 (142478)\n",
            "queue size: 112 (142482)\n",
            "queue size: 111 (142480)\n",
            "queue size: 110 (142477)\n",
            "queue size: 109 (142481)\n",
            "queue size: 108 (142475)\n",
            "queue size: 107 (142476)\n",
            "queue size: 106 (142479)\n",
            "queue size: 105 (142478)\n",
            "queue size: 104 (142475)\n",
            "queue size: 103 (142476)\n",
            "queue size: 102 (142478)\n",
            "queue size: 101 (142477)\n",
            "queue size: 100 (142480)\n",
            "queue size: 99 (142482)\n",
            "queue size: 98 (142475)\n",
            "queue size: 97 (142481)\n",
            "queue size: 96 (142480)\n",
            "queue size: 95 (142479)\n",
            "queue size: 94 (142477)\n",
            "queue size: 93 (142476)\n",
            "queue size: 92 (142478)\n",
            "queue size: 91 (142482)\n",
            "queue size: 90 (142477)\n",
            "queue size: 89 (142479)\n",
            "queue size: 88 (142481)\n",
            "queue size: 87 (142475)\n",
            "queue size: 86 (142476)\n",
            "queue size: 85 (142478)\n",
            "queue size: 84 (142481)\n",
            "queue size: 83 (142480)\n",
            "queue size: 82 (142477)\n",
            "queue size: 81 (142482)\n",
            "queue size: 80 (142479)\n",
            "queue size: 79 (142476)\n",
            "queue size: 78 (142475)\n",
            "queue size: 77 (142478)\n",
            "queue size: 76 (142481)\n",
            "queue size: 75 (142480)\n",
            "queue size: 74 (142477)\n",
            "queue size: 73 (142482)\n",
            "queue size: 72 (142479)\n",
            "queue size: 71 (142476)\n",
            "queue size: 70 (142475)\n",
            "queue size: 69 (142477)\n",
            "queue size: 68 (142481)\n",
            "queue size: 67 (142478)\n",
            "queue size: 66 (142476)\n",
            "queue size: 65 (142479)\n",
            "queue size: 64 (142480)\n",
            "queue size: 63 (142482)\n",
            "queue size: 62 (142477)\n",
            "queue size: 61 (142475)\n",
            "queue size: 60 (142479)\n",
            "queue size: 59 (142478)\n",
            "queue size: 58 (142482)\n",
            "queue size: 57 (142481)\n",
            "queue size: 56 (142476)\n",
            "queue size: 55 (142477)\n",
            "queue size: 54 (142480)\n",
            "queue size: 53 (142482)\n",
            "queue size: 52 (142477)\n",
            "queue size: 51 (142475)\n",
            "queue size: 50 (142478)\n",
            "queue size: 49 (142479)\n",
            "queue size: 48 (142476)\n",
            "queue size: 47 (142481)\n",
            "queue size: 46 (142479)\n",
            "queue size: 45 (142480)\n",
            "queue size: 44 (142477)\n",
            "queue size: 43 (142482)\n",
            "queue size: 42 (142475)\n",
            "queue size: 41 (142481)\n",
            "queue size: 40 (142476)\n",
            "queue size: 39 (142478)\n",
            "queue size: 38 (142479)\n",
            "queue size: 37 (142480)\n",
            "queue size: 36 (142475)\n",
            "queue size: 35 (142482)\n",
            "queue size: 34 (142479)\n",
            "queue size: 33 (142481)\n",
            "queue size: 32 (142477)\n",
            "queue size: 31 (142478)\n",
            "queue size: 30 (142480)\n",
            "queue size: 29 (142476)\n",
            "queue size: 28 (142475)\n",
            "queue size: 27 (142482)\n",
            "queue size: 26 (142478)\n",
            "queue size: 25 (142481)\n",
            "queue size: 24 (142479)\n",
            "queue size: 23 (142476)\n",
            "queue size: 22 (142477)\n",
            "queue size: 21 (142480)\n",
            "queue size: 20 (142482)\n",
            "queue size: 19 (142479)\n",
            "queue size: 18 (142481)\n",
            "queue size: 17 (142476)\n",
            "queue size: 16 (142477)\n",
            "queue size: 15 (142475)\n",
            "queue size: 14 (142478)\n",
            "queue size: 13 (142480)\n",
            "queue size: 12 (142482)\n",
            "queue size: 11 (142479)\n",
            "queue size: 10 (142479)\n",
            "queue size: 9 (142481)\n",
            "queue size: 8 (142475)\n",
            "queue size: 7 (142478)\n",
            "queue size: 6 (142480)\n",
            "queue size: 5 (142481)\n",
            "queue size: 4 (142477)\n",
            "queue size: 3 (142476)\n",
            "queue size: 2 (142482)\n",
            "queue size: 1 (142479)\n",
            "Worker (142478) finished. session_id: test_session_p142478_t138981758952064\n",
            "Worker (142476) finished. session_id: test_session_p142476_t138981758952064\n",
            "Worker (142477) finished. session_id: test_session_p142477_t138981758952064\n",
            "Worker (142480) finished. session_id: test_session_p142480_t138981758952064\n",
            "Worker (142475) finished. session_id: test_session_p142475_t138981758952064\n",
            "Worker (142482) finished. session_id: test_session_p142482_t138981758952064\n",
            "Worker (142481) finished. session_id: test_session_p142481_t138981758952064\n",
            "Worker (142479) finished. session_id: test_session_p142479_t138981758952064\n",
            "Deployment: llama2-7b-tp1-b768 Clients: 8, Prompt (mean): 2600 tokens, Generation (mean): 60 tokens, Query throughput: 2.676 queries/s, Token throughput (total): 973.571 tokens/s, Query latency: 2.989 s, Token generation latency: 0.044 s/token, First token received: 0.366 s\n",
            "Namespace(max_new_tokens=60, deployment_name='llama2-7b-tp1-b768', num_queries=512, warmup=1, client_num=12, prompt_length=2600, use_thread=False, stream=True, vllm=False, out_json_path=PosixPath('logs.llama2-7b-tp1-b768/llama2-7b-tp1-b768_c12_p2600_g60.json'))\n",
            "[2023-12-16 13:13:48,816] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:13:48,851] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:13:48,887] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:13:48,889] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:13:48,908] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:13:48,954] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:13:48,965] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:13:48,983] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:13:48,993] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:13:49,034] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:13:49,091] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:13:49,430] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "2023-12-16 13:13:51.606802: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:13:51.606925: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:13:51.609361: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:13:51.709237: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:13:51.709345: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:13:51.711063: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:13:51.905371: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:13:51.905485: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:13:51.907209: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:13:51.933995: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:13:51.934099: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:13:51.935741: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:13:51.943800: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:13:51.943910: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:13:51.945603: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:13:51.976805: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:13:51.976912: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:13:51.978605: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:13:52.029377: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:13:52.029491: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:13:52.031154: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:13:52.133367: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:13:52.133487: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:13:52.135241: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:13:52.151509: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:13:52.151564: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:13:52.153276: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:13:52.198100: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:13:52.198202: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:13:52.199920: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:13:52.256462: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:13:52.256514: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:13:52.258199: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:13:52.379900: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:13:52.380029: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:13:52.381737: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:13:53.630459: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:13:53.722398: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:13:53.936022: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:13:53.997690: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:13:54.049659: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:13:54.176876: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:13:54.272438: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:13:54.335833: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:13:54.434675: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:13:54.495260: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:13:54.516961: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:13:54.541342: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "warmup queue size: 524 (144302)\n",
            "warmup queue size: 524 (144309)\n",
            "warmup queue size: 524 (144304)\n",
            "warmup queue size: 523 (144303)\n",
            "warmup queue size: 523 (144306)\n",
            "warmup queue size: 523 (144305)\n",
            "warmup queue size: 523 (144308)\n",
            "warmup queue size: 522 (144311)\n",
            "warmup queue size: 522 (144307)\n",
            "warmup queue size: 522 (144313)\n",
            "warmup queue size: 521 (144312)\n",
            "warmup queue size: 521 (144310)\n",
            "queue size: 512 (144308)\n",
            "queue size: 511 (144305)\n",
            "queue size: 510 (144304)\n",
            "queue size: 509 (144310)\n",
            "queue size: 508 (144303)\n",
            "queue size: 507 (144312)\n",
            "queue size: 506 (144311)\n",
            "queue size: 505 (144313)\n",
            "queue size: 505 (144306)\n",
            "queue size: 503 (144302)\n",
            "queue size: 502 (144307)\n",
            "queue size: 501 (144309)\n",
            "queue size: 500 (144306)\n",
            "queue size: 499 (144308)\n",
            "queue size: 498 (144305)\n",
            "queue size: 497 (144312)\n",
            "queue size: 496 (144310)\n",
            "queue size: 495 (144302)\n",
            "queue size: 494 (144304)\n",
            "queue size: 493 (144303)\n",
            "queue size: 492 (144311)\n",
            "queue size: 491 (144309)\n",
            "queue size: 490 (144307)\n",
            "queue size: 489 (144308)\n",
            "queue size: 488 (144313)\n",
            "queue size: 487 (144306)\n",
            "queue size: 486 (144312)\n",
            "queue size: 486 (144305)\n",
            "queue size: 484 (144302)\n",
            "queue size: 483 (144310)\n",
            "queue size: 482 (144303)\n",
            "queue size: 481 (144311)\n",
            "queue size: 480 (144309)\n",
            "queue size: 479 (144304)\n",
            "queue size: 478 (144308)\n",
            "queue size: 477 (144307)\n",
            "queue size: 476 (144303)\n",
            "queue size: 475 (144313)\n",
            "queue size: 474 (144305)\n",
            "queue size: 473 (144309)\n",
            "queue size: 472 (144312)\n",
            "queue size: 471 (144311)\n",
            "queue size: 470 (144310)\n",
            "queue size: 469 (144309)\n",
            "queue size: 468 (144306)\n",
            "queue size: 467 (144304)\n",
            "queue size: 466 (144302)\n",
            "queue size: 465 (144308)\n",
            "queue size: 464 (144313)\n",
            "queue size: 463 (144310)\n",
            "queue size: 462 (144303)\n",
            "queue size: 461 (144305)\n",
            "queue size: 460 (144312)\n",
            "queue size: 459 (144304)\n",
            "queue size: 458 (144307)\n",
            "queue size: 457 (144311)\n",
            "queue size: 456 (144306)\n",
            "queue size: 455 (144309)\n",
            "queue size: 454 (144302)\n",
            "queue size: 453 (144303)\n",
            "queue size: 452 (144313)\n",
            "queue size: 451 (144305)\n",
            "queue size: 450 (144310)\n",
            "queue size: 449 (144304)\n",
            "queue size: 448 (144308)\n",
            "queue size: 447 (144311)\n",
            "queue size: 446 (144307)\n",
            "queue size: 445 (144312)\n",
            "queue size: 444 (144306)\n",
            "queue size: 443 (144303)\n",
            "queue size: 442 (144305)\n",
            "queue size: 441 (144309)\n",
            "queue size: 440 (144313)\n",
            "queue size: 439 (144310)\n",
            "queue size: 438 (144302)\n",
            "queue size: 437 (144311)\n",
            "queue size: 436 (144304)\n",
            "queue size: 435 (144313)\n",
            "queue size: 434 (144309)\n",
            "queue size: 433 (144308)\n",
            "queue size: 432 (144305)\n",
            "queue size: 431 (144307)\n",
            "queue size: 430 (144313)\n",
            "queue size: 429 (144306)\n",
            "queue size: 428 (144312)\n",
            "queue size: 427 (144311)\n",
            "queue size: 426 (144303)\n",
            "queue size: 425 (144302)\n",
            "queue size: 424 (144304)\n",
            "queue size: 423 (144310)\n",
            "queue size: 422 (144308)\n",
            "queue size: 421 (144312)\n",
            "queue size: 420 (144305)\n",
            "queue size: 419 (144313)\n",
            "queue size: 418 (144306)\n",
            "queue size: 417 (144307)\n",
            "queue size: 416 (144309)\n",
            "queue size: 415 (144310)\n",
            "queue size: 414 (144311)\n",
            "queue size: 413 (144308)\n",
            "queue size: 412 (144306)\n",
            "queue size: 411 (144312)\n",
            "queue size: 410 (144313)\n",
            "queue size: 409 (144302)\n",
            "queue size: 408 (144305)\n",
            "queue size: 407 (144304)\n",
            "queue size: 406 (144303)\n",
            "queue size: 405 (144308)\n",
            "queue size: 404 (144311)\n",
            "queue size: 403 (144310)\n",
            "queue size: 402 (144309)\n",
            "queue size: 401 (144313)\n",
            "queue size: 400 (144302)\n",
            "queue size: 399 (144307)\n",
            "queue size: 398 (144309)\n",
            "queue size: 397 (144308)\n",
            "queue size: 396 (144312)\n",
            "queue size: 395 (144305)\n",
            "queue size: 394 (144306)\n",
            "queue size: 393 (144303)\n",
            "queue size: 392 (144311)\n",
            "queue size: 391 (144310)\n",
            "queue size: 390 (144313)\n",
            "queue size: 389 (144304)\n",
            "queue size: 389 (144302)\n",
            "queue size: 387 (144305)\n",
            "queue size: 386 (144312)\n",
            "queue size: 385 (144307)\n",
            "queue size: 384 (144303)\n",
            "queue size: 383 (144308)\n",
            "queue size: 382 (144311)\n",
            "queue size: 381 (144309)\n",
            "queue size: 380 (144310)\n",
            "queue size: 379 (144302)\n",
            "queue size: 378 (144305)\n",
            "queue size: 377 (144313)\n",
            "queue size: 376 (144304)\n",
            "queue size: 375 (144310)\n",
            "queue size: 374 (144306)\n",
            "queue size: 373 (144307)\n",
            "queue size: 372 (144312)\n",
            "queue size: 371 (144303)\n",
            "queue size: 370 (144313)\n",
            "queue size: 369 (144311)\n",
            "queue size: 368 (144308)\n",
            "queue size: 367 (144306)\n",
            "queue size: 366 (144307)\n",
            "queue size: 365 (144304)\n",
            "queue size: 364 (144312)\n",
            "queue size: 363 (144310)\n",
            "queue size: 362 (144309)\n",
            "queue size: 361 (144302)\n",
            "queue size: 360 (144305)\n",
            "queue size: 359 (144306)\n",
            "queue size: 358 (144312)\n",
            "queue size: 357 (144313)\n",
            "queue size: 356 (144307)\n",
            "queue size: 355 (144303)\n",
            "queue size: 354 (144308)\n",
            "queue size: 353 (144311)\n",
            "queue size: 352 (144302)\n",
            "queue size: 351 (144304)\n",
            "queue size: 350 (144309)\n",
            "queue size: 349 (144310)\n",
            "queue size: 348 (144307)\n",
            "queue size: 347 (144305)\n",
            "queue size: 346 (144306)\n",
            "queue size: 345 (144312)\n",
            "queue size: 344 (144304)\n",
            "queue size: 343 (144311)\n",
            "queue size: 342 (144303)\n",
            "queue size: 341 (144308)\n",
            "queue size: 340 (144313)\n",
            "queue size: 339 (144302)\n",
            "queue size: 338 (144309)\n",
            "queue size: 337 (144310)\n",
            "queue size: 336 (144312)\n",
            "queue size: 335 (144305)\n",
            "queue size: 334 (144304)\n",
            "queue size: 333 (144307)\n",
            "queue size: 332 (144306)\n",
            "queue size: 331 (144313)\n",
            "queue size: 330 (144303)\n",
            "queue size: 329 (144311)\n",
            "queue size: 328 (144312)\n",
            "queue size: 327 (144310)\n",
            "queue size: 326 (144309)\n",
            "queue size: 325 (144304)\n",
            "queue size: 324 (144305)\n",
            "queue size: 323 (144303)\n",
            "queue size: 322 (144308)\n",
            "queue size: 321 (144306)\n",
            "queue size: 320 (144313)\n",
            "queue size: 319 (144302)\n",
            "queue size: 318 (144307)\n",
            "queue size: 317 (144310)\n",
            "queue size: 316 (144309)\n",
            "queue size: 315 (144311)\n",
            "queue size: 314 (144312)\n",
            "queue size: 313 (144303)\n",
            "queue size: 312 (144305)\n",
            "queue size: 311 (144302)\n",
            "queue size: 310 (144310)\n",
            "queue size: 309 (144311)\n",
            "queue size: 308 (144313)\n",
            "queue size: 307 (144304)\n",
            "queue size: 306 (144308)\n",
            "queue size: 305 (144306)\n",
            "queue size: 304 (144307)\n",
            "queue size: 303 (144309)\n",
            "queue size: 302 (144313)\n",
            "queue size: 301 (144304)\n",
            "queue size: 300 (144312)\n",
            "queue size: 299 (144305)\n",
            "queue size: 299 (144303)\n",
            "queue size: 297 (144308)\n",
            "queue size: 296 (144309)\n",
            "queue size: 295 (144302)\n",
            "queue size: 294 (144306)\n",
            "queue size: 293 (144311)\n",
            "queue size: 292 (144310)\n",
            "queue size: 291 (144307)\n",
            "queue size: 290 (144304)\n",
            "queue size: 289 (144305)\n",
            "queue size: 288 (144313)\n",
            "queue size: 287 (144312)\n",
            "queue size: 286 (144308)\n",
            "queue size: 285 (144303)\n",
            "queue size: 284 (144309)\n",
            "queue size: 283 (144306)\n",
            "queue size: 282 (144304)\n",
            "queue size: 281 (144313)\n",
            "queue size: 280 (144302)\n",
            "queue size: 279 (144307)\n",
            "queue size: 278 (144310)\n",
            "queue size: 277 (144311)\n",
            "queue size: 276 (144306)\n",
            "queue size: 275 (144312)\n",
            "queue size: 274 (144303)\n",
            "queue size: 273 (144305)\n",
            "queue size: 272 (144309)\n",
            "queue size: 271 (144304)\n",
            "queue size: 270 (144302)\n",
            "queue size: 269 (144308)\n",
            "queue size: 268 (144311)\n",
            "queue size: 267 (144305)\n",
            "queue size: 266 (144310)\n",
            "queue size: 265 (144313)\n",
            "queue size: 264 (144306)\n",
            "queue size: 263 (144309)\n",
            "queue size: 262 (144303)\n",
            "queue size: 261 (144307)\n",
            "queue size: 260 (144312)\n",
            "queue size: 259 (144305)\n",
            "queue size: 258 (144304)\n",
            "queue size: 257 (144302)\n",
            "queue size: 256 (144311)\n",
            "queue size: 255 (144308)\n",
            "queue size: 254 (144305)\n",
            "queue size: 253 (144310)\n",
            "queue size: 252 (144306)\n",
            "queue size: 251 (144312)\n",
            "queue size: 250 (144313)\n",
            "queue size: 249 (144307)\n",
            "queue size: 248 (144308)\n",
            "queue size: 247 (144303)\n",
            "queue size: 246 (144302)\n",
            "queue size: 245 (144309)\n",
            "queue size: 244 (144304)\n",
            "queue size: 243 (144305)\n",
            "queue size: 242 (144311)\n",
            "queue size: 241 (144306)\n",
            "queue size: 240 (144310)\n",
            "queue size: 239 (144313)\n",
            "queue size: 238 (144303)\n",
            "queue size: 237 (144307)\n",
            "queue size: 236 (144304)\n",
            "queue size: 235 (144312)\n",
            "queue size: 234 (144309)\n",
            "queue size: 233 (144302)\n",
            "queue size: 232 (144305)\n",
            "queue size: 231 (144308)\n",
            "queue size: 230 (144306)\n",
            "queue size: 229 (144311)\n",
            "queue size: 228 (144313)\n",
            "queue size: 227 (144302)\n",
            "queue size: 226 (144303)\n",
            "queue size: 225 (144307)\n",
            "queue size: 224 (144312)\n",
            "queue size: 223 (144310)\n",
            "queue size: 222 (144305)\n",
            "queue size: 221 (144306)\n",
            "queue size: 220 (144309)\n",
            "queue size: 219 (144313)\n",
            "queue size: 218 (144304)\n",
            "queue size: 217 (144308)\n",
            "queue size: 216 (144311)\n",
            "queue size: 215 (144307)\n",
            "queue size: 214 (144312)\n",
            "queue size: 213 (144302)\n",
            "queue size: 212 (144304)\n",
            "queue size: 211 (144306)\n",
            "queue size: 210 (144309)\n",
            "queue size: 209 (144308)\n",
            "queue size: 208 (144313)\n",
            "queue size: 207 (144311)\n",
            "queue size: 206 (144303)\n",
            "queue size: 205 (144307)\n",
            "queue size: 205 (144310)\n",
            "queue size: 203 (144305)\n",
            "queue size: 202 (144312)\n",
            "queue size: 201 (144306)\n",
            "queue size: 200 (144302)\n",
            "queue size: 199 (144303)\n",
            "queue size: 198 (144308)\n",
            "queue size: 197 (144313)\n",
            "queue size: 196 (144309)\n",
            "queue size: 195 (144304)\n",
            "queue size: 194 (144311)\n",
            "queue size: 193 (144310)\n",
            "queue size: 192 (144307)\n",
            "queue size: 191 (144305)\n",
            "queue size: 190 (144312)\n",
            "queue size: 189 (144302)\n",
            "queue size: 188 (144303)\n",
            "queue size: 187 (144308)\n",
            "queue size: 186 (144313)\n",
            "queue size: 185 (144309)\n",
            "queue size: 184 (144306)\n",
            "queue size: 183 (144307)\n",
            "queue size: 182 (144310)\n",
            "queue size: 181 (144308)\n",
            "queue size: 180 (144312)\n",
            "queue size: 179 (144305)\n",
            "queue size: 178 (144304)\n",
            "queue size: 177 (144311)\n",
            "queue size: 176 (144303)\n",
            "queue size: 175 (144302)\n",
            "queue size: 174 (144306)\n",
            "queue size: 173 (144307)\n",
            "queue size: 172 (144303)\n",
            "queue size: 171 (144310)\n",
            "queue size: 170 (144313)\n",
            "queue size: 169 (144308)\n",
            "queue size: 168 (144311)\n",
            "queue size: 167 (144309)\n",
            "queue size: 166 (144304)\n",
            "queue size: 165 (144302)\n",
            "queue size: 164 (144312)\n",
            "queue size: 163 (144306)\n",
            "queue size: 162 (144305)\n",
            "queue size: 161 (144303)\n",
            "queue size: 160 (144313)\n",
            "queue size: 159 (144309)\n",
            "queue size: 158 (144310)\n",
            "queue size: 157 (144304)\n",
            "queue size: 156 (144307)\n",
            "queue size: 155 (144308)\n",
            "queue size: 154 (144302)\n",
            "queue size: 153 (144312)\n",
            "queue size: 152 (144303)\n",
            "queue size: 151 (144311)\n",
            "queue size: 150 (144305)\n",
            "queue size: 149 (144306)\n",
            "queue size: 148 (144313)\n",
            "queue size: 147 (144309)\n",
            "queue size: 146 (144304)\n",
            "queue size: 145 (144310)\n",
            "queue size: 144 (144307)\n",
            "queue size: 143 (144303)\n",
            "queue size: 142 (144308)\n",
            "queue size: 141 (144312)\n",
            "queue size: 140 (144306)\n",
            "queue size: 139 (144302)\n",
            "queue size: 138 (144311)\n",
            "queue size: 137 (144309)\n",
            "queue size: 136 (144305)\n",
            "queue size: 135 (144308)\n",
            "queue size: 134 (144313)\n",
            "queue size: 133 (144304)\n",
            "queue size: 132 (144307)\n",
            "queue size: 131 (144303)\n",
            "queue size: 130 (144310)\n",
            "queue size: 129 (144311)\n",
            "queue size: 128 (144312)\n",
            "queue size: 127 (144310)\n",
            "queue size: 126 (144306)\n",
            "queue size: 125 (144309)\n",
            "queue size: 124 (144305)\n",
            "queue size: 123 (144313)\n",
            "queue size: 122 (144302)\n",
            "queue size: 121 (144304)\n",
            "queue size: 120 (144310)\n",
            "queue size: 119 (144307)\n",
            "queue size: 118 (144303)\n",
            "queue size: 117 (144308)\n",
            "queue size: 116 (144311)\n",
            "queue size: 115 (144313)\n",
            "queue size: 114 (144306)\n",
            "queue size: 113 (144309)\n",
            "queue size: 112 (144312)\n",
            "queue size: 111 (144302)\n",
            "queue size: 110 (144313)\n",
            "queue size: 109 (144311)\n",
            "queue size: 108 (144303)\n",
            "queue size: 107 (144304)\n",
            "queue size: 106 (144305)\n",
            "queue size: 105 (144307)\n",
            "queue size: 104 (144312)\n",
            "queue size: 103 (144309)\n",
            "queue size: 102 (144310)\n",
            "queue size: 101 (144307)\n",
            "queue size: 100 (144306)\n",
            "queue size: 99 (144303)\n",
            "queue size: 98 (144311)\n",
            "queue size: 97 (144308)\n",
            "queue size: 96 (144313)\n",
            "queue size: 95 (144302)\n",
            "queue size: 94 (144309)\n",
            "queue size: 93 (144310)\n",
            "queue size: 92 (144304)\n",
            "queue size: 91 (144305)\n",
            "queue size: 90 (144307)\n",
            "queue size: 89 (144313)\n",
            "queue size: 88 (144306)\n",
            "queue size: 87 (144311)\n",
            "queue size: 86 (144313)\n",
            "queue size: 85 (144303)\n",
            "queue size: 84 (144312)\n",
            "queue size: 83 (144308)\n",
            "queue size: 82 (144309)\n",
            "queue size: 81 (144302)\n",
            "queue size: 80 (144310)\n",
            "queue size: 79 (144304)\n",
            "queue size: 78 (144305)\n",
            "queue size: 77 (144307)\n",
            "queue size: 76 (144313)\n",
            "queue size: 75 (144309)\n",
            "queue size: 74 (144312)\n",
            "queue size: 73 (144306)\n",
            "queue size: 72 (144303)\n",
            "queue size: 71 (144304)\n",
            "queue size: 70 (144311)\n",
            "queue size: 69 (144308)\n",
            "queue size: 68 (144310)\n",
            "queue size: 67 (144304)\n",
            "queue size: 66 (144307)\n",
            "queue size: 65 (144306)\n",
            "queue size: 64 (144305)\n",
            "queue size: 63 (144309)\n",
            "queue size: 62 (144311)\n",
            "queue size: 61 (144312)\n",
            "queue size: 60 (144302)\n",
            "queue size: 59 (144303)\n",
            "queue size: 58 (144313)\n",
            "queue size: 57 (144307)\n",
            "queue size: 56 (144309)\n",
            "queue size: 55 (144304)\n",
            "queue size: 54 (144306)\n",
            "queue size: 53 (144308)\n",
            "queue size: 52 (144305)\n",
            "queue size: 51 (144307)\n",
            "queue size: 50 (144310)\n",
            "queue size: 49 (144302)\n",
            "queue size: 48 (144303)\n",
            "queue size: 47 (144312)\n",
            "queue size: 46 (144313)\n",
            "queue size: 45 (144311)\n",
            "queue size: 44 (144306)\n",
            "queue size: 43 (144309)\n",
            "queue size: 42 (144304)\n",
            "queue size: 41 (144308)\n",
            "queue size: 40 (144310)\n",
            "queue size: 39 (144307)\n",
            "queue size: 38 (144302)\n",
            "queue size: 37 (144311)\n",
            "queue size: 36 (144305)\n",
            "queue size: 35 (144313)\n",
            "queue size: 34 (144312)\n",
            "queue size: 33 (144303)\n",
            "queue size: 32 (144309)\n",
            "queue size: 31 (144306)\n",
            "queue size: 30 (144312)\n",
            "queue size: 29 (144304)\n",
            "queue size: 28 (144308)\n",
            "queue size: 27 (144307)\n",
            "queue size: 26 (144310)\n",
            "queue size: 25 (144313)\n",
            "queue size: 24 (144311)\n",
            "queue size: 23 (144309)\n",
            "queue size: 22 (144306)\n",
            "queue size: 21 (144302)\n",
            "queue size: 20 (144303)\n",
            "queue size: 19 (144312)\n",
            "queue size: 18 (144307)\n",
            "queue size: 17 (144305)\n",
            "queue size: 16 (144304)\n",
            "queue size: 15 (144308)\n",
            "queue size: 14 (144310)\n",
            "queue size: 13 (144308)\n",
            "queue size: 12 (144312)\n",
            "queue size: 11 (144305)\n",
            "queue size: 10 (144306)\n",
            "queue size: 9 (144309)\n",
            "queue size: 8 (144302)\n",
            "queue size: 7 (144308)\n",
            "queue size: 6 (144307)\n",
            "queue size: 5 (144313)\n",
            "queue size: 4 (144311)\n",
            "queue size: 3 (144303)\n",
            "queue size: 2 (144310)\n",
            "queue size: 1 (144305)\n",
            "Worker (144312) finished. session_id: test_session_p144312_t132992628171392\n",
            "Worker (144304) finished. session_id: test_session_p144304_t132992628171392\n",
            "Worker (144308) finished. session_id: test_session_p144308_t132992628171392\n",
            "Worker (144306) finished. session_id: test_session_p144306_t132992628171392\n",
            "Worker (144305) finished. session_id: test_session_p144305_t132992628171392\n",
            "Worker (144311) finished. session_id: test_session_p144311_t132992628171392\n",
            "Worker (144313) finished. session_id: test_session_p144313_t132992628171392\n",
            "Worker (144309) finished. session_id: test_session_p144309_t132992628171392\n",
            "Worker (144307) finished. session_id: test_session_p144307_t132992628171392\n",
            "Worker (144310) finished. session_id: test_session_p144310_t132992628171392\n",
            "Worker (144303) finished. session_id: test_session_p144303_t132992628171392\n",
            "Worker (144302) finished. session_id: test_session_p144302_t132992628171392\n",
            "Deployment: llama2-7b-tp1-b768 Clients: 12, Prompt (mean): 2600 tokens, Generation (mean): 60 tokens, Query throughput: 3.024 queries/s, Token throughput (total): 742.205 tokens/s, Query latency: 3.968 s, Token generation latency: 0.059 s/token, First token received: 0.505 s\n",
            "Namespace(max_new_tokens=60, deployment_name='llama2-7b-tp1-b768', num_queries=512, warmup=1, client_num=16, prompt_length=2600, use_thread=False, stream=True, vllm=False, out_json_path=PosixPath('logs.llama2-7b-tp1-b768/llama2-7b-tp1-b768_c16_p2600_g60.json'))\n",
            "[2023-12-16 13:17:03,433] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:17:03,526] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:17:03,542] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:17:03,594] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:17:03,635] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:17:03,654] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:17:03,666] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:17:03,722] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:17:03,765] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:17:03,785] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:17:03,784] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:17:03,819] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:17:03,851] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:17:03,872] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:17:03,947] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:17:04,001] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "2023-12-16 13:17:06.918899: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:17:06.919088: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:17:06.921534: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:17:06.932338: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:17:06.932437: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:17:06.934113: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:17:07.198539: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:17:07.210985: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:17:07.212791: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:17:07.266825: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:17:07.266970: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:17:07.268728: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:17:07.277115: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:17:07.277164: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:17:07.278885: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:17:07.298022: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:17:07.298128: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:17:07.299829: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:17:07.419113: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:17:07.419229: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:17:07.420978: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:17:07.569787: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:17:07.569844: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:17:07.571584: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:17:07.628326: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:17:07.628449: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:17:07.630212: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:17:07.712424: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:17:07.712532: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:17:07.714222: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:17:07.741701: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:17:07.741826: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:17:07.743565: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:17:07.905080: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:17:07.905195: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:17:07.906874: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:17:07.975695: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:17:07.975815: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:17:07.977592: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:17:08.098817: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:17:08.098931: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:17:08.100644: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:17:08.108571: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:17:08.108659: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:17:08.110308: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:17:08.144400: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:17:08.144455: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:17:08.146194: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:17:09.685962: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:17:09.812118: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:17:09.963820: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:17:10.140783: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:17:10.192276: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:17:10.361272: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:17:10.398102: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:17:10.421318: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:17:10.433228: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:17:10.626058: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:17:10.646976: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:17:10.736178: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:17:10.750185: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:17:10.896775: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:17:11.074376: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:17:11.450854: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "warmup queue size: 528 (146238)\n",
            "warmup queue size: 528 (146239)\n",
            "warmup queue size: 528 (146231)\n",
            "warmup queue size: 528 (146230)\n",
            "warmup queue size: 527 (146225)\n",
            "warmup queue size: 527 (146235)\n",
            "warmup queue size: 526 (146229)\n",
            "warmup queue size: 526 (146233)\n",
            "warmup queue size: 526 (146236)\n",
            "warmup queue size: 526 (146232)\n",
            "warmup queue size: 525 (146240)\n",
            "warmup queue size: 525 (146237)\n",
            "warmup queue size: 525 (146228)\n",
            "warmup queue size: 524 (146227)\n",
            "warmup queue size: 524 (146234)\n",
            "warmup queue size: 524 (146226)\n",
            "queue size: 512 (146237)\n",
            "queue size: 511 (146240)\n",
            "queue size: 510 (146238)\n",
            "queue size: 509 (146233)\n",
            "queue size: 508 (146227)\n",
            "queue size: 507 (146234)\n",
            "queue size: 506 (146226)\n",
            "queue size: 505 (146235)\n",
            "queue size: 504 (146228)\n",
            "queue size: 503 (146230)\n",
            "queue size: 502 (146236)\n",
            "queue size: 501 (146229)\n",
            "queue size: 500 (146239)\n",
            "queue size: 499 (146225)\n",
            "queue size: 498 (146231)\n",
            "queue size: 497 (146232)\n",
            "queue size: 496 (146237)\n",
            "queue size: 495 (146240)\n",
            "queue size: 494 (146233)\n",
            "queue size: 493 (146234)\n",
            "queue size: 492 (146238)\n",
            "queue size: 491 (146235)\n",
            "queue size: 490 (146227)\n",
            "queue size: 489 (146226)\n",
            "queue size: 488 (146229)\n",
            "queue size: 487 (146239)\n",
            "queue size: 486 (146225)\n",
            "queue size: 485 (146236)\n",
            "queue size: 484 (146230)\n",
            "queue size: 483 (146232)\n",
            "queue size: 482 (146228)\n",
            "queue size: 481 (146227)\n",
            "queue size: 480 (146231)\n",
            "queue size: 479 (146237)\n",
            "queue size: 478 (146229)\n",
            "queue size: 477 (146234)\n",
            "queue size: 476 (146226)\n",
            "queue size: 475 (146235)\n",
            "queue size: 474 (146227)\n",
            "queue size: 473 (146233)\n",
            "queue size: 472 (146239)\n",
            "queue size: 471 (146240)\n",
            "queue size: 470 (146229)\n",
            "queue size: 469 (146225)\n",
            "queue size: 468 (146238)\n",
            "queue size: 467 (146232)\n",
            "queue size: 466 (146230)\n",
            "queue size: 465 (146231)\n",
            "queue size: 464 (146228)\n",
            "queue size: 463 (146235)\n",
            "queue size: 462 (146236)\n",
            "queue size: 461 (146237)\n",
            "queue size: 460 (146226)\n",
            "queue size: 459 (146234)\n",
            "queue size: 458 (146225)\n",
            "queue size: 457 (146229)\n",
            "queue size: 456 (146227)\n",
            "queue size: 455 (146239)\n",
            "queue size: 454 (146232)\n",
            "queue size: 453 (146240)\n",
            "queue size: 452 (146230)\n",
            "queue size: 451 (146231)\n",
            "queue size: 450 (146238)\n",
            "queue size: 449 (146233)\n",
            "queue size: 448 (146239)\n",
            "queue size: 447 (146237)\n",
            "queue size: 446 (146234)\n",
            "queue size: 445 (146228)\n",
            "queue size: 444 (146235)\n",
            "queue size: 443 (146226)\n",
            "queue size: 442 (146225)\n",
            "queue size: 441 (146236)\n",
            "queue size: 440 (146239)\n",
            "queue size: 439 (146229)\n",
            "queue size: 438 (146233)\n",
            "queue size: 437 (146238)\n",
            "queue size: 436 (146227)\n",
            "queue size: 435 (146232)\n",
            "queue size: 434 (146230)\n",
            "queue size: 433 (146226)\n",
            "queue size: 432 (146240)\n",
            "queue size: 431 (146231)\n",
            "queue size: 430 (146228)\n",
            "queue size: 429 (146235)\n",
            "queue size: 428 (146234)\n",
            "queue size: 427 (146236)\n",
            "queue size: 426 (146237)\n",
            "queue size: 425 (146227)\n",
            "queue size: 424 (146239)\n",
            "queue size: 423 (146233)\n",
            "queue size: 422 (146238)\n",
            "queue size: 421 (146229)\n",
            "queue size: 420 (146228)\n",
            "queue size: 419 (146232)\n",
            "queue size: 418 (146231)\n",
            "queue size: 417 (146237)\n",
            "queue size: 416 (146225)\n",
            "queue size: 415 (146234)\n",
            "queue size: 414 (146226)\n",
            "queue size: 413 (146235)\n",
            "queue size: 412 (146230)\n",
            "queue size: 411 (146229)\n",
            "queue size: 410 (146240)\n",
            "queue size: 409 (146239)\n",
            "queue size: 408 (146238)\n",
            "queue size: 407 (146233)\n",
            "queue size: 406 (146231)\n",
            "queue size: 405 (146237)\n",
            "queue size: 404 (146236)\n",
            "queue size: 403 (146240)\n",
            "queue size: 402 (146235)\n",
            "queue size: 401 (146227)\n",
            "queue size: 400 (146232)\n",
            "queue size: 399 (146225)\n",
            "queue size: 398 (146228)\n",
            "queue size: 397 (146226)\n",
            "queue size: 396 (146230)\n",
            "queue size: 395 (146229)\n",
            "queue size: 394 (146239)\n",
            "queue size: 393 (146238)\n",
            "queue size: 392 (146240)\n",
            "queue size: 391 (146234)\n",
            "queue size: 390 (146236)\n",
            "queue size: 389 (146233)\n",
            "queue size: 388 (146227)\n",
            "queue size: 387 (146232)\n",
            "queue size: 386 (146237)\n",
            "queue size: 385 (146225)\n",
            "queue size: 384 (146230)\n",
            "queue size: 383 (146226)\n",
            "queue size: 382 (146228)\n",
            "queue size: 381 (146229)\n",
            "queue size: 380 (146231)\n",
            "queue size: 379 (146227)\n",
            "queue size: 378 (146238)\n",
            "queue size: 377 (146240)\n",
            "queue size: 376 (146239)\n",
            "queue size: 375 (146225)\n",
            "queue size: 374 (146235)\n",
            "queue size: 373 (146236)\n",
            "queue size: 372 (146234)\n",
            "queue size: 371 (146228)\n",
            "queue size: 370 (146230)\n",
            "queue size: 369 (146229)\n",
            "queue size: 368 (146231)\n",
            "queue size: 367 (146226)\n",
            "queue size: 366 (146233)\n",
            "queue size: 365 (146225)\n",
            "queue size: 364 (146232)\n",
            "queue size: 363 (146237)\n",
            "queue size: 362 (146234)\n",
            "queue size: 361 (146235)\n",
            "queue size: 360 (146238)\n",
            "queue size: 359 (146239)\n",
            "queue size: 358 (146227)\n",
            "queue size: 357 (146236)\n",
            "queue size: 356 (146240)\n",
            "queue size: 355 (146230)\n",
            "queue size: 354 (146229)\n",
            "queue size: 353 (146228)\n",
            "queue size: 352 (146232)\n",
            "queue size: 351 (146233)\n",
            "queue size: 350 (146226)\n",
            "queue size: 350 (146231)\n",
            "queue size: 348 (146239)\n",
            "queue size: 347 (146235)\n",
            "queue size: 346 (146237)\n",
            "queue size: 345 (146225)\n",
            "queue size: 344 (146232)\n",
            "queue size: 343 (146234)\n",
            "queue size: 342 (146228)\n",
            "queue size: 341 (146240)\n",
            "queue size: 340 (146238)\n",
            "queue size: 340 (146236)\n",
            "queue size: 338 (146229)\n",
            "queue size: 337 (146239)\n",
            "queue size: 336 (146226)\n",
            "queue size: 335 (146227)\n",
            "queue size: 334 (146230)\n",
            "queue size: 333 (146233)\n",
            "queue size: 332 (146232)\n",
            "queue size: 331 (146237)\n",
            "queue size: 330 (146225)\n",
            "queue size: 329 (146227)\n",
            "queue size: 328 (146228)\n",
            "queue size: 327 (146230)\n",
            "queue size: 326 (146231)\n",
            "queue size: 325 (146234)\n",
            "queue size: 324 (146229)\n",
            "queue size: 323 (146236)\n",
            "queue size: 322 (146235)\n",
            "queue size: 321 (146238)\n",
            "queue size: 320 (146239)\n",
            "queue size: 319 (146240)\n",
            "queue size: 318 (146226)\n",
            "queue size: 317 (146228)\n",
            "queue size: 316 (146232)\n",
            "queue size: 315 (146233)\n",
            "queue size: 314 (146237)\n",
            "queue size: 313 (146236)\n",
            "queue size: 312 (146230)\n",
            "queue size: 311 (146225)\n",
            "queue size: 310 (146234)\n",
            "queue size: 309 (146227)\n",
            "queue size: 308 (146231)\n",
            "queue size: 307 (146232)\n",
            "queue size: 306 (146229)\n",
            "queue size: 305 (146233)\n",
            "queue size: 304 (146238)\n",
            "queue size: 303 (146239)\n",
            "queue size: 302 (146237)\n",
            "queue size: 301 (146235)\n",
            "queue size: 300 (146225)\n",
            "queue size: 299 (146240)\n",
            "queue size: 298 (146232)\n",
            "queue size: 297 (146227)\n",
            "queue size: 296 (146236)\n",
            "queue size: 295 (146234)\n",
            "queue size: 294 (146228)\n",
            "queue size: 293 (146231)\n",
            "queue size: 292 (146226)\n",
            "queue size: 291 (146233)\n",
            "queue size: 290 (146229)\n",
            "queue size: 289 (146230)\n",
            "queue size: 288 (146238)\n",
            "queue size: 287 (146237)\n",
            "queue size: 286 (146232)\n",
            "queue size: 285 (146236)\n",
            "queue size: 284 (146239)\n",
            "queue size: 283 (146240)\n",
            "queue size: 282 (146225)\n",
            "queue size: 281 (146233)\n",
            "queue size: 280 (146234)\n",
            "queue size: 279 (146227)\n",
            "queue size: 278 (146231)\n",
            "queue size: 277 (146238)\n",
            "queue size: 276 (146229)\n",
            "queue size: 275 (146235)\n",
            "queue size: 274 (146226)\n",
            "queue size: 273 (146233)\n",
            "queue size: 272 (146228)\n",
            "queue size: 271 (146236)\n",
            "queue size: 270 (146232)\n",
            "queue size: 269 (146230)\n",
            "queue size: 268 (146234)\n",
            "queue size: 267 (146237)\n",
            "queue size: 266 (146239)\n",
            "queue size: 265 (146235)\n",
            "queue size: 264 (146227)\n",
            "queue size: 263 (146225)\n",
            "queue size: 262 (146240)\n",
            "queue size: 261 (146231)\n",
            "queue size: 260 (146229)\n",
            "queue size: 259 (146238)\n",
            "queue size: 258 (146237)\n",
            "queue size: 257 (146226)\n",
            "queue size: 256 (146228)\n",
            "queue size: 255 (146233)\n",
            "queue size: 254 (146225)\n",
            "queue size: 253 (146234)\n",
            "queue size: 252 (146240)\n",
            "queue size: 251 (146236)\n",
            "queue size: 250 (146230)\n",
            "queue size: 249 (146232)\n",
            "queue size: 248 (146235)\n",
            "queue size: 247 (146239)\n",
            "queue size: 246 (146227)\n",
            "queue size: 245 (146229)\n",
            "queue size: 244 (146231)\n",
            "queue size: 243 (146237)\n",
            "queue size: 242 (146226)\n",
            "queue size: 241 (146233)\n",
            "queue size: 240 (146238)\n",
            "queue size: 239 (146240)\n",
            "queue size: 238 (146225)\n",
            "queue size: 237 (146234)\n",
            "queue size: 236 (146236)\n",
            "queue size: 235 (146228)\n",
            "queue size: 234 (146232)\n",
            "queue size: 233 (146239)\n",
            "queue size: 232 (146230)\n",
            "queue size: 231 (146227)\n",
            "queue size: 230 (146229)\n",
            "queue size: 229 (146233)\n",
            "queue size: 228 (146235)\n",
            "queue size: 227 (146237)\n",
            "queue size: 226 (146236)\n",
            "queue size: 225 (146238)\n",
            "queue size: 224 (146225)\n",
            "queue size: 223 (146226)\n",
            "queue size: 222 (146239)\n",
            "queue size: 221 (146231)\n",
            "queue size: 220 (146230)\n",
            "queue size: 219 (146240)\n",
            "queue size: 218 (146234)\n",
            "queue size: 217 (146233)\n",
            "queue size: 216 (146235)\n",
            "queue size: 215 (146228)\n",
            "queue size: 214 (146236)\n",
            "queue size: 213 (146237)\n",
            "queue size: 212 (146238)\n",
            "queue size: 211 (146225)\n",
            "queue size: 210 (146229)\n",
            "queue size: 209 (146227)\n",
            "queue size: 208 (146232)\n",
            "queue size: 207 (146226)\n",
            "queue size: 206 (146240)\n",
            "queue size: 205 (146239)\n",
            "queue size: 204 (146231)\n",
            "queue size: 203 (146236)\n",
            "queue size: 202 (146233)\n",
            "queue size: 201 (146235)\n",
            "queue size: 200 (146234)\n",
            "queue size: 199 (146230)\n",
            "queue size: 198 (146228)\n",
            "queue size: 197 (146237)\n",
            "queue size: 196 (146232)\n",
            "queue size: 195 (146238)\n",
            "queue size: 194 (146226)\n",
            "queue size: 193 (146240)\n",
            "queue size: 192 (146225)\n",
            "queue size: 191 (146229)\n",
            "queue size: 190 (146239)\n",
            "queue size: 189 (146231)\n",
            "queue size: 188 (146235)\n",
            "queue size: 187 (146234)\n",
            "queue size: 186 (146238)\n",
            "queue size: 185 (146228)\n",
            "queue size: 184 (146227)\n",
            "queue size: 183 (146236)\n",
            "queue size: 182 (146232)\n",
            "queue size: 181 (146233)\n",
            "queue size: 180 (146230)\n",
            "queue size: 179 (146225)\n",
            "queue size: 178 (146237)\n",
            "queue size: 177 (146229)\n",
            "queue size: 176 (146239)\n",
            "queue size: 175 (146227)\n",
            "queue size: 174 (146231)\n",
            "queue size: 173 (146228)\n",
            "queue size: 172 (146226)\n",
            "queue size: 171 (146238)\n",
            "queue size: 170 (146236)\n",
            "queue size: 169 (146235)\n",
            "queue size: 168 (146240)\n",
            "queue size: 167 (146230)\n",
            "queue size: 166 (146232)\n",
            "queue size: 165 (146225)\n",
            "queue size: 164 (146237)\n",
            "queue size: 163 (146234)\n",
            "queue size: 162 (146227)\n",
            "queue size: 161 (146231)\n",
            "queue size: 160 (146233)\n",
            "queue size: 159 (146229)\n",
            "queue size: 158 (146235)\n",
            "queue size: 157 (146226)\n",
            "queue size: 156 (146228)\n",
            "queue size: 155 (146236)\n",
            "queue size: 154 (146240)\n",
            "queue size: 153 (146239)\n",
            "queue size: 152 (146232)\n",
            "queue size: 151 (146238)\n",
            "queue size: 150 (146230)\n",
            "queue size: 149 (146225)\n",
            "queue size: 148 (146233)\n",
            "queue size: 147 (146237)\n",
            "queue size: 146 (146234)\n",
            "queue size: 145 (146231)\n",
            "queue size: 145 (146229)\n",
            "queue size: 143 (146226)\n",
            "queue size: 142 (146227)\n",
            "queue size: 141 (146236)\n",
            "queue size: 140 (146228)\n",
            "queue size: 139 (146230)\n",
            "queue size: 138 (146235)\n",
            "queue size: 137 (146240)\n",
            "queue size: 136 (146232)\n",
            "queue size: 135 (146238)\n",
            "queue size: 134 (146234)\n",
            "queue size: 133 (146239)\n",
            "queue size: 132 (146225)\n",
            "queue size: 131 (146229)\n",
            "queue size: 130 (146233)\n",
            "queue size: 129 (146231)\n",
            "queue size: 128 (146227)\n",
            "queue size: 127 (146235)\n",
            "queue size: 126 (146236)\n",
            "queue size: 125 (146230)\n",
            "queue size: 124 (146238)\n",
            "queue size: 123 (146237)\n",
            "queue size: 122 (146226)\n",
            "queue size: 121 (146240)\n",
            "queue size: 120 (146228)\n",
            "queue size: 119 (146229)\n",
            "queue size: 118 (146239)\n",
            "queue size: 117 (146234)\n",
            "queue size: 116 (146237)\n",
            "queue size: 115 (146233)\n",
            "queue size: 114 (146232)\n",
            "queue size: 113 (146238)\n",
            "queue size: 112 (146230)\n",
            "queue size: 111 (146236)\n",
            "queue size: 110 (146231)\n",
            "queue size: 109 (146235)\n",
            "queue size: 108 (146225)\n",
            "queue size: 107 (146228)\n",
            "queue size: 106 (146240)\n",
            "queue size: 105 (146237)\n",
            "queue size: 104 (146227)\n",
            "queue size: 103 (146226)\n",
            "queue size: 102 (146234)\n",
            "queue size: 101 (146239)\n",
            "queue size: 100 (146229)\n",
            "queue size: 99 (146236)\n",
            "queue size: 98 (146231)\n",
            "queue size: 97 (146238)\n",
            "queue size: 96 (146235)\n",
            "queue size: 95 (146233)\n",
            "queue size: 94 (146232)\n",
            "queue size: 93 (146227)\n",
            "queue size: 92 (146225)\n",
            "queue size: 91 (146227)\n",
            "queue size: 90 (146240)\n",
            "queue size: 89 (146228)\n",
            "queue size: 88 (146230)\n",
            "queue size: 87 (146234)\n",
            "queue size: 86 (146237)\n",
            "queue size: 85 (146229)\n",
            "queue size: 84 (146236)\n",
            "queue size: 83 (146231)\n",
            "queue size: 82 (146238)\n",
            "queue size: 81 (146239)\n",
            "queue size: 80 (146226)\n",
            "queue size: 79 (146235)\n",
            "queue size: 78 (146232)\n",
            "queue size: 77 (146240)\n",
            "queue size: 76 (146234)\n",
            "queue size: 75 (146225)\n",
            "queue size: 74 (146233)\n",
            "queue size: 73 (146235)\n",
            "queue size: 72 (146230)\n",
            "queue size: 71 (146239)\n",
            "queue size: 70 (146237)\n",
            "queue size: 69 (146229)\n",
            "queue size: 68 (146227)\n",
            "queue size: 67 (146232)\n",
            "queue size: 66 (146238)\n",
            "queue size: 65 (146231)\n",
            "queue size: 64 (146228)\n",
            "queue size: 63 (146226)\n",
            "queue size: 62 (146236)\n",
            "queue size: 61 (146233)\n",
            "queue size: 60 (146239)\n",
            "queue size: 59 (146231)\n",
            "queue size: 58 (146235)\n",
            "queue size: 57 (146240)\n",
            "queue size: 56 (146225)\n",
            "queue size: 55 (146230)\n",
            "queue size: 54 (146234)\n",
            "queue size: 53 (146227)\n",
            "queue size: 52 (146232)\n",
            "queue size: 51 (146226)\n",
            "queue size: 50 (146228)\n",
            "queue size: 49 (146236)\n",
            "queue size: 48 (146238)\n",
            "queue size: 47 (146229)\n",
            "queue size: 46 (146237)\n",
            "queue size: 45 (146233)\n",
            "queue size: 44 (146236)\n",
            "queue size: 43 (146235)\n",
            "queue size: 42 (146231)\n",
            "queue size: 41 (146227)\n",
            "queue size: 40 (146240)\n",
            "queue size: 39 (146234)\n",
            "queue size: 38 (146239)\n",
            "queue size: 37 (146230)\n",
            "queue size: 36 (146226)\n",
            "queue size: 36 (146225)\n",
            "queue size: 34 (146229)\n",
            "queue size: 33 (146232)\n",
            "queue size: 32 (146235)\n",
            "queue size: 31 (146228)\n",
            "queue size: 30 (146233)\n",
            "queue size: 29 (146239)\n",
            "queue size: 28 (146238)\n",
            "queue size: 27 (146240)\n",
            "queue size: 26 (146237)\n",
            "queue size: 25 (146227)\n",
            "queue size: 24 (146234)\n",
            "queue size: 23 (146225)\n",
            "queue size: 22 (146236)\n",
            "queue size: 21 (146231)\n",
            "queue size: 20 (146230)\n",
            "queue size: 19 (146229)\n",
            "queue size: 18 (146226)\n",
            "queue size: 17 (146227)\n",
            "queue size: 16 (146240)\n",
            "queue size: 15 (146233)\n",
            "queue size: 14 (146228)\n",
            "queue size: 13 (146239)\n",
            "queue size: 12 (146237)\n",
            "queue size: 11 (146238)\n",
            "queue size: 10 (146229)\n",
            "queue size: 9 (146235)\n",
            "queue size: 8 (146230)\n",
            "queue size: 7 (146236)\n",
            "queue size: 6 (146232)\n",
            "queue size: 5 (146234)\n",
            "queue size: 4 (146225)\n",
            "queue size: 3 (146233)\n",
            "queue size: 2 (146226)\n",
            "queue size: 1 (146235)\n",
            "Worker (146239) finished. session_id: test_session_p146239_t138481107718784\n",
            "Worker (146231) finished. session_id: test_session_p146231_t138481107718784\n",
            "Worker (146237) finished. session_id: test_session_p146237_t138481107718784\n",
            "Worker (146227) finished. session_id: test_session_p146227_t138481107718784\n",
            "Worker (146228) finished. session_id: test_session_p146228_t138481107718784\n",
            "Worker (146232) finished. session_id: test_session_p146232_t138481107718784\n",
            "Worker (146240) finished. session_id: test_session_p146240_t138481107718784\n",
            "Worker (146238) finished. session_id: test_session_p146238_t138481107718784\n",
            "Worker (146229) finished. session_id: test_session_p146229_t138481107718784\n",
            "Worker (146234) finished. session_id: test_session_p146234_t138481107718784\n",
            "Worker (146226) finished. session_id: test_session_p146226_t138481107718784\n",
            "Worker (146233) finished. session_id: test_session_p146233_t138481107718784\n",
            "Worker (146235) finished. session_id: test_session_p146235_t138481107718784\n",
            "Worker (146225) finished. session_id: test_session_p146225_t138481107718784\n",
            "Worker (146230) finished. session_id: test_session_p146230_t138481107718784\n",
            "Worker (146236) finished. session_id: test_session_p146236_t138481107718784\n",
            "Deployment: llama2-7b-tp1-b768 Clients: 16, Prompt (mean): 2600 tokens, Generation (mean): 60 tokens, Query throughput: 3.197 queries/s, Token throughput (total): 585.125 tokens/s, Query latency: 5.005 s, Token generation latency: 0.073 s/token, First token received: 0.705 s\n",
            "Namespace(max_new_tokens=60, deployment_name='llama2-7b-tp1-b768', num_queries=512, warmup=1, client_num=20, prompt_length=2600, use_thread=False, stream=True, vllm=False, out_json_path=PosixPath('logs.llama2-7b-tp1-b768/llama2-7b-tp1-b768_c20_p2600_g60.json'))\n",
            "[2023-12-16 13:20:12,419] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:20:12,657] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:20:12,891] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:20:13,057] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:20:13,073] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:20:13,113] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:20:13,167] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:20:13,220] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:20:13,277] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:20:13,322] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:20:13,346] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:20:13,366] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:20:13,367] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:20:13,400] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:20:13,424] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:20:13,585] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:20:13,651] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:20:13,688] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:20:13,708] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:20:13,746] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "2023-12-16 13:20:16.457756: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:20:16.457928: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:20:16.460305: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:20:16.821694: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:20:16.821812: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:20:16.823517: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:20:17.504685: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:20:17.504821: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:20:17.506545: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:20:17.520316: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:20:17.520362: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:20:17.522017: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:20:17.645299: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:20:17.645412: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:20:17.647099: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:20:17.703324: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:20:17.703427: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:20:17.705082: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:20:17.761468: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:20:17.773987: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:20:17.775683: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:20:17.936271: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:20:17.936387: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:20:17.938094: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:20:17.953038: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:20:17.965955: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:20:17.967755: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:20:17.977647: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:20:17.979991: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:20:17.981690: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:20:18.013276: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:20:18.013588: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:20:18.015458: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:20:18.015742: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:20:18.015822: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:20:18.017573: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:20:18.458110: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:20:18.470988: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:20:18.472766: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:20:18.755101: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:20:18.755089: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:20:18.755130: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:20:18.755205: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:20:18.756764: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:20:18.756764: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:20:18.901033: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:20:18.901164: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:20:18.902837: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:20:19.181022: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:20:19.181149: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:20:19.182846: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:20:19.239017: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:20:19.246668: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:20:19.254989: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:20:19.256779: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:20:19.270654: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:20:19.270765: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:20:19.272456: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:20:19.522681: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:20:19.534985: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:20:19.536671: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:20:20.821751: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:20:21.167558: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:20:21.192885: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:20:21.196595: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:20:21.437175: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:20:21.548939: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:20:21.686422: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:20:21.914322: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:20:21.977901: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:20:22.110491: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:20:22.180459: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:20:22.210365: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:20:22.354399: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:20:22.459486: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:20:22.469732: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:20:22.736014: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:20:22.980183: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:20:23.252697: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:20:24.292382: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "warmup queue size: 532 (148346)\n",
            "warmup queue size: 532 (148329)\n",
            "warmup queue size: 532 (148332)\n",
            "warmup queue size: 531 (148335)\n",
            "warmup queue size: 531 (148345)\n",
            "warmup queue size: 531 (148343)\n",
            "warmup queue size: 530 (148333)\n",
            "warmup queue size: 530 (148340)\n",
            "warmup queue size: 530 (148330)\n",
            "warmup queue size: 529 (148331)\n",
            "warmup queue size: 529 (148344)\n",
            "warmup queue size: 529 (148334)\n",
            "warmup queue size: 528 (148347)\n",
            "warmup queue size: 528 (148328)\n",
            "warmup queue size: 528 (148339)\n",
            "warmup queue size: 527 (148336)\n",
            "warmup queue size: 527 (148337)\n",
            "warmup queue size: 527 (148341)\n",
            "warmup queue size: 526 (148342)\n",
            "warmup queue size: 526 (148338)\n",
            "queue size: 512 (148330)\n",
            "queue size: 511 (148338)\n",
            "queue size: 510 (148342)\n",
            "queue size: 509 (148334)\n",
            "queue size: 508 (148335)\n",
            "queue size: 507 (148328)\n",
            "queue size: 506 (148347)\n",
            "queue size: 505 (148329)\n",
            "queue size: 504 (148331)\n",
            "queue size: 503 (148344)\n",
            "queue size: 502 (148337)\n",
            "queue size: 501 (148343)\n",
            "queue size: 500 (148332)\n",
            "queue size: 499 (148346)\n",
            "queue size: 498 (148340)\n",
            "queue size: 497 (148333)\n",
            "queue size: 496 (148345)\n",
            "queue size: 495 (148341)\n",
            "queue size: 494 (148336)\n",
            "queue size: 493 (148339)\n",
            "queue size: 492 (148338)\n",
            "queue size: 491 (148334)\n",
            "queue size: 490 (148335)\n",
            "queue size: 489 (148328)\n",
            "queue size: 488 (148340)\n",
            "queue size: 487 (148342)\n",
            "queue size: 486 (148329)\n",
            "queue size: 485 (148333)\n",
            "queue size: 484 (148345)\n",
            "queue size: 483 (148347)\n",
            "queue size: 482 (148330)\n",
            "queue size: 481 (148331)\n",
            "queue size: 480 (148343)\n",
            "queue size: 479 (148346)\n",
            "queue size: 478 (148328)\n",
            "queue size: 477 (148341)\n",
            "queue size: 476 (148337)\n",
            "queue size: 475 (148336)\n",
            "queue size: 474 (148329)\n",
            "queue size: 473 (148332)\n",
            "queue size: 472 (148334)\n",
            "queue size: 471 (148344)\n",
            "queue size: 470 (148338)\n",
            "queue size: 469 (148340)\n",
            "queue size: 468 (148347)\n",
            "queue size: 467 (148335)\n",
            "queue size: 466 (148339)\n",
            "queue size: 465 (148342)\n",
            "queue size: 464 (148345)\n",
            "queue size: 463 (148341)\n",
            "queue size: 462 (148328)\n",
            "queue size: 461 (148343)\n",
            "queue size: 460 (148336)\n",
            "queue size: 459 (148333)\n",
            "queue size: 459 (148330)\n",
            "queue size: 457 (148346)\n",
            "queue size: 456 (148332)\n",
            "queue size: 455 (148329)\n",
            "queue size: 454 (148337)\n",
            "queue size: 453 (148340)\n",
            "queue size: 452 (148331)\n",
            "queue size: 451 (148335)\n",
            "queue size: 450 (148334)\n",
            "queue size: 449 (148344)\n",
            "queue size: 448 (148347)\n",
            "queue size: 447 (148339)\n",
            "queue size: 446 (148341)\n",
            "queue size: 445 (148338)\n",
            "queue size: 444 (148332)\n",
            "queue size: 443 (148342)\n",
            "queue size: 442 (148330)\n",
            "queue size: 441 (148346)\n",
            "queue size: 440 (148345)\n",
            "queue size: 439 (148336)\n",
            "queue size: 438 (148328)\n",
            "queue size: 437 (148335)\n",
            "queue size: 436 (148340)\n",
            "Deadlock detected. Resetting KV cache and recomputing requests. Consider limiting number of concurrent requests or decreasing max lengths of prompts/generations.\n",
            "queue size: 435 (148343)\n",
            "queue size: 434 (148333)\n",
            "queue size: 433 (148337)\n",
            "queue size: 432 (148331)\n",
            "queue size: 431 (148329)\n",
            "queue size: 430 (148344)\n",
            "queue size: 429 (148347)\n",
            "queue size: 428 (148340)\n",
            "queue size: 427 (148332)\n",
            "queue size: 426 (148339)\n",
            "queue size: 425 (148341)\n",
            "queue size: 424 (148338)\n",
            "queue size: 423 (148334)\n",
            "queue size: 422 (148342)\n",
            "queue size: 421 (148328)\n",
            "queue size: 420 (148336)\n",
            "queue size: 419 (148333)\n",
            "queue size: 418 (148347)\n",
            "queue size: 417 (148330)\n",
            "queue size: 416 (148335)\n",
            "queue size: 415 (148346)\n",
            "queue size: 414 (148344)\n",
            "queue size: 413 (148345)\n",
            "queue size: 412 (148329)\n",
            "queue size: 411 (148331)\n",
            "queue size: 410 (148339)\n",
            "queue size: 409 (148347)\n",
            "queue size: 408 (148341)\n",
            "queue size: 407 (148328)\n",
            "queue size: 406 (148343)\n",
            "queue size: 405 (148332)\n",
            "queue size: 404 (148338)\n",
            "queue size: 403 (148337)\n",
            "queue size: 402 (148340)\n",
            "queue size: 401 (148342)\n",
            "queue size: 400 (148336)\n",
            "queue size: 399 (148333)\n",
            "queue size: 398 (148335)\n",
            "queue size: 397 (148331)\n",
            "queue size: 396 (148330)\n",
            "queue size: 395 (148334)\n",
            "queue size: 394 (148329)\n",
            "queue size: 393 (148346)\n",
            "queue size: 392 (148330)\n",
            "queue size: 391 (148347)\n",
            "queue size: 390 (148341)\n",
            "queue size: 389 (148345)\n",
            "queue size: 388 (148338)\n",
            "queue size: 387 (148328)\n",
            "queue size: 386 (148332)\n",
            "queue size: 385 (148337)\n",
            "queue size: 384 (148344)\n",
            "queue size: 383 (148343)\n",
            "queue size: 382 (148342)\n",
            "queue size: 381 (148336)\n",
            "queue size: 380 (148340)\n",
            "queue size: 379 (148346)\n",
            "queue size: 378 (148335)\n",
            "queue size: 377 (148333)\n",
            "queue size: 376 (148339)\n",
            "queue size: 375 (148341)\n",
            "queue size: 374 (148330)\n",
            "queue size: 373 (148338)\n",
            "queue size: 372 (148345)\n",
            "queue size: 371 (148347)\n",
            "queue size: 370 (148331)\n",
            "queue size: 369 (148334)\n",
            "queue size: 368 (148343)\n",
            "queue size: 367 (148329)\n",
            "queue size: 366 (148340)\n",
            "queue size: 365 (148342)\n",
            "queue size: 364 (148332)\n",
            "queue size: 363 (148344)\n",
            "queue size: 362 (148335)\n",
            "queue size: 361 (148333)\n",
            "queue size: 360 (148337)\n",
            "queue size: 359 (148336)\n",
            "queue size: 358 (148328)\n",
            "queue size: 357 (148345)\n",
            "queue size: 356 (148346)\n",
            "queue size: 355 (148330)\n",
            "queue size: 354 (148329)\n",
            "queue size: 353 (148341)\n",
            "queue size: 352 (148339)\n",
            "queue size: 351 (148334)\n",
            "queue size: 350 (148347)\n",
            "queue size: 349 (148338)\n",
            "queue size: 348 (148331)\n",
            "queue size: 347 (148343)\n",
            "queue size: 346 (148333)\n",
            "queue size: 345 (148337)\n",
            "queue size: 344 (148346)\n",
            "queue size: 343 (148332)\n",
            "queue size: 342 (148335)\n",
            "queue size: 341 (148342)\n",
            "queue size: 340 (148328)\n",
            "queue size: 339 (148336)\n",
            "queue size: 338 (148340)\n",
            "queue size: 337 (148344)\n",
            "queue size: 336 (148339)\n",
            "queue size: 335 (148329)\n",
            "queue size: 334 (148341)\n",
            "queue size: 333 (148332)\n",
            "queue size: 332 (148347)\n",
            "queue size: 331 (148335)\n",
            "queue size: 330 (148345)\n",
            "queue size: 329 (148334)\n",
            "queue size: 328 (148331)\n",
            "queue size: 327 (148330)\n",
            "queue size: 326 (148333)\n",
            "queue size: 325 (148337)\n",
            "queue size: 324 (148343)\n",
            "queue size: 323 (148347)\n",
            "queue size: 322 (148338)\n",
            "queue size: 321 (148346)\n",
            "queue size: 320 (148336)\n",
            "queue size: 319 (148328)\n",
            "queue size: 318 (148335)\n",
            "queue size: 317 (148340)\n",
            "queue size: 316 (148329)\n",
            "queue size: 315 (148339)\n",
            "queue size: 314 (148342)\n",
            "queue size: 313 (148332)\n",
            "queue size: 312 (148344)\n",
            "queue size: 311 (148343)\n",
            "queue size: 310 (148341)\n",
            "queue size: 309 (148347)\n",
            "queue size: 308 (148331)\n",
            "queue size: 307 (148334)\n",
            "queue size: 306 (148345)\n",
            "queue size: 305 (148338)\n",
            "queue size: 304 (148330)\n",
            "queue size: 303 (148328)\n",
            "queue size: 302 (148339)\n",
            "queue size: 301 (148337)\n",
            "queue size: 300 (148346)\n",
            "queue size: 299 (148340)\n",
            "queue size: 298 (148332)\n",
            "queue size: 297 (148333)\n",
            "queue size: 296 (148329)\n",
            "queue size: 295 (148342)\n",
            "queue size: 294 (148336)\n",
            "queue size: 293 (148335)\n",
            "queue size: 292 (148344)\n",
            "queue size: 291 (148341)\n",
            "queue size: 290 (148345)\n",
            "queue size: 289 (148330)\n",
            "queue size: 288 (148343)\n",
            "queue size: 287 (148331)\n",
            "queue size: 286 (148334)\n",
            "queue size: 285 (148340)\n",
            "queue size: 284 (148328)\n",
            "queue size: 283 (148338)\n",
            "queue size: 282 (148329)\n",
            "queue size: 281 (148337)\n",
            "queue size: 280 (148332)\n",
            "queue size: 279 (148330)\n",
            "queue size: 278 (148335)\n",
            "queue size: 277 (148347)\n",
            "queue size: 276 (148346)\n",
            "queue size: 275 (148342)\n",
            "queue size: 274 (148343)\n",
            "queue size: 273 (148336)\n",
            "queue size: 272 (148338)\n",
            "queue size: 271 (148347)\n",
            "queue size: 270 (148344)\n",
            "queue size: 269 (148339)\n",
            "queue size: 268 (148334)\n",
            "queue size: 267 (148331)\n",
            "queue size: 266 (148333)\n",
            "queue size: 265 (148345)\n",
            "queue size: 264 (148341)\n",
            "queue size: 263 (148328)\n",
            "queue size: 262 (148340)\n",
            "queue size: 261 (148342)\n",
            "queue size: 260 (148337)\n",
            "queue size: 259 (148329)\n",
            "queue size: 258 (148332)\n",
            "queue size: 257 (148347)\n",
            "queue size: 256 (148346)\n",
            "queue size: 255 (148344)\n",
            "queue size: 254 (148335)\n",
            "queue size: 253 (148330)\n",
            "queue size: 252 (148343)\n",
            "queue size: 251 (148336)\n",
            "queue size: 250 (148338)\n",
            "queue size: 249 (148334)\n",
            "queue size: 248 (148328)\n",
            "queue size: 247 (148333)\n",
            "queue size: 246 (148345)\n",
            "queue size: 245 (148331)\n",
            "queue size: 244 (148342)\n",
            "queue size: 243 (148339)\n",
            "queue size: 242 (148337)\n",
            "queue size: 241 (148340)\n",
            "queue size: 240 (148329)\n",
            "queue size: 239 (148344)\n",
            "queue size: 238 (148341)\n",
            "queue size: 237 (148347)\n",
            "queue size: 236 (148332)\n",
            "queue size: 235 (148334)\n",
            "queue size: 234 (148330)\n",
            "queue size: 233 (148335)\n",
            "queue size: 232 (148336)\n",
            "queue size: 231 (148346)\n",
            "queue size: 230 (148342)\n",
            "queue size: 229 (148328)\n",
            "queue size: 228 (148345)\n",
            "queue size: 227 (148343)\n",
            "queue size: 226 (148338)\n",
            "queue size: 225 (148340)\n",
            "queue size: 224 (148329)\n",
            "queue size: 223 (148333)\n",
            "queue size: 222 (148344)\n",
            "queue size: 221 (148347)\n",
            "queue size: 220 (148331)\n",
            "queue size: 219 (148330)\n",
            "queue size: 218 (148332)\n",
            "queue size: 217 (148334)\n",
            "queue size: 216 (148339)\n",
            "queue size: 215 (148335)\n",
            "queue size: 214 (148336)\n",
            "queue size: 213 (148346)\n",
            "queue size: 212 (148337)\n",
            "queue size: 211 (148341)\n",
            "queue size: 210 (148343)\n",
            "queue size: 209 (148342)\n",
            "queue size: 208 (148328)\n",
            "queue size: 207 (148344)\n",
            "queue size: 206 (148340)\n",
            "queue size: 205 (148329)\n",
            "Deadlock detected. Resetting KV cache and recomputing requests. Consider limiting number of concurrent requests or decreasing max lengths of prompts/generations.\n",
            "queue size: 204 (148345)\n",
            "queue size: 203 (148338)\n",
            "queue size: 202 (148331)\n",
            "queue size: 201 (148333)\n",
            "queue size: 200 (148347)\n",
            "queue size: 199 (148330)\n",
            "queue size: 198 (148340)\n",
            "queue size: 197 (148335)\n",
            "queue size: 196 (148332)\n",
            "queue size: 195 (148339)\n",
            "queue size: 194 (148336)\n",
            "queue size: 193 (148329)\n",
            "queue size: 192 (148346)\n",
            "queue size: 191 (148337)\n",
            "queue size: 190 (148334)\n",
            "queue size: 189 (148341)\n",
            "queue size: 188 (148342)\n",
            "queue size: 187 (148328)\n",
            "queue size: 186 (148338)\n",
            "queue size: 185 (148343)\n",
            "queue size: 184 (148347)\n",
            "queue size: 183 (148344)\n",
            "queue size: 182 (148345)\n",
            "queue size: 181 (148330)\n",
            "queue size: 180 (148346)\n",
            "queue size: 179 (148329)\n",
            "queue size: 178 (148340)\n",
            "queue size: 177 (148337)\n",
            "queue size: 176 (148336)\n",
            "queue size: 175 (148335)\n",
            "queue size: 174 (148331)\n",
            "queue size: 173 (148332)\n",
            "queue size: 172 (148333)\n",
            "queue size: 171 (148342)\n",
            "queue size: 170 (148334)\n",
            "queue size: 169 (148338)\n",
            "queue size: 168 (148344)\n",
            "queue size: 167 (148328)\n",
            "queue size: 166 (148345)\n",
            "queue size: 165 (148339)\n",
            "queue size: 164 (148341)\n",
            "queue size: 163 (148343)\n",
            "queue size: 162 (148337)\n",
            "queue size: 161 (148346)\n",
            "queue size: 160 (148330)\n",
            "queue size: 159 (148340)\n",
            "queue size: 158 (148336)\n",
            "queue size: 157 (148347)\n",
            "queue size: 156 (148332)\n",
            "queue size: 155 (148331)\n",
            "queue size: 154 (148335)\n",
            "queue size: 153 (148329)\n",
            "queue size: 152 (148344)\n",
            "queue size: 151 (148339)\n",
            "queue size: 150 (148333)\n",
            "queue size: 149 (148328)\n",
            "queue size: 148 (148338)\n",
            "queue size: 147 (148342)\n",
            "queue size: 146 (148334)\n",
            "queue size: 145 (148343)\n",
            "queue size: 144 (148345)\n",
            "queue size: 143 (148341)\n",
            "queue size: 142 (148336)\n",
            "queue size: 141 (148337)\n",
            "queue size: 140 (148330)\n",
            "queue size: 139 (148340)\n",
            "queue size: 138 (148346)\n",
            "queue size: 137 (148335)\n",
            "queue size: 136 (148347)\n",
            "queue size: 135 (148332)\n",
            "queue size: 134 (148329)\n",
            "queue size: 133 (148333)\n",
            "queue size: 132 (148344)\n",
            "queue size: 131 (148334)\n",
            "queue size: 130 (148341)\n",
            "queue size: 129 (148328)\n",
            "queue size: 128 (148342)\n",
            "queue size: 127 (148338)\n",
            "queue size: 126 (148340)\n",
            "queue size: 125 (148337)\n",
            "queue size: 124 (148343)\n",
            "queue size: 123 (148331)\n",
            "queue size: 122 (148339)\n",
            "queue size: 121 (148336)\n",
            "queue size: 120 (148334)\n",
            "queue size: 119 (148346)\n",
            "queue size: 118 (148345)\n",
            "queue size: 117 (148344)\n",
            "queue size: 116 (148329)\n",
            "queue size: 115 (148330)\n",
            "queue size: 114 (148332)\n",
            "queue size: 113 (148335)\n",
            "queue size: 112 (148342)\n",
            "queue size: 111 (148328)\n",
            "queue size: 110 (148343)\n",
            "queue size: 109 (148347)\n",
            "queue size: 108 (148337)\n",
            "queue size: 107 (148341)\n",
            "queue size: 106 (148345)\n",
            "queue size: 105 (148340)\n",
            "queue size: 104 (148346)\n",
            "queue size: 103 (148338)\n",
            "queue size: 102 (148333)\n",
            "queue size: 101 (148336)\n",
            "queue size: 100 (148344)\n",
            "queue size: 99 (148331)\n",
            "queue size: 98 (148339)\n",
            "queue size: 97 (148342)\n",
            "queue size: 96 (148329)\n",
            "queue size: 95 (148332)\n",
            "queue size: 94 (148330)\n",
            "queue size: 93 (148342)\n",
            "queue size: 92 (148334)\n",
            "queue size: 91 (148335)\n",
            "queue size: 90 (148343)\n",
            "queue size: 89 (148337)\n",
            "queue size: 88 (148341)\n",
            "queue size: 87 (148328)\n",
            "queue size: 86 (148347)\n",
            "queue size: 85 (148345)\n",
            "queue size: 84 (148332)\n",
            "queue size: 83 (148340)\n",
            "queue size: 82 (148339)\n",
            "queue size: 81 (148333)\n",
            "queue size: 80 (148344)\n",
            "queue size: 79 (148346)\n",
            "queue size: 78 (148336)\n",
            "queue size: 77 (148342)\n",
            "queue size: 76 (148328)\n",
            "queue size: 75 (148338)\n",
            "queue size: 74 (148329)\n",
            "queue size: 73 (148337)\n",
            "queue size: 72 (148335)\n",
            "queue size: 71 (148330)\n",
            "queue size: 70 (148331)\n",
            "queue size: 69 (148347)\n",
            "queue size: 68 (148343)\n",
            "queue size: 67 (148334)\n",
            "queue size: 66 (148341)\n",
            "queue size: 65 (148339)\n",
            "queue size: 64 (148346)\n",
            "queue size: 63 (148337)\n",
            "queue size: 62 (148344)\n",
            "queue size: 61 (148345)\n",
            "queue size: 60 (148340)\n",
            "queue size: 59 (148333)\n",
            "queue size: 58 (148332)\n",
            "queue size: 57 (148328)\n",
            "queue size: 56 (148331)\n",
            "queue size: 55 (148338)\n",
            "queue size: 54 (148330)\n",
            "queue size: 53 (148335)\n",
            "queue size: 52 (148329)\n",
            "queue size: 51 (148342)\n",
            "queue size: 50 (148347)\n",
            "queue size: 49 (148336)\n",
            "queue size: 48 (148341)\n",
            "queue size: 47 (148345)\n",
            "queue size: 46 (148334)\n",
            "queue size: 45 (148339)\n",
            "queue size: 44 (148344)\n",
            "queue size: 43 (148343)\n",
            "queue size: 42 (148337)\n",
            "queue size: 41 (148338)\n",
            "queue size: 40 (148340)\n",
            "queue size: 39 (148333)\n",
            "queue size: 38 (148346)\n",
            "queue size: 37 (148342)\n",
            "queue size: 36 (148328)\n",
            "queue size: 35 (148332)\n",
            "queue size: 34 (148335)\n",
            "queue size: 33 (148331)\n",
            "queue size: 32 (148341)\n",
            "queue size: 31 (148345)\n",
            "queue size: 30 (148336)\n",
            "queue size: 29 (148330)\n",
            "queue size: 28 (148334)\n",
            "queue size: 27 (148343)\n",
            "queue size: 26 (148347)\n",
            "queue size: 25 (148339)\n",
            "queue size: 24 (148329)\n",
            "queue size: 23 (148337)\n",
            "queue size: 22 (148333)\n",
            "queue size: 21 (148331)\n",
            "queue size: 20 (148344)\n",
            "queue size: 19 (148332)\n",
            "queue size: 18 (148346)\n",
            "queue size: 17 (148342)\n",
            "queue size: 16 (148335)\n",
            "queue size: 15 (148343)\n",
            "queue size: 14 (148334)\n",
            "queue size: 13 (148328)\n",
            "queue size: 12 (148336)\n",
            "queue size: 11 (148341)\n",
            "queue size: 10 (148338)\n",
            "queue size: 9 (148340)\n",
            "queue size: 8 (148345)\n",
            "queue size: 7 (148337)\n",
            "queue size: 6 (148347)\n",
            "queue size: 5 (148342)\n",
            "queue size: 4 (148331)\n",
            "queue size: 3 (148344)\n",
            "queue size: 2 (148330)\n",
            "queue size: 1 (148339)\n",
            "Worker (148344) finished. session_id: test_session_p148344_t132593624576640\n",
            "Worker (148334) finished. session_id: test_session_p148334_t132593624576640\n",
            "Worker (148333) finished. session_id: test_session_p148333_t132593624576640\n",
            "Worker (148329) finished. session_id: test_session_p148329_t132593624576640\n",
            "Worker (148346) finished. session_id: test_session_p148346_t132593624576640\n",
            "Worker (148332) finished. session_id: test_session_p148332_t132593624576640\n",
            "Worker (148338) finished. session_id: test_session_p148338_t132593624576640\n",
            "Worker (148340) finished. session_id: test_session_p148340_t132593624576640\n",
            "Worker (148336) finished. session_id: test_session_p148336_t132593624576640\n",
            "Worker (148339) finished. session_id: test_session_p148339_t132593624576640\n",
            "Worker (148328) finished. session_id: test_session_p148328_t132593624576640\n",
            "Worker (148341) finished. session_id: test_session_p148341_t132593624576640\n",
            "Worker (148335) finished. session_id: test_session_p148335_t132593624576640\n",
            "Worker (148343) finished. session_id: test_session_p148343_t132593624576640\n",
            "Worker (148345) finished. session_id: test_session_p148345_t132593624576640\n",
            "Worker (148342) finished. session_id: test_session_p148342_t132593624576640\n",
            "Worker (148347) finished. session_id: test_session_p148347_t132593624576640\n",
            "Worker (148337) finished. session_id: test_session_p148337_t132593624576640\n",
            "Worker (148331) finished. session_id: test_session_p148331_t132593624576640\n",
            "Worker (148330) finished. session_id: test_session_p148330_t132593624576640\n",
            "Deployment: llama2-7b-tp1-b768 Clients: 20, Prompt (mean): 2600 tokens, Generation (mean): 60 tokens, Query throughput: 3.114 queries/s, Token throughput (total): 451.091 tokens/s, Query latency: 6.422 s, Token generation latency: 0.084 s/token, First token received: 1.464 s\n",
            "Namespace(max_new_tokens=60, deployment_name='llama2-7b-tp1-b768', num_queries=512, warmup=1, client_num=24, prompt_length=2600, use_thread=False, stream=True, vllm=False, out_json_path=PosixPath('logs.llama2-7b-tp1-b768/llama2-7b-tp1-b768_c24_p2600_g60.json'))\n",
            "[2023-12-16 13:23:30,605] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:23:30,823] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:23:31,023] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:23:31,149] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:23:31,191] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:23:31,255] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:23:31,435] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:23:31,456] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:23:31,468] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:23:31,475] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:23:31,549] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:23:31,657] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:23:31,752] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:23:31,902] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:23:31,908] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:23:31,910] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:23:32,148] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:23:32,149] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:23:32,219] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:23:32,234] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:23:32,253] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:23:32,263] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:23:32,280] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:23:32,322] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "2023-12-16 13:23:34.953206: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:23:34.953323: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:23:34.955664: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:23:35.500972: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:23:35.501078: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:23:35.502854: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:23:36.073671: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:23:36.073727: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:23:36.075461: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:23:36.080211: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:23:36.080300: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:23:36.081885: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:23:36.537680: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:23:36.537796: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:23:36.539425: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:23:36.869146: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:23:36.879988: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:23:36.881984: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:23:37.154624: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:23:37.154730: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:23:37.156400: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:23:37.301859: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:23:37.303988: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:23:37.305685: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:23:37.595596: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:23:37.595722: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:23:37.597504: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:23:37.940818: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:23:37.940934: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:23:37.942683: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:23:37.993797: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:23:38.010985: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:23:38.012783: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:23:38.053665: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:23:38.053717: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:23:38.055416: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:23:38.155214: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:23:38.168996: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:23:38.170826: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:23:38.344429: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:23:38.344480: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:23:38.346157: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:23:38.385916: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:23:38.386044: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:23:38.387805: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:23:38.390281: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:23:38.398980: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:23:38.400762: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:23:38.500263: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:23:38.500372: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:23:38.502124: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:23:38.586331: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:23:38.586437: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:23:38.588166: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:23:38.622287: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:23:38.622400: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:23:38.624172: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:23:38.975809: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:23:38.988776: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:23:38.992987: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:23:38.994796: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:23:39.002987: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:23:39.004795: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:23:39.119960: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:23:39.128989: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:23:39.130731: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:23:39.227827: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:23:39.227938: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:23:39.229683: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:23:39.384810: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:23:39.384926: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:23:39.386734: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:23:39.572360: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:23:40.132390: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:23:40.180479: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:23:40.398321: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:23:40.743970: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:23:40.836214: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:23:40.924134: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:23:40.959505: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:23:41.039469: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:23:41.378767: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:23:42.023824: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:23:42.149116: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:23:42.500696: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:23:42.837582: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:23:42.892787: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:23:42.914254: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:23:43.005569: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:23:43.178296: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:23:43.332295: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:23:43.533449: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:23:43.550480: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:23:43.587757: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:23:43.676039: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:23:43.989710: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "warmup queue size: 536 (150683)\n",
            "warmup queue size: 536 (150680)\n",
            "warmup queue size: 536 (150670)\n",
            "warmup queue size: 535 (150676)\n",
            "warmup queue size: 535 (150669)\n",
            "warmup queue size: 535 (150685)\n",
            "warmup queue size: 534 (150677)\n",
            "warmup queue size: 534 (150674)\n",
            "warmup queue size: 534 (150678)\n",
            "warmup queue size: 533 (150679)\n",
            "warmup queue size: 533 (150691)\n",
            "warmup queue size: 533 (150686)\n",
            "warmup queue size: 533 (150689)\n",
            "warmup queue size: 532 (150687)\n",
            "warmup queue size: 532 (150684)\n",
            "warmup queue size: 532 (150690)\n",
            "warmup queue size: 531 (150688)\n",
            "warmup queue size: 531 (150675)\n",
            "warmup queue size: 531 (150672)\n",
            "warmup queue size: 530 (150681)\n",
            "warmup queue size: 530 (150671)\n",
            "warmup queue size: 530 (150673)\n",
            "warmup queue size: 530 (150692)\n",
            "warmup queue size: 528 (150682)\n",
            "queue size: 512 (150669)\n",
            "queue size: 511 (150670)\n",
            "queue size: 510 (150676)\n",
            "queue size: 509 (150692)\n",
            "queue size: 508 (150690)\n",
            "queue size: 507 (150678)\n",
            "queue size: 506 (150686)\n",
            "queue size: 505 (150685)\n",
            "queue size: 504 (150679)\n",
            "queue size: 503 (150675)\n",
            "queue size: 502 (150683)\n",
            "queue size: 501 (150688)\n",
            "queue size: 500 (150689)\n",
            "queue size: 499 (150671)\n",
            "queue size: 498 (150691)\n",
            "queue size: 497 (150673)\n",
            "queue size: 496 (150681)\n",
            "queue size: 495 (150674)\n",
            "queue size: 494 (150682)\n",
            "queue size: 493 (150672)\n",
            "queue size: 492 (150680)\n",
            "queue size: 491 (150677)\n",
            "queue size: 490 (150687)\n",
            "queue size: 489 (150684)\n",
            "queue size: 488 (150679)\n",
            "queue size: 487 (150686)\n",
            "queue size: 486 (150669)\n",
            "queue size: 485 (150692)\n",
            "queue size: 484 (150673)\n",
            "queue size: 483 (150685)\n",
            "queue size: 482 (150675)\n",
            "queue size: 481 (150678)\n",
            "queue size: 480 (150676)\n",
            "queue size: 479 (150690)\n",
            "queue size: 478 (150682)\n",
            "queue size: 477 (150683)\n",
            "queue size: 476 (150671)\n",
            "queue size: 475 (150670)\n",
            "queue size: 474 (150689)\n",
            "queue size: 473 (150681)\n",
            "queue size: 472 (150691)\n",
            "queue size: 471 (150677)\n",
            "queue size: 470 (150688)\n",
            "queue size: 469 (150674)\n",
            "queue size: 468 (150680)\n",
            "queue size: 467 (150692)\n",
            "queue size: 466 (150669)\n",
            "queue size: 465 (150685)\n",
            "queue size: 464 (150686)\n",
            "queue size: 463 (150687)\n",
            "queue size: 462 (150672)\n",
            "queue size: 461 (150679)\n",
            "queue size: 460 (150678)\n",
            "queue size: 459 (150675)\n",
            "queue size: 458 (150673)\n",
            "queue size: 457 (150670)\n",
            "queue size: 456 (150683)\n",
            "queue size: 455 (150676)\n",
            "queue size: 454 (150684)\n",
            "queue size: 453 (150690)\n",
            "queue size: 452 (150671)\n",
            "queue size: 451 (150689)\n",
            "queue size: 450 (150677)\n",
            "queue size: 449 (150682)\n",
            "queue size: 448 (150686)\n",
            "queue size: 447 (150681)\n",
            "queue size: 446 (150685)\n",
            "queue size: 445 (150669)\n",
            "queue size: 444 (150691)\n",
            "queue size: 443 (150688)\n",
            "queue size: 442 (150680)\n",
            "queue size: 441 (150675)\n",
            "queue size: 440 (150674)\n",
            "queue size: 439 (150679)\n",
            "queue size: 438 (150672)\n",
            "queue size: 437 (150678)\n",
            "queue size: 436 (150692)\n",
            "queue size: 435 (150670)\n",
            "queue size: 434 (150671)\n",
            "queue size: 433 (150683)\n",
            "queue size: 432 (150681)\n",
            "queue size: 431 (150687)\n",
            "queue size: 430 (150690)\n",
            "queue size: 429 (150676)\n",
            "queue size: 428 (150685)\n",
            "queue size: 427 (150684)\n",
            "queue size: 426 (150689)\n",
            "queue size: 425 (150680)\n",
            "queue size: 424 (150673)\n",
            "queue size: 423 (150669)\n",
            "queue size: 422 (150678)\n",
            "queue size: 421 (150691)\n",
            "queue size: 420 (150682)\n",
            "queue size: 419 (150672)\n",
            "queue size: 418 (150677)\n",
            "queue size: 417 (150686)\n",
            "queue size: 416 (150671)\n",
            "queue size: 415 (150679)\n",
            "queue size: 414 (150674)\n",
            "queue size: 413 (150683)\n",
            "queue size: 412 (150689)\n",
            "queue size: 411 (150688)\n",
            "queue size: 410 (150676)\n",
            "queue size: 409 (150670)\n",
            "queue size: 408 (150681)\n",
            "queue size: 407 (150675)\n",
            "queue size: 406 (150692)\n",
            "queue size: 405 (150690)\n",
            "queue size: 404 (150685)\n",
            "queue size: 403 (150684)\n",
            "queue size: 402 (150680)\n",
            "queue size: 401 (150673)\n",
            "queue size: 400 (150672)\n",
            "queue size: 399 (150687)\n",
            "queue size: 398 (150682)\n",
            "queue size: 397 (150683)\n",
            "queue size: 396 (150669)\n",
            "queue size: 395 (150685)\n",
            "queue size: 394 (150686)\n",
            "queue size: 393 (150671)\n",
            "queue size: 392 (150691)\n",
            "queue size: 391 (150679)\n",
            "queue size: 390 (150689)\n",
            "queue size: 389 (150688)\n",
            "queue size: 388 (150678)\n",
            "queue size: 387 (150674)\n",
            "queue size: 386 (150670)\n",
            "queue size: 385 (150681)\n",
            "queue size: 384 (150673)\n",
            "queue size: 383 (150676)\n",
            "queue size: 382 (150692)\n",
            "queue size: 381 (150675)\n",
            "queue size: 380 (150677)\n",
            "queue size: 379 (150682)\n",
            "queue size: 378 (150672)\n",
            "queue size: 377 (150669)\n",
            "queue size: 376 (150683)\n",
            "queue size: 375 (150687)\n",
            "queue size: 374 (150684)\n",
            "queue size: 373 (150690)\n",
            "queue size: 372 (150679)\n",
            "queue size: 371 (150680)\n",
            "queue size: 370 (150678)\n",
            "queue size: 369 (150685)\n",
            "queue size: 368 (150689)\n",
            "queue size: 367 (150686)\n",
            "queue size: 366 (150691)\n",
            "queue size: 365 (150670)\n",
            "queue size: 364 (150688)\n",
            "queue size: 363 (150681)\n",
            "queue size: 362 (150671)\n",
            "queue size: 361 (150677)\n",
            "queue size: 360 (150692)\n",
            "queue size: 359 (150674)\n",
            "queue size: 358 (150687)\n",
            "queue size: 357 (150676)\n",
            "queue size: 356 (150673)\n",
            "queue size: 355 (150669)\n",
            "queue size: 354 (150675)\n",
            "queue size: 353 (150682)\n",
            "queue size: 352 (150690)\n",
            "queue size: 351 (150672)\n",
            "queue size: 350 (150683)\n",
            "queue size: 349 (150685)\n",
            "queue size: 348 (150689)\n",
            "queue size: 347 (150679)\n",
            "queue size: 346 (150688)\n",
            "queue size: 345 (150678)\n",
            "queue size: 344 (150691)\n",
            "queue size: 343 (150684)\n",
            "queue size: 342 (150680)\n",
            "queue size: 341 (150686)\n",
            "queue size: 340 (150692)\n",
            "queue size: 339 (150688)\n",
            "queue size: 338 (150671)\n",
            "queue size: 338 (150677)\n",
            "queue size: 336 (150674)\n",
            "queue size: 335 (150672)\n",
            "queue size: 334 (150687)\n",
            "queue size: 333 (150670)\n",
            "queue size: 332 (150683)\n",
            "queue size: 331 (150675)\n",
            "queue size: 330 (150681)\n",
            "queue size: 329 (150673)\n",
            "queue size: 328 (150669)\n",
            "queue size: 327 (150682)\n",
            "queue size: 326 (150676)\n",
            "queue size: 325 (150690)\n",
            "queue size: 324 (150679)\n",
            "queue size: 323 (150688)\n",
            "queue size: 322 (150684)\n",
            "queue size: 321 (150689)\n",
            "queue size: 320 (150691)\n",
            "queue size: 319 (150686)\n",
            "queue size: 318 (150685)\n",
            "queue size: 317 (150678)\n",
            "queue size: 316 (150683)\n",
            "queue size: 315 (150680)\n",
            "queue size: 314 (150692)\n",
            "queue size: 313 (150675)\n",
            "queue size: 312 (150677)\n",
            "queue size: 311 (150674)\n",
            "queue size: 310 (150681)\n",
            "queue size: 309 (150671)\n",
            "queue size: 308 (150672)\n",
            "queue size: 307 (150682)\n",
            "queue size: 306 (150673)\n",
            "queue size: 305 (150688)\n",
            "queue size: 304 (150690)\n",
            "queue size: 303 (150670)\n",
            "queue size: 302 (150689)\n",
            "queue size: 301 (150679)\n",
            "queue size: 300 (150687)\n",
            "queue size: 299 (150669)\n",
            "queue size: 298 (150684)\n",
            "queue size: 297 (150676)\n",
            "queue size: 296 (150691)\n",
            "queue size: 295 (150685)\n",
            "queue size: 294 (150692)\n",
            "queue size: 293 (150686)\n",
            "queue size: 292 (150677)\n",
            "queue size: 291 (150680)\n",
            "queue size: 290 (150683)\n",
            "queue size: 289 (150682)\n",
            "queue size: 288 (150675)\n",
            "queue size: 287 (150674)\n",
            "queue size: 286 (150671)\n",
            "queue size: 285 (150690)\n",
            "queue size: 284 (150673)\n",
            "queue size: 283 (150678)\n",
            "queue size: 282 (150676)\n",
            "queue size: 281 (150679)\n",
            "queue size: 280 (150672)\n",
            "queue size: 279 (150691)\n",
            "queue size: 278 (150689)\n",
            "queue size: 277 (150680)\n",
            "queue size: 276 (150687)\n",
            "queue size: 275 (150681)\n",
            "queue size: 274 (150688)\n",
            "queue size: 273 (150684)\n",
            "queue size: 272 (150685)\n",
            "queue size: 271 (150670)\n",
            "queue size: 270 (150692)\n",
            "queue size: 269 (150669)\n",
            "queue size: 268 (150677)\n",
            "queue size: 267 (150678)\n",
            "queue size: 266 (150686)\n",
            "queue size: 265 (150683)\n",
            "queue size: 264 (150682)\n",
            "queue size: 263 (150675)\n",
            "queue size: 262 (150691)\n",
            "queue size: 261 (150673)\n",
            "queue size: 260 (150690)\n",
            "queue size: 259 (150689)\n",
            "queue size: 258 (150671)\n",
            "queue size: 257 (150674)\n",
            "queue size: 256 (150679)\n",
            "queue size: 255 (150676)\n",
            "queue size: 254 (150672)\n",
            "queue size: 253 (150687)\n",
            "queue size: 252 (150670)\n",
            "queue size: 251 (150688)\n",
            "queue size: 250 (150684)\n",
            "queue size: 249 (150669)\n",
            "queue size: 248 (150677)\n",
            "queue size: 247 (150680)\n",
            "queue size: 246 (150681)\n",
            "queue size: 245 (150692)\n",
            "queue size: 244 (150678)\n",
            "queue size: 243 (150685)\n",
            "queue size: 242 (150683)\n",
            "queue size: 241 (150675)\n",
            "queue size: 240 (150686)\n",
            "queue size: 239 (150674)\n",
            "queue size: 238 (150691)\n",
            "queue size: 237 (150673)\n",
            "queue size: 236 (150689)\n",
            "queue size: 235 (150682)\n",
            "queue size: 234 (150679)\n",
            "Deadlock detected. Resetting KV cache and recomputing requests. Consider limiting number of concurrent requests or decreasing max lengths of prompts/generations.\n",
            "queue size: 233 (150690)\n",
            "queue size: 232 (150671)\n",
            "queue size: 231 (150676)\n",
            "queue size: 230 (150672)\n",
            "queue size: 229 (150670)\n",
            "queue size: 228 (150682)\n",
            "queue size: 227 (150687)\n",
            "queue size: 226 (150691)\n",
            "queue size: 225 (150669)\n",
            "queue size: 224 (150677)\n",
            "queue size: 223 (150673)\n",
            "queue size: 222 (150688)\n",
            "queue size: 221 (150692)\n",
            "queue size: 220 (150675)\n",
            "queue size: 219 (150683)\n",
            "queue size: 218 (150678)\n",
            "queue size: 217 (150679)\n",
            "queue size: 216 (150689)\n",
            "queue size: 215 (150684)\n",
            "queue size: 214 (150680)\n",
            "queue size: 213 (150686)\n",
            "queue size: 212 (150681)\n",
            "queue size: 211 (150685)\n",
            "queue size: 210 (150674)\n",
            "queue size: 209 (150672)\n",
            "queue size: 208 (150690)\n",
            "queue size: 207 (150671)\n",
            "queue size: 206 (150676)\n",
            "queue size: 205 (150670)\n",
            "queue size: 204 (150682)\n",
            "queue size: 203 (150677)\n",
            "queue size: 202 (150673)\n",
            "queue size: 201 (150691)\n",
            "queue size: 200 (150687)\n",
            "queue size: 199 (150688)\n",
            "queue size: 198 (150692)\n",
            "queue size: 197 (150675)\n",
            "queue size: 196 (150689)\n",
            "queue size: 195 (150679)\n",
            "queue size: 194 (150680)\n",
            "queue size: 193 (150685)\n",
            "queue size: 192 (150683)\n",
            "queue size: 191 (150669)\n",
            "queue size: 190 (150684)\n",
            "queue size: 189 (150678)\n",
            "queue size: 188 (150681)\n",
            "queue size: 187 (150690)\n",
            "queue size: 186 (150686)\n",
            "queue size: 185 (150671)\n",
            "queue size: 184 (150687)\n",
            "queue size: 183 (150691)\n",
            "queue size: 182 (150676)\n",
            "queue size: 181 (150670)\n",
            "queue size: 180 (150688)\n",
            "queue size: 179 (150673)\n",
            "queue size: 178 (150674)\n",
            "queue size: 177 (150682)\n",
            "queue size: 176 (150672)\n",
            "queue size: 175 (150689)\n",
            "queue size: 174 (150692)\n",
            "queue size: 173 (150680)\n",
            "queue size: 172 (150679)\n",
            "queue size: 171 (150669)\n",
            "queue size: 170 (150684)\n",
            "queue size: 169 (150677)\n",
            "queue size: 168 (150675)\n",
            "queue size: 167 (150685)\n",
            "queue size: 166 (150681)\n",
            "queue size: 165 (150671)\n",
            "queue size: 164 (150678)\n",
            "queue size: 163 (150686)\n",
            "queue size: 162 (150683)\n",
            "queue size: 161 (150687)\n",
            "queue size: 160 (150670)\n",
            "queue size: 159 (150690)\n",
            "queue size: 158 (150676)\n",
            "queue size: 157 (150691)\n",
            "queue size: 156 (150672)\n",
            "queue size: 155 (150680)\n",
            "queue size: 154 (150688)\n",
            "queue size: 153 (150682)\n",
            "queue size: 152 (150689)\n",
            "queue size: 151 (150673)\n",
            "queue size: 150 (150674)\n",
            "queue size: 149 (150669)\n",
            "queue size: 148 (150681)\n",
            "queue size: 147 (150679)\n",
            "queue size: 147 (150692)\n",
            "queue size: 145 (150684)\n",
            "queue size: 144 (150675)\n",
            "queue size: 143 (150685)\n",
            "queue size: 142 (150677)\n",
            "queue size: 141 (150683)\n",
            "queue size: 140 (150671)\n",
            "queue size: 139 (150678)\n",
            "queue size: 138 (150687)\n",
            "queue size: 137 (150670)\n",
            "queue size: 136 (150676)\n",
            "queue size: 135 (150688)\n",
            "queue size: 134 (150673)\n",
            "queue size: 133 (150691)\n",
            "queue size: 132 (150680)\n",
            "queue size: 131 (150682)\n",
            "queue size: 130 (150672)\n",
            "queue size: 129 (150669)\n",
            "queue size: 128 (150679)\n",
            "queue size: 127 (150686)\n",
            "queue size: 126 (150690)\n",
            "queue size: 125 (150674)\n",
            "queue size: 124 (150689)\n",
            "queue size: 123 (150692)\n",
            "queue size: 122 (150678)\n",
            "queue size: 121 (150671)\n",
            "queue size: 120 (150681)\n",
            "queue size: 119 (150677)\n",
            "queue size: 118 (150685)\n",
            "queue size: 117 (150684)\n",
            "queue size: 116 (150676)\n",
            "queue size: 115 (150670)\n",
            "queue size: 114 (150680)\n",
            "queue size: 113 (150687)\n",
            "queue size: 112 (150675)\n",
            "queue size: 111 (150691)\n",
            "queue size: 110 (150690)\n",
            "queue size: 109 (150686)\n",
            "queue size: 108 (150673)\n",
            "queue size: 107 (150688)\n",
            "queue size: 106 (150683)\n",
            "queue size: 105 (150669)\n",
            "queue size: 104 (150684)\n",
            "queue size: 103 (150674)\n",
            "queue size: 102 (150672)\n",
            "queue size: 101 (150681)\n",
            "queue size: 100 (150682)\n",
            "queue size: 99 (150689)\n",
            "queue size: 98 (150671)\n",
            "queue size: 97 (150678)\n",
            "queue size: 96 (150692)\n",
            "queue size: 95 (150679)\n",
            "queue size: 94 (150685)\n",
            "queue size: 93 (150677)\n",
            "queue size: 92 (150676)\n",
            "queue size: 91 (150680)\n",
            "queue size: 90 (150670)\n",
            "queue size: 89 (150674)\n",
            "queue size: 88 (150687)\n",
            "queue size: 87 (150683)\n",
            "queue size: 86 (150690)\n",
            "queue size: 85 (150675)\n",
            "queue size: 84 (150688)\n",
            "queue size: 83 (150673)\n",
            "queue size: 82 (150686)\n",
            "queue size: 81 (150684)\n",
            "queue size: 80 (150681)\n",
            "queue size: 79 (150679)\n",
            "queue size: 78 (150678)\n",
            "queue size: 77 (150691)\n",
            "queue size: 76 (150672)\n",
            "queue size: 75 (150685)\n",
            "queue size: 74 (150689)\n",
            "queue size: 73 (150671)\n",
            "queue size: 72 (150669)\n",
            "queue size: 71 (150692)\n",
            "queue size: 70 (150670)\n",
            "queue size: 69 (150682)\n",
            "queue size: 68 (150683)\n",
            "queue size: 67 (150684)\n",
            "queue size: 66 (150685)\n",
            "queue size: 65 (150674)\n",
            "queue size: 64 (150676)\n",
            "queue size: 63 (150680)\n",
            "queue size: 62 (150687)\n",
            "queue size: 61 (150677)\n",
            "queue size: 60 (150688)\n",
            "queue size: 59 (150678)\n",
            "queue size: 58 (150679)\n",
            "queue size: 57 (150673)\n",
            "queue size: 56 (150681)\n",
            "queue size: 55 (150686)\n",
            "queue size: 54 (150675)\n",
            "queue size: 53 (150691)\n",
            "queue size: 52 (150690)\n",
            "queue size: 51 (150689)\n",
            "queue size: 50 (150682)\n",
            "queue size: 49 (150671)\n",
            "queue size: 48 (150670)\n",
            "queue size: 47 (150672)\n",
            "queue size: 46 (150680)\n",
            "queue size: 45 (150692)\n",
            "queue size: 44 (150684)\n",
            "queue size: 43 (150669)\n",
            "queue size: 42 (150683)\n",
            "queue size: 41 (150678)\n",
            "queue size: 40 (150674)\n",
            "queue size: 39 (150685)\n",
            "queue size: 38 (150677)\n",
            "queue size: 37 (150676)\n",
            "queue size: 36 (150681)\n",
            "queue size: 35 (150687)\n",
            "queue size: 34 (150673)\n",
            "queue size: 33 (150686)\n",
            "queue size: 32 (150675)\n",
            "queue size: 31 (150689)\n",
            "queue size: 30 (150688)\n",
            "queue size: 29 (150691)\n",
            "queue size: 28 (150679)\n",
            "queue size: 27 (150682)\n",
            "queue size: 26 (150690)\n",
            "queue size: 25 (150678)\n",
            "queue size: 24 (150669)\n",
            "queue size: 23 (150680)\n",
            "queue size: 22 (150672)\n",
            "queue size: 22 (150692)\n",
            "queue size: 20 (150683)\n",
            "queue size: 19 (150681)\n",
            "queue size: 18 (150687)\n",
            "queue size: 17 (150684)\n",
            "queue size: 16 (150677)\n",
            "queue size: 15 (150682)\n",
            "queue size: 14 (150670)\n",
            "queue size: 13 (150671)\n",
            "queue size: 12 (150674)\n",
            "queue size: 11 (150685)\n",
            "queue size: 10 (150678)\n",
            "queue size: 9 (150689)\n",
            "queue size: 8 (150673)\n",
            "queue size: 7 (150676)\n",
            "queue size: 6 (150691)\n",
            "queue size: 5 (150679)\n",
            "queue size: 4 (150685)\n",
            "queue size: 3 (150686)\n",
            "queue size: 2 (150672)\n",
            "queue size: 1 (150688)\n",
            "Worker (150690) finished. session_id: test_session_p150690_t140038569493120\n",
            "Worker (150675) finished. session_id: test_session_p150675_t140038569493120\n",
            "Worker (150687) finished. session_id: test_session_p150687_t140038569493120\n",
            "Worker (150684) finished. session_id: test_session_p150684_t140038569493120\n",
            "Worker (150689) finished. session_id: test_session_p150689_t140038569493120\n",
            "Worker (150692) finished. session_id: test_session_p150692_t140038569493120\n",
            "Worker (150681) finished. session_id: test_session_p150681_t140038569493120\n",
            "Worker (150677) finished. session_id: test_session_p150677_t140038569493120\n",
            "Worker (150683) finished. session_id: test_session_p150683_t140038569493120\n",
            "Worker (150669) finished. session_id: test_session_p150669_t140038569493120\n",
            "Worker (150680) finished. session_id: test_session_p150680_t140038569493120\n",
            "Worker (150671) finished. session_id: test_session_p150671_t140038569493120\n",
            "Worker (150676) finished. session_id: test_session_p150676_t140038569493120\n",
            "Worker (150691) finished. session_id: test_session_p150691_t140038569493120\n",
            "Worker (150670) finished. session_id: test_session_p150670_t140038569493120\n",
            "Worker (150673) finished. session_id: test_session_p150673_t140038569493120\n",
            "Worker (150682) finished. session_id: test_session_p150682_t140038569493120\n",
            "Worker (150674) finished. session_id: test_session_p150674_t140038569493120\n",
            "Worker (150685) finished. session_id: test_session_p150685_t140038569493120\n",
            "Worker (150678) finished. session_id: test_session_p150678_t140038569493120\n",
            "Worker (150672) finished. session_id: test_session_p150672_t140038569493120\n",
            "Worker (150686) finished. session_id: test_session_p150686_t140038569493120\n",
            "Worker (150679) finished. session_id: test_session_p150679_t140038569493120\n",
            "Worker (150688) finished. session_id: test_session_p150688_t140038569493120\n",
            "Deployment: llama2-7b-tp1-b768 Clients: 24, Prompt (mean): 2600 tokens, Generation (mean): 60 tokens, Query throughput: 3.205 queries/s, Token throughput (total): 373.146 tokens/s, Query latency: 7.489 s, Token generation latency: 0.083 s/token, First token received: 2.601 s\n",
            "Namespace(max_new_tokens=60, deployment_name='llama2-7b-tp1-b768', num_queries=512, warmup=1, client_num=28, prompt_length=2600, use_thread=False, stream=True, vllm=False, out_json_path=PosixPath('logs.llama2-7b-tp1-b768/llama2-7b-tp1-b768_c28_p2600_g60.json'))\n",
            "[2023-12-16 13:26:48,220] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:26:48,310] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:26:48,577] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:26:48,748] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:26:48,797] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:26:48,839] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:26:48,843] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:26:48,860] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:26:48,879] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:26:48,927] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:26:48,928] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:26:49,009] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:26:49,059] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:26:49,100] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:26:49,181] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:26:49,253] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:26:49,315] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:26:49,322] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:26:49,329] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:26:49,382] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:26:49,417] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:26:49,427] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:26:49,546] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:26:49,556] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:26:49,715] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:26:49,823] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:26:49,868] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:26:49,910] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "2023-12-16 13:26:54.528137: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:26:54.528241: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:26:54.530636: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:26:54.658896: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:26:54.659025: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:26:54.660726: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:26:54.765310: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:26:54.777989: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:26:54.779877: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:26:54.817711: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:26:54.817763: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:26:54.819411: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:26:54.975837: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:26:54.975959: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:26:54.977713: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:26:55.166210: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:26:55.166341: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:26:55.168000: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:26:55.404334: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:26:55.404446: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:26:55.417554: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:26:55.417660: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:26:55.421739: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:26:55.422210: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:26:55.530329: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:26:55.538986: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:26:55.540830: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:26:55.642133: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:26:55.654800: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:26:55.656654: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:26:55.894777: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:26:55.898102: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:26:55.899927: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:26:56.019408: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:26:56.027992: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:26:56.029807: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:26:56.360139: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:26:56.360252: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:26:56.361891: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:26:56.393015: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:26:56.393123: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:26:56.394836: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:26:56.427186: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:26:56.427293: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:26:56.429034: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:26:56.480023: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:26:56.480075: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:26:56.481795: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:26:56.639867: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:26:56.642981: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:26:56.644758: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:26:56.668900: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:26:56.681993: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:26:56.683874: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:26:56.728117: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:26:56.737907: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:26:56.738039: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:26:56.739800: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:26:56.747380: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:26:56.761852: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:26:56.764985: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:26:56.765218: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:26:56.766887: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:26:56.766955: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:26:56.790019: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:26:56.791873: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:26:57.080749: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:26:57.080860: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:26:57.082577: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:26:57.135704: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:26:57.135822: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:26:57.139626: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:26:57.140361: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:26:57.151987: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:26:57.153786: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:26:57.464305: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:26:57.464423: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:26:57.466175: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:26:57.469138: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:26:57.469225: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:26:57.470973: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:26:57.497046: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:26:57.497094: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:26:57.498792: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:26:59.053364: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:26:59.315819: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:26:59.380846: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:26:59.716757: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:26:59.835365: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:26:59.889535: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:26:59.923640: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:27:00.253359: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:27:00.754301: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:27:00.811453: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:27:00.880274: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:27:00.930819: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:27:00.991638: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:27:01.012477: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:27:01.178561: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:27:01.208098: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:27:01.354808: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:27:01.359961: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:27:01.499228: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:27:01.580183: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:27:01.768929: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:27:01.862233: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:27:01.906910: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:27:01.964926: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:27:02.189473: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:27:02.342761: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:27:02.430794: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:27:02.776987: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "warmup queue size: 540 (153224)\n",
            "warmup queue size: 540 (153209)\n",
            "warmup queue size: 539 (153230)\n",
            "warmup queue size: 539 (153233)\n",
            "warmup queue size: 539 (153205)\n",
            "warmup queue size: 538 (153208)\n",
            "warmup queue size: 538 (153210)\n",
            "warmup queue size: 538 (153202)\n",
            "warmup queue size: 538 (153206)\n",
            "warmup queue size: 537 (153222)\n",
            "warmup queue size: 537 (153204)\n",
            "warmup queue size: 537 (153219)\n",
            "warmup queue size: 537 (153216)\n",
            "warmup queue size: 536 (153218)\n",
            "warmup queue size: 536 (153232)\n",
            "warmup queue size: 536 (153217)\n",
            "warmup queue size: 535 (153215)\n",
            "warmup queue size: 535 (153213)\n",
            "warmup queue size: 535 (153211)\n",
            "warmup queue size: 535 (153220)\n",
            "warmup queue size: 534 (153214)\n",
            "warmup queue size: 534 (153212)\n",
            "warmup queue size: 534 (153226)\n",
            "warmup queue size: 533 (153225)\n",
            "warmup queue size: 533 (153221)\n",
            "warmup queue size: 533 (153203)\n",
            "warmup queue size: 533 (153207)\n",
            "warmup queue size: 532 (153223)\n",
            "queue size: 512 (153223)\n",
            "queue size: 511 (153207)\n",
            "queue size: 510 (153217)\n",
            "queue size: 509 (153225)\n",
            "queue size: 508 (153204)\n",
            "queue size: 507 (153224)\n",
            "queue size: 506 (153216)\n",
            "queue size: 505 (153208)\n",
            "queue size: 504 (153209)\n",
            "queue size: 503 (153215)\n",
            "queue size: 502 (153202)\n",
            "queue size: 501 (153233)\n",
            "queue size: 500 (153210)\n",
            "queue size: 499 (153213)\n",
            "queue size: 498 (153214)\n",
            "queue size: 497 (153212)\n",
            "queue size: 496 (153211)\n",
            "queue size: 495 (153232)\n",
            "queue size: 494 (153222)\n",
            "queue size: 493 (153205)\n",
            "queue size: 492 (153203)\n",
            "queue size: 491 (153230)\n",
            "queue size: 490 (153218)\n",
            "queue size: 489 (153206)\n",
            "queue size: 488 (153220)\n",
            "queue size: 487 (153221)\n",
            "queue size: 487 (153226)\n",
            "queue size: 485 (153219)\n",
            "queue size: 484 (153223)\n",
            "queue size: 483 (153208)\n",
            "queue size: 482 (153207)\n",
            "queue size: 481 (153202)\n",
            "queue size: 480 (153217)\n",
            "queue size: 479 (153224)\n",
            "queue size: 478 (153204)\n",
            "queue size: 477 (153209)\n",
            "queue size: 476 (153213)\n",
            "queue size: 475 (153216)\n",
            "queue size: 474 (153215)\n",
            "queue size: 473 (153230)\n",
            "queue size: 472 (153210)\n",
            "queue size: 471 (153225)\n",
            "queue size: 470 (153205)\n",
            "queue size: 469 (153222)\n",
            "queue size: 468 (153211)\n",
            "queue size: 467 (153233)\n",
            "queue size: 466 (153214)\n",
            "queue size: 465 (153232)\n",
            "queue size: 464 (153206)\n",
            "queue size: 463 (153218)\n",
            "queue size: 462 (153203)\n",
            "queue size: 461 (153220)\n",
            "queue size: 460 (153221)\n",
            "queue size: 459 (153212)\n",
            "queue size: 458 (153208)\n",
            "queue size: 457 (153219)\n",
            "queue size: 456 (153223)\n",
            "queue size: 455 (153207)\n",
            "queue size: 454 (153224)\n",
            "queue size: 453 (153210)\n",
            "queue size: 452 (153226)\n",
            "queue size: 451 (153230)\n",
            "queue size: 450 (153202)\n",
            "queue size: 449 (153215)\n",
            "queue size: 448 (153217)\n",
            "queue size: 447 (153213)\n",
            "queue size: 446 (153204)\n",
            "queue size: 445 (153233)\n",
            "queue size: 444 (153209)\n",
            "queue size: 443 (153222)\n",
            "queue size: 442 (153205)\n",
            "queue size: 441 (153211)\n",
            "queue size: 440 (153216)\n",
            "queue size: 439 (153230)\n",
            "queue size: 438 (153221)\n",
            "queue size: 437 (153232)\n",
            "queue size: 436 (153225)\n",
            "queue size: 435 (153206)\n",
            "queue size: 434 (153220)\n",
            "queue size: 433 (153203)\n",
            "queue size: 432 (153218)\n",
            "queue size: 431 (153224)\n",
            "queue size: 430 (153207)\n",
            "queue size: 429 (153202)\n",
            "queue size: 428 (153212)\n",
            "queue size: 427 (153214)\n",
            "queue size: 426 (153210)\n",
            "queue size: 425 (153233)\n",
            "queue size: 424 (153226)\n",
            "queue size: 423 (153219)\n",
            "queue size: 422 (153204)\n",
            "queue size: 421 (153208)\n",
            "queue size: 420 (153223)\n",
            "queue size: 419 (153213)\n",
            "queue size: 418 (153205)\n",
            "queue size: 417 (153217)\n",
            "queue size: 416 (153220)\n",
            "queue size: 415 (153211)\n",
            "queue size: 414 (153232)\n",
            "queue size: 413 (153222)\n",
            "queue size: 412 (153216)\n",
            "queue size: 411 (153215)\n",
            "queue size: 410 (153209)\n",
            "queue size: 409 (153221)\n",
            "queue size: 408 (153225)\n",
            "queue size: 407 (153206)\n",
            "queue size: 406 (153203)\n",
            "queue size: 405 (153218)\n",
            "queue size: 404 (153214)\n",
            "queue size: 403 (153230)\n",
            "queue size: 402 (153212)\n",
            "queue size: 401 (153224)\n",
            "queue size: 400 (153216)\n",
            "queue size: 399 (153233)\n",
            "queue size: 398 (153202)\n",
            "queue size: 397 (153226)\n",
            "queue size: 396 (153223)\n",
            "queue size: 395 (153219)\n",
            "queue size: 394 (153213)\n",
            "queue size: 393 (153207)\n",
            "queue size: 392 (153204)\n",
            "queue size: 391 (153208)\n",
            "queue size: 390 (153221)\n",
            "queue size: 389 (153217)\n",
            "queue size: 388 (153220)\n",
            "queue size: 387 (153230)\n",
            "queue size: 386 (153205)\n",
            "queue size: 385 (153232)\n",
            "queue size: 384 (153210)\n",
            "queue size: 383 (153211)\n",
            "queue size: 382 (153203)\n",
            "queue size: 381 (153225)\n",
            "queue size: 380 (153214)\n",
            "queue size: 379 (153218)\n",
            "queue size: 378 (153206)\n",
            "queue size: 377 (153215)\n",
            "queue size: 376 (153222)\n",
            "queue size: 375 (153233)\n",
            "queue size: 374 (153209)\n",
            "queue size: 373 (153223)\n",
            "queue size: 372 (153202)\n",
            "queue size: 371 (153212)\n",
            "queue size: 370 (153216)\n",
            "queue size: 369 (153213)\n",
            "queue size: 368 (153207)\n",
            "queue size: 367 (153226)\n",
            "queue size: 366 (153224)\n",
            "queue size: 365 (153220)\n",
            "queue size: 364 (153221)\n",
            "queue size: 363 (153219)\n",
            "queue size: 362 (153211)\n",
            "queue size: 361 (153208)\n",
            "queue size: 360 (153204)\n",
            "queue size: 359 (153232)\n",
            "queue size: 358 (153230)\n",
            "queue size: 357 (153233)\n",
            "queue size: 356 (153217)\n",
            "queue size: 355 (153205)\n",
            "queue size: 354 (153215)\n",
            "queue size: 353 (153222)\n",
            "queue size: 352 (153210)\n",
            "queue size: 351 (153225)\n",
            "queue size: 350 (153214)\n",
            "queue size: 349 (153202)\n",
            "queue size: 348 (153206)\n",
            "queue size: 347 (153209)\n",
            "queue size: 346 (153203)\n",
            "queue size: 345 (153218)\n",
            "queue size: 344 (153207)\n",
            "queue size: 343 (153213)\n",
            "queue size: 342 (153216)\n",
            "queue size: 341 (153224)\n",
            "queue size: 340 (153232)\n",
            "queue size: 339 (153230)\n",
            "queue size: 338 (153226)\n",
            "queue size: 337 (153223)\n",
            "queue size: 336 (153211)\n",
            "queue size: 335 (153221)\n",
            "queue size: 334 (153212)\n",
            "queue size: 333 (153219)\n",
            "queue size: 332 (153208)\n",
            "queue size: 331 (153220)\n",
            "queue size: 330 (153204)\n",
            "queue size: 329 (153205)\n",
            "queue size: 328 (153217)\n",
            "queue size: 327 (153210)\n",
            "queue size: 326 (153225)\n",
            "queue size: 325 (153233)\n",
            "queue size: 324 (153215)\n",
            "queue size: 323 (153209)\n",
            "queue size: 322 (153202)\n",
            "queue size: 321 (153222)\n",
            "queue size: 320 (153214)\n",
            "queue size: 319 (153232)\n",
            "queue size: 318 (153230)\n",
            "queue size: 317 (153206)\n",
            "queue size: 316 (153207)\n",
            "queue size: 315 (153218)\n",
            "queue size: 314 (153226)\n",
            "queue size: 313 (153203)\n",
            "queue size: 312 (153221)\n",
            "queue size: 311 (153213)\n",
            "queue size: 310 (153220)\n",
            "queue size: 309 (153219)\n",
            "queue size: 308 (153223)\n",
            "queue size: 307 (153224)\n",
            "queue size: 306 (153208)\n",
            "queue size: 305 (153205)\n",
            "queue size: 304 (153204)\n",
            "queue size: 303 (153216)\n",
            "queue size: 302 (153211)\n",
            "queue size: 301 (153212)\n",
            "queue size: 300 (153217)\n",
            "queue size: 299 (153225)\n",
            "queue size: 298 (153202)\n",
            "queue size: 297 (153215)\n",
            "queue size: 296 (153214)\n",
            "queue size: 295 (153209)\n",
            "queue size: 294 (153210)\n",
            "queue size: 293 (153218)\n",
            "queue size: 292 (153232)\n",
            "queue size: 291 (153206)\n",
            "queue size: 290 (153222)\n",
            "queue size: 289 (153221)\n",
            "queue size: 288 (153226)\n",
            "queue size: 287 (153219)\n",
            "queue size: 286 (153205)\n",
            "queue size: 285 (153207)\n",
            "queue size: 284 (153233)\n",
            "queue size: 283 (153220)\n",
            "queue size: 282 (153204)\n",
            "queue size: 281 (153223)\n",
            "queue size: 280 (153230)\n",
            "queue size: 279 (153203)\n",
            "queue size: 278 (153225)\n",
            "queue size: 277 (153224)\n",
            "queue size: 276 (153216)\n",
            "queue size: 275 (153213)\n",
            "queue size: 274 (153211)\n",
            "queue size: 273 (153208)\n",
            "queue size: 272 (153217)\n",
            "queue size: 271 (153212)\n",
            "queue size: 270 (153206)\n",
            "queue size: 269 (153202)\n",
            "queue size: 268 (153215)\n",
            "queue size: 267 (153207)\n",
            "queue size: 266 (153214)\n",
            "queue size: 265 (153218)\n",
            "queue size: 264 (153232)\n",
            "queue size: 263 (153219)\n",
            "queue size: 262 (153210)\n",
            "queue size: 261 (153205)\n",
            "queue size: 260 (153209)\n",
            "queue size: 259 (153222)\n",
            "queue size: 258 (153221)\n",
            "queue size: 257 (153226)\n",
            "queue size: 256 (153233)\n",
            "queue size: 255 (153204)\n",
            "queue size: 254 (153203)\n",
            "queue size: 253 (153223)\n",
            "queue size: 252 (153224)\n",
            "queue size: 251 (153225)\n",
            "queue size: 250 (153220)\n",
            "queue size: 249 (153216)\n",
            "queue size: 248 (153213)\n",
            "queue size: 247 (153212)\n",
            "queue size: 246 (153208)\n",
            "queue size: 245 (153230)\n",
            "queue size: 244 (153211)\n",
            "queue size: 243 (153218)\n",
            "queue size: 242 (153202)\n",
            "queue size: 241 (153206)\n",
            "queue size: 240 (153217)\n",
            "queue size: 239 (153207)\n",
            "queue size: 238 (153232)\n",
            "queue size: 237 (153209)\n",
            "queue size: 236 (153214)\n",
            "queue size: 235 (153210)\n",
            "queue size: 234 (153215)\n",
            "queue size: 233 (153226)\n",
            "queue size: 232 (153219)\n",
            "queue size: 231 (153233)\n",
            "queue size: 230 (153205)\n",
            "queue size: 229 (153224)\n",
            "queue size: 228 (153216)\n",
            "queue size: 227 (153220)\n",
            "queue size: 226 (153223)\n",
            "queue size: 225 (153225)\n",
            "queue size: 224 (153213)\n",
            "queue size: 223 (153222)\n",
            "queue size: 222 (153207)\n",
            "queue size: 221 (153212)\n",
            "queue size: 220 (153204)\n",
            "queue size: 219 (153203)\n",
            "queue size: 218 (153218)\n",
            "queue size: 217 (153221)\n",
            "queue size: 216 (153208)\n",
            "queue size: 215 (153230)\n",
            "queue size: 214 (153232)\n",
            "queue size: 213 (153206)\n",
            "queue size: 212 (153217)\n",
            "queue size: 211 (153215)\n",
            "queue size: 210 (153202)\n",
            "queue size: 209 (153211)\n",
            "queue size: 208 (153214)\n",
            "queue size: 207 (153209)\n",
            "queue size: 206 (153219)\n",
            "queue size: 205 (153233)\n",
            "queue size: 204 (153205)\n",
            "queue size: 203 (153210)\n",
            "queue size: 202 (153224)\n",
            "queue size: 201 (153216)\n",
            "queue size: 200 (153225)\n",
            "queue size: 199 (153213)\n",
            "queue size: 198 (153203)\n",
            "queue size: 197 (153207)\n",
            "queue size: 196 (153226)\n",
            "queue size: 195 (153220)\n",
            "queue size: 194 (153222)\n",
            "queue size: 193 (153223)\n",
            "queue size: 192 (153204)\n",
            "queue size: 191 (153208)\n",
            "queue size: 190 (153212)\n",
            "queue size: 189 (153230)\n",
            "queue size: 188 (153214)\n",
            "queue size: 187 (153211)\n",
            "queue size: 186 (153232)\n",
            "queue size: 185 (153218)\n",
            "queue size: 184 (153206)\n",
            "queue size: 183 (153209)\n",
            "queue size: 182 (153202)\n",
            "queue size: 181 (153217)\n",
            "queue size: 180 (153221)\n",
            "queue size: 179 (153205)\n",
            "queue size: 178 (153219)\n",
            "queue size: 177 (153224)\n",
            "queue size: 176 (153213)\n",
            "queue size: 175 (153210)\n",
            "queue size: 174 (153215)\n",
            "queue size: 173 (153203)\n",
            "queue size: 172 (153233)\n",
            "queue size: 171 (153223)\n",
            "queue size: 170 (153216)\n",
            "queue size: 169 (153226)\n",
            "queue size: 168 (153207)\n",
            "queue size: 167 (153222)\n",
            "queue size: 166 (153204)\n",
            "queue size: 165 (153225)\n",
            "queue size: 164 (153212)\n",
            "queue size: 163 (153230)\n",
            "queue size: 162 (153208)\n",
            "queue size: 161 (153220)\n",
            "queue size: 160 (153217)\n",
            "queue size: 159 (153206)\n",
            "queue size: 158 (153214)\n",
            "queue size: 157 (153209)\n",
            "queue size: 156 (153211)\n",
            "queue size: 155 (153218)\n",
            "queue size: 154 (153232)\n",
            "queue size: 153 (153205)\n",
            "queue size: 152 (153215)\n",
            "queue size: 151 (153202)\n",
            "queue size: 150 (153221)\n",
            "queue size: 149 (153219)\n",
            "queue size: 148 (153213)\n",
            "queue size: 147 (153210)\n",
            "queue size: 146 (153224)\n",
            "queue size: 145 (153216)\n",
            "queue size: 144 (153203)\n",
            "queue size: 143 (153233)\n",
            "queue size: 142 (153226)\n",
            "queue size: 141 (153207)\n",
            "queue size: 140 (153204)\n",
            "queue size: 139 (153206)\n",
            "queue size: 138 (153208)\n",
            "queue size: 137 (153225)\n",
            "queue size: 136 (153230)\n",
            "queue size: 135 (153218)\n",
            "queue size: 134 (153209)\n",
            "queue size: 133 (153223)\n",
            "queue size: 132 (153212)\n",
            "queue size: 131 (153220)\n",
            "queue size: 130 (153222)\n",
            "queue size: 129 (153214)\n",
            "queue size: 128 (153232)\n",
            "queue size: 127 (153210)\n",
            "queue size: 126 (153217)\n",
            "queue size: 125 (153213)\n",
            "queue size: 124 (153211)\n",
            "queue size: 123 (153221)\n",
            "queue size: 122 (153202)\n",
            "queue size: 121 (153205)\n",
            "queue size: 120 (153203)\n",
            "queue size: 119 (153216)\n",
            "queue size: 118 (153204)\n",
            "queue size: 117 (153215)\n",
            "queue size: 116 (153207)\n",
            "queue size: 115 (153224)\n",
            "queue size: 114 (153209)\n",
            "queue size: 113 (153218)\n",
            "queue size: 112 (153226)\n",
            "queue size: 111 (153219)\n",
            "queue size: 110 (153233)\n",
            "queue size: 109 (153225)\n",
            "queue size: 108 (153223)\n",
            "queue size: 107 (153232)\n",
            "queue size: 106 (153208)\n",
            "queue size: 105 (153206)\n",
            "queue size: 104 (153212)\n",
            "queue size: 103 (153222)\n",
            "queue size: 102 (153220)\n",
            "queue size: 101 (153214)\n",
            "queue size: 100 (153230)\n",
            "queue size: 99 (153217)\n",
            "queue size: 98 (153211)\n",
            "queue size: 97 (153221)\n",
            "queue size: 96 (153210)\n",
            "queue size: 95 (153213)\n",
            "queue size: 94 (153202)\n",
            "queue size: 93 (153205)\n",
            "queue size: 92 (153209)\n",
            "queue size: 91 (153219)\n",
            "queue size: 90 (153203)\n",
            "queue size: 89 (153204)\n",
            "queue size: 88 (153207)\n",
            "queue size: 87 (153215)\n",
            "queue size: 86 (153216)\n",
            "queue size: 85 (153222)\n",
            "queue size: 84 (153226)\n",
            "queue size: 83 (153206)\n",
            "queue size: 82 (153225)\n",
            "queue size: 81 (153233)\n",
            "queue size: 80 (153232)\n",
            "queue size: 79 (153220)\n",
            "queue size: 78 (153224)\n",
            "queue size: 77 (153208)\n",
            "queue size: 76 (153218)\n",
            "queue size: 75 (153212)\n",
            "queue size: 74 (153223)\n",
            "queue size: 73 (153211)\n",
            "queue size: 72 (153213)\n",
            "queue size: 71 (153204)\n",
            "queue size: 70 (153221)\n",
            "queue size: 69 (153214)\n",
            "queue size: 68 (153210)\n",
            "queue size: 67 (153217)\n",
            "queue size: 66 (153222)\n",
            "queue size: 65 (153230)\n",
            "queue size: 64 (153209)\n",
            "queue size: 63 (153216)\n",
            "queue size: 62 (153219)\n",
            "queue size: 61 (153215)\n",
            "queue size: 60 (153207)\n",
            "queue size: 59 (153203)\n",
            "queue size: 58 (153205)\n",
            "queue size: 57 (153225)\n",
            "queue size: 56 (153202)\n",
            "queue size: 55 (153208)\n",
            "queue size: 54 (153206)\n",
            "queue size: 53 (153233)\n",
            "queue size: 52 (153224)\n",
            "queue size: 51 (153220)\n",
            "queue size: 50 (153226)\n",
            "queue size: 49 (153204)\n",
            "queue size: 48 (153212)\n",
            "queue size: 47 (153218)\n",
            "queue size: 46 (153232)\n",
            "queue size: 45 (153217)\n",
            "queue size: 44 (153211)\n",
            "queue size: 43 (153223)\n",
            "queue size: 42 (153214)\n",
            "queue size: 41 (153209)\n",
            "queue size: 40 (153213)\n",
            "queue size: 39 (153230)\n",
            "queue size: 38 (153216)\n",
            "queue size: 37 (153221)\n",
            "queue size: 36 (153219)\n",
            "queue size: 35 (153210)\n",
            "queue size: 34 (153203)\n",
            "queue size: 33 (153222)\n",
            "queue size: 32 (153215)\n",
            "queue size: 31 (153205)\n",
            "queue size: 30 (153204)\n",
            "queue size: 29 (153220)\n",
            "queue size: 28 (153207)\n",
            "queue size: 27 (153206)\n",
            "queue size: 26 (153208)\n",
            "queue size: 25 (153233)\n",
            "queue size: 24 (153226)\n",
            "queue size: 23 (153223)\n",
            "queue size: 22 (153211)\n",
            "queue size: 21 (153224)\n",
            "queue size: 20 (153202)\n",
            "queue size: 19 (153232)\n",
            "queue size: 18 (153225)\n",
            "queue size: 17 (153212)\n",
            "queue size: 16 (153218)\n",
            "queue size: 15 (153222)\n",
            "queue size: 14 (153214)\n",
            "queue size: 13 (153220)\n",
            "queue size: 12 (153230)\n",
            "queue size: 11 (153217)\n",
            "queue size: 10 (153221)\n",
            "queue size: 9 (153219)\n",
            "queue size: 8 (153209)\n",
            "queue size: 7 (153232)\n",
            "queue size: 6 (153204)\n",
            "queue size: 5 (153216)\n",
            "queue size: 4 (153213)\n",
            "queue size: 3 (153203)\n",
            "queue size: 2 (153210)\n",
            "queue size: 1 (153208)\n",
            "Worker (153233) finished. session_id: test_session_p153233_t135288872485504\n",
            "Worker (153206) finished. session_id: test_session_p153206_t135288872485504\n",
            "Worker (153212) finished. session_id: test_session_p153212_t135288872485504\n",
            "Worker (153207) finished. session_id: test_session_p153207_t135288872485504\n",
            "Worker (153205) finished. session_id: test_session_p153205_t135288872485504\n",
            "Worker (153226) finished. session_id: test_session_p153226_t135288872485504\n",
            "Worker (153215) finished. session_id: test_session_p153215_t135288872485504\n",
            "Worker (153224) finished. session_id: test_session_p153224_t135288872485504\n",
            "Worker (153214) finished. session_id: test_session_p153214_t135288872485504\n",
            "Worker (153222) finished. session_id: test_session_p153222_t135288872485504\n",
            "Worker (153211) finished. session_id: test_session_p153211_t135288872485504\n",
            "Worker (153218) finished. session_id: test_session_p153218_t135288872485504\n",
            "Worker (153223) finished. session_id: test_session_p153223_t135288872485504\n",
            "Worker (153202) finished. session_id: test_session_p153202_t135288872485504\n",
            "Worker (153232) finished. session_id: test_session_p153232_t135288872485504\n",
            "Worker (153230) finished. session_id: test_session_p153230_t135288872485504\n",
            "Worker (153213) finished. session_id: test_session_p153213_t135288872485504\n",
            "Worker (153225) finished. session_id: test_session_p153225_t135288872485504\n",
            "Worker (153217) finished. session_id: test_session_p153217_t135288872485504\n",
            "Worker (153221) finished. session_id: test_session_p153221_t135288872485504\n",
            "Worker (153216) finished. session_id: test_session_p153216_t135288872485504\n",
            "Worker (153219) finished. session_id: test_session_p153219_t135288872485504\n",
            "Worker (153209) finished. session_id: test_session_p153209_t135288872485504\n",
            "Worker (153220) finished. session_id: test_session_p153220_t135288872485504\n",
            "Worker (153203) finished. session_id: test_session_p153203_t135288872485504\n",
            "Worker (153204) finished. session_id: test_session_p153204_t135288872485504\n",
            "Worker (153208) finished. session_id: test_session_p153208_t135288872485504\n",
            "Worker (153210) finished. session_id: test_session_p153210_t135288872485504\n",
            "Deployment: llama2-7b-tp1-b768 Clients: 28, Prompt (mean): 2600 tokens, Generation (mean): 60 tokens, Query throughput: 3.296 queries/s, Token throughput (total): 325.035 tokens/s, Query latency: 8.494 s, Token generation latency: 0.081 s/token, First token received: 3.731 s\n",
            "Namespace(max_new_tokens=60, deployment_name='llama2-7b-tp1-b768', num_queries=512, warmup=1, client_num=32, prompt_length=2600, use_thread=False, stream=True, vllm=False, out_json_path=PosixPath('logs.llama2-7b-tp1-b768/llama2-7b-tp1-b768_c32_p2600_g60.json'))\n",
            "[2023-12-16 13:30:05,302] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:30:05,755] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:30:05,781] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:30:05,796] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:30:06,021] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:30:06,036] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:30:06,098] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:30:06,148] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:30:06,213] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:30:06,237] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:30:06,243] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:30:06,374] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:30:06,422] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:30:06,429] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:30:06,448] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:30:06,536] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:30:06,558] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:30:06,618] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:30:06,743] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:30:06,790] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:30:06,797] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:30:06,797] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:30:06,801] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:30:06,820] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:30:06,850] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:30:06,971] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:30:07,000] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:30:07,014] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:30:07,097] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:30:07,151] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:30:07,174] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-12-16 13:30:07,478] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "2023-12-16 13:30:11.122429: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:30:11.122548: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:30:11.124978: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:30:11.854886: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:30:11.855012: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:30:11.857454: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:30:13.087327: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:30:13.102026: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:30:13.103852: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:30:13.210783: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:30:13.210890: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:30:13.212584: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:30:13.242055: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:30:13.248989: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:30:13.250778: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:30:13.510213: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:30:13.513739: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:30:13.517990: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:30:13.519925: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:30:13.529991: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:30:13.531790: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:30:13.584362: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:30:13.584469: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:30:13.586193: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:30:13.617732: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:30:13.617839: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:30:13.619560: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:30:14.029696: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:30:14.029804: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:30:14.032502: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:30:14.032600: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:30:14.034199: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:30:14.034371: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:30:14.083221: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:30:14.083321: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:30:14.085025: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:30:14.179581: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:30:14.189062: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:30:14.189186: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:30:14.190918: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:30:14.190989: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:30:14.192680: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:30:14.196309: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:30:14.196350: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:30:14.197920: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:30:14.284000: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:30:14.284105: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:30:14.285797: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:30:14.291105: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:30:14.291150: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:30:14.292772: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:30:14.376606: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:30:14.397002: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:30:14.398809: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:30:14.414703: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:30:14.420986: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:30:14.426911: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:30:14.454582: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:30:14.460980: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:30:14.462668: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:30:14.514330: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:30:14.514438: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:30:14.516130: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:30:14.534816: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:30:14.534865: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:30:14.536573: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:30:14.678325: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:30:14.679997: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:30:14.681807: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:30:14.684270: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:30:14.684350: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:30:14.686000: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:30:14.902333: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:30:14.902386: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:30:14.904107: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:30:14.914802: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:30:14.914850: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:30:14.937584: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:30:15.005656: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:30:15.021028: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:30:15.022845: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:30:15.147153: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:30:15.155985: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:30:15.157795: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:30:15.248566: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:30:15.260986: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:30:15.262796: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:30:15.539472: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:30:15.539529: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:30:15.541266: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:30:16.062016: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:30:16.062124: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:30:16.063853: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:30:16.835991: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:30:17.159965: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:30:17.160016: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:30:17.161704: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:30:17.864006: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:30:17.887016: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:30:17.916936: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:30:18.434950: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:30:18.805424: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:30:19.071024: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:30:19.256896: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:30:19.318021: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:30:19.341727: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:30:19.350150: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:30:19.386340: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:30:19.722795: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:30:19.893313: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:30:19.904914: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:30:20.019267: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:30:20.046528: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:30:20.048804: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:30:20.259322: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:30:20.355781: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:30:20.656667: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:30:20.889834: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:30:20.926485: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:30:20.931874: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:30:20.969616: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:30:21.428397: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:30:21.592275: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:30:21.638159: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:30:21.660330: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:30:21.857940: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:30:22.703843: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-16 13:30:23.592082: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "warmup queue size: 544 (155938)\n",
            "warmup queue size: 544 (155925)\n",
            "warmup queue size: 544 (155910)\n",
            "warmup queue size: 543 (155934)\n",
            "warmup queue size: 543 (155915)\n",
            "warmup queue size: 543 (155924)\n",
            "warmup queue size: 543 (155926)\n",
            "warmup queue size: 542 (155936)\n",
            "warmup queue size: 542 (155911)\n",
            "warmup queue size: 542 (155937)\n",
            "warmup queue size: 541 (155908)\n",
            "warmup queue size: 541 (155912)\n",
            "warmup queue size: 541 (155906)\n",
            "warmup queue size: 541 (155921)\n",
            "warmup queue size: 541 (155916)\n",
            "warmup queue size: 540 (155907)\n",
            "warmup queue size: 540 (155919)\n",
            "warmup queue size: 540 (155923)\n",
            "warmup queue size: 539 (155913)\n",
            "warmup queue size: 539 (155939)\n",
            "warmup queue size: 539 (155935)\n",
            "warmup queue size: 538 (155932)\n",
            "warmup queue size: 538 (155920)\n",
            "warmup queue size: 538 (155905)\n",
            "warmup queue size: 538 (155922)\n",
            "warmup queue size: 537 (155918)\n",
            "warmup queue size: 537 (155931)\n",
            "warmup queue size: 537 (155917)\n",
            "warmup queue size: 536 (155909)\n",
            "warmup queue size: 536 (155933)\n",
            "warmup queue size: 536 (155914)\n",
            "warmup queue size: 532 (155940)\n",
            "queue size: 512 (155919)\n",
            "queue size: 511 (155918)\n",
            "queue size: 510 (155920)\n",
            "queue size: 509 (155905)\n",
            "queue size: 508 (155940)\n",
            "queue size: 507 (155921)\n",
            "queue size: 506 (155906)\n",
            "queue size: 505 (155913)\n",
            "queue size: 504 (155924)\n",
            "queue size: 503 (155910)\n",
            "queue size: 502 (155916)\n",
            "queue size: 501 (155931)\n",
            "queue size: 500 (155926)\n",
            "queue size: 499 (155932)\n",
            "queue size: 498 (155922)\n",
            "queue size: 497 (155907)\n",
            "queue size: 496 (155915)\n",
            "queue size: 495 (155938)\n",
            "queue size: 494 (155934)\n",
            "queue size: 493 (155909)\n",
            "queue size: 493 (155911)\n",
            "queue size: 491 (155914)\n",
            "queue size: 490 (155912)\n",
            "queue size: 489 (155908)\n",
            "queue size: 488 (155939)\n",
            "queue size: 487 (155933)\n",
            "queue size: 486 (155935)\n",
            "queue size: 485 (155936)\n",
            "queue size: 484 (155925)\n",
            "queue size: 483 (155937)\n",
            "queue size: 482 (155917)\n",
            "queue size: 481 (155923)\n",
            "queue size: 480 (155920)\n",
            "queue size: 479 (155921)\n",
            "queue size: 478 (155919)\n",
            "queue size: 477 (155918)\n",
            "queue size: 476 (155931)\n",
            "queue size: 475 (155940)\n",
            "queue size: 474 (155916)\n",
            "queue size: 473 (155932)\n",
            "queue size: 472 (155924)\n",
            "queue size: 471 (155906)\n",
            "queue size: 470 (155905)\n",
            "queue size: 469 (155910)\n",
            "queue size: 468 (155922)\n",
            "queue size: 467 (155907)\n",
            "queue size: 466 (155914)\n",
            "queue size: 465 (155909)\n",
            "queue size: 464 (155926)\n",
            "queue size: 463 (155938)\n",
            "queue size: 462 (155915)\n",
            "queue size: 461 (155911)\n",
            "queue size: 460 (155913)\n",
            "queue size: 459 (155912)\n",
            "queue size: 458 (155934)\n",
            "queue size: 457 (155933)\n",
            "queue size: 456 (155920)\n",
            "queue size: 455 (155923)\n",
            "queue size: 454 (155908)\n",
            "queue size: 453 (155917)\n",
            "queue size: 452 (155939)\n",
            "queue size: 451 (155925)\n",
            "queue size: 450 (155935)\n",
            "queue size: 449 (155940)\n",
            "queue size: 448 (155936)\n",
            "queue size: 447 (155918)\n",
            "queue size: 446 (155931)\n",
            "queue size: 445 (155919)\n",
            "queue size: 444 (155937)\n",
            "queue size: 443 (155932)\n",
            "queue size: 442 (155922)\n",
            "queue size: 441 (155921)\n",
            "queue size: 440 (155924)\n",
            "queue size: 439 (155905)\n",
            "queue size: 438 (155910)\n",
            "queue size: 437 (155906)\n",
            "queue size: 436 (155938)\n",
            "queue size: 435 (155907)\n",
            "queue size: 434 (155915)\n",
            "queue size: 433 (155934)\n",
            "queue size: 432 (155916)\n",
            "queue size: 431 (155909)\n",
            "queue size: 430 (155911)\n",
            "queue size: 429 (155917)\n",
            "queue size: 428 (155913)\n",
            "queue size: 427 (155914)\n",
            "queue size: 426 (155908)\n",
            "queue size: 425 (155926)\n",
            "queue size: 424 (155923)\n",
            "queue size: 423 (155922)\n",
            "queue size: 422 (155920)\n",
            "queue size: 421 (155935)\n",
            "queue size: 420 (155940)\n",
            "queue size: 419 (155912)\n",
            "queue size: 418 (155919)\n",
            "queue size: 417 (155925)\n",
            "queue size: 416 (155936)\n",
            "queue size: 415 (155933)\n",
            "queue size: 414 (155939)\n",
            "queue size: 413 (155931)\n",
            "queue size: 412 (155937)\n",
            "queue size: 411 (155932)\n",
            "queue size: 410 (155924)\n",
            "queue size: 409 (155921)\n",
            "queue size: 408 (155907)\n",
            "queue size: 407 (155918)\n",
            "queue size: 406 (155938)\n",
            "queue size: 405 (155905)\n",
            "queue size: 404 (155934)\n",
            "queue size: 403 (155916)\n",
            "queue size: 402 (155940)\n",
            "queue size: 401 (155906)\n",
            "queue size: 400 (155913)\n",
            "queue size: 399 (155911)\n",
            "queue size: 398 (155909)\n",
            "queue size: 397 (155914)\n",
            "queue size: 396 (155917)\n",
            "queue size: 395 (155910)\n",
            "queue size: 394 (155926)\n",
            "queue size: 393 (155923)\n",
            "queue size: 392 (155908)\n",
            "queue size: 391 (155925)\n",
            "queue size: 390 (155922)\n",
            "queue size: 389 (155915)\n",
            "queue size: 388 (155918)\n",
            "queue size: 387 (155920)\n",
            "queue size: 386 (155939)\n",
            "queue size: 385 (155937)\n",
            "queue size: 384 (155936)\n",
            "queue size: 383 (155931)\n",
            "queue size: 382 (155935)\n",
            "queue size: 381 (155933)\n",
            "queue size: 380 (155912)\n",
            "queue size: 379 (155919)\n",
            "queue size: 378 (155934)\n",
            "queue size: 377 (155938)\n",
            "queue size: 376 (155924)\n",
            "queue size: 375 (155907)\n",
            "queue size: 374 (155940)\n",
            "queue size: 373 (155906)\n",
            "queue size: 372 (155905)\n",
            "queue size: 371 (155921)\n",
            "queue size: 370 (155917)\n",
            "queue size: 369 (155932)\n",
            "queue size: 368 (155909)\n",
            "queue size: 367 (155916)\n",
            "queue size: 366 (155925)\n",
            "queue size: 365 (155911)\n",
            "queue size: 364 (155913)\n",
            "queue size: 363 (155923)\n",
            "queue size: 362 (155910)\n",
            "queue size: 361 (155914)\n",
            "queue size: 360 (155926)\n",
            "queue size: 359 (155908)\n",
            "queue size: 358 (155915)\n",
            "queue size: 357 (155937)\n",
            "queue size: 356 (155936)\n",
            "queue size: 355 (155918)\n",
            "queue size: 354 (155912)\n",
            "queue size: 353 (155939)\n",
            "queue size: 352 (155935)\n",
            "queue size: 351 (155922)\n",
            "queue size: 350 (155920)\n",
            "queue size: 349 (155931)\n",
            "queue size: 348 (155921)\n",
            "queue size: 347 (155924)\n",
            "queue size: 346 (155934)\n",
            "queue size: 345 (155938)\n",
            "queue size: 344 (155916)\n",
            "queue size: 343 (155940)\n",
            "queue size: 342 (155907)\n",
            "queue size: 342 (155933)\n",
            "queue size: 340 (155925)\n",
            "queue size: 339 (155917)\n",
            "queue size: 338 (155905)\n",
            "queue size: 337 (155919)\n",
            "queue size: 336 (155932)\n",
            "queue size: 335 (155912)\n",
            "queue size: 334 (155906)\n",
            "queue size: 333 (155909)\n",
            "queue size: 332 (155918)\n",
            "queue size: 331 (155923)\n",
            "queue size: 330 (155908)\n",
            "queue size: 329 (155926)\n",
            "queue size: 328 (155913)\n",
            "queue size: 327 (155910)\n",
            "queue size: 326 (155911)\n",
            "queue size: 325 (155937)\n",
            "queue size: 324 (155914)\n",
            "queue size: 323 (155921)\n",
            "queue size: 322 (155915)\n",
            "queue size: 321 (155936)\n",
            "queue size: 320 (155924)\n",
            "queue size: 319 (155935)\n",
            "queue size: 318 (155939)\n",
            "queue size: 317 (155934)\n",
            "queue size: 316 (155940)\n",
            "queue size: 315 (155917)\n",
            "queue size: 314 (155938)\n",
            "queue size: 313 (155922)\n",
            "queue size: 312 (155925)\n",
            "queue size: 311 (155907)\n",
            "queue size: 310 (155919)\n",
            "queue size: 309 (155931)\n",
            "queue size: 308 (155905)\n",
            "queue size: 307 (155916)\n",
            "queue size: 306 (155920)\n",
            "queue size: 305 (155932)\n",
            "queue size: 304 (155933)\n",
            "queue size: 303 (155906)\n",
            "queue size: 302 (155918)\n",
            "queue size: 301 (155908)\n",
            "queue size: 300 (155912)\n",
            "queue size: 299 (155913)\n",
            "queue size: 298 (155923)\n",
            "queue size: 297 (155921)\n",
            "queue size: 296 (155910)\n",
            "queue size: 295 (155937)\n",
            "queue size: 294 (155926)\n",
            "queue size: 293 (155924)\n",
            "queue size: 292 (155915)\n",
            "queue size: 291 (155922)\n",
            "queue size: 290 (155934)\n",
            "queue size: 289 (155909)\n",
            "queue size: 288 (155914)\n",
            "queue size: 287 (155939)\n",
            "queue size: 286 (155925)\n",
            "queue size: 285 (155940)\n",
            "queue size: 284 (155911)\n",
            "queue size: 283 (155936)\n",
            "queue size: 282 (155907)\n",
            "queue size: 281 (155916)\n",
            "queue size: 280 (155938)\n",
            "queue size: 279 (155917)\n",
            "queue size: 278 (155935)\n",
            "queue size: 277 (155919)\n",
            "queue size: 276 (155913)\n",
            "queue size: 275 (155905)\n",
            "queue size: 274 (155931)\n",
            "queue size: 273 (155920)\n",
            "queue size: 272 (155932)\n",
            "queue size: 271 (155933)\n",
            "queue size: 270 (155937)\n",
            "queue size: 269 (155912)\n",
            "queue size: 268 (155926)\n",
            "queue size: 267 (155908)\n",
            "queue size: 266 (155906)\n",
            "queue size: 265 (155918)\n",
            "queue size: 264 (155921)\n",
            "queue size: 263 (155923)\n",
            "queue size: 262 (155910)\n",
            "queue size: 261 (155915)\n",
            "queue size: 260 (155934)\n",
            "queue size: 259 (155939)\n",
            "queue size: 258 (155909)\n",
            "queue size: 257 (155924)\n",
            "queue size: 256 (155922)\n",
            "queue size: 255 (155940)\n",
            "queue size: 254 (155911)\n",
            "queue size: 253 (155925)\n",
            "queue size: 252 (155917)\n",
            "queue size: 251 (155916)\n",
            "queue size: 250 (155936)\n",
            "queue size: 249 (155914)\n",
            "queue size: 248 (155907)\n",
            "queue size: 247 (155920)\n",
            "queue size: 246 (155919)\n",
            "queue size: 245 (155935)\n",
            "queue size: 244 (155905)\n",
            "queue size: 243 (155938)\n",
            "queue size: 242 (155932)\n",
            "queue size: 241 (155937)\n",
            "queue size: 240 (155926)\n",
            "queue size: 239 (155913)\n",
            "queue size: 239 (155931)\n",
            "queue size: 237 (155918)\n",
            "queue size: 236 (155921)\n",
            "queue size: 235 (155933)\n",
            "queue size: 234 (155909)\n",
            "queue size: 233 (155915)\n",
            "queue size: 232 (155912)\n",
            "queue size: 231 (155934)\n",
            "queue size: 230 (155939)\n",
            "queue size: 229 (155924)\n",
            "queue size: 228 (155908)\n",
            "queue size: 227 (155922)\n",
            "queue size: 226 (155917)\n",
            "queue size: 225 (155923)\n",
            "queue size: 224 (155940)\n",
            "queue size: 223 (155906)\n",
            "queue size: 222 (155910)\n",
            "queue size: 221 (155916)\n",
            "queue size: 220 (155911)\n",
            "queue size: 219 (155925)\n",
            "queue size: 218 (155919)\n",
            "queue size: 217 (155914)\n",
            "queue size: 216 (155938)\n",
            "queue size: 215 (155907)\n",
            "queue size: 214 (155936)\n",
            "queue size: 213 (155926)\n",
            "queue size: 212 (155920)\n",
            "queue size: 211 (155905)\n",
            "queue size: 210 (155935)\n",
            "queue size: 209 (155913)\n",
            "queue size: 208 (155931)\n",
            "queue size: 207 (155932)\n",
            "queue size: 206 (155918)\n",
            "queue size: 205 (155921)\n",
            "queue size: 204 (155915)\n",
            "queue size: 203 (155912)\n",
            "queue size: 202 (155922)\n",
            "queue size: 201 (155939)\n",
            "queue size: 200 (155933)\n",
            "queue size: 199 (155934)\n",
            "queue size: 198 (155937)\n",
            "queue size: 197 (155909)\n",
            "queue size: 196 (155940)\n",
            "queue size: 195 (155908)\n",
            "queue size: 194 (155924)\n",
            "queue size: 193 (155906)\n",
            "queue size: 192 (155938)\n",
            "queue size: 191 (155914)\n",
            "queue size: 190 (155910)\n",
            "queue size: 189 (155916)\n",
            "queue size: 188 (155919)\n",
            "queue size: 187 (155917)\n",
            "queue size: 186 (155907)\n",
            "queue size: 185 (155911)\n",
            "queue size: 184 (155923)\n",
            "queue size: 183 (155920)\n",
            "queue size: 182 (155936)\n",
            "queue size: 181 (155925)\n",
            "queue size: 180 (155905)\n",
            "queue size: 180 (155935)\n",
            "queue size: 178 (155932)\n",
            "queue size: 177 (155918)\n",
            "queue size: 176 (155926)\n",
            "queue size: 175 (155939)\n",
            "queue size: 174 (155913)\n",
            "queue size: 173 (155915)\n",
            "queue size: 172 (155921)\n",
            "queue size: 171 (155922)\n",
            "queue size: 170 (155933)\n",
            "queue size: 169 (155909)\n",
            "queue size: 168 (155931)\n",
            "queue size: 167 (155937)\n",
            "queue size: 166 (155912)\n",
            "queue size: 165 (155934)\n",
            "queue size: 164 (155916)\n",
            "queue size: 163 (155938)\n",
            "queue size: 162 (155940)\n",
            "queue size: 161 (155906)\n",
            "queue size: 160 (155908)\n",
            "queue size: 159 (155914)\n",
            "queue size: 158 (155924)\n",
            "queue size: 157 (155917)\n",
            "queue size: 156 (155919)\n",
            "queue size: 155 (155907)\n",
            "queue size: 154 (155936)\n",
            "queue size: 153 (155910)\n",
            "queue size: 152 (155923)\n",
            "queue size: 151 (155920)\n",
            "queue size: 150 (155911)\n",
            "queue size: 149 (155932)\n",
            "queue size: 148 (155925)\n",
            "queue size: 147 (155905)\n",
            "queue size: 146 (155918)\n",
            "queue size: 145 (155926)\n",
            "queue size: 144 (155913)\n",
            "queue size: 143 (155915)\n",
            "queue size: 142 (155933)\n",
            "queue size: 141 (155937)\n",
            "queue size: 140 (155922)\n",
            "queue size: 139 (155938)\n",
            "queue size: 138 (155921)\n",
            "queue size: 137 (155934)\n",
            "queue size: 136 (155939)\n",
            "queue size: 135 (155909)\n",
            "queue size: 134 (155935)\n",
            "queue size: 133 (155940)\n",
            "queue size: 132 (155907)\n",
            "queue size: 131 (155912)\n",
            "queue size: 130 (155931)\n",
            "queue size: 129 (155919)\n",
            "queue size: 128 (155924)\n",
            "queue size: 127 (155908)\n",
            "queue size: 127 (155914)\n",
            "queue size: 125 (155906)\n",
            "queue size: 124 (155916)\n",
            "queue size: 123 (155923)\n",
            "queue size: 122 (155910)\n",
            "queue size: 121 (155925)\n",
            "queue size: 120 (155936)\n",
            "queue size: 119 (155932)\n",
            "queue size: 118 (155933)\n",
            "queue size: 117 (155915)\n",
            "queue size: 116 (155911)\n",
            "queue size: 115 (155917)\n",
            "queue size: 115 (155920)\n",
            "queue size: 113 (155937)\n",
            "queue size: 112 (155926)\n",
            "queue size: 111 (155939)\n",
            "queue size: 110 (155918)\n",
            "queue size: 109 (155905)\n",
            "queue size: 108 (155922)\n",
            "queue size: 107 (155921)\n",
            "queue size: 106 (155938)\n",
            "queue size: 105 (155913)\n",
            "queue size: 104 (155934)\n",
            "queue size: 103 (155935)\n",
            "queue size: 102 (155907)\n",
            "queue size: 101 (155909)\n",
            "queue size: 100 (155912)\n",
            "queue size: 99 (155940)\n",
            "queue size: 98 (155931)\n",
            "queue size: 97 (155919)\n",
            "queue size: 96 (155924)\n",
            "queue size: 95 (155914)\n",
            "queue size: 94 (155910)\n",
            "queue size: 93 (155932)\n",
            "queue size: 92 (155916)\n",
            "queue size: 91 (155906)\n",
            "queue size: 90 (155908)\n",
            "queue size: 89 (155936)\n",
            "queue size: 88 (155939)\n",
            "queue size: 87 (155937)\n",
            "queue size: 86 (155933)\n",
            "queue size: 85 (155923)\n",
            "queue size: 84 (155915)\n",
            "queue size: 83 (155918)\n",
            "queue size: 82 (155917)\n",
            "queue size: 81 (155920)\n",
            "queue size: 80 (155925)\n",
            "queue size: 79 (155926)\n",
            "queue size: 78 (155938)\n",
            "queue size: 77 (155911)\n",
            "queue size: 76 (155935)\n",
            "queue size: 75 (155919)\n",
            "queue size: 74 (155913)\n",
            "queue size: 73 (155905)\n",
            "queue size: 72 (155921)\n",
            "queue size: 71 (155934)\n",
            "queue size: 70 (155922)\n",
            "queue size: 69 (155912)\n",
            "queue size: 68 (155910)\n",
            "queue size: 67 (155914)\n",
            "queue size: 66 (155940)\n",
            "queue size: 65 (155924)\n",
            "queue size: 64 (155931)\n",
            "queue size: 63 (155909)\n",
            "queue size: 62 (155932)\n",
            "queue size: 61 (155907)\n",
            "queue size: 60 (155908)\n",
            "queue size: 59 (155923)\n",
            "queue size: 58 (155906)\n",
            "queue size: 57 (155936)\n",
            "queue size: 56 (155933)\n",
            "queue size: 55 (155937)\n",
            "queue size: 54 (155916)\n",
            "queue size: 53 (155926)\n",
            "queue size: 52 (155939)\n",
            "queue size: 51 (155918)\n",
            "queue size: 50 (155915)\n",
            "queue size: 49 (155919)\n",
            "queue size: 48 (155920)\n",
            "queue size: 47 (155917)\n",
            "queue size: 46 (155921)\n",
            "queue size: 45 (155911)\n",
            "queue size: 44 (155925)\n",
            "queue size: 43 (155934)\n",
            "queue size: 42 (155905)\n",
            "queue size: 41 (155938)\n",
            "queue size: 40 (155922)\n",
            "queue size: 39 (155914)\n",
            "queue size: 38 (155913)\n",
            "queue size: 38 (155935)\n",
            "queue size: 36 (155912)\n",
            "queue size: 35 (155936)\n",
            "queue size: 34 (155910)\n",
            "queue size: 33 (155940)\n",
            "queue size: 32 (155923)\n",
            "queue size: 31 (155932)\n",
            "queue size: 30 (155909)\n",
            "queue size: 29 (155907)\n",
            "queue size: 28 (155906)\n",
            "queue size: 27 (155939)\n",
            "queue size: 26 (155918)\n",
            "queue size: 25 (155908)\n",
            "queue size: 24 (155916)\n",
            "queue size: 23 (155933)\n",
            "queue size: 22 (155931)\n",
            "queue size: 21 (155924)\n",
            "queue size: 20 (155937)\n",
            "queue size: 19 (155917)\n",
            "queue size: 18 (155915)\n",
            "queue size: 17 (155938)\n",
            "queue size: 16 (155911)\n",
            "queue size: 15 (155926)\n",
            "queue size: 14 (155925)\n",
            "queue size: 13 (155919)\n",
            "queue size: 12 (155939)\n",
            "queue size: 11 (155921)\n",
            "queue size: 10 (155913)\n",
            "queue size: 9 (155920)\n",
            "queue size: 8 (155905)\n",
            "queue size: 7 (155934)\n",
            "queue size: 6 (155910)\n",
            "queue size: 5 (155940)\n",
            "queue size: 4 (155935)\n",
            "queue size: 3 (155936)\n",
            "queue size: 2 (155912)\n",
            "queue size: 1 (155908)\n",
            "Worker (155923) finished. session_id: test_session_p155923_t140647843099264\n",
            "Worker (155922) finished. session_id: test_session_p155922_t140647843099264\n",
            "Worker (155914) finished. session_id: test_session_p155914_t140647843099264\n",
            "Worker (155907) finished. session_id: test_session_p155907_t140647843099264\n",
            "Worker (155931) finished. session_id: test_session_p155931_t140647843099264\n",
            "Worker (155933) finished. session_id: test_session_p155933_t140647843099264\n",
            "Worker (155909) finished. session_id: test_session_p155909_t140647843099264\n",
            "Worker (155916) finished. session_id: test_session_p155916_t140647843099264\n",
            "Worker (155932) finished. session_id: test_session_p155932_t140647843099264\n",
            "Worker (155906) finished. session_id: test_session_p155906_t140647843099264\n",
            "Worker (155926) finished. session_id: test_session_p155926_t140647843099264\n",
            "Worker (155937) finished. session_id: test_session_p155937_t140647843099264\n",
            "Worker (155939) finished. session_id: test_session_p155939_t140647843099264\n",
            "Worker (155918) finished. session_id: test_session_p155918_t140647843099264\n",
            "Worker (155915) finished. session_id: test_session_p155915_t140647843099264\n",
            "Worker (155917) finished. session_id: test_session_p155917_t140647843099264\n",
            "Worker (155919) finished. session_id: test_session_p155919_t140647843099264\n",
            "Worker (155911) finished. session_id: test_session_p155911_t140647843099264\n",
            "Worker (155938) finished. session_id: test_session_p155938_t140647843099264\n",
            "Worker (155921) finished. session_id: test_session_p155921_t140647843099264\n",
            "Worker (155924) finished. session_id: test_session_p155924_t140647843099264\n",
            "Worker (155905) finished. session_id: test_session_p155905_t140647843099264\n",
            "Worker (155934) finished. session_id: test_session_p155934_t140647843099264\n",
            "Worker (155925) finished. session_id: test_session_p155925_t140647843099264\n",
            "Worker (155910) finished. session_id: test_session_p155910_t140647843099264\n",
            "Worker (155920) finished. session_id: test_session_p155920_t140647843099264\n",
            "Worker (155935) finished. session_id: test_session_p155935_t140647843099264\n",
            "Worker (155913) finished. session_id: test_session_p155913_t140647843099264\n",
            "Worker (155936) finished. session_id: test_session_p155936_t140647843099264\n",
            "Worker (155908) finished. session_id: test_session_p155908_t140647843099264\n",
            "Worker (155912) finished. session_id: test_session_p155912_t140647843099264\n",
            "Worker (155940) finished. session_id: test_session_p155940_t140647843099264\n",
            "Deployment: llama2-7b-tp1-b768 Clients: 32, Prompt (mean): 2600 tokens, Generation (mean): 60 tokens, Query throughput: 3.294 queries/s, Token throughput (total): 280.758 tokens/s, Query latency: 9.715 s, Token generation latency: 0.081 s/token, First token received: 4.917 s\n",
            "+ echo 'Stopping server'\n",
            "Stopping server\n",
            "+ python server.py -d llama2-7b-tp1-b768 stop\n",
            "[2023-12-16 13:33:25,052] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "2023-12-16 13:33:27.237068: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:33:27.237121: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:33:27.238792: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:33:28.490677: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "running stop\n",
            "+ sleep 120\n",
            "[2023-12-16 13:33:31,824] [INFO] [launch.py:347:main] Process 132890 exits successfully.\n",
            "+ python plot_th_lat.py --log_dir . --test --no_vllm\n",
            "Found 11\n",
            "./logs.llama2-7b-tp1-b768/llama2-7b-tp1-b768_c24_p2600_g60.json\n",
            "./logs.llama2-7b-tp1-b768/llama2-7b-tp1-b768_c1_p2600_g60.json\n",
            "./logs.llama2-7b-tp1-b768/llama2-7b-tp1-b768_c6_p2600_g60.json\n",
            "./logs.llama2-7b-tp1-b768/llama2-7b-tp1-b768_c16_p2600_g60.json\n",
            "./logs.llama2-7b-tp1-b768/llama2-7b-tp1-b768_c32_p2600_g60.json\n",
            "./logs.llama2-7b-tp1-b768/llama2-7b-tp1-b768_c28_p2600_g60.json\n",
            "./logs.llama2-7b-tp1-b768/llama2-7b-tp1-b768_c8_p2600_g60.json\n",
            "./logs.llama2-7b-tp1-b768/llama2-7b-tp1-b768_c4_p2600_g60.json\n",
            "./logs.llama2-7b-tp1-b768/llama2-7b-tp1-b768_c2_p2600_g60.json\n",
            "./logs.llama2-7b-tp1-b768/llama2-7b-tp1-b768_c20_p2600_g60.json\n",
            "./logs.llama2-7b-tp1-b768/llama2-7b-tp1-b768_c12_p2600_g60.json\n",
            "Saving charts/throughput_latency/th_lat_curve_llama7b_tp1_p2600g60.png\n",
            "+ python plot_effective_throughput.py --log_dir . --test --no_vllm\n",
            "model: 7b Prompt: 2600, Generation: 60, TP: 1 sla_token_gen: 1\n",
            "Found 11 files\n",
            "Saved charts/goodtput/goodput_llama7b_SLAp512g1_tp1_b768_p2600g60_cum.png\n",
            "Found 11 files\n",
            "Saved charts/goodtput/goodput_llama7b_SLAp512g1_tp1_b768_p2600g60_ema16.png\n",
            "model: 7b Prompt: 2600, Generation: 60, TP: 1 sla_token_gen: 2\n",
            "Found 11 files\n",
            "Saved charts/goodtput/goodput_llama7b_SLAp512g2_tp1_b768_p2600g60_cum.png\n",
            "Found 11 files\n",
            "Saved charts/goodtput/goodput_llama7b_SLAp512g2_tp1_b768_p2600g60_ema16.png\n",
            "model: 7b Prompt: 2600, Generation: 60, TP: 1 sla_token_gen: 3\n",
            "Found 11 files\n",
            "Saved charts/goodtput/goodput_llama7b_SLAp512g3_tp1_b768_p2600g60_cum.png\n",
            "Found 11 files\n",
            "Saved charts/goodtput/goodput_llama7b_SLAp512g3_tp1_b768_p2600g60_ema16.png\n",
            "model: 7b Prompt: 2600, Generation: 60, TP: 1 sla_token_gen: 4\n",
            "Found 11 files\n",
            "Saved charts/goodtput/goodput_llama7b_SLAp512g4_tp1_b768_p2600g60_cum.png\n",
            "Found 11 files\n",
            "Saved charts/goodtput/goodput_llama7b_SLAp512g4_tp1_b768_p2600g60_ema16.png\n",
            "model: 7b Prompt: 2600, Generation: 60, TP: 1 sla_token_gen: 6\n",
            "Found 11 files\n",
            "Saved charts/goodtput/goodput_llama7b_SLAp512g6_tp1_b768_p2600g60_cum.png\n",
            "Found 11 files\n",
            "Saved charts/goodtput/goodput_llama7b_SLAp512g6_tp1_b768_p2600g60_ema16.png\n",
            "model: 7b Prompt: 2600, Generation: 60, TP: 1 sla_token_gen: 8\n",
            "Found 11 files\n",
            "Saved charts/goodtput/goodput_llama7b_SLAp512g8_tp1_b768_p2600g60_cum.png\n",
            "Found 11 files\n",
            "Saved charts/goodtput/goodput_llama7b_SLAp512g8_tp1_b768_p2600g60_ema16.png\n",
            "+ echo 'Find the plots in the charts directory and the logs inside logs.llama2-7b-tp1-b768'\n",
            "Find the plots in the charts directory and the logs inside logs.llama2-7b-tp1-b768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd DeepSpeedExamples/benchmarks/inference/mii && ls -gh logs.llama2-7b-tp1-b768/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdSmgVT22IQc",
        "outputId": "7d508ba5-90b9-466a-8462-0f91b8eae528"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 87M\n",
            "-rw-r--r-- 1 root  25K Dec 16 13:16 bench_client_num_c12_p2600_g60.log\n",
            "-rw-r--r-- 1 root  29K Dec 16 13:20 bench_client_num_c16_p2600_g60.log\n",
            "-rw-r--r-- 1 root  14K Dec 16 12:55 bench_client_num_c1_p2600_g60.log\n",
            "-rw-r--r-- 1 root  33K Dec 16 13:23 bench_client_num_c20_p2600_g60.log\n",
            "-rw-r--r-- 1 root  37K Dec 16 13:26 bench_client_num_c24_p2600_g60.log\n",
            "-rw-r--r-- 1 root  40K Dec 16 13:30 bench_client_num_c28_p2600_g60.log\n",
            "-rw-r--r-- 1 root  15K Dec 16 13:01 bench_client_num_c2_p2600_g60.log\n",
            "-rw-r--r-- 1 root  44K Dec 16 13:33 bench_client_num_c32_p2600_g60.log\n",
            "-rw-r--r-- 1 root  17K Dec 16 13:06 bench_client_num_c4_p2600_g60.log\n",
            "-rw-r--r-- 1 root  19K Dec 16 13:10 bench_client_num_c6_p2600_g60.log\n",
            "-rw-r--r-- 1 root  21K Dec 16 13:13 bench_client_num_c8_p2600_g60.log\n",
            "-rw-r--r-- 1 root 7.8M Dec 16 13:16 llama2-7b-tp1-b768_c12_p2600_g60.json\n",
            "-rw-r--r-- 1 root 7.8M Dec 16 13:20 llama2-7b-tp1-b768_c16_p2600_g60.json\n",
            "-rw-r--r-- 1 root 7.9M Dec 16 12:55 llama2-7b-tp1-b768_c1_p2600_g60.json\n",
            "-rw-r--r-- 1 root 7.8M Dec 16 13:23 llama2-7b-tp1-b768_c20_p2600_g60.json\n",
            "-rw-r--r-- 1 root 7.8M Dec 16 13:26 llama2-7b-tp1-b768_c24_p2600_g60.json\n",
            "-rw-r--r-- 1 root 7.8M Dec 16 13:30 llama2-7b-tp1-b768_c28_p2600_g60.json\n",
            "-rw-r--r-- 1 root 7.9M Dec 16 13:01 llama2-7b-tp1-b768_c2_p2600_g60.json\n",
            "-rw-r--r-- 1 root 7.8M Dec 16 13:33 llama2-7b-tp1-b768_c32_p2600_g60.json\n",
            "-rw-r--r-- 1 root 7.9M Dec 16 13:06 llama2-7b-tp1-b768_c4_p2600_g60.json\n",
            "-rw-r--r-- 1 root 7.9M Dec 16 13:10 llama2-7b-tp1-b768_c6_p2600_g60.json\n",
            "-rw-r--r-- 1 root 7.8M Dec 16 13:13 llama2-7b-tp1-b768_c8_p2600_g60.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd DeepSpeedExamples/benchmarks/inference/mii && ls -gh charts/goodtput/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLW-fSmg2Udh",
        "outputId": "1aaf1699-d02b-4de6-b5ec-d389467968e0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 480K\n",
            "-rw-r--r-- 1 root 38K Dec 16 13:37 goodput_llama7b_SLAp512g1_tp1_b768_p2600g60_cum.png\n",
            "-rw-r--r-- 1 root 38K Dec 16 13:38 goodput_llama7b_SLAp512g1_tp1_b768_p2600g60_ema16.png\n",
            "-rw-r--r-- 1 root 38K Dec 16 13:39 goodput_llama7b_SLAp512g2_tp1_b768_p2600g60_cum.png\n",
            "-rw-r--r-- 1 root 38K Dec 16 13:40 goodput_llama7b_SLAp512g2_tp1_b768_p2600g60_ema16.png\n",
            "-rw-r--r-- 1 root 38K Dec 16 13:40 goodput_llama7b_SLAp512g3_tp1_b768_p2600g60_cum.png\n",
            "-rw-r--r-- 1 root 38K Dec 16 13:41 goodput_llama7b_SLAp512g3_tp1_b768_p2600g60_ema16.png\n",
            "-rw-r--r-- 1 root 38K Dec 16 13:42 goodput_llama7b_SLAp512g4_tp1_b768_p2600g60_cum.png\n",
            "-rw-r--r-- 1 root 38K Dec 16 13:43 goodput_llama7b_SLAp512g4_tp1_b768_p2600g60_ema16.png\n",
            "-rw-r--r-- 1 root 38K Dec 16 13:44 goodput_llama7b_SLAp512g6_tp1_b768_p2600g60_cum.png\n",
            "-rw-r--r-- 1 root 38K Dec 16 13:45 goodput_llama7b_SLAp512g6_tp1_b768_p2600g60_ema16.png\n",
            "-rw-r--r-- 1 root 38K Dec 16 13:46 goodput_llama7b_SLAp512g8_tp1_b768_p2600g60_cum.png\n",
            "-rw-r--r-- 1 root 38K Dec 16 13:47 goodput_llama7b_SLAp512g8_tp1_b768_p2600g60_ema16.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL.Image\n",
        "\n",
        "img = PIL.Image.open('/content/DeepSpeedExamples/benchmarks/inference/mii/charts/goodtput/goodput_llama7b_SLAp512g8_tp1_b768_p2600g60_cum.png')\n",
        "img\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "6whVw8kzBGvM",
        "outputId": "b0756256-9680-42d7-a767-48c9f293bac2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=700x400>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL.Image\n",
        "\n",
        "img = PIL.Image.open('/content/DeepSpeedExamples/benchmarks/inference/mii/charts/goodtput/goodput_llama7b_SLAp512g8_tp1_b768_p2600g60_ema16.png')\n",
        "img\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "EDyiQ2ocA0LF",
        "outputId": "cabff2c4-83d9-441e-9586-2a707bdbdcc9"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=700x400>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd DeepSpeedExamples/benchmarks/inference/mii && ls -gh charts/throughput_latency/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2OUv7Hb2aFw",
        "outputId": "f57f09d1-e378-47f0-d308-a431aaf81a60"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 32K\n",
            "-rw-r--r-- 1 root 29K Dec 16 13:36 th_lat_curve_llama7b_tp1_p2600g60.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL.Image\n",
        "\n",
        "img = PIL.Image.open('/content/DeepSpeedExamples/benchmarks/inference/mii/charts/throughput_latency/th_lat_curve_llama7b_tp1_p2600g60.png')\n",
        "img\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "vVrdj5vZ_Psg",
        "outputId": "d4e890c6-398e-4b00-ef54-fdefc8efab29"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=600x400>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "```\n",
        "nvidia-smi --query-gpu=timestamp,memory.total,memory.free,memory.used,name,utilization.gpu,utilization.memory --format=csv -l 2\n",
        "timestamp, memory.total [MiB], memory.free [MiB], memory.used [MiB], name, utilization.gpu [%], utilization.memory [%]\n",
        "2023/12/16 12:45:16.063, 40960 MiB, 944 MiB, 39569 MiB, NVIDIA A100-SXM4-40GB, 85 %, 65 %\n",
        "2023/12/16 12:45:18.064, 40960 MiB, 944 MiB, 39569 MiB, NVIDIA A100-SXM4-40GB, 82 %, 67 %\n",
        "2023/12/16 12:45:20.065, 40960 MiB, 944 MiB, 39569 MiB, NVIDIA A100-SXM4-40GB, 83 %, 49 %\n",
        "2023/12/16 12:45:22.066, 40960 MiB, 944 MiB, 39569 MiB, NVIDIA A100-SXM4-40GB, 84 %, 66 %\n",
        "2023/12/16 12:45:24.067, 40960 MiB, 944 MiB, 39569 MiB, NVIDIA A100-SXM4-40GB, 81 %, 60 %\n",
        "2023/12/16 12:45:26.068, 40960 MiB, 944 MiB, 39569 MiB, NVIDIA A100-SXM4-40GB, 80 %, 63 %\n",
        "2023/12/16 12:45:28.070, 40960 MiB, 944 MiB, 39569 MiB, NVIDIA A100-SXM4-40GB, 85 %, 65 %\n",
        "2023/12/16 12:45:30.071, 40960 MiB, 944 MiB, 39569 MiB, NVIDIA A100-SXM4-40GB, 85 %, 64 %\n",
        "2023/12/16 12:45:32.071, 40960 MiB, 944 MiB, 39569 MiB, NVIDIA A100-SXM4-40GB, 88 %, 60 %\n",
        "2023/12/16 12:45:34.073, 40960 MiB, 944 MiB, 39569 MiB, NVIDIA A100-SXM4-40GB, 86 %, 69 %\n",
        "2023/12/16 12:45:36.074, 40960 MiB, 944 MiB, 39569 MiB, NVIDIA A100-SXM4-40GB, 85 %, 64 %\n",
        "2023/12/16 12:45:38.075, 40960 MiB, 944 MiB, 39569 MiB, NVIDIA A100-SXM4-40GB, 88 %, 68 %\n",
        "2023/12/16 12:45:40.076, 40960 MiB, 944 MiB, 39569 MiB, NVIDIA A100-SXM4-40GB, 88 %, 66 %\n",
        "2023/12/16 12:45:42.076, 40960 MiB, 944 MiB, 39569 MiB, NVIDIA A100-SXM4-40GB, 87 %, 63 %\n",
        "```"
      ],
      "metadata": {
        "id": "PrTwPSSOqM9O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd DeepSpeedExamples/benchmarks/inference/mii \\\n",
        "  && python server.py --model_name  mistralai/Mistral-7B-Instruct-v0.2 -d Mistral-7B-Instruct-tp1-b768 -m 1 -b 768 start"
      ],
      "metadata": {
        "id": "vE7zd6sGKAvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd DeepSpeedExamples/benchmarks/inference/mii && python server.py -d Mistral-7B-Instruct-tp1-b768 stop"
      ],
      "metadata": {
        "id": "sCqdAGzErqB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mixtral\n",
        "\n",
        "- https://docs.mistral.ai/models/\n",
        "\n",
        "- https://mistral.ai/news/la-plateforme/\n",
        "\n",
        "- https://mistral.ai/news/mixtral-of-experts/ （MoE）"
      ],
      "metadata": {
        "id": "MGxNbH0pDpBc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#cpu\n",
        "\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "#model_id = \"mistralai/Mixtral-8x7B-v0.1\"\n",
        "model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
        "\n",
        "text = \"Hello my name is\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens=20)\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "d5c19393cb7b4117b7bd688f47841854",
            "af743e24883b4fcbb71dcf66eb93085a",
            "bae633cf4dcb49e99c8d25523d3610e5",
            "644ab2e3208c4b16995fceaa011b51b7",
            "46251cd9b6424f7db36deab9304b7d6f",
            "f24376a0f88a4bd99f33c956f455d3b9",
            "2799064976bb4770b4336a17121b3c2d",
            "87dd4f8043364bbab0aa2351ef39ff0b",
            "f8b9a7fe2cf14cfda4dd0ee50e161293",
            "10d81750454a4f5cb04dc1c828c5a716",
            "8487d042de104b8c84ff8557a1dff6f2"
          ]
        },
        "id": "I8aNOlhyDqw1",
        "outputId": "2895b8a3-8afe-44cf-b7bf-0f198a3387c0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d5c19393cb7b4117b7bd688f47841854"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello my name is Kieran and I am a 21 year old student from the UK. I am currently studying for a degree in Computer Science and I have a strong passion for technology and programming. I have been using Linux for around 5 years now and I have a good understanding of the Linux operating system. I have experience with various distributions such as Ubuntu, Debian, Fedora, and Arch Linux. I am also familiar with various programming languages such as Python, Java, C++, and HTML/CSS. I am always looking to learn new things and expand my knowledge in technology and programming. I am also an avid gamer and I enjoy playing games on my Linux system. I hope to use this blog to share my experiences and knowledge with others and to learn from others as well. If you have any questions or comments, please feel free to leave them below. Thank you for visiting my blog!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#gpu\n",
        "\n",
        "\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "device = \"cuda\" # the device to load the model onto\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
        "\n",
        "# chat\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"What is your favourite condiment?\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"Well, I'm quite partial to a good squeeze of fresh lemon juice. It adds just the right amount of zesty flavour to whatever I'm cooking up in the kitchen!\"},\n",
        "    {\"role\": \"user\", \"content\": \"Do you have mayonnaise recipes?\"}\n",
        "]\n",
        "\n",
        "encodeds = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\n",
        "\n",
        "model_inputs = encodeds.to(device)\n",
        "model.to(device)\n",
        "\n",
        "generated_ids = model.generate(model_inputs, max_new_tokens=1000, do_sample=True)\n",
        "decoded = tokenizer.batch_decode(generated_ids)\n",
        "print(decoded[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416,
          "referenced_widgets": [
            "d1205f4faf404c948a7401d068e7d2e4",
            "2adba48cf5264d5aaddd72c180574a87",
            "5614398ae73141beb9be5ce378396562",
            "473bbaf77f594a91a2fdf7a7407238e1",
            "38f55f15bf41448581e3569d0ac6b4e5",
            "1fac98800ce24d49b7d16cbfd52fd186",
            "d908ebff12c542a3ac4722cf9e6bacbd",
            "87ee759a9bed45d3ab0e23f0d05b5380",
            "5ed40000a5b149b8bcba39aabe1f08a7",
            "773e91d0e97a498a8178fe8ce8fa9e55",
            "15fe3103f7004f1780ae34829bdc6000"
          ]
        },
        "id": "jBQ9oz6_Hdmm",
        "outputId": "5c321d2c-fcab-46a4-fc63-160c600aff80"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d1205f4faf404c948a7401d068e7d2e4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> [INST] What is your favourite condiment? [/INST]Well, I'm quite partial to a good squeeze of fresh lemon juice. It adds just the right amount of zesty flavour to whatever I'm cooking up in the kitchen!</s> [INST] Do you have mayonnaise recipes? [/INST] Yes, I can share a simple and classic homemade mayonnaise recipe with you. Here's what you'll need:\n",
            "\n",
            "Ingredients:\n",
            "- 1 egg yolk\n",
            "- 1 tablespoon Dijon mustard\n",
            "- 1 cup (200 ml) vegetable oil\n",
            "- 1 tablespoon white wine vinegar\n",
            "- 1 tablespoon water\n",
            "- Salt to taste\n",
            "\n",
            "Instructions:\n",
            "1. In a medium bowl, whisk together the egg yolk and Dijon mustard until they are well combined.\n",
            "2. Start adding the oil very slowly, drop by drop, while constantly whisking the mixture. This is an important step to prevent the oil from separating from the yolk and creating an oily mess. Once the oil has been fully incorporated, you can start adding it in a thin stream.\n",
            "3. When about half of the oil has been added, you can start adding the white wine vinegar and water in a thin stream while continuously whisking.\n",
            "4. Once you have added all the oil, vinegar and water, whisk in a small pinch of salt to taste.\n",
            "5. Your homemade mayonnaise is now ready to use! Storer the mayonnaise in the refrigerator in an airtight container to keep for up to one week.\n",
            "\n",
            "Enjoy your homemade mayonnaise on sandwiches, burgers, or as a dip for your favorite vegetables!</s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sleep 7200"
      ],
      "metadata": {
        "id": "eq1jiR2vBE3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TensorRT"
      ],
      "metadata": {
        "id": "JAc12FCsioE_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://developer.nvidia.com/tensorrt\n",
        "%%bash\n",
        "os=\"ubuntu2204\"\n",
        "#tag=\"9.2.0-cuda-12.2\"\n",
        "tag=\"8.6.1-cuda-12.2\"\n",
        "sudo dpkg -i nv-tensorrt-local-repo-${os}-${tag}_1.0-1_amd64.deb\n",
        "sudo cp /var/nv-tensorrt-local-repo-${os}-${tag}/*-keyring.gpg /usr/share/keyrings/\n",
        "sudo apt-get update\n",
        "\n",
        "# if no, need install the last tensorrt version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRe4ghvMXP06",
        "outputId": "24a8a0cc-1f01-449d-ba70-8aa9ffd397cc"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "dpkg: error: cannot access archive 'nv-tensorrt-local-repo-ubuntu2204-8.6.1-cuda-12.2_1.0-1_amd64.deb': No such file or directory\n",
            "cp: cannot stat '/var/nv-tensorrt-local-repo-ubuntu2204-8.6.1-cuda-12.2/*-keyring.gpg': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/NVIDIA/TensorRT.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8RpicCPiqrN",
        "outputId": "1df53369-316a-424e-9ebe-90faf4a2c848"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'TensorRT'...\n",
            "remote: Enumerating objects: 17205, done.\u001b[K\n",
            "remote: Counting objects: 100% (2236/2236), done.\u001b[K\n",
            "remote: Compressing objects: 100% (507/507), done.\u001b[K\n",
            "remote: Total 17205 (delta 1796), reused 1869 (delta 1720), pack-reused 14969\u001b[K\n",
            "Receiving objects: 100% (17205/17205), 101.66 MiB | 15.75 MiB/s, done.\n",
            "Resolving deltas: 100% (12185/12185), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd TensorRT && git checkout v9.2.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nO6JiZg-i2OS",
        "outputId": "2547e1be-6196-458b-caaa-26af62e90f35"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Note: switching to 'v9.2.0'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by switching back to a branch.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -c with the switch command. Example:\n",
            "\n",
            "  git switch -c <new-branch-name>\n",
            "\n",
            "Or undo this operation with:\n",
            "\n",
            "  git switch -\n",
            "\n",
            "Turn off this advice by setting config variable advice.detachedHead to false\n",
            "\n",
            "HEAD is now at a1820ecd Fix some typos in Readme.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd TensorRT && git submodule update --init --recursive\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62oXlzBNi-r7",
        "outputId": "0a5bfd7f-5b42-4b66-9a44-7620ece71321"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submodule 'parsers/onnx' (https://github.com/onnx/onnx-tensorrt.git) registered for path 'parsers/onnx'\n",
            "Submodule 'third_party/cub' (https://github.com/NVlabs/cub.git) registered for path 'third_party/cub'\n",
            "Submodule 'third_party/protobuf' (https://github.com/protocolbuffers/protobuf.git) registered for path 'third_party/protobuf'\n",
            "Cloning into '/content/TensorRT/parsers/onnx'...\n",
            "Cloning into '/content/TensorRT/third_party/cub'...\n",
            "Cloning into '/content/TensorRT/third_party/protobuf'...\n",
            "Submodule path 'parsers/onnx': checked out '6ba67d3428e05f690145373ca87fb8d32f98df45'\n",
            "Submodule 'third_party/onnx' (https://github.com/onnx/onnx.git) registered for path 'parsers/onnx/third_party/onnx'\n",
            "Cloning into '/content/TensorRT/parsers/onnx/third_party/onnx'...\n",
            "Submodule path 'parsers/onnx/third_party/onnx': checked out 'ad834eb73ee0cd9b6fa9ea892caeed5fa17d7dc0'\n",
            "Submodule 'third_party/benchmark' (https://github.com/google/benchmark.git) registered for path 'parsers/onnx/third_party/onnx/third_party/benchmark'\n",
            "Submodule 'third_party/pybind11' (https://github.com/pybind/pybind11.git) registered for path 'parsers/onnx/third_party/onnx/third_party/pybind11'\n",
            "Cloning into '/content/TensorRT/parsers/onnx/third_party/onnx/third_party/benchmark'...\n",
            "Cloning into '/content/TensorRT/parsers/onnx/third_party/onnx/third_party/pybind11'...\n",
            "Submodule path 'parsers/onnx/third_party/onnx/third_party/benchmark': checked out '0d98dba29d66e93259db7daa53a9327df767a415'\n",
            "Submodule path 'parsers/onnx/third_party/onnx/third_party/pybind11': checked out '914c06fb252b6cc3727d0eedab6736e88a3fcb01'\n",
            "Submodule path 'third_party/cub': checked out 'c3cceac115c072fb63df1836ff46d8c60d9eb304'\n",
            "Submodule path 'third_party/protobuf': checked out 'aea4a275e28329f648e046469c095eef74254bb2'\n",
            "Submodule 'third_party/benchmark' (https://github.com/google/benchmark.git) registered for path 'third_party/protobuf/third_party/benchmark'\n",
            "Submodule 'third_party/googletest' (https://github.com/google/googletest.git) registered for path 'third_party/protobuf/third_party/googletest'\n",
            "Cloning into '/content/TensorRT/third_party/protobuf/third_party/benchmark'...\n",
            "Cloning into '/content/TensorRT/third_party/protobuf/third_party/googletest'...\n",
            "Submodule path 'third_party/protobuf/third_party/benchmark': checked out '5b7683f49e1e9223cf9927b24f6fd3d6bd82e3f8'\n",
            "Submodule path 'third_party/protobuf/third_party/googletest': checked out '5ec7f0c4a113e2f18ac2c6cc7df51ad6afc24081'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd TensorRT && cmake -B build -S ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDX6FIy8jPtV",
        "outputId": "463aa41f-f8f8-4a11-eb51-3b41b0a2079f"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0mBuilding for TensorRT version: 8.6.1, library version: 8\u001b[0m\n",
            "-- The CXX compiler identification is GNU 11.4.0\n",
            "-- The CUDA compiler identification is NVIDIA 12.2.140\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Check for working CXX compiler: /usr/bin/g++ - skipped\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Detecting CUDA compiler ABI info\n",
            "-- Detecting CUDA compiler ABI info - done\n",
            "-- Check for working CUDA compiler: /usr/local/cuda/bin/nvcc - skipped\n",
            "-- Detecting CUDA compile features\n",
            "-- Detecting CUDA compile features - done\n",
            "-- Targeting TRT Platform: x86_64\n",
            "-- CUDA version set to 12.0.1\n",
            "-- cuDNN version set to 8.8\n",
            "-- Protobuf version set to 3.20.1\n",
            "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
            "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success\n",
            "-- Found Threads: TRUE  \n",
            "\u001b[33mCMake Warning (dev) at CMakeLists.txt:116 (find_package):\n",
            "  Policy CMP0146 is not set: The FindCUDA module is removed.  Run \"cmake\n",
            "  --help-policy CMP0146\" for policy details.  Use the cmake_policy command to\n",
            "  set the policy and suppress this warning.\n",
            "\n",
            "This warning is for project developers.  Use -Wno-dev to suppress it.\n",
            "\u001b[0m\n",
            "-- Found CUDA: /usr/local/cuda (found suitable version \"12.0.1\", minimum required is \"12.0.1\") \n",
            "\u001b[33mCMake Warning (dev) at /usr/local/lib/python3.10/dist-packages/cmake/data/share/cmake-3.27/Modules/ExternalProject.cmake:3136 (message):\n",
            "  The DOWNLOAD_EXTRACT_TIMESTAMP option was not given and policy CMP0135 is\n",
            "  not set.  The policy's OLD behavior will be used.  When using a URL\n",
            "  download, the timestamps of extracted files should preferably be that of\n",
            "  the time of extraction, otherwise code that depends on the extracted\n",
            "  contents might not be rebuilt if the URL changes.  The OLD behavior\n",
            "  preserves the timestamps from the archive instead, but this is usually not\n",
            "  what you want.  Update your project to the NEW behavior or specify the\n",
            "  DOWNLOAD_EXTRACT_TIMESTAMP option with a value of true to avoid this\n",
            "  robustness issue.\n",
            "Call Stack (most recent call first):\n",
            "  /usr/local/lib/python3.10/dist-packages/cmake/data/share/cmake-3.27/Modules/ExternalProject.cmake:4345 (_ep_add_download_command)\n",
            "  third_party/protobuf.cmake:30 (ExternalProject_Add)\n",
            "  CMakeLists.txt:130 (configure_protobuf)\n",
            "This warning is for project developers.  Use -Wno-dev to suppress it.\n",
            "\u001b[0m\n",
            "-- Using libprotobuf /content/TensorRT/build/third_party.protobuf/lib/libprotobuf.a\n",
            "-- ========================= Importing and creating target nvinfer ==========================\n",
            "-- Looking for library nvinfer\n",
            "-- Library that was found nvinfer_LIB_PATH-NOTFOUND\n",
            "-- ==========================================================================================\n",
            "-- ========================= Importing and creating target nvuffparser ==========================\n",
            "-- Looking for library nvparsers\n",
            "-- Library that was found nvparsers_LIB_PATH-NOTFOUND\n",
            "-- ==========================================================================================\n",
            "-- GPU_ARCHS is not defined. Generating CUDA code for default SMs: 53;60;61;70;75;80;86\n",
            "-- Protobuf proto/trtcaffe.proto -> proto/trtcaffe.pb.cc proto/trtcaffe.pb.h\n",
            "-- /content/TensorRT/build/parsers/caffe\n",
            "-- The C compiler identification is GNU 11.4.0\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Check for working C compiler: /usr/bin/cc - skipped\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "\u001b[0mCMake Deprecation Warning at parsers/onnx/third_party/onnx/CMakeLists.txt:2 (cmake_minimum_required):\n",
            "  Compatibility with CMake < 3.5 will be removed from a future version of\n",
            "  CMake.\n",
            "\n",
            "  Update the VERSION argument <min> value or use a ...<max> suffix to tell\n",
            "  CMake that the project does not need compatibility with older versions.\n",
            "\n",
            "\u001b[0m\n",
            "-- Build type not set - defaulting to Release\n",
            "\u001b[33mCMake Warning (dev) at parsers/onnx/third_party/onnx/CMakeLists.txt:119 (find_package):\n",
            "  Policy CMP0148 is not set: The FindPythonInterp and FindPythonLibs modules\n",
            "  are removed.  Run \"cmake --help-policy CMP0148\" for policy details.  Use\n",
            "  the cmake_policy command to set the policy and suppress this warning.\n",
            "\n",
            "This warning is for project developers.  Use -Wno-dev to suppress it.\n",
            "\u001b[0m\n",
            "-- Found PythonInterp: /usr/local/bin/python (found version \"3.10.12\") \n",
            "\u001b[0mGenerated: /content/TensorRT/build/parsers/onnx/third_party/onnx/onnx/onnx_onnx2trt_onnx-ml.proto\u001b[0m\n",
            "\u001b[0mGenerated: /content/TensorRT/build/parsers/onnx/third_party/onnx/onnx/onnx-operators_onnx2trt_onnx-ml.proto\u001b[0m\n",
            "\u001b[0mGenerated: /content/TensorRT/build/parsers/onnx/third_party/onnx/onnx/onnx-data_onnx2trt_onnx.proto\u001b[0m\n",
            "-- \n",
            "-- ******** Summary ********\n",
            "--   CMake version             : 3.27.9\n",
            "--   CMake command             : /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake\n",
            "--   System                    : Linux\n",
            "--   C++ compiler              : /usr/bin/g++\n",
            "--   C++ compiler version      : 11.4.0\n",
            "--   CXX flags                 : -Wno-deprecated-declarations  -DBUILD_SYSTEM=cmake_oss -Wall -Wno-deprecated-declarations -Wno-unused-function -Wnon-virtual-dtor\n",
            "--   Build type                : Release\n",
            "--   Compile definitions       : _PROTOBUF_INSTALL_DIR=/content/TensorRT/build;SOURCE_LENGTH=18;ONNX_NAMESPACE=onnx2trt_onnx;__STDC_FORMAT_MACROS\n",
            "--   CMAKE_PREFIX_PATH         : \n",
            "--   CMAKE_INSTALL_PREFIX      : /content/TensorRT/build/..\n",
            "--   CMAKE_MODULE_PATH         : \n",
            "-- \n",
            "--   ONNX version              : 1.13.1\n",
            "--   ONNX NAMESPACE            : onnx2trt_onnx\n",
            "--   ONNX_USE_LITE_PROTO       : OFF\n",
            "--   USE_PROTOBUF_SHARED_LIBS  : OFF\n",
            "--   Protobuf_USE_STATIC_LIBS  : ON\n",
            "--   ONNX_DISABLE_EXCEPTIONS   : OFF\n",
            "--   ONNX_WERROR               : OFF\n",
            "--   ONNX_BUILD_TESTS          : OFF\n",
            "--   ONNX_BUILD_BENCHMARKS     : OFF\n",
            "-- \n",
            "--   Protobuf compiler         : \n",
            "--   Protobuf includes         : \n",
            "--   Protobuf libraries        : \n",
            "--   BUILD_ONNX_PYTHON         : OFF\n",
            "-- Found CUDA headers at /usr/local/cuda/include\n",
            "-- Found TensorRT headers at /content/TensorRT/include\n",
            "-- Find TensorRT libs at TENSORRT_LIBRARY_INFER-NOTFOUND;TENSORRT_LIBRARY_INFER_PLUGIN-NOTFOUND\n",
            "-- Could NOT find TENSORRT (missing: TENSORRT_LIBRARY) \n",
            "\u001b[0mERRORCannot find TensorRT library.\u001b[0m\n",
            "\u001b[0mONNX_INCLUDE_DIR\u001b[0m\n",
            "-- Adding new sample: sample_algorithm_selector\n",
            "--     - Parsers Used: uff;caffe;onnx\n",
            "--     - InferPlugin Used: OFF\n",
            "--     - Licensing: samples\n",
            "\u001b[0mONNX_INCLUDE_DIR\u001b[0m\n",
            "-- Adding new sample: sample_char_rnn\n",
            "--     - Parsers Used: uff;caffe;onnx\n",
            "--     - InferPlugin Used: OFF\n",
            "--     - Licensing: samples\n",
            "\u001b[0mONNX_INCLUDE_DIR\u001b[0m\n",
            "-- Adding new sample: sample_dynamic_reshape\n",
            "--     - Parsers Used: onnx\n",
            "--     - InferPlugin Used: OFF\n",
            "--     - Licensing: samples\n",
            "\u001b[0mONNX_INCLUDE_DIR\u001b[0m\n",
            "-- Adding new sample: sample_int8_api\n",
            "--     - Parsers Used: onnx\n",
            "--     - InferPlugin Used: OFF\n",
            "--     - Licensing: samples\n",
            "\u001b[0mONNX_INCLUDE_DIR\u001b[0m\n",
            "-- Adding new sample: sample_onnx_mnist\n",
            "--     - Parsers Used: onnx\n",
            "--     - InferPlugin Used: OFF\n",
            "--     - Licensing: samples\n",
            "\u001b[0mONNX_INCLUDE_DIR\u001b[0m\n",
            "-- Adding new sample: sample_io_formats\n",
            "--     - Parsers Used: uff;caffe;onnx\n",
            "--     - InferPlugin Used: OFF\n",
            "--     - Licensing: samples\n",
            "\u001b[0mONNX_INCLUDE_DIR\u001b[0m\n",
            "-- Adding new sample: sample_onnx_mnist_coord_conv_ac\n",
            "--     - Parsers Used: onnx\n",
            "--     - InferPlugin Used: ON\n",
            "--     - Licensing: samples\n",
            "\u001b[0mONNX_INCLUDE_DIR\u001b[0m\n",
            "-- Adding new sample: sample_named_dimensions\n",
            "--     - Parsers Used: onnx\n",
            "--     - InferPlugin Used: OFF\n",
            "--     - Licensing: samples\n",
            "\u001b[0mONNX_INCLUDE_DIR\u001b[0m\n",
            "-- Adding new sample: trtexec\n",
            "--     - Parsers Used: caffe;uff;onnx\n",
            "--     - InferPlugin Used: OFF\n",
            "--     - Licensing: samples\n",
            "-- Configuring done (3.2s)\n",
            "\u001b[0mCMake Error: The following variables are used in this project, but they are set to NOTFOUND.\n",
            "Please set them or make sure they are set and tested correctly in the CMake files:\n",
            "TENSORRT_LIBRARY_INFER\n",
            "    linked by target \"nvonnxparser_static\" in directory /content/TensorRT/parsers/onnx\n",
            "    linked by target \"nvonnxparser\" in directory /content/TensorRT/parsers/onnx\n",
            "TENSORRT_LIBRARY_INFER_PLUGIN\n",
            "    linked by target \"nvonnxparser_static\" in directory /content/TensorRT/parsers/onnx\n",
            "    linked by target \"nvonnxparser\" in directory /content/TensorRT/parsers/onnx\n",
            "nvinfer_LIB_PATH\n",
            "    linked by target \"nvinfer_plugin\" in directory /content/TensorRT/plugin\n",
            "\u001b[0m\n",
            "\u001b[33mCMake Warning (dev) in plugin/CMakeLists.txt:\n",
            "  Policy CMP0104 is not set: CMAKE_CUDA_ARCHITECTURES now detected for NVCC,\n",
            "  empty CUDA_ARCHITECTURES not allowed.  Run \"cmake --help-policy CMP0104\"\n",
            "  for policy details.  Use the cmake_policy command to set the policy and\n",
            "  suppress this warning.\n",
            "\n",
            "  CUDA_ARCHITECTURES is empty for target \"nvinfer_plugin\".\n",
            "This warning is for project developers.  Use -Wno-dev to suppress it.\n",
            "\u001b[0m\n",
            "\u001b[33mCMake Warning (dev) in plugin/CMakeLists.txt:\n",
            "  Policy CMP0104 is not set: CMAKE_CUDA_ARCHITECTURES now detected for NVCC,\n",
            "  empty CUDA_ARCHITECTURES not allowed.  Run \"cmake --help-policy CMP0104\"\n",
            "  for policy details.  Use the cmake_policy command to set the policy and\n",
            "  suppress this warning.\n",
            "\n",
            "  CUDA_ARCHITECTURES is empty for target \"nvinfer_plugin_static\".\n",
            "This warning is for project developers.  Use -Wno-dev to suppress it.\n",
            "\u001b[0m\n",
            "-- Generating done (0.2s)\n",
            "\u001b[0mCMake Generate step failed.  Build files cannot be regenerated correctly.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd TensorRT && make -C build"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6KUgnYPj0Yp",
        "outputId": "7b2ddf12-acae-4dfd-9cdc-813a116c5dad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "make: Entering directory '/content/TensorRT/build'\n",
            "make[1]: Entering directory '/content/TensorRT/build'\n",
            "make[2]: Entering directory '/content/TensorRT/build'\n",
            "make[2]: Leaving directory '/content/TensorRT/build'\n",
            "make[2]: Entering directory '/content/TensorRT/build'\n",
            "[  0%] \u001b[34m\u001b[1mCreating directories for 'third_party.protobuf'\u001b[0m\n",
            "[  1%] \u001b[34m\u001b[1mPerforming download step (download, verify and extract) for 'third_party.protobuf'\u001b[0m\n",
            "-- Downloading...\n",
            "   dst='/content/TensorRT/build/third_party.protobuf/src/protobuf-cpp-3.20.1.tar.gz'\n",
            "   timeout='none'\n",
            "   inactivity timeout='none'\n",
            "-- Using src='https://github.com/google/protobuf/releases/download/v3.20.1/protobuf-cpp-3.20.1.tar.gz'\n",
            "-- [download 1% complete]\n",
            "-- [download 2% complete]\n",
            "-- [download 4% complete]\n",
            "-- [download 5% complete]\n",
            "-- [download 7% complete]\n",
            "-- [download 10% complete]\n",
            "-- [download 11% complete]\n",
            "-- [download 12% complete]\n",
            "-- [download 14% complete]\n",
            "-- [download 16% complete]\n",
            "-- [download 26% complete]\n",
            "-- [download 27% complete]\n",
            "-- [download 30% complete]\n",
            "-- [download 38% complete]\n",
            "-- [download 40% complete]\n",
            "-- [download 74% complete]\n",
            "-- [download 100% complete]\n",
            "-- Downloading... done\n",
            "-- extracting...\n",
            "     src='/content/TensorRT/build/third_party.protobuf/src/protobuf-cpp-3.20.1.tar.gz'\n",
            "     dst='/content/TensorRT/build/third_party.protobuf/src/third_party.protobuf'\n",
            "-- extracting... [tar xfz]\n",
            "-- extracting... [analysis]\n",
            "-- extracting... [rename]\n",
            "-- extracting... [clean up]\n",
            "-- extracting... done\n",
            "[  1%] \u001b[34m\u001b[1mNo update step for 'third_party.protobuf'\u001b[0m\n",
            "[  1%] \u001b[34m\u001b[1mNo patch step for 'third_party.protobuf'\u001b[0m\n",
            "[  1%] \u001b[34m\u001b[1mPerforming configure step for 'third_party.protobuf'\u001b[0m\n",
            "-- The C compiler identification is GNU 11.4.0\n",
            "-- The CXX compiler identification is GNU 11.4.0\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Check for working C compiler: /usr/bin/gcc - skipped\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Check for working CXX compiler: /usr/bin/g++ - skipped\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- \n",
            "-- 3.20.1.0\n",
            "-- Performing Test protobuf_HAVE_LD_VERSION_SCRIPT\n",
            "-- Performing Test protobuf_HAVE_LD_VERSION_SCRIPT - Success\n",
            "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
            "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success\n",
            "-- Found Threads: TRUE  \n",
            "-- Found ZLIB: /usr/lib/x86_64-linux-gnu/libz.so (found version \"1.2.11\")  \n",
            "-- Performing Test protobuf_HAVE_BUILTIN_ATOMICS\n",
            "-- Performing Test protobuf_HAVE_BUILTIN_ATOMICS - Success\n",
            "-- Configuring done (0.7s)\n",
            "-- Generating done (0.0s)\n",
            "-- Build files have been written to: /content/TensorRT/build/third_party.protobuf/src/third_party.protobuf\n",
            "[  1%] \u001b[34m\u001b[1mPerforming build step for 'third_party.protobuf'\u001b[0m\n",
            "make[3]: Entering directory '/content/TensorRT/build/third_party.protobuf/src/third_party.protobuf'\n",
            "make[4]: Entering directory '/content/TensorRT/build/third_party.protobuf/src/third_party.protobuf'\n",
            "make[5]: Entering directory '/content/TensorRT/build/third_party.protobuf/src/third_party.protobuf'\n",
            "make[5]: Leaving directory '/content/TensorRT/build/third_party.protobuf/src/third_party.protobuf'\n",
            "make[5]: Entering directory '/content/TensorRT/build/third_party.protobuf/src/third_party.protobuf'\n",
            "[  0%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf-lite.dir/src/google/protobuf/any_lite.cc.o\u001b[0m\n",
            "[  1%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf-lite.dir/src/google/protobuf/arena.cc.o\u001b[0m\n",
            "[  1%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf-lite.dir/src/google/protobuf/arenastring.cc.o\u001b[0m\n",
            "[  2%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf-lite.dir/src/google/protobuf/arenaz_sampler.cc.o\u001b[0m\n",
            "[  2%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf-lite.dir/src/google/protobuf/extension_set.cc.o\u001b[0m\n",
            "[  3%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf-lite.dir/src/google/protobuf/generated_enum_util.cc.o\u001b[0m\n",
            "[  3%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf-lite.dir/src/google/protobuf/generated_message_tctable_lite.cc.o\u001b[0m\n",
            "In file included from \u001b[01m\u001b[K/content/TensorRT/build/third_party.protobuf/src/third_party.protobuf/src/google/protobuf/generated_message_tctable_lite.cc:36\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/TensorRT/build/third_party.protobuf/src/third_party.protobuf/src/google/protobuf/generated_message_tctable_impl.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid google_private::protobuf::internal::AlignFail(uintptr_t) [with long unsigned int align = 4]\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/TensorRT/build/third_party.protobuf/src/third_party.protobuf/src/google/protobuf/generated_message_tctable_impl.h:256:1:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Knoreturn\u001b[m\u001b[K’ function does return\n",
            "  256 | \u001b[01;35m\u001b[K}\u001b[m\u001b[K\n",
            "      | \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TensorRT/build/third_party.protobuf/src/third_party.protobuf/src/google/protobuf/generated_message_tctable_impl.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid google_private::protobuf::internal::AlignFail(uintptr_t) [with long unsigned int align = 8]\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/TensorRT/build/third_party.protobuf/src/third_party.protobuf/src/google/protobuf/generated_message_tctable_impl.h:256:1:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Knoreturn\u001b[m\u001b[K’ function does return\n",
            "[  4%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf-lite.dir/src/google/protobuf/generated_message_util.cc.o\u001b[0m\n",
            "[  4%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf-lite.dir/src/google/protobuf/implicit_weak_message.cc.o\u001b[0m\n",
            "[  5%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf-lite.dir/src/google/protobuf/inlined_string_field.cc.o\u001b[0m\n",
            "[  5%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf-lite.dir/src/google/protobuf/io/coded_stream.cc.o\u001b[0m\n",
            "[  6%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf-lite.dir/src/google/protobuf/io/io_win32.cc.o\u001b[0m\n",
            "[  6%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf-lite.dir/src/google/protobuf/io/strtod.cc.o\u001b[0m\n",
            "[  7%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf-lite.dir/src/google/protobuf/io/zero_copy_stream.cc.o\u001b[0m\n",
            "[  7%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf-lite.dir/src/google/protobuf/io/zero_copy_stream_impl.cc.o\u001b[0m\n",
            "[  8%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf-lite.dir/src/google/protobuf/io/zero_copy_stream_impl_lite.cc.o\u001b[0m\n",
            "[  8%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf-lite.dir/src/google/protobuf/map.cc.o\u001b[0m\n",
            "[  9%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf-lite.dir/src/google/protobuf/message_lite.cc.o\u001b[0m\n",
            "[  9%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf-lite.dir/src/google/protobuf/parse_context.cc.o\u001b[0m\n",
            "[  9%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf-lite.dir/src/google/protobuf/repeated_field.cc.o\u001b[0m\n",
            "[ 10%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf-lite.dir/src/google/protobuf/repeated_ptr_field.cc.o\u001b[0m\n",
            "[ 10%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf-lite.dir/src/google/protobuf/stubs/bytestream.cc.o\u001b[0m\n",
            "[ 11%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf-lite.dir/src/google/protobuf/stubs/common.cc.o\u001b[0m\n",
            "[ 11%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf-lite.dir/src/google/protobuf/stubs/int128.cc.o\u001b[0m\n",
            "[ 12%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf-lite.dir/src/google/protobuf/stubs/status.cc.o\u001b[0m\n",
            "[ 12%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf-lite.dir/src/google/protobuf/stubs/statusor.cc.o\u001b[0m\n",
            "[ 13%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf-lite.dir/src/google/protobuf/stubs/stringpiece.cc.o\u001b[0m\n",
            "[ 13%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf-lite.dir/src/google/protobuf/stubs/stringprintf.cc.o\u001b[0m\n",
            "[ 14%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf-lite.dir/src/google/protobuf/stubs/structurally_valid.cc.o\u001b[0m\n",
            "[ 14%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf-lite.dir/src/google/protobuf/stubs/strutil.cc.o\u001b[0m\n",
            "[ 15%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf-lite.dir/src/google/protobuf/stubs/time.cc.o\u001b[0m\n",
            "[ 15%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf-lite.dir/src/google/protobuf/wire_format_lite.cc.o\u001b[0m\n",
            "[ 16%] \u001b[32m\u001b[1mLinking CXX static library libprotobuf-lite.a\u001b[0m\n",
            "make[5]: Leaving directory '/content/TensorRT/build/third_party.protobuf/src/third_party.protobuf'\n",
            "[ 16%] Built target libprotobuf-lite\n",
            "make[5]: Entering directory '/content/TensorRT/build/third_party.protobuf/src/third_party.protobuf'\n",
            "make[5]: Leaving directory '/content/TensorRT/build/third_party.protobuf/src/third_party.protobuf'\n",
            "make[5]: Entering directory '/content/TensorRT/build/third_party.protobuf/src/third_party.protobuf'\n",
            "[ 16%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/any_lite.cc.o\u001b[0m\n",
            "[ 16%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/arena.cc.o\u001b[0m\n",
            "[ 17%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/arenastring.cc.o\u001b[0m\n",
            "[ 17%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/arenaz_sampler.cc.o\u001b[0m\n",
            "[ 18%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/extension_set.cc.o\u001b[0m\n",
            "[ 18%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/generated_enum_util.cc.o\u001b[0m\n",
            "[ 19%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/generated_message_tctable_lite.cc.o\u001b[0m\n",
            "In file included from \u001b[01m\u001b[K/content/TensorRT/build/third_party.protobuf/src/third_party.protobuf/src/google/protobuf/generated_message_tctable_lite.cc:36\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/TensorRT/build/third_party.protobuf/src/third_party.protobuf/src/google/protobuf/generated_message_tctable_impl.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid google_private::protobuf::internal::AlignFail(uintptr_t) [with long unsigned int align = 4]\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/TensorRT/build/third_party.protobuf/src/third_party.protobuf/src/google/protobuf/generated_message_tctable_impl.h:256:1:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Knoreturn\u001b[m\u001b[K’ function does return\n",
            "  256 | \u001b[01;35m\u001b[K}\u001b[m\u001b[K\n",
            "      | \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TensorRT/build/third_party.protobuf/src/third_party.protobuf/src/google/protobuf/generated_message_tctable_impl.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid google_private::protobuf::internal::AlignFail(uintptr_t) [with long unsigned int align = 8]\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/TensorRT/build/third_party.protobuf/src/third_party.protobuf/src/google/protobuf/generated_message_tctable_impl.h:256:1:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Knoreturn\u001b[m\u001b[K’ function does return\n",
            "[ 19%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/generated_message_util.cc.o\u001b[0m\n",
            "[ 20%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/implicit_weak_message.cc.o\u001b[0m\n",
            "[ 20%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/inlined_string_field.cc.o\u001b[0m\n",
            "[ 21%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/io/coded_stream.cc.o\u001b[0m\n",
            "[ 21%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/io/io_win32.cc.o\u001b[0m\n",
            "[ 22%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/io/strtod.cc.o\u001b[0m\n",
            "[ 22%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/io/zero_copy_stream.cc.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/io/zero_copy_stream_impl.cc.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/io/zero_copy_stream_impl_lite.cc.o\u001b[0m\n",
            "[ 24%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/map.cc.o\u001b[0m\n",
            "[ 24%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/message_lite.cc.o\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/parse_context.cc.o\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/repeated_field.cc.o\u001b[0m\n",
            "[ 26%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/repeated_ptr_field.cc.o\u001b[0m\n",
            "[ 26%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/stubs/bytestream.cc.o\u001b[0m\n",
            "[ 27%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/stubs/common.cc.o\u001b[0m\n",
            "[ 27%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/stubs/int128.cc.o\u001b[0m\n",
            "[ 28%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/stubs/status.cc.o\u001b[0m\n",
            "[ 28%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/stubs/statusor.cc.o\u001b[0m\n",
            "[ 29%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/stubs/stringpiece.cc.o\u001b[0m\n",
            "[ 29%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/stubs/stringprintf.cc.o\u001b[0m\n",
            "[ 30%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/stubs/structurally_valid.cc.o\u001b[0m\n",
            "[ 30%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/stubs/strutil.cc.o\u001b[0m\n",
            "[ 31%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/stubs/time.cc.o\u001b[0m\n",
            "[ 31%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/wire_format_lite.cc.o\u001b[0m\n",
            "[ 32%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/any.cc.o\u001b[0m\n",
            "[ 32%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/any.pb.cc.o\u001b[0m\n",
            "[ 32%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/api.pb.cc.o\u001b[0m\n",
            "[ 33%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/compiler/importer.cc.o\u001b[0m\n",
            "[ 33%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/compiler/parser.cc.o\u001b[0m\n",
            "[ 34%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/descriptor.cc.o\u001b[0m\n",
            "[ 34%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/descriptor.pb.cc.o\u001b[0m\n",
            "[ 35%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/descriptor_database.cc.o\u001b[0m\n",
            "[ 35%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/duration.pb.cc.o\u001b[0m\n",
            "[ 36%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/dynamic_message.cc.o\u001b[0m\n",
            "[ 36%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/empty.pb.cc.o\u001b[0m\n",
            "[ 37%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/extension_set_heavy.cc.o\u001b[0m\n",
            "[ 37%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/field_mask.pb.cc.o\u001b[0m\n",
            "[ 38%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/generated_message_bases.cc.o\u001b[0m\n",
            "[ 38%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/generated_message_reflection.cc.o\u001b[0m\n",
            "[ 39%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/generated_message_tctable_full.cc.o\u001b[0m\n",
            "[ 39%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/io/gzip_stream.cc.o\u001b[0m\n",
            "[ 40%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/io/printer.cc.o\u001b[0m\n",
            "[ 40%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/io/tokenizer.cc.o\u001b[0m\n",
            "[ 41%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/map_field.cc.o\u001b[0m\n",
            "[ 41%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/message.cc.o\u001b[0m\n",
            "[ 42%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/reflection_ops.cc.o\u001b[0m\n",
            "[ 42%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/service.cc.o\u001b[0m\n",
            "[ 43%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/source_context.pb.cc.o\u001b[0m\n",
            "[ 43%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/struct.pb.cc.o\u001b[0m\n",
            "[ 44%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/stubs/substitute.cc.o\u001b[0m\n",
            "[ 44%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/text_format.cc.o\u001b[0m\n",
            "[ 45%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/timestamp.pb.cc.o\u001b[0m\n",
            "[ 45%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/type.pb.cc.o\u001b[0m\n",
            "[ 46%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/unknown_field_set.cc.o\u001b[0m\n",
            "[ 46%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/util/delimited_message_util.cc.o\u001b[0m\n",
            "[ 47%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/util/field_comparator.cc.o\u001b[0m\n",
            "[ 47%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/util/field_mask_util.cc.o\u001b[0m\n",
            "[ 48%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/util/internal/datapiece.cc.o\u001b[0m\n",
            "[ 48%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/util/internal/default_value_objectwriter.cc.o\u001b[0m\n",
            "[ 49%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/util/internal/error_listener.cc.o\u001b[0m\n",
            "[ 49%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/util/internal/field_mask_utility.cc.o\u001b[0m\n",
            "[ 49%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/util/internal/json_escaping.cc.o\u001b[0m\n",
            "[ 50%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/util/internal/json_objectwriter.cc.o\u001b[0m\n",
            "[ 50%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/util/internal/json_stream_parser.cc.o\u001b[0m\n",
            "[ 51%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/util/internal/object_writer.cc.o\u001b[0m\n",
            "[ 51%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/util/internal/proto_writer.cc.o\u001b[0m\n",
            "[ 52%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/util/internal/protostream_objectsource.cc.o\u001b[0m\n",
            "[ 52%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/util/internal/protostream_objectwriter.cc.o\u001b[0m\n",
            "[ 53%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/util/internal/type_info.cc.o\u001b[0m\n",
            "[ 53%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/util/internal/utility.cc.o\u001b[0m\n",
            "[ 54%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/util/json_util.cc.o\u001b[0m\n",
            "[ 54%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/util/message_differencer.cc.o\u001b[0m\n",
            "[ 55%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/util/time_util.cc.o\u001b[0m\n",
            "[ 55%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/util/type_resolver_util.cc.o\u001b[0m\n",
            "[ 56%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/wire_format.cc.o\u001b[0m\n",
            "[ 56%] \u001b[32mBuilding CXX object CMakeFiles/libprotobuf.dir/src/google/protobuf/wrappers.pb.cc.o\u001b[0m\n",
            "[ 57%] \u001b[32m\u001b[1mLinking CXX static library libprotobuf.a\u001b[0m\n",
            "make[5]: Leaving directory '/content/TensorRT/build/third_party.protobuf/src/third_party.protobuf'\n",
            "[ 57%] Built target libprotobuf\n",
            "make[5]: Entering directory '/content/TensorRT/build/third_party.protobuf/src/third_party.protobuf'\n",
            "make[5]: Leaving directory '/content/TensorRT/build/third_party.protobuf/src/third_party.protobuf'\n",
            "make[5]: Entering directory '/content/TensorRT/build/third_party.protobuf/src/third_party.protobuf'\n",
            "[ 57%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/code_generator.cc.o\u001b[0m\n",
            "[ 58%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/command_line_interface.cc.o\u001b[0m\n",
            "[ 58%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/cpp/cpp_enum.cc.o\u001b[0m\n",
            "[ 59%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/cpp/cpp_enum_field.cc.o\u001b[0m\n",
            "[ 59%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/cpp/cpp_extension.cc.o\u001b[0m\n",
            "[ 60%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/cpp/cpp_field.cc.o\u001b[0m\n",
            "[ 60%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/cpp/cpp_file.cc.o\u001b[0m\n",
            "[ 61%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/cpp/cpp_generator.cc.o\u001b[0m\n",
            "[ 61%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/cpp/cpp_helpers.cc.o\u001b[0m\n",
            "[ 62%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/cpp/cpp_map_field.cc.o\u001b[0m\n",
            "[ 62%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/cpp/cpp_message.cc.o\u001b[0m\n",
            "[ 63%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/cpp/cpp_message_field.cc.o\u001b[0m\n",
            "[ 63%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/cpp/cpp_padding_optimizer.cc.o\u001b[0m\n",
            "[ 64%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/cpp/cpp_parse_function_generator.cc.o\u001b[0m\n",
            "[ 64%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/cpp/cpp_primitive_field.cc.o\u001b[0m\n",
            "[ 65%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/cpp/cpp_service.cc.o\u001b[0m\n",
            "[ 65%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/cpp/cpp_string_field.cc.o\u001b[0m\n",
            "[ 66%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/csharp/csharp_doc_comment.cc.o\u001b[0m\n",
            "[ 66%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/csharp/csharp_enum.cc.o\u001b[0m\n",
            "[ 66%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/csharp/csharp_enum_field.cc.o\u001b[0m\n",
            "[ 67%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/csharp/csharp_field_base.cc.o\u001b[0m\n",
            "[ 67%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/csharp/csharp_generator.cc.o\u001b[0m\n",
            "[ 68%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/csharp/csharp_helpers.cc.o\u001b[0m\n",
            "[ 68%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/csharp/csharp_map_field.cc.o\u001b[0m\n",
            "[ 69%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/csharp/csharp_message.cc.o\u001b[0m\n",
            "[ 69%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/csharp/csharp_message_field.cc.o\u001b[0m\n",
            "[ 70%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/csharp/csharp_primitive_field.cc.o\u001b[0m\n",
            "[ 70%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/csharp/csharp_reflection_class.cc.o\u001b[0m\n",
            "[ 71%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/csharp/csharp_repeated_enum_field.cc.o\u001b[0m\n",
            "[ 71%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/csharp/csharp_repeated_message_field.cc.o\u001b[0m\n",
            "[ 72%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/csharp/csharp_repeated_primitive_field.cc.o\u001b[0m\n",
            "[ 72%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/csharp/csharp_source_generator_base.cc.o\u001b[0m\n",
            "[ 73%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/csharp/csharp_wrapper_field.cc.o\u001b[0m\n",
            "[ 73%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/java/java_context.cc.o\u001b[0m\n",
            "[ 74%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/java/java_doc_comment.cc.o\u001b[0m\n",
            "[ 74%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/java/java_enum.cc.o\u001b[0m\n",
            "[ 75%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/java/java_enum_field.cc.o\u001b[0m\n",
            "[ 75%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/java/java_enum_field_lite.cc.o\u001b[0m\n",
            "[ 76%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/java/java_enum_lite.cc.o\u001b[0m\n",
            "[ 76%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/java/java_extension.cc.o\u001b[0m\n",
            "[ 77%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/java/java_extension_lite.cc.o\u001b[0m\n",
            "[ 77%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/java/java_field.cc.o\u001b[0m\n",
            "[ 78%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/java/java_file.cc.o\u001b[0m\n",
            "[ 78%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/java/java_generator.cc.o\u001b[0m\n",
            "[ 79%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/java/java_generator_factory.cc.o\u001b[0m\n",
            "[ 79%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/java/java_helpers.cc.o\u001b[0m\n",
            "[ 80%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/java/java_kotlin_generator.cc.o\u001b[0m\n",
            "[ 80%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/java/java_map_field.cc.o\u001b[0m\n",
            "[ 81%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/java/java_map_field_lite.cc.o\u001b[0m\n",
            "[ 81%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/java/java_message.cc.o\u001b[0m\n",
            "[ 82%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/java/java_message_builder.cc.o\u001b[0m\n",
            "[ 82%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/java/java_message_builder_lite.cc.o\u001b[0m\n",
            "[ 83%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/java/java_message_field.cc.o\u001b[0m\n",
            "[ 83%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/java/java_message_field_lite.cc.o\u001b[0m\n",
            "[ 83%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/java/java_message_lite.cc.o\u001b[0m\n",
            "[ 84%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/java/java_name_resolver.cc.o\u001b[0m\n",
            "[ 84%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/java/java_primitive_field.cc.o\u001b[0m\n",
            "[ 85%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/java/java_primitive_field_lite.cc.o\u001b[0m\n",
            "[ 85%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/java/java_service.cc.o\u001b[0m\n",
            "[ 86%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/java/java_shared_code_generator.cc.o\u001b[0m\n",
            "[ 86%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/java/java_string_field.cc.o\u001b[0m\n",
            "[ 87%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/java/java_string_field_lite.cc.o\u001b[0m\n",
            "[ 87%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/js/js_generator.cc.o\u001b[0m\n",
            "[ 88%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/js/well_known_types_embed.cc.o\u001b[0m\n",
            "[ 88%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/objectivec/objectivec_enum.cc.o\u001b[0m\n",
            "[ 89%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/objectivec/objectivec_enum_field.cc.o\u001b[0m\n",
            "[ 89%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/objectivec/objectivec_extension.cc.o\u001b[0m\n",
            "[ 90%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/objectivec/objectivec_field.cc.o\u001b[0m\n",
            "[ 90%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/objectivec/objectivec_file.cc.o\u001b[0m\n",
            "[ 91%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/objectivec/objectivec_generator.cc.o\u001b[0m\n",
            "[ 91%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/objectivec/objectivec_helpers.cc.o\u001b[0m\n",
            "[ 92%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/objectivec/objectivec_map_field.cc.o\u001b[0m\n",
            "[ 92%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/objectivec/objectivec_message.cc.o\u001b[0m\n",
            "[ 93%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/objectivec/objectivec_message_field.cc.o\u001b[0m\n",
            "[ 93%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/objectivec/objectivec_oneof.cc.o\u001b[0m\n",
            "[ 94%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/objectivec/objectivec_primitive_field.cc.o\u001b[0m\n",
            "[ 94%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/php/php_generator.cc.o\u001b[0m\n",
            "[ 95%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/plugin.cc.o\u001b[0m\n",
            "[ 95%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/plugin.pb.cc.o\u001b[0m\n",
            "[ 96%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/python/python_generator.cc.o\u001b[0m\n",
            "[ 96%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/python/python_helpers.cc.o\u001b[0m\n",
            "[ 97%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/python/python_pyi_generator.cc.o\u001b[0m\n",
            "[ 97%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/ruby/ruby_generator.cc.o\u001b[0m\n",
            "[ 98%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/subprocess.cc.o\u001b[0m\n",
            "[ 98%] \u001b[32mBuilding CXX object CMakeFiles/libprotoc.dir/src/google/protobuf/compiler/zip_writer.cc.o\u001b[0m\n",
            "[ 99%] \u001b[32m\u001b[1mLinking CXX static library libprotoc.a\u001b[0m\n",
            "make[5]: Leaving directory '/content/TensorRT/build/third_party.protobuf/src/third_party.protobuf'\n",
            "[ 99%] Built target libprotoc\n",
            "make[5]: Entering directory '/content/TensorRT/build/third_party.protobuf/src/third_party.protobuf'\n",
            "make[5]: Leaving directory '/content/TensorRT/build/third_party.protobuf/src/third_party.protobuf'\n",
            "make[5]: Entering directory '/content/TensorRT/build/third_party.protobuf/src/third_party.protobuf'\n",
            "[ 99%] \u001b[32mBuilding CXX object CMakeFiles/protoc.dir/src/google/protobuf/compiler/main.cc.o\u001b[0m\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX executable protoc\u001b[0m\n",
            "make[5]: Leaving directory '/content/TensorRT/build/third_party.protobuf/src/third_party.protobuf'\n",
            "[100%] Built target protoc\n",
            "make[4]: Leaving directory '/content/TensorRT/build/third_party.protobuf/src/third_party.protobuf'\n",
            "make[3]: Leaving directory '/content/TensorRT/build/third_party.protobuf/src/third_party.protobuf'\n",
            "[  1%] \u001b[34m\u001b[1mPerforming install step for 'third_party.protobuf'\u001b[0m\n",
            "make[3]: Entering directory '/content/TensorRT/build/third_party.protobuf/src/third_party.protobuf'\n",
            "make[4]: Entering directory '/content/TensorRT/build/third_party.protobuf/src/third_party.protobuf'\n",
            "make[5]: Entering directory '/content/TensorRT/build/third_party.protobuf/src/third_party.protobuf'\n",
            "make[5]: Leaving directory '/content/TensorRT/build/third_party.protobuf/src/third_party.protobuf'\n",
            "[ 16%] Built target libprotobuf-lite\n",
            "make[5]: Entering directory '/content/TensorRT/build/third_party.protobuf/src/third_party.protobuf'\n",
            "make[5]: Leaving directory '/content/TensorRT/build/third_party.protobuf/src/third_party.protobuf'\n",
            "[ 57%] Built target libprotobuf\n",
            "make[5]: Entering directory '/content/TensorRT/build/third_party.protobuf/src/third_party.protobuf'\n",
            "make[5]: Leaving directory '/content/TensorRT/build/third_party.protobuf/src/third_party.protobuf'\n",
            "[ 99%] Built target libprotoc\n",
            "make[5]: Entering directory '/content/TensorRT/build/third_party.protobuf/src/third_party.protobuf'\n",
            "make[5]: Leaving directory '/content/TensorRT/build/third_party.protobuf/src/third_party.protobuf'\n",
            "[100%] Built target protoc\n",
            "make[4]: Leaving directory '/content/TensorRT/build/third_party.protobuf/src/third_party.protobuf'\n",
            "\u001b[36mInstall the project...\u001b[0m\n",
            "-- Install configuration: \"\"\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/lib/libprotobuf-lite.a\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/lib/libprotobuf.a\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/lib/libprotoc.a\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/bin/protoc-3.20.1.0\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/bin/protoc\n",
            "-- Set runtime path of \"/content/TensorRT/build/third_party.protobuf/bin/protoc-3.20.1.0\" to \"$ORIGIN/../lib\"\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/lib/pkgconfig/protobuf.pc\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/lib/pkgconfig/protobuf-lite.pc\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/any.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/any.pb.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/api.pb.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/arena.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/arena_impl.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/arenastring.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/arenaz_sampler.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/compiler/code_generator.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/compiler/command_line_interface.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/compiler/cpp/cpp_file.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/compiler/cpp/cpp_generator.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/compiler/cpp/cpp_helpers.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/compiler/cpp/cpp_names.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/compiler/csharp/csharp_doc_comment.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/compiler/csharp/csharp_generator.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/compiler/csharp/csharp_names.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/compiler/csharp/csharp_options.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/compiler/importer.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/compiler/java/java_generator.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/compiler/java/java_kotlin_generator.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/compiler/java/java_names.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/compiler/js/js_generator.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/compiler/objectivec/objectivec_generator.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/compiler/objectivec/objectivec_helpers.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/compiler/parser.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/compiler/php/php_generator.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/compiler/plugin.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/compiler/plugin.pb.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/compiler/python/python_generator.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/compiler/python/python_pyi_generator.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/compiler/python/python_helpers.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/compiler/ruby/ruby_generator.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/descriptor.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/descriptor.pb.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/descriptor_database.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/duration.pb.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/dynamic_message.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/empty.pb.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/explicitly_constructed.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/extension_set.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/extension_set_inl.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/field_access_listener.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/field_mask.pb.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/generated_enum_reflection.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/generated_enum_util.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/generated_message_bases.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/generated_message_reflection.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/generated_message_tctable_decl.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/generated_message_tctable_impl.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/generated_message_util.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/has_bits.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/implicit_weak_message.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/inlined_string_field.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/io/coded_stream.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/io/gzip_stream.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/io/io_win32.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/io/printer.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/io/strtod.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/io/tokenizer.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/io/zero_copy_stream.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/io/zero_copy_stream_impl.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/io/zero_copy_stream_impl_lite.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/map.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/map_entry.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/map_entry_lite.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/map_field.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/map_field_inl.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/map_field_lite.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/map_type_handler.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/message.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/message_lite.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/metadata.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/metadata_lite.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/parse_context.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/port.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/port_def.inc\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/port_undef.inc\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/reflection.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/reflection_ops.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/repeated_field.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/repeated_ptr_field.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/service.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/source_context.pb.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/struct.pb.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/stubs/bytestream.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/stubs/callback.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/stubs/casts.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/stubs/common.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/stubs/hash.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/stubs/logging.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/stubs/macros.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/stubs/map_util.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/stubs/mutex.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/stubs/once.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/stubs/platform_macros.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/stubs/port.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/stubs/status.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/stubs/stl_util.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/stubs/stringpiece.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/stubs/strutil.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/stubs/template_util.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/text_format.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/timestamp.pb.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/type.pb.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/unknown_field_set.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/util/delimited_message_util.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/util/field_comparator.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/util/field_mask_util.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/util/json_util.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/util/message_differencer.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/util/time_util.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/util/type_resolver.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/util/type_resolver_util.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/wire_format.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/wire_format_lite.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/wrappers.pb.h\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/any.proto\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/api.proto\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/compiler/plugin.proto\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/descriptor.proto\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/duration.proto\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/empty.proto\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/field_mask.proto\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/source_context.proto\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/struct.proto\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/timestamp.proto\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/type.proto\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/wrappers.proto\n",
            "-- Up-to-date: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/any.proto\n",
            "-- Up-to-date: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/api.proto\n",
            "-- Up-to-date: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/compiler/plugin.proto\n",
            "-- Up-to-date: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/descriptor.proto\n",
            "-- Up-to-date: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/duration.proto\n",
            "-- Up-to-date: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/empty.proto\n",
            "-- Up-to-date: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/field_mask.proto\n",
            "-- Up-to-date: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/source_context.proto\n",
            "-- Up-to-date: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/struct.proto\n",
            "-- Up-to-date: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/timestamp.proto\n",
            "-- Up-to-date: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/type.proto\n",
            "-- Up-to-date: /content/TensorRT/build/third_party.protobuf/include/google/protobuf/wrappers.proto\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/lib/cmake/protobuf/protobuf-targets.cmake\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/lib/cmake/protobuf/protobuf-targets-noconfig.cmake\n",
            "-- Up-to-date: /content/TensorRT/build/third_party.protobuf/lib/cmake/protobuf\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/lib/cmake/protobuf/protobuf-module.cmake\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/lib/cmake/protobuf/protobuf-config-version.cmake\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/lib/cmake/protobuf/protobuf-config.cmake\n",
            "-- Installing: /content/TensorRT/build/third_party.protobuf/lib/cmake/protobuf/protobuf-options.cmake\n",
            "make[3]: Leaving directory '/content/TensorRT/build/third_party.protobuf/src/third_party.protobuf'\n",
            "[  1%] \u001b[34m\u001b[1mCompleted 'third_party.protobuf'\u001b[0m\n",
            "make[2]: Leaving directory '/content/TensorRT/build'\n",
            "[  1%] Built target third_party.protobuf\n",
            "make[2]: Entering directory '/content/TensorRT/build'\n",
            "make[2]: Leaving directory '/content/TensorRT/build'\n",
            "make[2]: Entering directory '/content/TensorRT/build'\n",
            "[  1%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/batchTilePlugin/batchTilePlugin.cpp.o\u001b[0m\n",
            "[  1%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/batchedNMSPlugin/batchedNMSPlugin.cpp.o\u001b[0m\n",
            "[  1%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/clipPlugin/clipPlugin.cpp.o\u001b[0m\n",
            "[  1%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/coordConvACPlugin/coordConvACPlugin.cpp.o\u001b[0m\n",
            "[  2%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/cropAndResizePlugin/cropAndResizePlugin.cpp.o\u001b[0m\n",
            "[  2%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/decodeBbox3DPlugin/decodeBbox3D.cpp.o\u001b[0m\n",
            "[  2%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/detectionLayerPlugin/detectionLayerPlugin.cpp.o\u001b[0m\n",
            "[  2%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/disentangledAttentionPlugin/disentangledAttentionPlugin.cpp.o\u001b[0m\n",
            "[  2%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/efficientNMSPlugin/efficientNMSPlugin.cpp.o\u001b[0m\n",
            "[  2%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/efficientNMSPlugin/tftrt/efficientNMSExplicitTFTRTPlugin.cpp.o\u001b[0m\n",
            "[  2%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/efficientNMSPlugin/tftrt/efficientNMSImplicitTFTRTPlugin.cpp.o\u001b[0m\n",
            "[  3%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/flattenConcat/flattenConcat.cpp.o\u001b[0m\n",
            "[  3%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/generateDetectionPlugin/generateDetectionPlugin.cpp.o\u001b[0m\n",
            "[  3%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/gridAnchorPlugin/gridAnchorPlugin.cpp.o\u001b[0m\n",
            "[  3%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/groupNormalizationPlugin/groupNormalizationPlugin.cpp.o\u001b[0m\n",
            "[  3%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/leakyReluPlugin/lReluPlugin.cpp.o\u001b[0m\n",
            "[  3%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/modulatedDeformConvPlugin/modulatedDeformConvPlugin.cpp.o\u001b[0m\n",
            "[  4%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/multilevelCropAndResizePlugin/multilevelCropAndResizePlugin.cpp.o\u001b[0m\n",
            "[  4%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/multilevelProposeROI/multilevelProposeROIPlugin.cpp.o\u001b[0m\n",
            "[  4%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/multiscaleDeformableAttnPlugin/multiscaleDeformableAttnPlugin.cpp.o\u001b[0m\n",
            "[  4%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/nmsPlugin/nmsPlugin.cpp.o\u001b[0m\n",
            "[  4%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/normalizePlugin/normalizePlugin.cpp.o\u001b[0m\n",
            "[  4%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/nvFasterRCNN/nvFasterRCNNPlugin.cpp.o\u001b[0m\n",
            "[  5%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/pillarScatterPlugin/pillarScatter.cpp.o\u001b[0m\n",
            "[  5%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/priorBoxPlugin/priorBoxPlugin.cpp.o\u001b[0m\n",
            "[  5%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/proposalLayerPlugin/proposalLayerPlugin.cpp.o\u001b[0m\n",
            "[  5%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/proposalPlugin/proposalPlugin.cpp.o\u001b[0m\n",
            "[  5%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/pyramidROIAlignPlugin/pyramidROIAlignPlugin.cpp.o\u001b[0m\n",
            "[  5%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/regionPlugin/regionPlugin.cpp.o\u001b[0m\n",
            "[  5%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/reorgPlugin/reorgPlugin.cpp.o\u001b[0m\n",
            "[  6%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/resizeNearestPlugin/resizeNearestPlugin.cpp.o\u001b[0m\n",
            "[  6%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/roiAlignPlugin/roiAlignPlugin.cpp.o\u001b[0m\n",
            "[  6%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/scatterPlugin/scatterPlugin.cpp.o\u001b[0m\n",
            "[  6%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/specialSlicePlugin/specialSlicePlugin.cpp.o\u001b[0m\n",
            "[  6%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/voxelGeneratorPlugin/voxelGenerator.cpp.o\u001b[0m\n",
            "[  6%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention/src/fused_multihead_attention_fp16_128_64_kernel.sm75.cpp.o\u001b[0m\n",
            "[  7%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention/src/fused_multihead_attention_fp16_128_64_kernel.sm80.cpp.o\u001b[0m\n",
            "[  7%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention/src/fused_multihead_attention_fp16_128_64_kernel.sm87.cpp.o\u001b[0m\n",
            "[  7%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention/src/fused_multihead_attention_fp16_128_64_kernel.sm90.cpp.o\u001b[0m\n",
            "[  7%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention/src/fused_multihead_attention_fp16_384_64_kernel.sm75.cpp.o\u001b[0m\n",
            "[  7%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention/src/fused_multihead_attention_fp16_384_64_kernel.sm80.cpp.o\u001b[0m\n",
            "[  7%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention/src/fused_multihead_attention_fp16_384_64_kernel.sm86.cpp.o\u001b[0m\n",
            "[  8%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention/src/fused_multihead_attention_fp16_384_64_kernel.sm87.cpp.o\u001b[0m\n",
            "[  8%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention/src/fused_multihead_attention_fp16_384_64_kernel.sm90.cpp.o\u001b[0m\n",
            "[  8%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention/src/fused_multihead_attention_fp16_512_64_kernel.sm90.cpp.o\u001b[0m\n",
            "[  8%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention/src/fused_multihead_attention_fp16_64_64_kernel.sm75.cpp.o\u001b[0m\n",
            "[  8%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention/src/fused_multihead_attention_fp16_64_64_kernel.sm80.cpp.o\u001b[0m\n",
            "[  8%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention/src/fused_multihead_attention_fp16_64_64_kernel.sm87.cpp.o\u001b[0m\n",
            "[  8%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention/src/fused_multihead_attention_fp16_64_64_kernel.sm90.cpp.o\u001b[0m\n",
            "[  9%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention/src/fused_multihead_attention_fp16_96_64_kernel.sm75.cpp.o\u001b[0m\n",
            "[  9%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention/src/fused_multihead_attention_fp16_96_64_kernel.sm80.cpp.o\u001b[0m\n",
            "[  9%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention/src/fused_multihead_attention_fp16_96_64_kernel.sm87.cpp.o\u001b[0m\n",
            "[  9%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention/src/fused_multihead_attention_fp16_96_64_kernel.sm90.cpp.o\u001b[0m\n",
            "[  9%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention/src/fused_multihead_attention_int8_128_64_kernel.sm75.cpp.o\u001b[0m\n",
            "[  9%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention/src/fused_multihead_attention_int8_128_64_kernel.sm80.cpp.o\u001b[0m\n",
            "[ 10%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention/src/fused_multihead_attention_int8_128_64_kernel.sm87.cpp.o\u001b[0m\n",
            "[ 10%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention/src/fused_multihead_attention_int8_128_64_kernel.sm90.cpp.o\u001b[0m\n",
            "[ 10%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention/src/fused_multihead_attention_int8_384_64_kernel.sm75.cpp.o\u001b[0m\n",
            "[ 10%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention/src/fused_multihead_attention_int8_384_64_kernel.sm80.cpp.o\u001b[0m\n",
            "[ 10%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention/src/fused_multihead_attention_int8_384_64_kernel.sm87.cpp.o\u001b[0m\n",
            "[ 10%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention/src/fused_multihead_attention_int8_384_64_kernel.sm90.cpp.o\u001b[0m\n",
            "[ 11%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention/src/fused_multihead_attention_int8_512_64_kernel.sm90.cpp.o\u001b[0m\n",
            "[ 11%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention/src/fused_multihead_attention_int8_64_64_kernel.sm80.cpp.o\u001b[0m\n",
            "[ 11%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention/src/fused_multihead_attention_int8_96_64_kernel.sm80.cpp.o\u001b[0m\n",
            "[ 11%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_fp16_128_32_kernel.sm75.cpp.o\u001b[0m\n",
            "[ 11%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_fp16_128_32_kernel.sm80.cpp.o\u001b[0m\n",
            "[ 11%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_fp16_128_64_kernel.sm75.cpp.o\u001b[0m\n",
            "[ 11%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_fp16_128_64_kernel.sm80.cpp.o\u001b[0m\n",
            "[ 12%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_fp16_128_64_kernel.sm86.cpp.o\u001b[0m\n",
            "[ 12%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_fp16_128_64_kernel.sm87.cpp.o\u001b[0m\n",
            "[ 12%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_fp16_128_64_kernel.sm90.cpp.o\u001b[0m\n",
            "[ 12%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_fp16_256_32_kernel.sm75.cpp.o\u001b[0m\n",
            "[ 12%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_fp16_256_32_kernel.sm80.cpp.o\u001b[0m\n",
            "[ 12%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_fp16_256_64_kernel.sm75.cpp.o\u001b[0m\n",
            "[ 13%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_fp16_256_64_kernel.sm80.cpp.o\u001b[0m\n",
            "[ 13%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_fp16_256_64_kernel.sm86.cpp.o\u001b[0m\n",
            "[ 13%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_fp16_256_64_kernel.sm87.cpp.o\u001b[0m\n",
            "[ 13%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_fp16_256_64_kernel.sm90.cpp.o\u001b[0m\n",
            "[ 13%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_fp16_384_64_kernel.sm75.cpp.o\u001b[0m\n",
            "[ 13%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_fp16_384_64_kernel.sm80.cpp.o\u001b[0m\n",
            "[ 15%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_fp16_384_64_kernel.sm86.cpp.o\u001b[0m\n",
            "[ 15%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_fp16_384_64_kernel.sm87.cpp.o\u001b[0m\n",
            "[ 15%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_fp16_384_64_kernel.sm90.cpp.o\u001b[0m\n",
            "[ 15%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_fp16_512_32_kernel.sm75.cpp.o\u001b[0m\n",
            "[ 15%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_fp16_512_32_kernel.sm80.cpp.o\u001b[0m\n",
            "[ 15%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_fp16_512_64_kernel.sm75.cpp.o\u001b[0m\n",
            "[ 15%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_fp16_512_64_kernel.sm80.cpp.o\u001b[0m\n",
            "[ 16%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_fp16_512_64_kernel.sm90.cpp.o\u001b[0m\n",
            "[ 16%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_fp16_64_64_kernel.sm75.cpp.o\u001b[0m\n",
            "[ 16%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_fp16_64_64_kernel.sm80.cpp.o\u001b[0m\n",
            "[ 16%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_fp16_64_64_kernel.sm86.cpp.o\u001b[0m\n",
            "[ 16%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_fp16_64_64_kernel.sm87.cpp.o\u001b[0m\n",
            "[ 16%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_fp16_64_64_kernel.sm90.cpp.o\u001b[0m\n",
            "[ 17%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_fp16_96_64_kernel.sm75.cpp.o\u001b[0m\n",
            "[ 17%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_fp16_96_64_kernel.sm80.cpp.o\u001b[0m\n",
            "[ 17%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_fp16_96_64_kernel.sm86.cpp.o\u001b[0m\n",
            "[ 17%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_fp16_96_64_kernel.sm87.cpp.o\u001b[0m\n",
            "[ 17%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_fp16_96_64_kernel.sm90.cpp.o\u001b[0m\n",
            "[ 17%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_il_int8_128_32_kernel.sm80.cpp.o\u001b[0m\n",
            "[ 18%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_il_int8_128_64_kernel.sm87.cpp.o\u001b[0m\n",
            "[ 18%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_il_int8_128_64_kernel.sm90.cpp.o\u001b[0m\n",
            "[ 18%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_il_int8_192_64_kernel.sm87.cpp.o\u001b[0m\n",
            "[ 18%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_il_int8_192_64_kernel.sm90.cpp.o\u001b[0m\n",
            "[ 18%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_il_int8_256_64_kernel.sm87.cpp.o\u001b[0m\n",
            "[ 18%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_il_int8_256_64_kernel.sm90.cpp.o\u001b[0m\n",
            "[ 18%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_il_int8_384_64_kernel.sm87.cpp.o\u001b[0m\n",
            "[ 19%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_il_int8_384_64_kernel.sm90.cpp.o\u001b[0m\n",
            "[ 19%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_il_int8_64_64_kernel.sm80.cpp.o\u001b[0m\n",
            "[ 19%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_il_int8_64_64_kernel.sm87.cpp.o\u001b[0m\n",
            "[ 19%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_il_int8_64_64_kernel.sm90.cpp.o\u001b[0m\n",
            "[ 19%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_il_int8_96_64_kernel.sm80.cpp.o\u001b[0m\n",
            "[ 19%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_il_int8_96_64_kernel.sm87.cpp.o\u001b[0m\n",
            "[ 20%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_il_int8_96_64_kernel.sm90.cpp.o\u001b[0m\n",
            "[ 20%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_int8_128_32_kernel.sm75.cpp.o\u001b[0m\n",
            "[ 20%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_int8_128_32_kernel.sm80.cpp.o\u001b[0m\n",
            "[ 20%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_int8_128_64_kernel.sm72.cpp.o\u001b[0m\n",
            "[ 20%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_int8_128_64_kernel.sm75.cpp.o\u001b[0m\n",
            "[ 20%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_int8_128_64_kernel.sm80.cpp.o\u001b[0m\n",
            "[ 21%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_int8_128_64_kernel.sm86.cpp.o\u001b[0m\n",
            "[ 21%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_int8_128_64_kernel.sm87.cpp.o\u001b[0m\n",
            "[ 21%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_int8_128_64_kernel.sm90.cpp.o\u001b[0m\n",
            "[ 21%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_int8_192_64_kernel.sm72.cpp.o\u001b[0m\n",
            "[ 21%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_int8_192_64_kernel.sm75.cpp.o\u001b[0m\n",
            "[ 21%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_int8_192_64_kernel.sm80.cpp.o\u001b[0m\n",
            "[ 21%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_int8_192_64_kernel.sm86.cpp.o\u001b[0m\n",
            "[ 22%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_int8_192_64_kernel.sm87.cpp.o\u001b[0m\n",
            "[ 22%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_int8_192_64_kernel.sm90.cpp.o\u001b[0m\n",
            "[ 22%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_int8_256_32_kernel.sm75.cpp.o\u001b[0m\n",
            "[ 22%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_int8_256_32_kernel.sm80.cpp.o\u001b[0m\n",
            "[ 22%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_int8_256_64_kernel.sm72.cpp.o\u001b[0m\n",
            "[ 22%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_int8_256_64_kernel.sm75.cpp.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_int8_256_64_kernel.sm80.cpp.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_int8_256_64_kernel.sm86.cpp.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_int8_256_64_kernel.sm87.cpp.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_int8_256_64_kernel.sm90.cpp.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_int8_384_64_kernel.sm72.cpp.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_int8_384_64_kernel.sm75.cpp.o\u001b[0m\n",
            "[ 24%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_int8_384_64_kernel.sm80.cpp.o\u001b[0m\n",
            "[ 24%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_int8_384_64_kernel.sm86.cpp.o\u001b[0m\n",
            "[ 24%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_int8_384_64_kernel.sm87.cpp.o\u001b[0m\n",
            "[ 24%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_int8_384_64_kernel.sm90.cpp.o\u001b[0m\n",
            "[ 24%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_int8_512_32_kernel.sm75.cpp.o\u001b[0m\n",
            "[ 24%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_int8_512_32_kernel.sm80.cpp.o\u001b[0m\n",
            "[ 24%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_int8_512_64_kernel.sm75.cpp.o\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_int8_512_64_kernel.sm80.cpp.o\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_int8_512_64_kernel.sm90.cpp.o\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_int8_64_64_kernel.sm80.cpp.o\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_int8_64_64_kernel.sm87.cpp.o\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_int8_64_64_kernel.sm90.cpp.o\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_int8_96_64_kernel.sm80.cpp.o\u001b[0m\n",
            "[ 26%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_int8_96_64_kernel.sm87.cpp.o\u001b[0m\n",
            "[ 26%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/fused_multihead_attention_v2/src/fused_multihead_attention_v2_int8_96_64_kernel.sm90.cpp.o\u001b[0m\n",
            "[ 26%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/qkvToContextInt8InterleavedPlugin.cpp.o\u001b[0m\n",
            "[ 26%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/bertQKVToContextPlugin/qkvToContextPlugin.cpp.o\u001b[0m\n",
            "[ 26%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/embLayerNormPlugin/embLayerNormPlugin.cpp.o\u001b[0m\n",
            "[ 26%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/embLayerNormPlugin/embLayerNormVarSeqlenPlugin.cpp.o\u001b[0m\n",
            "[ 27%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/fcPlugin/fcPlugin.cpp.o\u001b[0m\n",
            "[ 27%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/geluPlugin/geluPlugin.cpp.o\u001b[0m\n",
            "[ 27%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/skipLayerNormPlugin/skipLayerNormInt8InterleavedPlugin.cpp.o\u001b[0m\n",
            "[ 27%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/skipLayerNormPlugin/skipLayerNormPlugin.cpp.o\u001b[0m\n",
            "[ 27%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/common/kernels/kernel.cpp.o\u001b[0m\n",
            "[ 27%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/common/checkMacrosPlugin.cpp.o\u001b[0m\n",
            "[ 27%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/common/cudaDriverWrapper.cpp.o\u001b[0m\n",
            "[ 29%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/common/nmsHelper.cpp.o\u001b[0m\n",
            "[ 29%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/common/plugin.cpp.o\u001b[0m\n",
            "[ 29%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/common/reducedMathPlugin.cpp.o\u001b[0m\n",
            "[ 29%] \u001b[32mBuilding CXX object plugin/CMakeFiles/nvinfer_plugin.dir/common/vfcCommon.cpp.o\u001b[0m\n",
            "[ 29%] \u001b[32mBuilding CUDA object plugin/CMakeFiles/nvinfer_plugin.dir/batchedNMSPlugin/batchedNMSInference.cu.o\u001b[0m\n",
            "[ 29%] \u001b[32mBuilding CUDA object plugin/CMakeFiles/nvinfer_plugin.dir/batchedNMSPlugin/gatherNMSOutputs.cu.o\u001b[0m\n",
            "[ 30%] \u001b[32mBuilding CUDA object plugin/CMakeFiles/nvinfer_plugin.dir/clipPlugin/clip.cu.o\u001b[0m\n",
            "[ 30%] \u001b[32mBuilding CUDA object plugin/CMakeFiles/nvinfer_plugin.dir/coordConvACPlugin/coordConvACPluginKernels.cu.o\u001b[0m\n",
            "[ 30%] \u001b[32mBuilding CUDA object plugin/CMakeFiles/nvinfer_plugin.dir/disentangledAttentionPlugin/disentangledKernel.cu.o\u001b[0m\n",
            "[ 30%] \u001b[32mBuilding CUDA object plugin/CMakeFiles/nvinfer_plugin.dir/efficientNMSPlugin/efficientNMSInference.cu.o\u001b[0m\n",
            "[ 30%] \u001b[32mBuilding CUDA object plugin/CMakeFiles/nvinfer_plugin.dir/groupNormalizationPlugin/groupNormalizationKernel.cu.o\u001b[0m\n",
            "[ 30%] \u001b[32mBuilding CUDA object plugin/CMakeFiles/nvinfer_plugin.dir/instanceNormalizationPlugin/instanceNormFwdImpl.cu.o\u001b[0m\n",
            "[ 31%] \u001b[32mBuilding CUDA object plugin/CMakeFiles/nvinfer_plugin.dir/instanceNormalizationPlugin/instanceNormalizationPlugin.cu.o\u001b[0m\n",
            "[ 31%] \u001b[32mBuilding CUDA object plugin/CMakeFiles/nvinfer_plugin.dir/modulatedDeformConvPlugin/modulatedDeformConvCudaHelper.cu.o\u001b[0m\n",
            "[ 31%] \u001b[32mBuilding CUDA object plugin/CMakeFiles/nvinfer_plugin.dir/modulatedDeformConvPlugin/modulatedDeformConvPluginKernel.cu.o\u001b[0m\n",
            "[ 31%] \u001b[32mBuilding CUDA object plugin/CMakeFiles/nvinfer_plugin.dir/multiscaleDeformableAttnPlugin/multiscaleDeformableAttn.cu.o\u001b[0m\n",
            "[ 31%] \u001b[32mBuilding CUDA object plugin/CMakeFiles/nvinfer_plugin.dir/roiAlignPlugin/roiAlignKernel.cu.o\u001b[0m\n",
            "[ 31%] \u001b[32mBuilding CUDA object plugin/CMakeFiles/nvinfer_plugin.dir/scatterPlugin/scatterLayer.cu.o\u001b[0m\n",
            "[ 31%] \u001b[32mBuilding CUDA object plugin/CMakeFiles/nvinfer_plugin.dir/splitPlugin/split.cu.o\u001b[0m\n",
            "[ 32%] \u001b[32mBuilding CUDA object plugin/CMakeFiles/nvinfer_plugin.dir/common/kernels/allClassNMS.cu.o\u001b[0m\n",
            "[ 32%] \u001b[32mBuilding CUDA object plugin/CMakeFiles/nvinfer_plugin.dir/common/kernels/bboxDeltas2Proposals.cu.o\u001b[0m\n",
            "[ 32%] \u001b[32mBuilding CUDA object plugin/CMakeFiles/nvinfer_plugin.dir/common/kernels/common.cu.o\u001b[0m\n",
            "[ 32%] \u001b[32mBuilding CUDA object plugin/CMakeFiles/nvinfer_plugin.dir/common/kernels/cropAndResizeKernel.cu.o\u001b[0m\n",
            "[ 32%] \u001b[32mBuilding CUDA object plugin/CMakeFiles/nvinfer_plugin.dir/common/kernels/decodeBBoxes.cu.o\u001b[0m\n",
            "[ 32%] \u001b[32mBuilding CUDA object plugin/CMakeFiles/nvinfer_plugin.dir/common/kernels/decodeBbox3DKernels.cu.o\u001b[0m\n",
            "[ 33%] \u001b[32mBuilding CUDA object plugin/CMakeFiles/nvinfer_plugin.dir/common/kernels/detectionForward.cu.o\u001b[0m\n",
            "[ 33%] \u001b[32mBuilding CUDA object plugin/CMakeFiles/nvinfer_plugin.dir/common/kernels/extractFgScores.cu.o\u001b[0m\n",
            "[ 33%] \u001b[32mBuilding CUDA object plugin/CMakeFiles/nvinfer_plugin.dir/common/kernels/gatherTopDetections.cu.o\u001b[0m\n",
            "[ 33%] \u001b[32mBuilding CUDA object plugin/CMakeFiles/nvinfer_plugin.dir/common/kernels/generateAnchors.cu.o\u001b[0m\n",
            "[ 33%] \u001b[32mBuilding CUDA object plugin/CMakeFiles/nvinfer_plugin.dir/common/kernels/gridAnchorLayer.cu.o\u001b[0m\n",
            "[ 33%] \u001b[32mBuilding CUDA object plugin/CMakeFiles/nvinfer_plugin.dir/common/kernels/lReLU.cu.o\u001b[0m\n",
            "[ 34%] \u001b[32mBuilding CUDA object plugin/CMakeFiles/nvinfer_plugin.dir/common/kernels/maskRCNNKernels.cu.o\u001b[0m\n",
            "[ 34%] \u001b[32mBuilding CUDA object plugin/CMakeFiles/nvinfer_plugin.dir/common/kernels/nmsLayer.cu.o\u001b[0m\n",
            "[ 34%] \u001b[32mBuilding CUDA object plugin/CMakeFiles/nvinfer_plugin.dir/common/kernels/normalizeLayer.cu.o\u001b[0m\n",
            "[ 34%] \u001b[32mBuilding CUDA object plugin/CMakeFiles/nvinfer_plugin.dir/common/kernels/permuteData.cu.o\u001b[0m\n",
            "[ 34%] \u001b[32mBuilding CUDA object plugin/CMakeFiles/nvinfer_plugin.dir/common/kernels/pillarScatterKernels.cu.o\u001b[0m\n",
            "[ 34%] \u001b[32mBuilding CUDA object plugin/CMakeFiles/nvinfer_plugin.dir/common/kernels/priorBoxLayer.cu.o\u001b[0m\n",
            "[ 34%] \u001b[32mBuilding CUDA object plugin/CMakeFiles/nvinfer_plugin.dir/common/kernels/proposalKernel.cu.o\u001b[0m\n",
            "[ 35%] \u001b[32mBuilding CUDA object plugin/CMakeFiles/nvinfer_plugin.dir/common/kernels/proposalsForward.cu.o\u001b[0m\n",
            "[ 35%] \u001b[32mBuilding CUDA object plugin/CMakeFiles/nvinfer_plugin.dir/common/kernels/regionForward.cu.o\u001b[0m\n",
            "[ 35%] \u001b[32mBuilding CUDA object plugin/CMakeFiles/nvinfer_plugin.dir/common/kernels/reorgForward.cu.o\u001b[0m\n",
            "[ 35%] \u001b[32mBuilding CUDA object plugin/CMakeFiles/nvinfer_plugin.dir/common/kernels/roiPooling.cu.o\u001b[0m\n",
            "[ 35%] \u001b[32mBuilding CUDA object plugin/CMakeFiles/nvinfer_plugin.dir/common/kernels/rproiInferenceFused.cu.o\u001b[0m\n",
            "[ 35%] \u001b[32mBuilding CUDA object plugin/CMakeFiles/nvinfer_plugin.dir/common/kernels/sortScoresPerClass.cu.o\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TensorRT-LLM"
      ],
      "metadata": {
        "id": "c0L4UDaqCWyt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/NVIDIA/TensorRT-LLM.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jc9Nj0MwClLF",
        "outputId": "caed5293-aa51-4d4f-afd5-059bb12ee6dd"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'TensorRT-LLM'...\n",
            "remote: Enumerating objects: 5607, done.\u001b[K\n",
            "remote: Counting objects: 100% (1413/1413), done.\u001b[K\n",
            "remote: Compressing objects: 100% (636/636), done.\u001b[K\n",
            "remote: Total 5607 (delta 883), reused 1120 (delta 767), pack-reused 4194\u001b[K\n",
            "Receiving objects: 100% (5607/5607), 60.78 MiB | 15.01 MiB/s, done.\n",
            "Resolving deltas: 100% (3730/3730), done.\n",
            "Updating files: 100% (1327/1327), done.\n",
            "Filtering content: 100% (4/4), 6.73 MiB | 4.86 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd TensorRT-LLM && git submodule update --init --recursive\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QETDGBOQkLH",
        "outputId": "b46f12f0-9b32-4182-98ce-c38ef8febd78"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submodule '3rdparty/NVTX' (https://github.com/NVIDIA/NVTX.git) registered for path '3rdparty/NVTX'\n",
            "Submodule '3rdparty/cutlass' (https://github.com/NVIDIA/cutlass.git) registered for path '3rdparty/cutlass'\n",
            "Submodule '3rdparty/cxxopts' (https://github.com/jarro2783/cxxopts) registered for path '3rdparty/cxxopts'\n",
            "Submodule '3rdparty/json' (https://github.com/nlohmann/json.git) registered for path '3rdparty/json'\n",
            "Cloning into '/content/TensorRT-LLM/3rdparty/NVTX'...\n",
            "Cloning into '/content/TensorRT-LLM/3rdparty/cutlass'...\n",
            "Cloning into '/content/TensorRT-LLM/3rdparty/cxxopts'...\n",
            "Cloning into '/content/TensorRT-LLM/3rdparty/json'...\n",
            "Submodule path '3rdparty/NVTX': checked out 'a1ceb0677f67371ed29a2b1c022794f077db5fe7'\n",
            "Submodule path '3rdparty/cutlass': checked out '39c6a83f231d6db2bc6b9c251e7add77d68cbfb4'\n",
            "Submodule path '3rdparty/cxxopts': checked out 'eb787304d67ec22f7c3a184ee8b4c481d04357fd'\n",
            "Submodule path '3rdparty/json': checked out 'bc889afb4c5bf1c0d8ee29ef35eaaf4c8bef8a5d'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd TensorRT-LLM && git lfs install && git lfs pull\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lv2DVHzdQv7p",
        "outputId": "b615665b-4e97-4020-bb53-2ee7dace2be7"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated git hooks.\n",
            "Git LFS initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!uname -a\n",
        "!lsb_release -a\n",
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRtZRfBUXaWW",
        "outputId": "73488a69-f2ed-4740-f3f2-89e18407b09e"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linux 9988c5cb9588 6.1.58+ #1 SMP PREEMPT_DYNAMIC Sat Nov 18 15:31:17 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux\n",
            "No LSB modules are available.\n",
            "Distributor ID:\tUbuntu\n",
            "Description:\tUbuntu 22.04.3 LTS\n",
            "Release:\t22.04\n",
            "Codename:\tjammy\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd TensorRT-LLM && \\\n",
        "  python3 ./scripts/build_wheel.py --python_bindings --trt_root /usr/local/lib/python3.10/dist-packages/tensorrt_libs/ --clean \\\n",
        "  && pip install ./build/tensorrt_llm*.whl\n",
        "\n"
      ],
      "metadata": {
        "id": "-8EkDBlvRTEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /usr/local/tensorrt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38C8G5VjRYj2",
        "outputId": "5a94ddc8-4be4-45ff-d985-11bd7eaf0af5"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access '/usr/local/tensorrt': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y tensorrt-llm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FYeoHAkJnB5",
        "outputId": "8a2e0469-b8b2-4d3a-fb58-497a45157c82"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorrt-llm 0.6.1\n",
            "Uninstalling tensorrt-llm-0.6.1:\n",
            "  Successfully uninstalled tensorrt-llm-0.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd TensorRT-LLM && python setup.py install"
      ],
      "metadata": {
        "id": "7HWVewShF8gq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd TensorRT-LLM && pip install -r examples/bloom/requirements.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBSjsKxLC67-",
        "outputId": "bb909120-111a-4098-f6b1-fe91a6387e30"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets~=2.14.5 (from -r examples/bloom/requirements.txt (line 1))\n",
            "  Downloading datasets-2.14.7-py3-none-any.whl (520 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/520.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.1/520.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m520.4/520.4 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting evaluate~=0.4.1 (from -r examples/bloom/requirements.txt (line 2))\n",
            "  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rouge_score~=0.1.2 (from -r examples/bloom/requirements.txt (line 3))\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sentencepiece~=0.1.99 (from -r examples/bloom/requirements.txt (line 4))\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets~=2.14.5->-r examples/bloom/requirements.txt (line 1)) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets~=2.14.5->-r examples/bloom/requirements.txt (line 1)) (10.0.1)\n",
            "Collecting pyarrow-hotfix (from datasets~=2.14.5->-r examples/bloom/requirements.txt (line 1))\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets~=2.14.5->-r examples/bloom/requirements.txt (line 1))\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets~=2.14.5->-r examples/bloom/requirements.txt (line 1)) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets~=2.14.5->-r examples/bloom/requirements.txt (line 1)) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets~=2.14.5->-r examples/bloom/requirements.txt (line 1)) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets~=2.14.5->-r examples/bloom/requirements.txt (line 1)) (3.4.1)\n",
            "Collecting multiprocess (from datasets~=2.14.5->-r examples/bloom/requirements.txt (line 1))\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets~=2.14.5->-r examples/bloom/requirements.txt (line 1)) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets~=2.14.5->-r examples/bloom/requirements.txt (line 1)) (3.9.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets~=2.14.5->-r examples/bloom/requirements.txt (line 1)) (0.19.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets~=2.14.5->-r examples/bloom/requirements.txt (line 1)) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets~=2.14.5->-r examples/bloom/requirements.txt (line 1)) (6.0.1)\n",
            "Collecting responses<0.19 (from evaluate~=0.4.1->-r examples/bloom/requirements.txt (line 2))\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score~=0.1.2->-r examples/bloom/requirements.txt (line 3)) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score~=0.1.2->-r examples/bloom/requirements.txt (line 3)) (3.8.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score~=0.1.2->-r examples/bloom/requirements.txt (line 3)) (1.16.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets~=2.14.5->-r examples/bloom/requirements.txt (line 1)) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets~=2.14.5->-r examples/bloom/requirements.txt (line 1)) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets~=2.14.5->-r examples/bloom/requirements.txt (line 1)) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets~=2.14.5->-r examples/bloom/requirements.txt (line 1)) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets~=2.14.5->-r examples/bloom/requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets~=2.14.5->-r examples/bloom/requirements.txt (line 1)) (4.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets~=2.14.5->-r examples/bloom/requirements.txt (line 1)) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets~=2.14.5->-r examples/bloom/requirements.txt (line 1)) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets~=2.14.5->-r examples/bloom/requirements.txt (line 1)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets~=2.14.5->-r examples/bloom/requirements.txt (line 1)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets~=2.14.5->-r examples/bloom/requirements.txt (line 1)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets~=2.14.5->-r examples/bloom/requirements.txt (line 1)) (2023.11.17)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score~=0.1.2->-r examples/bloom/requirements.txt (line 3)) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score~=0.1.2->-r examples/bloom/requirements.txt (line 3)) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score~=0.1.2->-r examples/bloom/requirements.txt (line 3)) (2023.6.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets~=2.14.5->-r examples/bloom/requirements.txt (line 1)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets~=2.14.5->-r examples/bloom/requirements.txt (line 1)) (2023.3.post1)\n",
            "Building wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=93047121bc34ee701060db58b1befdfb3bea4b415d06ea324ec53764a187df38\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: sentencepiece, pyarrow-hotfix, dill, rouge_score, responses, multiprocess, datasets, evaluate\n",
            "Successfully installed datasets-2.14.7 dill-0.3.7 evaluate-0.4.1 multiprocess-0.70.15 pyarrow-hotfix-0.6 responses-0.18.0 rouge_score-0.1.2 sentencepiece-0.1.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list | grep tensorrt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BU6fBeoGHRl_",
        "outputId": "04decce1-cf5e-4766-9f58-c7f9eb85d1b2"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensorrt                         8.6.1.post1\n",
            "tensorrt-bindings                8.6.1\n",
            "tensorrt-libs                    8.6.1\n",
            "tensorrt-llm                     0.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y tensorrt\n",
        "!pip install --no-cache-dir --extra-index-url https://pypi.nvidia.com tensorrt==9.2.0.post12.dev5\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yrq1yStNHcwP",
        "outputId": "24c70ee6-13ea-48e4-826e-4a7cbc1642e6"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorrt 8.6.1.post1\n",
            "Uninstalling tensorrt-8.6.1.post1:\n",
            "  Successfully uninstalled tensorrt-8.6.1.post1\n",
            "Looking in indexes: https://pypi.org/simple, https://pypi.nvidia.com\n",
            "Collecting tensorrt==9.2.0.post12.dev5\n",
            "  Downloading https://pypi.nvidia.com/tensorrt/tensorrt-9.2.0.post12.dev5.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorrt_libs==9.2.0.post12.dev5 (from tensorrt==9.2.0.post12.dev5)\n",
            "  Downloading https://pypi.nvidia.com/tensorrt-libs/tensorrt_libs-9.2.0.post12.dev5-py2.py3-none-manylinux_2_17_x86_64.whl (1076.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 GB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorrt_bindings==9.2.0.post12.dev5 (from tensorrt==9.2.0.post12.dev5)\n",
            "  Downloading https://pypi.nvidia.com/tensorrt-bindings/tensorrt_bindings-9.2.0.post12.dev5-cp310-none-manylinux_2_17_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-cuda-runtime-cu12 in /usr/local/lib/python3.10/dist-packages (from tensorrt_libs==9.2.0.post12.dev5->tensorrt==9.2.0.post12.dev5) (12.3.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12 in /usr/local/lib/python3.10/dist-packages (from tensorrt_libs==9.2.0.post12.dev5->tensorrt==9.2.0.post12.dev5) (8.9.7.29)\n",
            "Requirement already satisfied: nvidia-cublas-cu12 in /usr/local/lib/python3.10/dist-packages (from tensorrt_libs==9.2.0.post12.dev5->tensorrt==9.2.0.post12.dev5) (12.3.4.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cudnn-cu12->tensorrt_libs==9.2.0.post12.dev5->tensorrt==9.2.0.post12.dev5) (12.3.103)\n",
            "Building wheels for collected packages: tensorrt\n",
            "  Building wheel for tensorrt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorrt: filename=tensorrt-9.2.0.post12.dev5-py2.py3-none-any.whl size=17625 sha256=e4030a42c958aa278d171cb8c40120b61c8a6de8abe948fa00b5d476509658cb\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-jr2clqqc/wheels/aa/96/bf/028c219d3560856a5fdb8b3aec8bf01e9d485521c092a64d02\n",
            "Successfully built tensorrt\n",
            "Installing collected packages: tensorrt_bindings, tensorrt_libs, tensorrt\n",
            "  Attempting uninstall: tensorrt_bindings\n",
            "    Found existing installation: tensorrt-bindings 8.6.1\n",
            "    Uninstalling tensorrt-bindings-8.6.1:\n",
            "      Successfully uninstalled tensorrt-bindings-8.6.1\n",
            "  Attempting uninstall: tensorrt_libs\n",
            "    Found existing installation: tensorrt-libs 8.6.1\n",
            "    Uninstalling tensorrt-libs-8.6.1:\n",
            "      Successfully uninstalled tensorrt-libs-8.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorrt-llm 0.6.1 requires transformers==4.33.1, but you have transformers 4.36.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tensorrt-9.2.0.post12.dev5 tensorrt_bindings-9.2.0.post12.dev5 tensorrt_libs-9.2.0.post12.dev5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd TensorRT-LLM && git lfs install\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHitwl8EDJ1y",
        "outputId": "cc5aa2c1-2068-4442-988d-751da37bae00"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated git hooks.\n",
            "Git LFS initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd TensorRT-LLM/examples/bloom \\\n",
        "  && rm -rf ./bloom/560M \\\n",
        "  && mkdir -p ./bloom/560M && git clone https://huggingface.co/bigscience/bloom-560m ./bloom/560M\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZ5Rp3_aDZSB",
        "outputId": "425abf7a-6bb3-44a8-f67e-a668a66e4f47"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into './bloom/560M'...\n",
            "remote: Enumerating objects: 111, done.\u001b[K\n",
            "remote: Total 111 (delta 0), reused 0 (delta 0), pack-reused 111\u001b[K\n",
            "Receiving objects: 100% (111/111), 28.49 KiB | 14.25 MiB/s, done.\n",
            "Resolving deltas: 100% (55/55), done.\n",
            "Filtering content: 100% (11/11), 12.27 GiB | 202.37 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Single GPU on BLOOM 560M\n",
        "!cd TensorRT-LLM/examples/bloom \\\n",
        "  && python convert_checkpoint.py --model_dir ./bloom/560M/ \\\n",
        "                --dtype float16 \\\n",
        "                --output_dir ./bloom/560M/trt_ckpt/fp16/1-gpu/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7P91hgEcD5xH",
        "outputId": "587e6c6d-29c5-49a4-d80c-0bcf116259e8"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/TensorRT-LLM/examples/bloom/convert_checkpoint.py\", line 17, in <module>\n",
            "    import tensorrt_llm\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorrt_llm-0.6.1-py3.10-linux-x86_64.egg/tensorrt_llm/__init__.py\", line 61, in <module>\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorrt_llm-0.6.1-py3.10-linux-x86_64.egg/tensorrt_llm/_common.py\", line 47, in _init\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorrt_llm-0.6.1-py3.10-linux-x86_64.egg/tensorrt_llm/plugin/plugin.py\", line 34, in _load_plugin_lib\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: /usr/local/lib/python3.10/dist-packages/tensorrt_llm-0.6.1-py3.10-linux-x86_64.egg/tensorrt_llm/libs/libnvinfer_plugin_tensorrt_llm.so: cannot open shared object file: Not a directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /usr/local/lib/python3.10/dist-packages/tensorrt_llm-0.6.1-py3.10-linux-x86_64.egg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QXlzo--KDlI",
        "outputId": "553ead84-48d7-4b43-f6d2-4f9ebe3afb6b"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access '/usr/local/lib/python3.10/dist-packages/tensorrt_llm-0.6.1-py3.10-linux-x86_64.egg': No such file or directory\n"
          ]
        }
      ]
    }
  ]
}