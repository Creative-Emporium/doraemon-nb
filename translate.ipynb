{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNrwiV7kpxw0re1GP4J49A3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weedge/doraemon-nb/blob/main/translate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "想把 HuggingFaceTB/cosmopedia 英文数据中的prompt和text 翻译成 中文， 然后看了下 deep_translator的实现， 翻译调用的是三方接口集成库， 于是使用这个库封装的谷歌翻译接口来翻译，但是三方平台接口多会有限流和接口调用频率限制，即使在代码中有容错处理， 比如常规的sleep下再调用，不影响整理处理流程，但是整体处理时间受接口限制，即使用批处理也如此，这个在大规模数据处理中使用三方接口时，经常会遇到的问题，用的三方服务，在技术上不好解决； 于是选择另外一种方案，看是否有开源的翻译模型，底层模型结构一般也是Transform架构 Encoder-decoder model ，也称sequence-to-sequence model； 比如 谷歌的T5模型， 但是推理速度受硬件条件影响，比较慢， 然后看了下meta nllb 模型，专门用来处理翻译的模型，单个 AI 模型中支持 200 种语言，开源地址： https://github.com/facebookresearch/fairseq/tree/nllb  \n",
        "\n",
        "模型相对现在的LLM参数量小一些，也在huggingface的Transforms库中集成 nllb-200-distilled-600M，直接可以load使用， 等等。。。 既然llm推理可以通过想llama.cpp通过加载ggml格式进行量化，在性能有少许折损的情况下降低推理成本，但是ggml格式还不支持nllb模型权重文件；那就直接用Transforms库来加载facebook/nllb-200-distilled-600M 模型来批量翻译试试看\n",
        "\n",
        "- 使用Transforms库进行翻译任务： https://huggingface.co/docs/transformers/tasks/translation\n",
        "\n",
        "- https://github.com/facebookresearch/fairseq/tree/nllb\n",
        "\n",
        "- https://ai.meta.com/blog/nllb-200-high-quality-machine-translation/\n",
        "\n",
        "后续尝试使用 [' Helsinki-NLP/opus-mt-en-zh '](https://huggingface.co/Helsinki-NLP/opus-mt-en-zh) 模型，\n"
      ],
      "metadata": {
        "id": "67spOXhsGVY_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehaV6p7PaW2z",
        "outputId": "b6975b21-912f-46c3-d1b8-4c93801cd71e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q -U datasets deep-translator transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli download \\\n",
        "  --repo-type dataset HuggingFaceTB/cosmopedia data/stories/train-00000-of-00043.parquet \\\n",
        "  --local-dir ./datas/datasets/HuggingFaceTB/cosmopedia \\\n",
        "  --local-dir-use-symlinks False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T76reoN4pU8F",
        "outputId": "ed99081e-5df5-4c55-8f37-b0e0cd627a53"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Consider using `hf_transfer` for faster downloads. This solution comes with some limitations. See https://huggingface.co/docs/huggingface_hub/hf_transfer for more details.\n",
            "downloading https://huggingface.co/datasets/HuggingFaceTB/cosmopedia/resolve/main/data/stories/train-00000-of-00043.parquet to /root/.cache/huggingface/hub/tmp_65cfxuf\n",
            "train-00000-of-00043.parquet: 100% 277M/277M [00:01<00:00, 190MB/s]\n",
            "./datas/datasets/HuggingFaceTB/cosmopedia/data/stories/train-00000-of-00043.parquet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat translate.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKnOMFt8Gw2P",
        "outputId": "fb1241ef-e6fa-4251-b7e3-2271f4f88dfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# https://huggingface.co/learn/nlp-course/chapter5/\n",
            "# https://zhuanlan.zhihu.com/p/564816807\n",
            "\n",
            "from deep_translator import GoogleTranslator\n",
            "from datasets import load_dataset, load_from_disk\n",
            "import argparse\n",
            "import time\n",
            "\n",
            "\n",
            "def translate_en2cn(item):\n",
            "    translated = \"\"\n",
            "    try_cn = 100\n",
            "    while try_cn > 0:\n",
            "        try:\n",
            "            translated_prompt = GoogleTranslator(source='en', target='zh-CN').translate(\n",
            "                item[\"prompt\"])\n",
            "            translated_text = GoogleTranslator(source='en', target='zh-CN').translate(\n",
            "                item[\"text\"])\n",
            "            break\n",
            "        except Exception as e:\n",
            "            print(\"An error occurred:\", e)\n",
            "            time.sleep(1)\n",
            "            try_cn -= 1\n",
            "\n",
            "    return {\"text_zh\": translated_text, \"prompt_zh\": translated_prompt}\n",
            "\n",
            "\n",
            "def batch_check_data(batch):\n",
            "    return [len(item) != 0 for item in batch[\"text_zh\"]]\n",
            "\n",
            "\n",
            "def translate2save(src_dataset_dir: str, target_dataset_dir: str):\n",
            "    data = load_dataset(src_dataset_dir, split=\"train[:100]\")\n",
            "    data = data.map(translate_en2cn, batched=False)\n",
            "    data.save_to_disk(target_dataset_dir)\n",
            "    print(data)\n",
            "\n",
            "\n",
            "def load2check(dataset_dir):\n",
            "    data = load_from_disk(dataset_dir)\n",
            "    print(\"filter before\", data)\n",
            "    data = data.filter(batch_check_data, batched=True)\n",
            "    print(\"filter after\", data)\n",
            "\n",
            "\n",
            "if __name__ == \"__main__\":\n",
            "    parser = argparse.ArgumentParser()\n",
            "    parser.add_argument(\"stage\", type=str, choices=[\"translate\", \"check\"])\n",
            "    parser.add_argument(\"-s\", \"--src_dir\", type=str,\n",
            "                        help=\"path to src dataset dir \")\n",
            "    parser.add_argument(\"-t\", \"--target_dir\", type=str,\n",
            "                        help=\"path to target dataset dir \", required=lambda x: x is not None)\n",
            "    args = parser.parse_args()\n",
            "\n",
            "    if args.stage == \"translate\":\n",
            "        translate2save(args.src_dir, args.target_dir)\n",
            "    elif args.stage == \"check\":\n",
            "        load2check(args.target_dir)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python translate.py translate -s ./datas/datasets/HuggingFaceTB/cosmopedia/data/stories \\\n",
        "  -t ./datas/datasets/HuggingFaceTB/cosmopedia_zh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWQZ4CyPnlYe",
        "outputId": "da581d56-5379-4e8a-85f4-1232d4689193"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Map: 100% 100/100 [03:34<00:00,  2.15s/ examples]\n",
            "Saving the dataset (1/1 shards): 100% 100/100 [00:00<00:00, 9226.77 examples/s]\n",
            "Dataset({\n",
            "    features: ['text', 'prompt', 'text_token_length', 'seed_data', 'format', 'audience', 'text_zh', 'prompt_zh'],\n",
            "    num_rows: 100\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## facebook/nllb"
      ],
      "metadata": {
        "id": "3s7ErRlPDZSf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\", use_auth_token=True, src_lang=\"eng_Latn\",target_lang=\"zho_Hans\")\n",
        "tokenizer\n"
      ],
      "metadata": {
        "id": "uTDZ5KN16_pt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f7e21d6-7962-44a8-ccc9-f982f94aeba3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py:732: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NllbTokenizerFast(name_or_path='facebook/nllb-200-distilled-600M', vocab_size=256204, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>', 'additional_special_tokens': ['ace_Arab', 'ace_Latn', 'acm_Arab', 'acq_Arab', 'aeb_Arab', 'afr_Latn', 'ajp_Arab', 'aka_Latn', 'amh_Ethi', 'apc_Arab', 'arb_Arab', 'ars_Arab', 'ary_Arab', 'arz_Arab', 'asm_Beng', 'ast_Latn', 'awa_Deva', 'ayr_Latn', 'azb_Arab', 'azj_Latn', 'bak_Cyrl', 'bam_Latn', 'ban_Latn', 'bel_Cyrl', 'bem_Latn', 'ben_Beng', 'bho_Deva', 'bjn_Arab', 'bjn_Latn', 'bod_Tibt', 'bos_Latn', 'bug_Latn', 'bul_Cyrl', 'cat_Latn', 'ceb_Latn', 'ces_Latn', 'cjk_Latn', 'ckb_Arab', 'crh_Latn', 'cym_Latn', 'dan_Latn', 'deu_Latn', 'dik_Latn', 'dyu_Latn', 'dzo_Tibt', 'ell_Grek', 'eng_Latn', 'epo_Latn', 'est_Latn', 'eus_Latn', 'ewe_Latn', 'fao_Latn', 'pes_Arab', 'fij_Latn', 'fin_Latn', 'fon_Latn', 'fra_Latn', 'fur_Latn', 'fuv_Latn', 'gla_Latn', 'gle_Latn', 'glg_Latn', 'grn_Latn', 'guj_Gujr', 'hat_Latn', 'hau_Latn', 'heb_Hebr', 'hin_Deva', 'hne_Deva', 'hrv_Latn', 'hun_Latn', 'hye_Armn', 'ibo_Latn', 'ilo_Latn', 'ind_Latn', 'isl_Latn', 'ita_Latn', 'jav_Latn', 'jpn_Jpan', 'kab_Latn', 'kac_Latn', 'kam_Latn', 'kan_Knda', 'kas_Arab', 'kas_Deva', 'kat_Geor', 'knc_Arab', 'knc_Latn', 'kaz_Cyrl', 'kbp_Latn', 'kea_Latn', 'khm_Khmr', 'kik_Latn', 'kin_Latn', 'kir_Cyrl', 'kmb_Latn', 'kon_Latn', 'kor_Hang', 'kmr_Latn', 'lao_Laoo', 'lvs_Latn', 'lij_Latn', 'lim_Latn', 'lin_Latn', 'lit_Latn', 'lmo_Latn', 'ltg_Latn', 'ltz_Latn', 'lua_Latn', 'lug_Latn', 'luo_Latn', 'lus_Latn', 'mag_Deva', 'mai_Deva', 'mal_Mlym', 'mar_Deva', 'min_Latn', 'mkd_Cyrl', 'plt_Latn', 'mlt_Latn', 'mni_Beng', 'khk_Cyrl', 'mos_Latn', 'mri_Latn', 'zsm_Latn', 'mya_Mymr', 'nld_Latn', 'nno_Latn', 'nob_Latn', 'npi_Deva', 'nso_Latn', 'nus_Latn', 'nya_Latn', 'oci_Latn', 'gaz_Latn', 'ory_Orya', 'pag_Latn', 'pan_Guru', 'pap_Latn', 'pol_Latn', 'por_Latn', 'prs_Arab', 'pbt_Arab', 'quy_Latn', 'ron_Latn', 'run_Latn', 'rus_Cyrl', 'sag_Latn', 'san_Deva', 'sat_Beng', 'scn_Latn', 'shn_Mymr', 'sin_Sinh', 'slk_Latn', 'slv_Latn', 'smo_Latn', 'sna_Latn', 'snd_Arab', 'som_Latn', 'sot_Latn', 'spa_Latn', 'als_Latn', 'srd_Latn', 'srp_Cyrl', 'ssw_Latn', 'sun_Latn', 'swe_Latn', 'swh_Latn', 'szl_Latn', 'tam_Taml', 'tat_Cyrl', 'tel_Telu', 'tgk_Cyrl', 'tgl_Latn', 'tha_Thai', 'tir_Ethi', 'taq_Latn', 'taq_Tfng', 'tpi_Latn', 'tsn_Latn', 'tso_Latn', 'tuk_Latn', 'tum_Latn', 'tur_Latn', 'twi_Latn', 'tzm_Tfng', 'uig_Arab', 'ukr_Cyrl', 'umb_Latn', 'urd_Arab', 'uzn_Latn', 'vec_Latn', 'vie_Latn', 'war_Latn', 'wol_Latn', 'xho_Latn', 'ydd_Hebr', 'yor_Latn', 'yue_Hant', 'zho_Hans', 'zho_Hant', 'zul_Latn']}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
              "\t0: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t1: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256001: AddedToken(\"ace_Arab\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256002: AddedToken(\"ace_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256003: AddedToken(\"acm_Arab\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256004: AddedToken(\"acq_Arab\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256005: AddedToken(\"aeb_Arab\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256006: AddedToken(\"afr_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256007: AddedToken(\"ajp_Arab\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256008: AddedToken(\"aka_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256009: AddedToken(\"amh_Ethi\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256010: AddedToken(\"apc_Arab\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256011: AddedToken(\"arb_Arab\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256012: AddedToken(\"ars_Arab\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256013: AddedToken(\"ary_Arab\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256014: AddedToken(\"arz_Arab\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256015: AddedToken(\"asm_Beng\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256016: AddedToken(\"ast_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256017: AddedToken(\"awa_Deva\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256018: AddedToken(\"ayr_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256019: AddedToken(\"azb_Arab\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256020: AddedToken(\"azj_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256021: AddedToken(\"bak_Cyrl\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256022: AddedToken(\"bam_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256023: AddedToken(\"ban_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256024: AddedToken(\"bel_Cyrl\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256025: AddedToken(\"bem_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256026: AddedToken(\"ben_Beng\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256027: AddedToken(\"bho_Deva\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256028: AddedToken(\"bjn_Arab\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256029: AddedToken(\"bjn_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256030: AddedToken(\"bod_Tibt\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256031: AddedToken(\"bos_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256032: AddedToken(\"bug_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256033: AddedToken(\"bul_Cyrl\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256034: AddedToken(\"cat_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256035: AddedToken(\"ceb_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256036: AddedToken(\"ces_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256037: AddedToken(\"cjk_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256038: AddedToken(\"ckb_Arab\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256039: AddedToken(\"crh_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256040: AddedToken(\"cym_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256041: AddedToken(\"dan_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256042: AddedToken(\"deu_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256043: AddedToken(\"dik_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256044: AddedToken(\"dyu_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256045: AddedToken(\"dzo_Tibt\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256046: AddedToken(\"ell_Grek\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256047: AddedToken(\"eng_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256048: AddedToken(\"epo_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256049: AddedToken(\"est_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256050: AddedToken(\"eus_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256051: AddedToken(\"ewe_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256052: AddedToken(\"fao_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256053: AddedToken(\"pes_Arab\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256054: AddedToken(\"fij_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256055: AddedToken(\"fin_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256056: AddedToken(\"fon_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256057: AddedToken(\"fra_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256058: AddedToken(\"fur_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256059: AddedToken(\"fuv_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256060: AddedToken(\"gla_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256061: AddedToken(\"gle_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256062: AddedToken(\"glg_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256063: AddedToken(\"grn_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256064: AddedToken(\"guj_Gujr\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256065: AddedToken(\"hat_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256066: AddedToken(\"hau_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256067: AddedToken(\"heb_Hebr\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256068: AddedToken(\"hin_Deva\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256069: AddedToken(\"hne_Deva\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256070: AddedToken(\"hrv_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256071: AddedToken(\"hun_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256072: AddedToken(\"hye_Armn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256073: AddedToken(\"ibo_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256074: AddedToken(\"ilo_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256075: AddedToken(\"ind_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256076: AddedToken(\"isl_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256077: AddedToken(\"ita_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256078: AddedToken(\"jav_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256079: AddedToken(\"jpn_Jpan\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256080: AddedToken(\"kab_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256081: AddedToken(\"kac_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256082: AddedToken(\"kam_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256083: AddedToken(\"kan_Knda\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256084: AddedToken(\"kas_Arab\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256085: AddedToken(\"kas_Deva\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256086: AddedToken(\"kat_Geor\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256087: AddedToken(\"knc_Arab\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256088: AddedToken(\"knc_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256089: AddedToken(\"kaz_Cyrl\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256090: AddedToken(\"kbp_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256091: AddedToken(\"kea_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256092: AddedToken(\"khm_Khmr\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256093: AddedToken(\"kik_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256094: AddedToken(\"kin_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256095: AddedToken(\"kir_Cyrl\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256096: AddedToken(\"kmb_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256097: AddedToken(\"kon_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256098: AddedToken(\"kor_Hang\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256099: AddedToken(\"kmr_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256100: AddedToken(\"lao_Laoo\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256101: AddedToken(\"lvs_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256102: AddedToken(\"lij_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256103: AddedToken(\"lim_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256104: AddedToken(\"lin_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256105: AddedToken(\"lit_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256106: AddedToken(\"lmo_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256107: AddedToken(\"ltg_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256108: AddedToken(\"ltz_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256109: AddedToken(\"lua_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256110: AddedToken(\"lug_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256111: AddedToken(\"luo_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256112: AddedToken(\"lus_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256113: AddedToken(\"mag_Deva\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256114: AddedToken(\"mai_Deva\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256115: AddedToken(\"mal_Mlym\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256116: AddedToken(\"mar_Deva\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256117: AddedToken(\"min_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256118: AddedToken(\"mkd_Cyrl\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256119: AddedToken(\"plt_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256120: AddedToken(\"mlt_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256121: AddedToken(\"mni_Beng\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256122: AddedToken(\"khk_Cyrl\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256123: AddedToken(\"mos_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256124: AddedToken(\"mri_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256125: AddedToken(\"zsm_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256126: AddedToken(\"mya_Mymr\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256127: AddedToken(\"nld_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256128: AddedToken(\"nno_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256129: AddedToken(\"nob_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256130: AddedToken(\"npi_Deva\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256131: AddedToken(\"nso_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256132: AddedToken(\"nus_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256133: AddedToken(\"nya_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256134: AddedToken(\"oci_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256135: AddedToken(\"gaz_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256136: AddedToken(\"ory_Orya\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256137: AddedToken(\"pag_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256138: AddedToken(\"pan_Guru\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256139: AddedToken(\"pap_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256140: AddedToken(\"pol_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256141: AddedToken(\"por_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256142: AddedToken(\"prs_Arab\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256143: AddedToken(\"pbt_Arab\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256144: AddedToken(\"quy_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256145: AddedToken(\"ron_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256146: AddedToken(\"run_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256147: AddedToken(\"rus_Cyrl\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256148: AddedToken(\"sag_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256149: AddedToken(\"san_Deva\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256150: AddedToken(\"sat_Beng\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256151: AddedToken(\"scn_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256152: AddedToken(\"shn_Mymr\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256153: AddedToken(\"sin_Sinh\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256154: AddedToken(\"slk_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256155: AddedToken(\"slv_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256156: AddedToken(\"smo_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256157: AddedToken(\"sna_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256158: AddedToken(\"snd_Arab\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256159: AddedToken(\"som_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256160: AddedToken(\"sot_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256161: AddedToken(\"spa_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256162: AddedToken(\"als_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256163: AddedToken(\"srd_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256164: AddedToken(\"srp_Cyrl\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256165: AddedToken(\"ssw_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256166: AddedToken(\"sun_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256167: AddedToken(\"swe_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256168: AddedToken(\"swh_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256169: AddedToken(\"szl_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256170: AddedToken(\"tam_Taml\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256171: AddedToken(\"tat_Cyrl\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256172: AddedToken(\"tel_Telu\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256173: AddedToken(\"tgk_Cyrl\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256174: AddedToken(\"tgl_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256175: AddedToken(\"tha_Thai\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256176: AddedToken(\"tir_Ethi\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256177: AddedToken(\"taq_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256178: AddedToken(\"taq_Tfng\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256179: AddedToken(\"tpi_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256180: AddedToken(\"tsn_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256181: AddedToken(\"tso_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256182: AddedToken(\"tuk_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256183: AddedToken(\"tum_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256184: AddedToken(\"tur_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256185: AddedToken(\"twi_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256186: AddedToken(\"tzm_Tfng\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256187: AddedToken(\"uig_Arab\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256188: AddedToken(\"ukr_Cyrl\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256189: AddedToken(\"umb_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256190: AddedToken(\"urd_Arab\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256191: AddedToken(\"uzn_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256192: AddedToken(\"vec_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256193: AddedToken(\"vie_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256194: AddedToken(\"war_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256195: AddedToken(\"wol_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256196: AddedToken(\"xho_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256197: AddedToken(\"ydd_Hebr\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256198: AddedToken(\"yor_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256199: AddedToken(\"yue_Hant\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256200: AddedToken(\"zho_Hans\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256201: AddedToken(\"zho_Hant\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256202: AddedToken(\"zul_Latn\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t256203: AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=True, special=True),\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\", use_auth_token=True)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEmGrPopDx7I",
        "outputId": "03675ebe-24fd-4cc4-ada9-57b145b8468e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py:468: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "M2M100ForConditionalGeneration(\n",
              "  (model): M2M100Model(\n",
              "    (shared): Embedding(256206, 1024, padding_idx=1)\n",
              "    (encoder): M2M100Encoder(\n",
              "      (embed_tokens): Embedding(256206, 1024, padding_idx=1)\n",
              "      (embed_positions): M2M100SinusoidalPositionalEmbedding()\n",
              "      (layers): ModuleList(\n",
              "        (0-11): 12 x M2M100EncoderLayer(\n",
              "          (self_attn): M2M100Attention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): ReLU()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (decoder): M2M100Decoder(\n",
              "      (embed_tokens): Embedding(256206, 1024, padding_idx=1)\n",
              "      (embed_positions): M2M100SinusoidalPositionalEmbedding()\n",
              "      (layers): ModuleList(\n",
              "        (0-11): 12 x M2M100DecoderLayer(\n",
              "          (self_attn): M2M100Attention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): ReLU()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): M2M100Attention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (lm_head): Linear(in_features=1024, out_features=256206, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "article = [\n",
        "    \"\"\"\n",
        "    Dr. Mitchell nodded approvingly. \"Yes, indeed! Fatty fish boast rich stores of omega-3 fatty acids – specifically EPA and DHA – which work miracles within our bodies.\n",
        "    Amongst numerous benefits, they decrease triglyceride levels, lower blood pressure, discourage plaque formation, and even suppress irregular heartbeats.\"\n",
        "    \"\"\",\n",
        "    \"\"\"\n",
        "    An intriguing idea took root in Alex's mind, blossoming rapidly into resolve. If these simple changes could make such profound differences in his life,\n",
        "    why stop there? Why not share this gift with others – friends, colleagues, strangers who might also benefit from understanding how food choices impact heart health?\n",
        "    Perhaps he could host educational events, cooking demonstrations, or write articles championing these powerful culinary tools.\n",
        "    Yes, he decided, that would be his mission – to spread awareness and inspire change, one plate at a time.\n",
        "    \"\"\",\n",
        "    \"\"\"\n",
        "    His thoughts must have shown on his face because Dr. Mitchell suddenly grinned, leaning back in her chair with satisfaction.\n",
        "    \"Ah, I see the wheels turning in that brilliant mind of yours, Alex. Go ahead, run with it!\"\n",
        "    \"\"\",\n",
        "]\n",
        "for item in article:\n",
        "  print(len(item))\n",
        "\n",
        "inputs = tokenizer(article, return_tensors=\"pt\",padding=True,truncation=True)\n",
        "\n",
        "translated_tokens = model.generate(**inputs, forced_bos_token_id=tokenizer.lang_code_to_id[\"zho_Hans\"], max_new_tokens=1024)\n",
        "tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lBT_AwmBF5i",
        "outputId": "ae93e863-1112-427a-dc1d-617caf26fff6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "335\n",
            "574\n",
            "232\n",
            "CPU times: user 48.6 s, sys: 74.7 ms, total: 48.7 s\n",
            "Wall time: 12.3 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['密切尔博士 赞成. \"是的,确实!脂肪鱼拥有丰富的欧米茄-3脂肪酸,特别是EPA和DHA,这些脂肪酸在我们的身体中能做出奇迹.',\n",
              " '亚历克斯的想法很有趣,迅速发展成决心.如果这些简单的变化可以在他的生活中产生如此深刻的差异,为什么不停下来?为什么不与他人分享这个礼物?朋友,同事,陌生人也可能会从了解食物选择如何影响心脏健康中受益?也许他可以举办教育活动,做饭示范,或写文章宣扬这些强大的食工具.',\n",
              " '他会在脸上看到他的想法,因为米切尔博士突然笑了,在椅子上仰卧,满意. \",我看到你的聪明智力转动,亚历克斯.']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helsinki-NLP/opus-mt"
      ],
      "metadata": {
        "id": "uXFvsfKZDeGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "model_checkpoint = \"Helsinki-NLP/opus-mt-en-zh\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "tokenizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGKyVNedCMMo",
        "outputId": "ea4ee4f5-7d42-4913-e85f-16a2c1707de3"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/marian/tokenization_marian.py:197: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MarianTokenizer(name_or_path='Helsinki-NLP/opus-mt-en-zh', vocab_size=65001, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
              "\t0: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t1: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t65000: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKSku69tDJFH",
        "outputId": "d8204745-0f00-4a80-a503-81f4e2a764f2"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MarianMTModel(\n",
              "  (model): MarianModel(\n",
              "    (shared): Embedding(65001, 512, padding_idx=65000)\n",
              "    (encoder): MarianEncoder(\n",
              "      (embed_tokens): Embedding(65001, 512, padding_idx=65000)\n",
              "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
              "      (layers): ModuleList(\n",
              "        (0-5): 6 x MarianEncoderLayer(\n",
              "          (self_attn): MarianAttention(\n",
              "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): SiLU()\n",
              "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (decoder): MarianDecoder(\n",
              "      (embed_tokens): Embedding(65001, 512, padding_idx=65000)\n",
              "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
              "      (layers): ModuleList(\n",
              "        (0-5): 6 x MarianDecoderLayer(\n",
              "          (self_attn): MarianAttention(\n",
              "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (activation_fn): SiLU()\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): MarianAttention(\n",
              "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (lm_head): Linear(in_features=512, out_features=65001, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "#text = [\"In terms of time, the Chinese space station was built more than 20 years later than the International Space Station.\",\"hello world.\"]\n",
        "article = [\n",
        "    \"\"\"\n",
        "    Dr. Mitchell nodded approvingly. \"Yes, indeed! Fatty fish boast rich stores of omega-3 fatty acids – specifically EPA and DHA – which work miracles within our bodies.\n",
        "    Amongst numerous benefits, they decrease triglyceride levels, lower blood pressure, discourage plaque formation, and even suppress irregular heartbeats.\"\n",
        "    \"\"\",\n",
        "    \"\"\"\n",
        "    An intriguing idea took root in Alex's mind, blossoming rapidly into resolve. If these simple changes could make such profound differences in his life,\n",
        "    why stop there? Why not share this gift with others – friends, colleagues, strangers who might also benefit from understanding how food choices impact heart health?\n",
        "    Perhaps he could host educational events, cooking demonstrations, or write articles championing these powerful culinary tools.\n",
        "    Yes, he decided, that would be his mission – to spread awareness and inspire change, one plate at a time.\n",
        "    \"\"\",\n",
        "    \"\"\"\n",
        "    His thoughts must have shown on his face because Dr. Mitchell suddenly grinned, leaning back in her chair with satisfaction.\n",
        "    \"Ah, I see the wheels turning in that brilliant mind of yours, Alex. Go ahead, run with it!\"\n",
        "    \"\"\",\n",
        "]\n",
        "for item in article:\n",
        "  print(len(item))\n",
        "\n",
        "# Tokenize the text\n",
        "inputs = tokenizer(article, return_tensors=\"pt\",padding=True,truncation=True).input_ids\n",
        "\n",
        "# Perform the translation and decode the output\n",
        "translation = model.generate(inputs, max_new_tokens=512, do_sample=True, top_k=30, top_p=0.95)\n",
        "\n",
        "result = tokenizer.batch_decode(translation, skip_special_tokens=True)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i86R3nuWDRHS",
        "outputId": "17f7b779-1023-40d3-9a22-d350d3b946be"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "335\n",
            "574\n",
            "232\n",
            "['米切尔博士点头同意。 “是的,事实上,胖鱼有丰富的欧美加-3脂肪酸库 — — 特别是美国环保局和丹麦卫生局 — — 为我们的身体带来了奇迹。 在许多好处中,它们降低了三重血压水平,降低了血压,抑制了形成斑块,甚至抑制了不规则的心跳。 ”', '一种有趣的想法在亚历克斯的脑海中扎根,迅速发展成决心。 如果这些简单的变化能让他的生活产生如此深刻的差别,为什么停下来呢? 为什么不和其他人分享这一礼物 — — 朋友、同事、陌生人,他们可能也从了解食物选择如何影响心脏健康中受益? 也许他可以主办教育活动、烹饪示威或撰写文章支持这些强大的烹饪工具。 是的,他决定,这将是他的使命 — — 传播意识和激励变革,一个一个一盘一盘。', '他一定在脸上表现出了自己的想法,因为米切尔博士突然微笑, 满心满意地坐在她的椅子上。 “啊,我看到你的聪明头脑,亚历克斯, 转动了轮子。继续,去跑吧!”']\n",
            "CPU times: user 20.6 s, sys: 48.8 ms, total: 20.7 s\n",
            "Wall time: 5.18 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 总结：\n",
        "\n",
        "facebook/nllb-200-distilled-600M 模型 翻译 效果一般，Helsinki-NLP/opus-mt-en-zh 整体效果还可以；以上翻译文本受文本长度限制，中文token可能由两个字组成(比如:\"一种\")，需要对长文本进行切割，然后在批量翻译，然后在组合；\n",
        "在本地部署模型翻译的方式pass,需要加载参数大模型才能有好的翻译效果(和硬件无关，和模型推理有关)， 而且推理速度需要硬件GPU来加持，会有模型调参实现成本和计算成本在；\n",
        "如果有机器支持，可以选用本地批量翻译的方式\n",
        "如果使用三方翻译接口，批量处理就会受制于接口的限制（限速，翻译文本长度，并发请求数等等）\n"
      ],
      "metadata": {
        "id": "AXt_SK5fLJ__"
      }
    }
  ]
}