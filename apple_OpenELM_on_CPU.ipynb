{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyP8YHjHd+z/ZVmxiYw1+i37",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "aff8e4a2b48a484eb9b53cb7699b0b7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e14a66bd8873431fbd301c7c961c8340",
              "IPY_MODEL_706341fc7ab546098c3539d2610d3197",
              "IPY_MODEL_c2ac07b5f4c245d6b6eb960a7ad1e49b"
            ],
            "layout": "IPY_MODEL_cb762987ef1343d1960f86f2eab0888b"
          }
        },
        "e14a66bd8873431fbd301c7c961c8340": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0685835ad658441fbed6373df8d0c1be",
            "placeholder": "​",
            "style": "IPY_MODEL_9639c1c675d14824af653d86d246bb87",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "706341fc7ab546098c3539d2610d3197": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f8f5d65dce44937816dd0f11f07bad3",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1e53ecb30c474dd7b5e9d2b187bec4e7",
            "value": 3
          }
        },
        "c2ac07b5f4c245d6b6eb960a7ad1e49b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8666eb5495f45818b8cedb5b3a47d13",
            "placeholder": "​",
            "style": "IPY_MODEL_6dde9942fddd4bf5b567f0c97ba60bab",
            "value": " 3/3 [00:08&lt;00:00,  2.62s/it]"
          }
        },
        "cb762987ef1343d1960f86f2eab0888b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0685835ad658441fbed6373df8d0c1be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9639c1c675d14824af653d86d246bb87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f8f5d65dce44937816dd0f11f07bad3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e53ecb30c474dd7b5e9d2b187bec4e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d8666eb5495f45818b8cedb5b3a47d13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6dde9942fddd4bf5b567f0c97ba60bab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weedge/doraemon-nb/blob/main/apple_OpenELM_on_CPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfL2ZsClBaoD",
        "outputId": "1e4838bc-12f2-44e5-b1d9-9cedf09db92d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Architecture:            x86_64\n",
            "  CPU op-mode(s):        32-bit, 64-bit\n",
            "  Address sizes:         46 bits physical, 48 bits virtual\n",
            "  Byte Order:            Little Endian\n",
            "CPU(s):                  8\n",
            "  On-line CPU(s) list:   0-7\n",
            "Vendor ID:               GenuineIntel\n",
            "  Model name:            Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "    CPU family:          6\n",
            "    Model:               79\n",
            "    Thread(s) per core:  2\n",
            "    Core(s) per socket:  4\n",
            "    Socket(s):           1\n",
            "    Stepping:            0\n",
            "    BogoMIPS:            4399.99\n",
            "    Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clf\n",
            "                         lush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_\n",
            "                         good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fm\n",
            "                         a cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hyp\n",
            "                         ervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsb\n",
            "                         ase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsa\n",
            "                         veopt arat md_clear arch_capabilities\n",
            "Virtualization features: \n",
            "  Hypervisor vendor:     KVM\n",
            "  Virtualization type:   full\n",
            "Caches (sum of all):     \n",
            "  L1d:                   128 KiB (4 instances)\n",
            "  L1i:                   128 KiB (4 instances)\n",
            "  L2:                    1 MiB (4 instances)\n",
            "  L3:                    55 MiB (1 instance)\n",
            "NUMA:                    \n",
            "  NUMA node(s):          1\n",
            "  NUMA node0 CPU(s):     0-7\n",
            "Vulnerabilities:         \n",
            "  Gather data sampling:  Not affected\n",
            "  Itlb multihit:         Not affected\n",
            "  L1tf:                  Mitigation; PTE Inversion\n",
            "  Mds:                   Vulnerable; SMT Host state unknown\n",
            "  Meltdown:              Vulnerable\n",
            "  Mmio stale data:       Vulnerable\n",
            "  Retbleed:              Vulnerable\n",
            "  Spec rstack overflow:  Not affected\n",
            "  Spec store bypass:     Vulnerable\n",
            "  Spectre v1:            Vulnerable: __user pointer sanitization and usercopy barriers only; no swap\n",
            "                         gs barriers\n",
            "  Spectre v2:            Vulnerable, IBPB: disabled, STIBP: disabled, PBRSB-eIBRS: Not affected\n",
            "  Srbds:                 Not affected\n",
            "  Tsx async abort:       Vulnerable\n"
          ]
        }
      ],
      "source": [
        "!lscpu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!free -h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IFDjgeTCar6",
        "outputId": "a089136e-b3e1-4d31-a335-a355a57f8dea"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               total        used        free      shared  buff/cache   available\n",
            "Mem:            50Gi       738Mi        46Gi       1.0Mi       3.8Gi        49Gi\n",
            "Swap:             0B          0B          0B\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/apple/OpenELM/raw/main/generate_openelm.py -O generate_openelm.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjKKGz9JCdXs",
        "outputId": "fdab7119-2a68-4af7-ac6f-18a5c9ffdbe1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-27 13:15:46--  https://huggingface.co/apple/OpenELM/raw/main/generate_openelm.py\n",
            "Resolving huggingface.co (huggingface.co)... 65.8.178.93, 65.8.178.118, 65.8.178.12, ...\n",
            "Connecting to huggingface.co (huggingface.co)|65.8.178.93|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7453 (7.3K) [text/plain]\n",
            "Saving to: ‘generate_openelm.py’\n",
            "\n",
            "\rgenerate_openelm.py   0%[                    ]       0  --.-KB/s               \rgenerate_openelm.py 100%[===================>]   7.28K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-04-27 13:15:46 (2.60 GB/s) - ‘generate_openelm.py’ saved [7453/7453]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "hf_token = userdata.get('HF_TOKEN')"
      ],
      "metadata": {
        "id": "MVGvzVnCCjTf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# generate"
      ],
      "metadata": {
        "id": "WZAEWig6E6pA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### use `prompt_lookup_num_tokens=10` Text generation strategies\n",
        "\n",
        "- https://twitter.com/joao_gante/status/1747322413006643259\n",
        "- https://huggingface.co/docs/transformers/generation_strategies"
      ],
      "metadata": {
        "id": "AXOIb_H_K4Ya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python generate_openelm.py --model apple/OpenELM-270M --hf_access_token $hf_token \\\n",
        "  --prompt 'Once upon a time there was' \\\n",
        "  --generate_kwargs repetition_penalty=1.2 prompt_lookup_num_tokens=10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCu1ZhlfnxgZ",
        "outputId": "57030310-8d91-44e6-b841-89649ea614b1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:root:No CUDA device detected, using cpu, expect slower speeds.\n",
            "config.json: 100% 1.30k/1.30k [00:00<00:00, 7.00MB/s]\n",
            "configuration_openelm.py: 100% 14.3k/14.3k [00:00<00:00, 47.6MB/s]\n",
            "A new version of the following files was downloaded from https://huggingface.co/apple/OpenELM-270M:\n",
            "- configuration_openelm.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "modeling_openelm.py: 100% 39.3k/39.3k [00:00<00:00, 8.00MB/s]\n",
            "A new version of the following files was downloaded from https://huggingface.co/apple/OpenELM-270M:\n",
            "- modeling_openelm.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "model.safetensors: 100% 1.09G/1.09G [00:08<00:00, 132MB/s]\n",
            "generation_config.json: 100% 111/111 [00:00<00:00, 632kB/s]\n",
            "tokenizer_config.json: 100% 776/776 [00:00<00:00, 4.33MB/s]\n",
            "tokenizer.model: 100% 500k/500k [00:00<00:00, 6.38MB/s]\n",
            "tokenizer.json: 100% 1.84M/1.84M [00:00<00:00, 14.4MB/s]\n",
            "special_tokens_map.json: 100% 414/414 [00:00<00:00, 2.52MB/s]\n",
            "2024-04-27 13:16:29.055299: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-27 13:16:29.055358: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-27 13:16:29.057169: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-27 13:16:30.274584: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\n",
            "\n",
            "\u001b[1m Prompt + Generated Output\u001b[0m\n",
            "\n",
            "Once upon a time there was a man named John. He was a farmer, and he had a wife named Mary. They were married for 20 years, and they had two children. One day, John's wife died, and the other died too.\n",
            "John's wife was very sick, and she was dying. She was in pain, and she was not able to work. Her husband was very sad, and he wanted to help her. So he went to his brother-in-law, who was also a farmer, and he asked him if he could come over and help.\n",
            "The brother-in-law said that he would be happy to do so, but he didn't want to go alone. So John went with his brother-in-law, and they went to the farm where John's wife was dying.\n",
            "They found her body, and they buried her. Then they took her clothes, and they put them in a box. They put her shoes, and they put her purse, and they put her hair. They put her clothes on her, and they put her shoes on her, and they put her purse on her.\n",
            "Then they put her hair in a p\n",
            "\n",
            "\n",
            "Generation took\u001b[1m\u001b[92m 17.15 \u001b[0mseconds.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python generate_openelm.py --model apple/OpenELM-270M-Instruct \\\n",
        "  --hf_access_token $hf_token \\\n",
        "  --prompt 'Once upon a time there was' \\\n",
        "  --generate_kwargs repetition_penalty=1.2 prompt_lookup_num_tokens=10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gz-NhxVfmsBx",
        "outputId": "48499787-cb37-4a24-eaee-87e4173cbac9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:root:No CUDA device detected, using cpu, expect slower speeds.\n",
            "config.json: 100% 1.30k/1.30k [00:00<00:00, 6.77MB/s]\n",
            "configuration_openelm.py: 100% 14.3k/14.3k [00:00<00:00, 47.5MB/s]\n",
            "A new version of the following files was downloaded from https://huggingface.co/apple/OpenELM-270M-Instruct:\n",
            "- configuration_openelm.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "modeling_openelm.py: 100% 39.3k/39.3k [00:00<00:00, 9.76MB/s]\n",
            "A new version of the following files was downloaded from https://huggingface.co/apple/OpenELM-270M-Instruct:\n",
            "- modeling_openelm.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "model.safetensors: 100% 543M/543M [00:04<00:00, 134MB/s]\n",
            "generation_config.json: 100% 111/111 [00:00<00:00, 700kB/s]\n",
            "2024-04-27 13:16:58.659424: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-27 13:16:58.659485: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-27 13:16:58.660838: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-27 13:16:59.902738: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\n",
            "\n",
            "\u001b[1m Prompt + Generated Output\u001b[0m\n",
            "\n",
            "Once upon a time there was a man named John Smith. He had been born in the small town of Pine Bluff, Arkansas, and raised by his single mother, Mary Ann. John's family moved to California when he was young, settling in San Francisco where he attended high school. After graduating from high school, John enlisted in the U.S. Army as a machine gunner.\n",
            "John's first assignment took him to Germany, serving with the 1st Battalion, 12th Infantry Regiment. During this time, John learned German and quickly became fluent in the language. In fact, it took him only two months to learn all 3,000 words of the alphabet. John's love for learning led him to attend college at Stanford University, majoring in history. While attending school, John also served as a rifleman in the 1st Armored Division.\n",
            "After completing his undergraduate education, John returned to California to join the U.S. Navy. Upon his return to California, John married Mary Lou, a local homemaker. They raised three children: John Jr., Kathy, and Sharon. John enjoyed spending time with\n",
            "\n",
            "\n",
            "Generation took\u001b[1m\u001b[92m 16.16 \u001b[0mseconds.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python generate_openelm.py --model apple/OpenELM-450M \\\n",
        "  --hf_access_token $hf_token \\\n",
        "  --prompt 'Once upon a time there was' \\\n",
        "  --generate_kwargs repetition_penalty=1.2 prompt_lookup_num_tokens=10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZ4CSJxxn3R1",
        "outputId": "8b565ce1-4a46-407f-c3c9-36e06e7bddf9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:root:No CUDA device detected, using cpu, expect slower speeds.\n",
            "config.json: 100% 1.41k/1.41k [00:00<00:00, 7.14MB/s]\n",
            "configuration_openelm.py: 100% 14.3k/14.3k [00:00<00:00, 47.0MB/s]\n",
            "A new version of the following files was downloaded from https://huggingface.co/apple/OpenELM-450M:\n",
            "- configuration_openelm.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "modeling_openelm.py: 100% 39.3k/39.3k [00:00<00:00, 8.07MB/s]\n",
            "A new version of the following files was downloaded from https://huggingface.co/apple/OpenELM-450M:\n",
            "- modeling_openelm.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "model.safetensors: 100% 1.83G/1.83G [00:30<00:00, 60.0MB/s]\n",
            "generation_config.json: 100% 111/111 [00:00<00:00, 623kB/s]\n",
            "2024-04-27 13:18:06.450390: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-27 13:18:06.450451: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-27 13:18:06.451862: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-27 13:18:07.670159: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\n",
            "\n",
            "\u001b[1m Prompt + Generated Output\u001b[0m\n",
            "\n",
            "Once upon a time there was a little girl who lived in the woods. She had a big heart and she loved to play with her friends. One day, she decided to go for a walk in the woods. As she walked, she saw a beautiful tree. It was so tall that it looked like a mountain. The tree was covered with leaves and flowers.\n",
            "The little girl thought that this tree was very pretty. She wanted to climb up to the tree and see what was inside. So, she went up to the tree and climbed up to the top. She was very excited when she saw that the tree was full of beautiful flowers. She also saw that the leaves were all different colors.\n",
            "She started to look around the tree and she noticed that there were many animals living in the tree. There were birds, bees, butterflies, and even some cats. The little girl was very happy when she saw all of these beautiful creatures.\n",
            "After she climbed up to the tree, she saw that there was a hole in the tree. She thought that this hole was where the animals would eat their food. She also thought that the animals would eat the leaves and flowers that were growing on the tree.\n",
            "The little girl was\n",
            "\n",
            "\n",
            "Generation took\u001b[1m\u001b[92m 28.63 \u001b[0mseconds.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python generate_openelm.py --model apple/OpenELM-450M-Instruct \\\n",
        "  --hf_access_token $hf_token \\\n",
        "  --prompt 'Once upon a time there was' \\\n",
        "  --generate_kwargs repetition_penalty=1.2 prompt_lookup_num_tokens=10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jp_1s7zModOV",
        "outputId": "8781496b-0e0c-49cd-db44-e0caec71af4d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:root:No CUDA device detected, using cpu, expect slower speeds.\n",
            "config.json: 100% 1.41k/1.41k [00:00<00:00, 6.73MB/s]\n",
            "configuration_openelm.py: 100% 14.3k/14.3k [00:00<00:00, 49.5MB/s]\n",
            "A new version of the following files was downloaded from https://huggingface.co/apple/OpenELM-450M-Instruct:\n",
            "- configuration_openelm.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "modeling_openelm.py: 100% 39.3k/39.3k [00:00<00:00, 10.0MB/s]\n",
            "A new version of the following files was downloaded from https://huggingface.co/apple/OpenELM-450M-Instruct:\n",
            "- modeling_openelm.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "model.safetensors: 100% 914M/914M [00:06<00:00, 136MB/s]\n",
            "generation_config.json: 100% 111/111 [00:00<00:00, 609kB/s]\n",
            "2024-04-27 13:18:49.639462: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-27 13:18:49.639527: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-27 13:18:49.640870: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-27 13:18:50.869998: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\n",
            "\n",
            "\u001b[1m Prompt + Generated Output\u001b[0m\n",
            "\n",
            "Once upon a time there was a little boy named Peter. His father, John, loved him dearly and wanted the very best for him. He taught Peter everything he knew about being a Christian, how to pray, and how to love others.\n",
            "One day, Peter's mother, Mary, came home from work. She saw her son standing in the doorway with a Bible in his hand. \"Come in,\" she called out. \"Peter, pick up your Bible and come sit down.\"\n",
            "Peter hesitated. \"I don't really want to read my Bible right now,\" he said. \"It's just sitting on the table next to my bed.\"\n",
            "\"Don't worry,\" Mary assured him. \"You can always take it out when you feel like reading.\"\n",
            "Peter sat down beside his mother's Bible. As the hours passed, Peter continued to study God's Word. One night, as he lay in bed, Mary heard Peter singing hymns of praise to God. Her heart melted. \"Oh, Peter, what a beautiful voice! You must be so proud of your dad teaching you this wonderful faith!\"\n",
            "The next morning, Mary took Peter to church. When they arrived,\n",
            "\n",
            "\n",
            "Generation took\u001b[1m\u001b[92m 28.05 \u001b[0mseconds.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python generate_openelm.py --model apple/OpenELM-1_1B \\\n",
        "  --hf_access_token $hf_token \\\n",
        "  --prompt 'Once upon a time there was' \\\n",
        "  --generate_kwargs repetition_penalty=1.2 prompt_lookup_num_tokens=10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXWcKFtCojmk",
        "outputId": "104ac7e7-3312-4a48-9fbf-80eab8bcb864"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:root:No CUDA device detected, using cpu, expect slower speeds.\n",
            "config.json: 100% 1.60k/1.60k [00:00<00:00, 7.92MB/s]\n",
            "configuration_openelm.py: 100% 14.3k/14.3k [00:00<00:00, 42.0MB/s]\n",
            "A new version of the following files was downloaded from https://huggingface.co/apple/OpenELM-1_1B:\n",
            "- configuration_openelm.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "modeling_openelm.py: 100% 39.3k/39.3k [00:00<00:00, 9.89MB/s]\n",
            "A new version of the following files was downloaded from https://huggingface.co/apple/OpenELM-1_1B:\n",
            "- modeling_openelm.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "model.safetensors: 100% 4.32G/4.32G [00:35<00:00, 123MB/s]\n",
            "generation_config.json: 100% 111/111 [00:00<00:00, 555kB/s]\n",
            "2024-04-27 13:20:13.436842: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-27 13:20:13.436921: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-27 13:20:13.440048: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-27 13:20:14.851765: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\n",
            "\n",
            "\u001b[1m Prompt + Generated Output\u001b[0m\n",
            "\n",
            "Once upon a time there was a little girl who loved to read. She had a bookshelf full of books and she would spend hours reading them. One day, her mother came home from work and asked her what she had been reading. The little girl told her that she had been reading a book about a boy who lived in the woods. Her mother said that it sounded like a good book and so she bought it for her daughter.\n",
            "The next day, the little girl went to the library and checked out the book. She read it all the way through and then she put it back on the shelf. A few days later, her mother came home from work and asked her what she had been reading. The little girl told her that she had been reading a book about a boy who lived in the woods. Her mother said that it sounded like a good book and so she bought it for her daughter.\n",
            "The next day, the little girl went to the library and checked out the book. She read it all the way through and then she put it back on the shelf. A few days later, her mother came home from work and asked her what she had been reading. The little girl told her that she had been reading a book\n",
            "\n",
            "\n",
            "Generation took\u001b[1m\u001b[92m 39.02 \u001b[0mseconds.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python generate_openelm.py --model apple/OpenELM-1_1B-Instruct \\\n",
        "  --hf_access_token $hf_token \\\n",
        "  --prompt 'Once upon a time there was' \\\n",
        "  --generate_kwargs repetition_penalty=1.2 prompt_lookup_num_tokens=10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QnHiqKtowl_",
        "outputId": "9fcfba18-9a2c-4b50-d13c-3d51d3da1240"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:root:No CUDA device detected, using cpu, expect slower speeds.\n",
            "config.json: 100% 1.60k/1.60k [00:00<00:00, 7.41MB/s]\n",
            "configuration_openelm.py: 100% 14.3k/14.3k [00:00<00:00, 43.7MB/s]\n",
            "A new version of the following files was downloaded from https://huggingface.co/apple/OpenELM-1_1B-Instruct:\n",
            "- configuration_openelm.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "modeling_openelm.py: 100% 39.3k/39.3k [00:00<00:00, 9.88MB/s]\n",
            "A new version of the following files was downloaded from https://huggingface.co/apple/OpenELM-1_1B-Instruct:\n",
            "- modeling_openelm.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "model.safetensors: 100% 2.16G/2.16G [00:17<00:00, 121MB/s]\n",
            "generation_config.json: 100% 111/111 [00:00<00:00, 609kB/s]\n",
            "2024-04-27 13:21:34.358087: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-27 13:21:34.358144: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-27 13:21:34.359592: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-27 13:21:35.595318: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\n",
            "\n",
            "\u001b[1m Prompt + Generated Output\u001b[0m\n",
            "\n",
            "Once upon a time there was a little boy named Jack.\n",
            "Jack loved to read, and he especially loved books about pirates.\n",
            "One day Jack's mommy took him to the library to check out some pirate books.\n",
            "As Jack walked down the stacks, his eyes kept scanning for one particular book: Captain Blood and the Seven Seventies.\n",
            "The title intrigued Jack because it sounded like a really cool adventure story set in an exotic place called the \"Seven Seventies.\"\n",
            "When Jack got home, his mommy told him all about Captain Blood and the Seven Seventies.\n",
            "\"It's a great pirate book,\" Mommy said. \"You'll love it!\"\n",
            "Jack couldn't wait to read it!\n",
            "But first, Jack asked if Daddy could help him make a special Pirate Jack costume.\n",
            "Daddy agreed, and they spent a whole weekend sewing and crafting Jack's Pirate Jack Costume.\n",
            "The Pirate Jack Costume featured a red shirt with white trim, black pants, a green felt hat with a gold buckle, and a long sword with a wooden handle and silver hilt.\n",
            "\n",
            "\n",
            "Generation took\u001b[1m\u001b[92m 53.26 \u001b[0mseconds.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python generate_openelm.py --model apple/OpenELM-3B \\\n",
        "  --hf_access_token $hf_token \\\n",
        "  --prompt 'Once upon a time there was' \\\n",
        "  --generate_kwargs repetition_penalty=1.2 prompt_lookup_num_tokens=10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_PGMcH_pSND",
        "outputId": "b89638a4-8e66-4263-afeb-a608aafac3dd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:root:No CUDA device detected, using cpu, expect slower speeds.\n",
            "config.json: 100% 1.77k/1.77k [00:00<00:00, 7.57MB/s]\n",
            "configuration_openelm.py: 100% 14.3k/14.3k [00:00<00:00, 48.2MB/s]\n",
            "A new version of the following files was downloaded from https://huggingface.co/apple/OpenELM-3B:\n",
            "- configuration_openelm.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "modeling_openelm.py: 100% 39.3k/39.3k [00:00<00:00, 10.1MB/s]\n",
            "A new version of the following files was downloaded from https://huggingface.co/apple/OpenELM-3B:\n",
            "- modeling_openelm.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "model.safetensors.index.json: 100% 24.2k/24.2k [00:00<00:00, 25.3MB/s]\n",
            "Downloading shards:   0% 0/3 [00:00<?, ?it/s]\n",
            "model-00001-of-00003.safetensors:   0% 0.00/4.98G [00:00<?, ?B/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   0% 10.5M/4.98G [00:00<01:28, 56.1MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   1% 31.5M/4.98G [00:00<00:53, 92.7MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   1% 52.4M/4.98G [00:00<00:44, 110MB/s] \u001b[A\n",
            "model-00001-of-00003.safetensors:   1% 73.4M/4.98G [00:00<00:40, 121MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   2% 94.4M/4.98G [00:00<00:38, 127MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   2% 115M/4.98G [00:00<00:37, 131MB/s] \u001b[A\n",
            "model-00001-of-00003.safetensors:   3% 136M/4.98G [00:01<00:36, 133MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   3% 157M/4.98G [00:01<00:35, 135MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   4% 178M/4.98G [00:01<00:35, 136MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   4% 199M/4.98G [00:01<00:34, 137MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   4% 220M/4.98G [00:01<00:34, 138MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   5% 241M/4.98G [00:01<00:34, 138MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   5% 262M/4.98G [00:02<00:34, 139MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   6% 283M/4.98G [00:02<00:33, 139MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   6% 304M/4.98G [00:02<00:33, 139MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   7% 325M/4.98G [00:02<00:33, 139MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   7% 346M/4.98G [00:02<00:33, 139MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   7% 367M/4.98G [00:02<00:33, 139MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   8% 388M/4.98G [00:02<00:33, 139MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   8% 409M/4.98G [00:03<00:33, 138MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   9% 430M/4.98G [00:03<00:32, 138MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   9% 451M/4.98G [00:03<00:32, 138MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   9% 472M/4.98G [00:03<00:32, 138MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  10% 493M/4.98G [00:03<00:32, 138MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  10% 514M/4.98G [00:03<00:32, 137MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  11% 535M/4.98G [00:03<00:32, 137MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  11% 556M/4.98G [00:04<00:32, 135MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  12% 577M/4.98G [00:04<00:32, 135MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  12% 598M/4.98G [00:04<00:32, 137MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  12% 619M/4.98G [00:04<00:31, 138MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  13% 640M/4.98G [00:04<00:31, 138MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  13% 661M/4.98G [00:04<00:31, 139MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  14% 682M/4.98G [00:05<00:30, 139MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  14% 703M/4.98G [00:05<00:30, 140MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  15% 724M/4.98G [00:05<00:31, 137MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  15% 744M/4.98G [00:05<00:30, 138MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  15% 765M/4.98G [00:05<00:30, 139MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  16% 786M/4.98G [00:05<00:30, 139MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  16% 807M/4.98G [00:05<00:29, 140MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  17% 828M/4.98G [00:06<00:29, 140MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  17% 849M/4.98G [00:06<00:29, 140MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  17% 870M/4.98G [00:06<00:29, 140MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  18% 891M/4.98G [00:06<00:29, 140MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  18% 912M/4.98G [00:06<00:29, 140MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  19% 933M/4.98G [00:06<00:28, 140MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  19% 954M/4.98G [00:07<00:28, 140MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  20% 975M/4.98G [00:07<00:28, 139MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  20% 996M/4.98G [00:07<00:28, 139MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  20% 1.02G/4.98G [00:07<00:28, 139MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  21% 1.04G/4.98G [00:07<00:29, 135MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  21% 1.06G/4.98G [00:07<00:29, 133MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  22% 1.08G/4.98G [00:07<00:29, 134MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  22% 1.10G/4.98G [00:08<00:28, 134MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  23% 1.12G/4.98G [00:08<00:28, 135MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  23% 1.14G/4.98G [00:08<00:28, 133MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  23% 1.16G/4.98G [00:08<00:28, 133MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  24% 1.18G/4.98G [00:08<00:28, 134MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  24% 1.21G/4.98G [00:08<00:27, 135MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  25% 1.23G/4.98G [00:09<00:27, 136MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  25% 1.25G/4.98G [00:09<00:27, 137MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  25% 1.27G/4.98G [00:09<00:26, 138MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  26% 1.29G/4.98G [00:09<00:26, 139MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  26% 1.31G/4.98G [00:09<00:26, 139MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  27% 1.33G/4.98G [00:09<00:26, 139MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  27% 1.35G/4.98G [00:09<00:26, 139MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  28% 1.37G/4.98G [00:10<00:25, 139MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  28% 1.39G/4.98G [00:10<00:25, 139MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  28% 1.42G/4.98G [00:10<00:25, 140MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  29% 1.44G/4.98G [00:10<00:26, 136MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  29% 1.46G/4.98G [00:10<00:27, 129MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  30% 1.48G/4.98G [00:10<00:27, 128MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  30% 1.50G/4.98G [00:11<00:26, 132MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  31% 1.52G/4.98G [00:11<00:25, 134MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  31% 1.54G/4.98G [00:11<00:25, 136MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  31% 1.56G/4.98G [00:11<00:24, 137MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  32% 1.58G/4.98G [00:11<00:28, 120MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  32% 1.60G/4.98G [00:11<00:32, 104MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  33% 1.63G/4.98G [00:12<00:33, 101MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  33% 1.65G/4.98G [00:12<00:32, 103MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  33% 1.67G/4.98G [00:12<00:32, 103MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  34% 1.69G/4.98G [00:12<00:30, 107MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  34% 1.71G/4.98G [00:13<00:31, 104MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  35% 1.73G/4.98G [00:13<00:31, 103MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  35% 1.75G/4.98G [00:13<00:30, 107MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  36% 1.77G/4.98G [00:13<00:29, 109MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  36% 1.79G/4.98G [00:13<00:29, 108MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  36% 1.81G/4.98G [00:13<00:29, 108MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  37% 1.84G/4.98G [00:14<00:28, 109MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  37% 1.86G/4.98G [00:14<00:41, 76.1MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  38% 1.88G/4.98G [00:14<00:35, 87.8MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  38% 1.90G/4.98G [00:14<00:31, 97.2MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  39% 1.92G/4.98G [00:15<00:30, 101MB/s] \u001b[A\n",
            "model-00001-of-00003.safetensors:  39% 1.94G/4.98G [00:15<00:27, 110MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  39% 1.96G/4.98G [00:15<00:26, 116MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  40% 1.98G/4.98G [00:15<00:24, 122MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  40% 2.00G/4.98G [00:15<00:23, 126MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  41% 2.02G/4.98G [00:15<00:22, 129MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  41% 2.04G/4.98G [00:16<00:22, 132MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  41% 2.07G/4.98G [00:16<00:21, 134MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  42% 2.09G/4.98G [00:16<00:21, 136MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  42% 2.11G/4.98G [00:16<00:21, 137MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  43% 2.13G/4.98G [00:16<00:20, 138MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  43% 2.15G/4.98G [00:16<00:20, 138MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  44% 2.17G/4.98G [00:16<00:20, 139MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  44% 2.19G/4.98G [00:17<00:20, 139MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  44% 2.21G/4.98G [00:17<00:19, 139MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  45% 2.23G/4.98G [00:17<00:19, 139MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  45% 2.25G/4.98G [00:17<00:19, 139MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  46% 2.28G/4.98G [00:17<00:19, 139MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  46% 2.30G/4.98G [00:17<00:19, 137MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  47% 2.32G/4.98G [00:18<00:19, 136MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  47% 2.34G/4.98G [00:18<00:19, 135MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  47% 2.36G/4.98G [00:18<00:19, 135MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  48% 2.38G/4.98G [00:18<00:20, 129MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  48% 2.40G/4.98G [00:18<00:20, 127MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  49% 2.42G/4.98G [00:18<00:20, 126MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  49% 2.44G/4.98G [00:19<00:19, 129MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  49% 2.46G/4.98G [00:19<00:19, 130MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  50% 2.49G/4.98G [00:19<00:19, 129MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  50% 2.51G/4.98G [00:19<00:19, 129MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  51% 2.53G/4.98G [00:19<00:18, 131MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  51% 2.55G/4.98G [00:19<00:18, 129MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  52% 2.57G/4.98G [00:19<00:18, 131MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  52% 2.59G/4.98G [00:20<00:18, 129MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  52% 2.61G/4.98G [00:20<00:18, 130MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  53% 2.63G/4.98G [00:20<00:18, 126MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  53% 2.65G/4.98G [00:20<00:18, 125MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  54% 2.67G/4.98G [00:20<00:18, 127MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  54% 2.69G/4.98G [00:20<00:17, 127MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  54% 2.72G/4.98G [00:21<00:17, 130MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  55% 2.74G/4.98G [00:21<00:17, 130MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  55% 2.76G/4.98G [00:21<00:17, 130MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  56% 2.78G/4.98G [00:21<00:16, 132MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  56% 2.80G/4.98G [00:21<00:16, 133MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  57% 2.82G/4.98G [00:21<00:16, 135MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  57% 2.84G/4.98G [00:22<00:16, 133MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  57% 2.86G/4.98G [00:22<00:16, 132MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  58% 2.88G/4.98G [00:22<00:15, 133MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  58% 2.90G/4.98G [00:22<00:15, 134MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  59% 2.93G/4.98G [00:22<00:15, 135MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  59% 2.95G/4.98G [00:23<00:22, 89.3MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  60% 2.97G/4.98G [00:23<00:20, 97.7MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  60% 2.99G/4.98G [00:23<00:19, 105MB/s] \u001b[A\n",
            "model-00001-of-00003.safetensors:  60% 3.01G/4.98G [00:23<00:18, 110MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  61% 3.03G/4.98G [00:23<00:16, 115MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  61% 3.05G/4.98G [00:23<00:15, 121MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  62% 3.07G/4.98G [00:24<00:15, 125MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  62% 3.09G/4.98G [00:24<00:14, 129MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  62% 3.11G/4.98G [00:24<00:14, 131MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  63% 3.14G/4.98G [00:24<00:13, 132MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  63% 3.16G/4.98G [00:24<00:13, 133MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  64% 3.18G/4.98G [00:24<00:13, 134MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  64% 3.20G/4.98G [00:25<00:13, 135MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  65% 3.22G/4.98G [00:25<00:13, 135MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  65% 3.24G/4.98G [00:25<00:14, 119MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  65% 3.26G/4.98G [00:25<00:15, 110MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  66% 3.28G/4.98G [00:25<00:14, 117MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  66% 3.30G/4.98G [00:26<00:16, 101MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  67% 3.32G/4.98G [00:26<00:15, 105MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  67% 3.34G/4.98G [00:26<00:14, 111MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  68% 3.37G/4.98G [00:26<00:16, 101MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  68% 3.39G/4.98G [00:26<00:15, 105MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  68% 3.41G/4.98G [00:27<00:16, 95.0MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  69% 3.43G/4.98G [00:27<00:14, 104MB/s] \u001b[A\n",
            "model-00001-of-00003.safetensors:  69% 3.45G/4.98G [00:27<00:13, 112MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  70% 3.47G/4.98G [00:27<00:12, 118MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  70% 3.49G/4.98G [00:27<00:15, 99.2MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  70% 3.51G/4.98G [00:28<00:16, 91.5MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  71% 3.52G/4.98G [00:28<00:16, 86.3MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  71% 3.54G/4.98G [00:28<00:15, 95.3MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  71% 3.55G/4.98G [00:28<00:15, 93.8MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  72% 3.57G/4.98G [00:28<00:16, 85.9MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  72% 3.58G/4.98G [00:28<00:16, 87.4MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  72% 3.59G/4.98G [00:28<00:15, 89.5MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  72% 3.61G/4.98G [00:29<00:15, 90.1MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  73% 3.63G/4.98G [00:29<00:14, 95.2MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  73% 3.65G/4.98G [00:29<00:13, 97.2MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  74% 3.67G/4.98G [00:29<00:12, 107MB/s] \u001b[A\n",
            "model-00001-of-00003.safetensors:  74% 3.69G/4.98G [00:29<00:11, 115MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  74% 3.71G/4.98G [00:30<00:10, 121MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  75% 3.73G/4.98G [00:30<00:09, 125MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  75% 3.75G/4.98G [00:30<00:09, 128MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  76% 3.77G/4.98G [00:30<00:09, 131MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  76% 3.80G/4.98G [00:30<00:08, 133MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  77% 3.82G/4.98G [00:30<00:08, 134MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  77% 3.84G/4.98G [00:30<00:08, 134MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  77% 3.86G/4.98G [00:31<00:08, 135MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  78% 3.88G/4.98G [00:31<00:08, 135MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  78% 3.90G/4.98G [00:31<00:07, 136MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  79% 3.92G/4.98G [00:31<00:07, 136MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  79% 3.94G/4.98G [00:31<00:07, 137MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  80% 3.96G/4.98G [00:31<00:07, 137MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  80% 3.98G/4.98G [00:32<00:07, 137MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  80% 4.01G/4.98G [00:32<00:07, 137MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  81% 4.03G/4.98G [00:32<00:07, 136MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  81% 4.05G/4.98G [00:32<00:06, 136MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  82% 4.07G/4.98G [00:32<00:06, 136MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  82% 4.09G/4.98G [00:32<00:06, 136MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  82% 4.11G/4.98G [00:32<00:06, 133MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  83% 4.13G/4.98G [00:33<00:06, 130MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  83% 4.15G/4.98G [00:33<00:06, 131MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  84% 4.17G/4.98G [00:33<00:06, 129MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  84% 4.19G/4.98G [00:33<00:06, 128MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  85% 4.22G/4.98G [00:33<00:06, 126MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  85% 4.24G/4.98G [00:33<00:05, 129MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  85% 4.26G/4.98G [00:34<00:05, 131MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  86% 4.28G/4.98G [00:34<00:05, 133MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  86% 4.30G/4.98G [00:34<00:05, 134MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  87% 4.32G/4.98G [00:34<00:04, 135MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  87% 4.34G/4.98G [00:34<00:04, 135MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  88% 4.36G/4.98G [00:34<00:04, 136MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  88% 4.38G/4.98G [00:35<00:04, 136MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  88% 4.40G/4.98G [00:35<00:04, 137MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  89% 4.42G/4.98G [00:35<00:04, 135MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  89% 4.45G/4.98G [00:35<00:04, 133MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  90% 4.47G/4.98G [00:35<00:03, 134MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  90% 4.49G/4.98G [00:35<00:03, 133MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  90% 4.51G/4.98G [00:35<00:03, 134MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  91% 4.53G/4.98G [00:36<00:03, 135MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  91% 4.55G/4.98G [00:36<00:03, 135MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  92% 4.57G/4.98G [00:36<00:03, 136MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  92% 4.59G/4.98G [00:36<00:02, 136MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  93% 4.61G/4.98G [00:36<00:02, 136MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  93% 4.63G/4.98G [00:36<00:02, 136MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  93% 4.66G/4.98G [00:37<00:02, 137MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  94% 4.68G/4.98G [00:37<00:02, 137MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  94% 4.70G/4.98G [00:37<00:02, 136MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  95% 4.72G/4.98G [00:37<00:01, 136MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  95% 4.74G/4.98G [00:37<00:02, 93.1MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  96% 4.76G/4.98G [00:38<00:02, 98.2MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  96% 4.78G/4.98G [00:38<00:01, 104MB/s] \u001b[A\n",
            "model-00001-of-00003.safetensors:  96% 4.80G/4.98G [00:38<00:01, 109MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  97% 4.82G/4.98G [00:38<00:01, 113MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  97% 4.84G/4.98G [00:38<00:01, 117MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  98% 4.87G/4.98G [00:38<00:01, 114MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  98% 4.89G/4.98G [00:39<00:00, 120MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  98% 4.91G/4.98G [00:39<00:00, 125MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  99% 4.93G/4.98G [00:39<00:00, 128MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  99% 4.95G/4.98G [00:39<00:00, 131MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors: 100% 4.98G/4.98G [00:39<00:00, 125MB/s]\n",
            "Downloading shards:  33% 1/3 [00:40<01:20, 40.08s/it]\n",
            "model-00002-of-00003.safetensors:   0% 0.00/4.90G [00:00<?, ?B/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   0% 21.0M/4.90G [00:00<00:36, 136MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   1% 41.9M/4.90G [00:00<00:35, 136MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   1% 62.9M/4.90G [00:00<00:36, 133MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   2% 83.9M/4.90G [00:00<00:36, 130MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   2% 105M/4.90G [00:00<00:36, 133MB/s] \u001b[A\n",
            "model-00002-of-00003.safetensors:   3% 126M/4.90G [00:00<00:35, 134MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   3% 147M/4.90G [00:01<00:35, 134MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   3% 168M/4.90G [00:01<00:35, 135MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   4% 189M/4.90G [00:01<00:34, 136MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   4% 210M/4.90G [00:01<00:34, 136MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   5% 231M/4.90G [00:01<00:34, 136MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   5% 252M/4.90G [00:01<00:34, 134MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   6% 273M/4.90G [00:02<00:34, 135MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   6% 294M/4.90G [00:02<00:34, 133MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   6% 315M/4.90G [00:02<00:34, 135MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   7% 336M/4.90G [00:02<00:33, 136MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   7% 357M/4.90G [00:02<00:33, 136MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   8% 377M/4.90G [00:02<00:33, 136MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   8% 398M/4.90G [00:02<00:33, 137MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   9% 419M/4.90G [00:03<00:32, 137MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   9% 440M/4.90G [00:03<00:32, 136MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   9% 461M/4.90G [00:03<00:33, 134MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  10% 482M/4.90G [00:03<00:32, 135MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  10% 503M/4.90G [00:03<00:32, 134MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  11% 524M/4.90G [00:03<00:32, 133MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  11% 545M/4.90G [00:04<00:32, 134MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  12% 566M/4.90G [00:04<00:32, 133MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  12% 587M/4.90G [00:04<00:33, 127MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  12% 608M/4.90G [00:04<00:33, 128MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  13% 629M/4.90G [00:04<00:33, 126MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  13% 650M/4.90G [00:04<00:34, 123MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  14% 671M/4.90G [00:05<00:34, 123MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  14% 692M/4.90G [00:05<00:34, 122MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  15% 713M/4.90G [00:05<00:33, 126MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  15% 734M/4.90G [00:05<00:32, 129MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  15% 755M/4.90G [00:05<00:31, 132MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  16% 776M/4.90G [00:05<00:30, 133MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  16% 797M/4.90G [00:06<00:30, 134MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  17% 818M/4.90G [00:06<00:30, 135MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  17% 839M/4.90G [00:06<00:29, 136MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  18% 860M/4.90G [00:06<00:29, 136MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  18% 881M/4.90G [00:06<00:29, 137MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  18% 902M/4.90G [00:06<00:29, 137MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  19% 923M/4.90G [00:06<00:29, 137MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  19% 944M/4.90G [00:07<00:29, 134MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  20% 965M/4.90G [00:07<00:29, 135MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  20% 986M/4.90G [00:07<00:28, 136MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  21% 1.01G/4.90G [00:07<00:28, 136MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  21% 1.03G/4.90G [00:07<00:28, 136MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  21% 1.05G/4.90G [00:07<00:28, 137MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  22% 1.07G/4.90G [00:08<00:28, 137MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  22% 1.09G/4.90G [00:08<00:28, 135MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  23% 1.11G/4.90G [00:08<00:28, 134MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  23% 1.13G/4.90G [00:08<00:28, 134MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  24% 1.15G/4.90G [00:08<00:27, 135MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  24% 1.17G/4.90G [00:08<00:27, 134MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  24% 1.20G/4.90G [00:08<00:27, 135MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  25% 1.22G/4.90G [00:09<00:39, 94.0MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  25% 1.24G/4.90G [00:09<00:35, 103MB/s] \u001b[A\n",
            "model-00002-of-00003.safetensors:  26% 1.26G/4.90G [00:09<00:32, 111MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  26% 1.28G/4.90G [00:09<00:30, 117MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  27% 1.30G/4.90G [00:09<00:29, 123MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  27% 1.32G/4.90G [00:10<00:28, 127MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  27% 1.34G/4.90G [00:10<00:28, 127MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  28% 1.36G/4.90G [00:10<00:27, 128MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  28% 1.38G/4.90G [00:10<00:27, 127MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  29% 1.41G/4.90G [00:10<00:27, 126MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  29% 1.43G/4.90G [00:10<00:27, 125MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  30% 1.45G/4.90G [00:11<00:27, 124MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  30% 1.47G/4.90G [00:11<00:27, 125MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  30% 1.49G/4.90G [00:11<00:27, 125MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  31% 1.51G/4.90G [00:11<00:27, 126MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  31% 1.53G/4.90G [00:11<00:27, 124MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  32% 1.55G/4.90G [00:11<00:26, 127MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  32% 1.57G/4.90G [00:12<00:25, 129MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  32% 1.59G/4.90G [00:12<00:25, 129MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  33% 1.61G/4.90G [00:12<00:25, 130MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  33% 1.64G/4.90G [00:12<00:24, 132MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  34% 1.66G/4.90G [00:12<00:24, 133MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  34% 1.68G/4.90G [00:12<00:24, 134MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  35% 1.70G/4.90G [00:13<00:23, 135MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  35% 1.72G/4.90G [00:13<00:23, 135MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  35% 1.74G/4.90G [00:13<00:23, 136MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  36% 1.76G/4.90G [00:13<00:23, 137MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  36% 1.78G/4.90G [00:13<00:22, 137MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  37% 1.80G/4.90G [00:13<00:22, 137MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  37% 1.82G/4.90G [00:13<00:22, 136MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  38% 1.85G/4.90G [00:14<00:22, 136MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  38% 1.87G/4.90G [00:14<00:24, 126MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  38% 1.89G/4.90G [00:14<00:23, 130MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  39% 1.91G/4.90G [00:14<00:22, 132MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  39% 1.93G/4.90G [00:14<00:22, 133MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  40% 1.95G/4.90G [00:14<00:22, 134MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  40% 1.97G/4.90G [00:15<00:21, 135MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  41% 1.99G/4.90G [00:15<00:21, 136MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  41% 2.01G/4.90G [00:15<00:21, 136MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  41% 2.03G/4.90G [00:15<00:21, 137MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  42% 2.06G/4.90G [00:15<00:20, 136MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  42% 2.08G/4.90G [00:15<00:21, 134MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  43% 2.10G/4.90G [00:16<00:21, 130MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  43% 2.12G/4.90G [00:16<00:21, 129MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  44% 2.14G/4.90G [00:16<00:21, 128MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  44% 2.16G/4.90G [00:16<00:21, 127MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  44% 2.18G/4.90G [00:16<00:21, 127MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  45% 2.20G/4.90G [00:16<00:21, 126MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  45% 2.22G/4.90G [00:17<00:21, 127MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  46% 2.24G/4.90G [00:17<00:21, 125MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  46% 2.26G/4.90G [00:17<00:21, 125MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  47% 2.29G/4.90G [00:17<00:20, 126MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  47% 2.31G/4.90G [00:17<00:21, 122MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  47% 2.33G/4.90G [00:17<00:20, 124MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  48% 2.35G/4.90G [00:18<00:20, 125MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  48% 2.37G/4.90G [00:18<00:20, 124MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  49% 2.39G/4.90G [00:18<00:20, 124MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  49% 2.41G/4.90G [00:18<00:20, 123MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  50% 2.43G/4.90G [00:18<00:20, 123MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  50% 2.45G/4.90G [00:18<00:19, 127MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  50% 2.47G/4.90G [00:19<00:18, 130MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  51% 2.50G/4.90G [00:19<00:18, 128MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  51% 2.52G/4.90G [00:19<00:18, 128MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  52% 2.54G/4.90G [00:19<00:18, 131MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  52% 2.56G/4.90G [00:19<00:17, 133MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  53% 2.58G/4.90G [00:19<00:17, 133MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  53% 2.60G/4.90G [00:19<00:17, 133MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  53% 2.62G/4.90G [00:20<00:17, 132MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  54% 2.64G/4.90G [00:20<00:16, 133MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  54% 2.66G/4.90G [00:20<00:16, 135MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  55% 2.68G/4.90G [00:20<00:16, 135MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  55% 2.71G/4.90G [00:20<00:16, 134MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  56% 2.73G/4.90G [00:20<00:16, 133MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  56% 2.75G/4.90G [00:21<00:16, 133MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  56% 2.77G/4.90G [00:21<00:16, 132MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  57% 2.79G/4.90G [00:21<00:16, 131MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  57% 2.81G/4.90G [00:21<00:15, 133MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  58% 2.83G/4.90G [00:21<00:15, 134MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  58% 2.85G/4.90G [00:21<00:15, 135MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  59% 2.87G/4.90G [00:22<00:14, 136MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  59% 2.89G/4.90G [00:22<00:14, 136MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  59% 2.92G/4.90G [00:22<00:14, 136MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  60% 2.94G/4.90G [00:22<00:14, 136MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  60% 2.96G/4.90G [00:22<00:14, 133MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  61% 2.98G/4.90G [00:22<00:14, 130MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  61% 3.00G/4.90G [00:22<00:14, 128MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  62% 3.02G/4.90G [00:23<00:15, 126MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  62% 3.04G/4.90G [00:23<00:14, 125MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  62% 3.06G/4.90G [00:23<00:14, 124MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  63% 3.08G/4.90G [00:23<00:14, 123MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  63% 3.10G/4.90G [00:23<00:14, 123MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  64% 3.12G/4.90G [00:24<00:14, 124MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  64% 3.15G/4.90G [00:24<00:13, 127MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  65% 3.17G/4.90G [00:24<00:13, 128MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  65% 3.19G/4.90G [00:24<00:14, 122MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  65% 3.21G/4.90G [00:24<00:13, 124MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  66% 3.23G/4.90G [00:24<00:13, 125MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  66% 3.25G/4.90G [00:25<00:13, 125MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  67% 3.27G/4.90G [00:25<00:18, 90.3MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  67% 3.29G/4.90G [00:25<00:16, 100MB/s] \u001b[A\n",
            "model-00002-of-00003.safetensors:  68% 3.31G/4.90G [00:25<00:14, 110MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  68% 3.33G/4.90G [00:25<00:13, 116MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  68% 3.36G/4.90G [00:26<00:12, 120MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  69% 3.38G/4.90G [00:26<00:12, 124MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  69% 3.40G/4.90G [00:26<00:11, 126MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  70% 3.42G/4.90G [00:26<00:11, 129MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  70% 3.44G/4.90G [00:26<00:11, 129MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  71% 3.46G/4.90G [00:26<00:10, 131MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  71% 3.48G/4.90G [00:26<00:10, 133MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  71% 3.50G/4.90G [00:27<00:10, 130MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  72% 3.52G/4.90G [00:27<00:10, 131MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  72% 3.54G/4.90G [00:27<00:10, 133MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  73% 3.57G/4.90G [00:27<00:10, 133MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  73% 3.59G/4.90G [00:27<00:09, 132MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  74% 3.61G/4.90G [00:27<00:09, 132MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  74% 3.63G/4.90G [00:28<00:09, 131MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  74% 3.65G/4.90G [00:28<00:09, 131MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  75% 3.67G/4.90G [00:28<00:09, 129MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  75% 3.69G/4.90G [00:28<00:09, 130MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  76% 3.71G/4.90G [00:28<00:09, 129MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  76% 3.73G/4.90G [00:28<00:09, 130MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  77% 3.75G/4.90G [00:29<00:08, 130MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  77% 3.77G/4.90G [00:29<00:08, 131MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  77% 3.80G/4.90G [00:29<00:08, 131MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  78% 3.82G/4.90G [00:29<00:08, 133MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  78% 3.84G/4.90G [00:29<00:07, 134MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  79% 3.86G/4.90G [00:29<00:07, 136MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  79% 3.88G/4.90G [00:29<00:07, 134MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  80% 3.90G/4.90G [00:30<00:07, 132MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  80% 3.92G/4.90G [00:30<00:07, 131MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  80% 3.94G/4.90G [00:30<00:07, 129MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  81% 3.96G/4.90G [00:30<00:07, 127MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  81% 3.98G/4.90G [00:30<00:07, 130MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  82% 4.01G/4.90G [00:30<00:06, 130MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  82% 4.03G/4.90G [00:31<00:06, 132MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  83% 4.05G/4.90G [00:31<00:06, 134MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  83% 4.07G/4.90G [00:31<00:06, 135MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  83% 4.09G/4.90G [00:31<00:06, 134MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  84% 4.11G/4.90G [00:31<00:05, 134MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  84% 4.13G/4.90G [00:31<00:05, 135MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  85% 4.15G/4.90G [00:32<00:05, 135MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  85% 4.17G/4.90G [00:32<00:05, 134MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  86% 4.19G/4.90G [00:32<00:05, 130MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  86% 4.22G/4.90G [00:32<00:05, 130MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  86% 4.24G/4.90G [00:32<00:05, 132MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  87% 4.26G/4.90G [00:32<00:04, 134MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  87% 4.28G/4.90G [00:32<00:04, 135MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  88% 4.30G/4.90G [00:33<00:04, 134MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  88% 4.32G/4.90G [00:33<00:04, 133MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  89% 4.34G/4.90G [00:33<00:04, 135MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  89% 4.36G/4.90G [00:33<00:04, 135MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  89% 4.38G/4.90G [00:33<00:03, 136MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  90% 4.40G/4.90G [00:33<00:03, 134MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  90% 4.42G/4.90G [00:34<00:03, 134MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  91% 4.45G/4.90G [00:34<00:03, 135MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  91% 4.47G/4.90G [00:34<00:03, 136MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  92% 4.49G/4.90G [00:34<00:03, 136MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  92% 4.51G/4.90G [00:34<00:03, 119MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  92% 4.53G/4.90G [00:34<00:03, 122MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  93% 4.55G/4.90G [00:35<00:02, 127MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  93% 4.57G/4.90G [00:35<00:02, 128MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  94% 4.59G/4.90G [00:35<00:02, 131MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  94% 4.61G/4.90G [00:35<00:02, 130MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  94% 4.63G/4.90G [00:35<00:02, 131MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  95% 4.66G/4.90G [00:35<00:01, 132MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  95% 4.68G/4.90G [00:36<00:01, 134MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  96% 4.70G/4.90G [00:36<00:01, 132MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  96% 4.72G/4.90G [00:36<00:01, 133MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  97% 4.74G/4.90G [00:36<00:01, 134MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  97% 4.76G/4.90G [00:36<00:01, 135MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  97% 4.78G/4.90G [00:36<00:00, 136MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  98% 4.80G/4.90G [00:36<00:00, 133MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  98% 4.82G/4.90G [00:37<00:00, 131MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  99% 4.84G/4.90G [00:37<00:00, 134MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  99% 4.87G/4.90G [00:37<00:00, 131MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors: 100% 4.89G/4.90G [00:37<00:00, 132MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors: 100% 4.90G/4.90G [00:37<00:00, 130MB/s]\n",
            "Downloading shards:  67% 2/3 [01:17<00:38, 38.77s/it]\n",
            "model-00003-of-00003.safetensors:   0% 0.00/2.26G [00:00<?, ?B/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:   1% 21.0M/2.26G [00:00<00:16, 135MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:   2% 41.9M/2.26G [00:00<00:16, 131MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:   3% 62.9M/2.26G [00:00<00:16, 132MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:   4% 83.9M/2.26G [00:00<00:16, 134MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:   5% 105M/2.26G [00:00<00:15, 135MB/s] \u001b[A\n",
            "model-00003-of-00003.safetensors:   6% 126M/2.26G [00:00<00:15, 136MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:   6% 147M/2.26G [00:01<00:15, 133MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:   7% 168M/2.26G [00:01<00:15, 131MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:   8% 189M/2.26G [00:01<00:16, 129MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:   9% 210M/2.26G [00:01<00:15, 129MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  10% 231M/2.26G [00:01<00:15, 131MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  11% 252M/2.26G [00:01<00:15, 131MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  12% 273M/2.26G [00:02<00:15, 132MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  13% 294M/2.26G [00:02<00:15, 130MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  14% 315M/2.26G [00:02<00:15, 128MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  15% 336M/2.26G [00:02<00:15, 126MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  16% 357M/2.26G [00:02<00:15, 124MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  17% 377M/2.26G [00:02<00:14, 126MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  18% 398M/2.26G [00:03<00:14, 129MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  19% 419M/2.26G [00:03<00:14, 131MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  19% 440M/2.26G [00:03<00:13, 133MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  20% 461M/2.26G [00:03<00:13, 132MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  21% 482M/2.26G [00:03<00:13, 134MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  22% 503M/2.26G [00:03<00:13, 134MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  23% 524M/2.26G [00:03<00:13, 133MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  24% 545M/2.26G [00:04<00:12, 133MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  25% 566M/2.26G [00:04<00:17, 94.6MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  26% 587M/2.26G [00:04<00:16, 103MB/s] \u001b[A\n",
            "model-00003-of-00003.safetensors:  27% 608M/2.26G [00:04<00:14, 111MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  28% 629M/2.26G [00:04<00:13, 118MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  29% 650M/2.26G [00:05<00:13, 123MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  30% 671M/2.26G [00:05<00:12, 127MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  31% 692M/2.26G [00:05<00:12, 126MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  32% 713M/2.26G [00:05<00:12, 126MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  32% 734M/2.26G [00:05<00:12, 124MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  33% 755M/2.26G [00:05<00:12, 123MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  34% 776M/2.26G [00:06<00:12, 123MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  35% 797M/2.26G [00:06<00:11, 124MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  36% 818M/2.26G [00:06<00:11, 124MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  37% 839M/2.26G [00:06<00:11, 126MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  38% 860M/2.26G [00:06<00:11, 125MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  39% 881M/2.26G [00:06<00:11, 124MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  40% 902M/2.26G [00:07<00:10, 126MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  41% 923M/2.26G [00:07<00:10, 127MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  42% 944M/2.26G [00:07<00:10, 128MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  43% 965M/2.26G [00:07<00:10, 129MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  44% 986M/2.26G [00:07<00:09, 131MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  45% 1.01G/2.26G [00:07<00:09, 133MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  45% 1.03G/2.26G [00:08<00:09, 134MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  46% 1.05G/2.26G [00:08<00:09, 133MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  47% 1.07G/2.26G [00:08<00:09, 131MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  48% 1.09G/2.26G [00:08<00:08, 132MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  49% 1.11G/2.26G [00:08<00:08, 133MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  50% 1.13G/2.26G [00:08<00:08, 135MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  51% 1.15G/2.26G [00:09<00:08, 135MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  52% 1.17G/2.26G [00:09<00:08, 131MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  53% 1.20G/2.26G [00:09<00:08, 130MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  54% 1.22G/2.26G [00:09<00:07, 131MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  55% 1.24G/2.26G [00:09<00:07, 130MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  56% 1.26G/2.26G [00:09<00:07, 129MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  57% 1.28G/2.26G [00:10<00:07, 131MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  58% 1.30G/2.26G [00:10<00:07, 133MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  58% 1.32G/2.26G [00:10<00:07, 129MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  59% 1.34G/2.26G [00:10<00:07, 126MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  60% 1.36G/2.26G [00:10<00:07, 126MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  61% 1.38G/2.26G [00:10<00:06, 127MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  62% 1.41G/2.26G [00:11<00:06, 126MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  63% 1.43G/2.26G [00:11<00:06, 125MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  64% 1.45G/2.26G [00:11<00:06, 124MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  65% 1.47G/2.26G [00:11<00:06, 127MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  66% 1.49G/2.26G [00:11<00:05, 129MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  67% 1.51G/2.26G [00:11<00:05, 131MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  68% 1.53G/2.26G [00:11<00:05, 133MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  69% 1.55G/2.26G [00:12<00:05, 134MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  70% 1.57G/2.26G [00:12<00:05, 133MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  71% 1.59G/2.26G [00:12<00:05, 133MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  71% 1.61G/2.26G [00:12<00:04, 131MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  72% 1.64G/2.26G [00:12<00:04, 133MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  73% 1.66G/2.26G [00:12<00:04, 132MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  74% 1.68G/2.26G [00:13<00:04, 132MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  75% 1.70G/2.26G [00:13<00:04, 132MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  76% 1.72G/2.26G [00:13<00:04, 134MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  77% 1.74G/2.26G [00:13<00:03, 134MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  78% 1.76G/2.26G [00:13<00:03, 135MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  79% 1.78G/2.26G [00:13<00:03, 136MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  80% 1.80G/2.26G [00:14<00:03, 136MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  81% 1.82G/2.26G [00:14<00:03, 134MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  82% 1.85G/2.26G [00:14<00:03, 135MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  83% 1.87G/2.26G [00:14<00:02, 136MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  84% 1.89G/2.26G [00:14<00:02, 136MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  84% 1.91G/2.26G [00:14<00:02, 136MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  85% 1.93G/2.26G [00:14<00:02, 136MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  86% 1.95G/2.26G [00:15<00:02, 136MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  87% 1.97G/2.26G [00:15<00:02, 135MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  88% 1.99G/2.26G [00:15<00:02, 131MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  89% 2.01G/2.26G [00:15<00:01, 127MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  90% 2.03G/2.26G [00:15<00:01, 126MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  91% 2.06G/2.26G [00:15<00:01, 129MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  92% 2.08G/2.26G [00:16<00:01, 121MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  93% 2.10G/2.26G [00:16<00:01, 124MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  94% 2.12G/2.26G [00:16<00:01, 127MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  95% 2.14G/2.26G [00:16<00:00, 128MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  96% 2.16G/2.26G [00:16<00:00, 129MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  97% 2.18G/2.26G [00:16<00:00, 128MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  97% 2.20G/2.26G [00:17<00:00, 130MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  98% 2.22G/2.26G [00:17<00:00, 132MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  99% 2.24G/2.26G [00:17<00:00, 133MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors: 100% 2.26G/2.26G [00:17<00:00, 129MB/s]\n",
            "Downloading shards: 100% 3/3 [01:35<00:00, 31.86s/it]\n",
            "Loading checkpoint shards: 100% 3/3 [00:04<00:00,  1.56s/it]\n",
            "generation_config.json: 100% 111/111 [00:00<00:00, 568kB/s]\n",
            "2024-04-27 13:26:03.804717: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-27 13:26:03.804782: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-27 13:26:03.806262: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-27 13:26:05.045824: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\n",
            "\n",
            "\u001b[1m Prompt + Generated Output\u001b[0m\n",
            "\n",
            "Once upon a time there was a little girl who loved to play with her dolls. She had many dolls, and she played with them every day.\n",
            "One day the little girl's mother told her that she would be going to the store to buy some groceries. The little girl asked if she could go with her. Her mother said yes, and they went to the store.\n",
            "When they got to the store, the little girl saw a beautiful doll in the window. It was a very expensive doll, and it was made of wood. The little girl wanted to buy it, but her mother said that she couldn't afford it.\n",
            "The little girl was very sad, but she knew that her mother loved her very much. So she decided to wait until her mother came home from the store.\n",
            "When the little girl's mother came home, she told her that she had bought the doll for her. The little girl was very happy, and she thanked her mother for the doll.\n",
            "The little girl's mother told her that she would have to take care of the doll. She told the little girl that she would have to feed it, bathe it, and put it to bed.\n",
            "The little girl was very happy\n",
            "\n",
            "\n",
            "Generation took\u001b[1m\u001b[92m 160.85 \u001b[0mseconds.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python generate_openelm.py --model apple/OpenELM-3B-Instruct \\\n",
        "  --hf_access_token $hf_token \\\n",
        "  --prompt 'Once upon a time there was' \\\n",
        "  --generate_kwargs repetition_penalty=1.2 prompt_lookup_num_tokens=10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKO-eqMjpTD3",
        "outputId": "7aa532f9-f0c9-4294-c3c3-a35edfe0036b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:root:No CUDA device detected, using cpu, expect slower speeds.\n",
            "config.json: 100% 1.77k/1.77k [00:00<00:00, 8.36MB/s]\n",
            "configuration_openelm.py: 100% 14.3k/14.3k [00:00<00:00, 37.9MB/s]\n",
            "A new version of the following files was downloaded from https://huggingface.co/apple/OpenELM-3B-Instruct:\n",
            "- configuration_openelm.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "modeling_openelm.py: 100% 39.3k/39.3k [00:00<00:00, 9.25MB/s]\n",
            "A new version of the following files was downloaded from https://huggingface.co/apple/OpenELM-3B-Instruct:\n",
            "- modeling_openelm.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "model.safetensors.index.json: 100% 24.2k/24.2k [00:00<00:00, 51.0MB/s]\n",
            "Downloading shards:   0% 0/2 [00:00<?, ?it/s]\n",
            "model-00001-of-00002.safetensors:   0% 0.00/4.94G [00:00<?, ?B/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   0% 10.5M/4.94G [00:00<01:29, 55.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 31.5M/4.94G [00:00<00:52, 93.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 52.4M/4.94G [00:00<00:44, 111MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 73.4M/4.94G [00:00<00:41, 118MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 94.4M/4.94G [00:00<00:39, 123MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 115M/4.94G [00:00<00:37, 128MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 136M/4.94G [00:01<00:37, 128MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 157M/4.94G [00:01<00:36, 130MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 178M/4.94G [00:01<00:36, 130MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 199M/4.94G [00:01<00:35, 133MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 220M/4.94G [00:01<00:35, 134MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 241M/4.94G [00:01<00:34, 135MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 262M/4.94G [00:02<00:34, 136MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 283M/4.94G [00:02<00:35, 132MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 304M/4.94G [00:02<00:34, 133MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 325M/4.94G [00:02<00:35, 130MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 346M/4.94G [00:02<00:35, 128MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 367M/4.94G [00:02<00:35, 131MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 388M/4.94G [00:03<00:34, 133MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 409M/4.94G [00:03<00:33, 135MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 430M/4.94G [00:03<00:33, 136MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 451M/4.94G [00:03<00:32, 137MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 472M/4.94G [00:03<00:32, 138MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 493M/4.94G [00:03<00:32, 137MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 514M/4.94G [00:03<00:33, 134MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 535M/4.94G [00:04<00:33, 132MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 556M/4.94G [00:04<00:33, 133MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 577M/4.94G [00:04<00:32, 132MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 598M/4.94G [00:04<00:34, 127MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 619M/4.94G [00:04<00:33, 129MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 640M/4.94G [00:04<00:33, 130MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 661M/4.94G [00:05<00:32, 131MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 682M/4.94G [00:05<00:32, 132MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 703M/4.94G [00:05<00:32, 132MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 724M/4.94G [00:05<00:31, 132MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 744M/4.94G [00:05<00:31, 133MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 765M/4.94G [00:05<00:31, 132MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 786M/4.94G [00:06<00:31, 133MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 807M/4.94G [00:06<00:30, 133MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 828M/4.94G [00:06<00:30, 133MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 849M/4.94G [00:06<00:30, 133MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 870M/4.94G [00:06<00:30, 134MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 891M/4.94G [00:06<00:30, 133MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 912M/4.94G [00:06<00:30, 134MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 933M/4.94G [00:07<00:29, 136MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 954M/4.94G [00:07<00:29, 137MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 975M/4.94G [00:07<00:28, 138MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 996M/4.94G [00:07<00:28, 138MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 1.02G/4.94G [00:07<00:28, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 1.04G/4.94G [00:07<00:28, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 1.06G/4.94G [00:08<00:27, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.08G/4.94G [00:08<00:27, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.10G/4.94G [00:08<00:27, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 1.12G/4.94G [00:08<00:27, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 1.14G/4.94G [00:08<00:27, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.16G/4.94G [00:08<00:27, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.18G/4.94G [00:08<00:26, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.21G/4.94G [00:09<00:26, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.23G/4.94G [00:09<00:26, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.25G/4.94G [00:09<00:26, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.27G/4.94G [00:09<00:26, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.29G/4.94G [00:09<00:26, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.31G/4.94G [00:09<00:25, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.33G/4.94G [00:09<00:25, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.35G/4.94G [00:10<00:25, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.37G/4.94G [00:10<00:25, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.39G/4.94G [00:10<00:25, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.42G/4.94G [00:10<00:26, 136MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.44G/4.94G [00:10<00:26, 133MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.46G/4.94G [00:10<00:26, 133MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.48G/4.94G [00:11<00:26, 131MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.50G/4.94G [00:11<00:26, 131MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.52G/4.94G [00:11<00:25, 132MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.54G/4.94G [00:11<00:25, 132MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.56G/4.94G [00:11<00:25, 131MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.58G/4.94G [00:11<00:25, 132MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.60G/4.94G [00:12<00:25, 133MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.63G/4.94G [00:12<00:24, 135MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.65G/4.94G [00:12<00:24, 136MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.67G/4.94G [00:12<00:23, 138MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.69G/4.94G [00:12<00:23, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.71G/4.94G [00:12<00:23, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.73G/4.94G [00:12<00:23, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.75G/4.94G [00:13<00:22, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.77G/4.94G [00:13<00:22, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.79G/4.94G [00:13<00:22, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.81G/4.94G [00:13<00:22, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.84G/4.94G [00:13<00:22, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.86G/4.94G [00:13<00:22, 136MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.88G/4.94G [00:14<00:22, 137MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.90G/4.94G [00:14<00:22, 137MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.92G/4.94G [00:14<00:21, 138MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.94G/4.94G [00:14<00:21, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 1.96G/4.94G [00:14<00:21, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 1.98G/4.94G [00:14<00:21, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.00G/4.94G [00:14<00:21, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.02G/4.94G [00:15<00:20, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.04G/4.94G [00:15<00:20, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.07G/4.94G [00:15<00:20, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.09G/4.94G [00:15<00:20, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 2.11G/4.94G [00:15<00:20, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 2.13G/4.94G [00:15<00:20, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 2.15G/4.94G [00:15<00:20, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 2.17G/4.94G [00:16<00:19, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 2.19G/4.94G [00:16<00:19, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 2.21G/4.94G [00:16<00:19, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 2.23G/4.94G [00:16<00:19, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.25G/4.94G [00:16<00:19, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.28G/4.94G [00:16<00:19, 134MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.30G/4.94G [00:17<00:19, 133MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 2.32G/4.94G [00:17<00:19, 133MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 2.34G/4.94G [00:17<00:19, 134MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.36G/4.94G [00:17<00:19, 133MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.38G/4.94G [00:17<00:19, 134MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.40G/4.94G [00:17<00:19, 131MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.42G/4.94G [00:18<00:19, 129MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.44G/4.94G [00:18<00:19, 128MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.46G/4.94G [00:18<00:19, 126MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.49G/4.94G [00:18<00:19, 129MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.51G/4.94G [00:18<00:18, 130MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.53G/4.94G [00:18<00:18, 129MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.55G/4.94G [00:18<00:18, 129MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.57G/4.94G [00:19<00:18, 130MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.59G/4.94G [00:19<00:18, 129MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.61G/4.94G [00:19<00:17, 132MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.63G/4.94G [00:19<00:17, 134MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.65G/4.94G [00:19<00:16, 136MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.67G/4.94G [00:19<00:16, 137MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.69G/4.94G [00:20<00:16, 138MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.72G/4.94G [00:20<00:16, 137MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.74G/4.94G [00:20<00:16, 138MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.76G/4.94G [00:20<00:15, 138MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.78G/4.94G [00:20<00:15, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.80G/4.94G [00:20<00:15, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.82G/4.94G [00:20<00:15, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.84G/4.94G [00:21<00:15, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.86G/4.94G [00:21<00:15, 137MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.88G/4.94G [00:21<00:14, 137MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.90G/4.94G [00:21<00:15, 135MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.93G/4.94G [00:21<00:14, 136MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 2.95G/4.94G [00:21<00:14, 136MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 2.97G/4.94G [00:22<00:14, 134MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 2.99G/4.94G [00:22<00:14, 135MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.01G/4.94G [00:22<00:14, 137MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.03G/4.94G [00:22<00:13, 137MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 3.05G/4.94G [00:22<00:13, 138MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 3.07G/4.94G [00:22<00:13, 138MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.09G/4.94G [00:22<00:13, 138MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.11G/4.94G [00:23<00:13, 137MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.14G/4.94G [00:23<00:13, 137MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.16G/4.94G [00:23<00:13, 137MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.18G/4.94G [00:23<00:13, 136MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 3.20G/4.94G [00:23<00:13, 132MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 3.22G/4.94G [00:23<00:13, 132MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.24G/4.94G [00:24<00:12, 132MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.26G/4.94G [00:24<00:13, 128MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.28G/4.94G [00:24<00:13, 126MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.30G/4.94G [00:24<00:13, 126MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.32G/4.94G [00:24<00:12, 125MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 3.34G/4.94G [00:24<00:12, 124MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 3.37G/4.94G [00:25<00:17, 91.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.39G/4.94G [00:25<00:15, 100MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.41G/4.94G [00:25<00:14, 109MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.43G/4.94G [00:25<00:12, 117MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 3.45G/4.94G [00:25<00:12, 123MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 3.47G/4.94G [00:26<00:11, 128MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.49G/4.94G [00:26<00:11, 131MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.51G/4.94G [00:26<00:10, 133MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.53G/4.94G [00:26<00:10, 135MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.55G/4.94G [00:26<00:10, 136MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.58G/4.94G [00:26<00:09, 137MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.60G/4.94G [00:26<00:09, 138MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.62G/4.94G [00:27<00:09, 138MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 3.64G/4.94G [00:27<00:09, 138MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 3.66G/4.94G [00:27<00:09, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 3.68G/4.94G [00:27<00:09, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.70G/4.94G [00:27<00:08, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.72G/4.94G [00:27<00:08, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.74G/4.94G [00:28<00:08, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.76G/4.94G [00:28<00:08, 138MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.79G/4.94G [00:28<00:08, 138MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.81G/4.94G [00:28<00:08, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.83G/4.94G [00:28<00:08, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.85G/4.94G [00:28<00:07, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.87G/4.94G [00:28<00:07, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.89G/4.94G [00:29<00:07, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.91G/4.94G [00:29<00:07, 138MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 3.93G/4.94G [00:29<00:07, 135MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 3.95G/4.94G [00:29<00:07, 129MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 3.97G/4.94G [00:29<00:07, 129MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 4.00G/4.94G [00:29<00:07, 131MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 4.02G/4.94G [00:30<00:07, 131MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.04G/4.94G [00:30<00:06, 131MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.06G/4.94G [00:30<00:06, 129MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 4.08G/4.94G [00:30<00:06, 131MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 4.10G/4.94G [00:30<00:06, 134MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 4.12G/4.94G [00:30<00:06, 135MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.14G/4.94G [00:30<00:05, 137MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.16G/4.94G [00:31<00:05, 138MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.18G/4.94G [00:31<00:05, 138MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.20G/4.94G [00:31<00:05, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.23G/4.94G [00:31<00:05, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 4.25G/4.94G [00:31<00:04, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 4.27G/4.94G [00:31<00:04, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 4.29G/4.94G [00:32<00:04, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 4.31G/4.94G [00:32<00:04, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.33G/4.94G [00:32<00:04, 138MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.35G/4.94G [00:32<00:04, 138MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.37G/4.94G [00:32<00:04, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 4.39G/4.94G [00:32<00:03, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 4.41G/4.94G [00:32<00:03, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.44G/4.94G [00:33<00:03, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.46G/4.94G [00:33<00:03, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 4.48G/4.94G [00:33<00:03, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 4.50G/4.94G [00:33<00:03, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 4.52G/4.94G [00:33<00:03, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 4.54G/4.94G [00:33<00:02, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 4.56G/4.94G [00:33<00:02, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 4.58G/4.94G [00:34<00:02, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 4.60G/4.94G [00:34<00:02, 135MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.62G/4.94G [00:34<00:02, 134MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.65G/4.94G [00:34<00:02, 134MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.67G/4.94G [00:34<00:02, 135MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 4.69G/4.94G [00:34<00:01, 134MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 4.71G/4.94G [00:35<00:01, 132MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.73G/4.94G [00:35<00:01, 133MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.75G/4.94G [00:35<00:01, 133MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 4.77G/4.94G [00:35<00:01, 131MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 4.79G/4.94G [00:35<00:01, 132MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 4.81G/4.94G [00:35<00:00, 134MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.83G/4.94G [00:36<00:00, 136MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.85G/4.94G [00:36<00:00, 137MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.88G/4.94G [00:36<00:00, 138MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.90G/4.94G [00:36<00:00, 138MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.92G/4.94G [00:36<00:00, 138MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 4.94G/4.94G [00:36<00:00, 134MB/s]\n",
            "Downloading shards:  50% 1/2 [00:37<00:37, 37.11s/it]\n",
            "model-00002-of-00002.safetensors:   0% 0.00/1.13G [00:00<?, ?B/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   2% 21.0M/1.13G [00:00<00:08, 138MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   4% 41.9M/1.13G [00:00<00:08, 132MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   6% 62.9M/1.13G [00:00<00:07, 134MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   7% 83.9M/1.13G [00:00<00:07, 136MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   9% 105M/1.13G [00:00<00:07, 135MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:  11% 126M/1.13G [00:00<00:07, 135MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  13% 147M/1.13G [00:01<00:07, 137MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  15% 168M/1.13G [00:01<00:07, 137MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  17% 189M/1.13G [00:01<00:06, 138MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  19% 210M/1.13G [00:01<00:06, 139MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  20% 231M/1.13G [00:01<00:06, 139MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  22% 252M/1.13G [00:01<00:06, 140MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  24% 273M/1.13G [00:01<00:06, 138MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  26% 294M/1.13G [00:02<00:06, 135MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  28% 315M/1.13G [00:02<00:06, 135MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  30% 336M/1.13G [00:02<00:05, 135MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  32% 357M/1.13G [00:02<00:05, 134MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  33% 377M/1.13G [00:02<00:05, 133MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  35% 398M/1.13G [00:02<00:05, 131MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  37% 419M/1.13G [00:03<00:05, 130MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  39% 440M/1.13G [00:03<00:05, 129MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  41% 461M/1.13G [00:03<00:05, 126MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  43% 482M/1.13G [00:03<00:05, 127MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  45% 503M/1.13G [00:03<00:04, 128MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  46% 524M/1.13G [00:03<00:04, 129MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  48% 545M/1.13G [00:04<00:04, 132MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  50% 566M/1.13G [00:04<00:04, 135MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  52% 587M/1.13G [00:04<00:03, 136MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  54% 608M/1.13G [00:04<00:03, 137MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  56% 629M/1.13G [00:04<00:03, 138MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  58% 650M/1.13G [00:04<00:03, 137MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  59% 671M/1.13G [00:04<00:03, 135MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  61% 692M/1.13G [00:05<00:03, 135MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  63% 713M/1.13G [00:05<00:03, 135MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  65% 734M/1.13G [00:05<00:02, 135MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  67% 755M/1.13G [00:05<00:02, 135MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  69% 776M/1.13G [00:05<00:02, 137MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  71% 797M/1.13G [00:05<00:02, 137MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  72% 818M/1.13G [00:06<00:02, 138MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  74% 839M/1.13G [00:06<00:02, 139MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  76% 860M/1.13G [00:06<00:01, 139MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  78% 881M/1.13G [00:06<00:01, 139MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  80% 902M/1.13G [00:06<00:01, 137MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  82% 923M/1.13G [00:06<00:01, 137MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  84% 944M/1.13G [00:06<00:01, 138MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  85% 965M/1.13G [00:07<00:01, 139MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  87% 986M/1.13G [00:07<00:01, 133MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  89% 1.01G/1.13G [00:07<00:00, 129MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  91% 1.03G/1.13G [00:07<00:00, 129MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  93% 1.05G/1.13G [00:07<00:00, 126MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  95% 1.07G/1.13G [00:07<00:00, 128MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  97% 1.09G/1.13G [00:08<00:00, 129MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  98% 1.11G/1.13G [00:08<00:00, 129MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors: 100% 1.13G/1.13G [00:08<00:00, 134MB/s]\n",
            "Downloading shards: 100% 2/2 [00:45<00:00, 22.84s/it]\n",
            "Loading checkpoint shards: 100% 2/2 [00:03<00:00,  1.78s/it]\n",
            "generation_config.json: 100% 111/111 [00:00<00:00, 445kB/s]\n",
            "2024-04-27 13:29:06.069821: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-27 13:29:06.069891: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-27 13:29:06.071239: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-27 13:29:07.298585: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\n",
            "\n",
            "\u001b[1m Prompt + Generated Output\u001b[0m\n",
            "\n",
            "Once upon a time there was a little girl named Rosie. Rosie loved to play dress-up, and her favorite costume was a princess dress. Her mother dressed Rosie in the princess dress every day, but Rosie wanted to wear it on special occasions, too.\n",
            "\n",
            "One day Rosie's mother told Rosie that Prince Charming would arrive at their house later that evening. Rosie couldn't wait! Prince Charming would surely ask Rosie to marry him, and she would wear her beautiful princess dress for their wedding. Rosie ran upstairs to get dressed.\n",
            "\n",
            "When Prince Charming arrived, Rosie wore her princess dress and tiara. Her mother helped her with her makeup, and Rosie practiced her curtsy. Prince Charming smiled and kissed Rosie's hand. Rosie hoped Prince Charming would ask her to marry him, but Prince Charming shook Rosie's hand instead. Prince Charming explained that Rosie's father had died when Rosie was very young, and Prince Charming wanted Rosie to choose her own husband. Rosie felt sad, but Prince Charming promised her\n",
            "\n",
            "\n",
            "Generation took\u001b[1m\u001b[92m 124.44 \u001b[0mseconds.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### use `assistant_model`\n",
        "\n",
        "- https://huggingface.co/blog/assisted-generation"
      ],
      "metadata": {
        "id": "kvfh3iJqJrV7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python generate_openelm.py --model apple/OpenELM-3B \\\n",
        "  --hf_access_token $hf_token \\\n",
        "  --prompt 'Once upon a time there was' \\\n",
        "  --generate_kwargs repetition_penalty=1.2 \\\n",
        "  --assistant_model apple/OpenELM-270M\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dyfy4s6RKIpY",
        "outputId": "665acfc8-87d2-4c05-a2a4-f40b2cd2cd4b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:root:No CUDA device detected, using cpu, expect slower speeds.\n",
            "Loading checkpoint shards: 100% 3/3 [00:08<00:00,  2.84s/it]\n",
            "2024-04-27 13:32:23.732093: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-27 13:32:23.732169: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-27 13:32:23.733612: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-27 13:32:25.183639: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\n",
            "\n",
            "\u001b[1m Prompt + Generated Output\u001b[0m\n",
            "\n",
            "Once upon a time there was a little girl who loved to play with her dolls. She had many dolls, and she played with them every day.\n",
            "One day the little girl's mother told her that she would be going to the store to buy some groceries. The little girl asked if she could go with her. Her mother said yes, and they went to the store.\n",
            "When they got to the store, the little girl saw a beautiful doll in the window. It was a very expensive doll, and it was made of wood. The little girl wanted to buy it, but her mother said that she couldn't afford it.\n",
            "The little girl was very sad, but she knew that her mother loved her very much. So she decided to wait until her mother came home from the store.\n",
            "When the little girl's mother came home, she told her that she had bought the doll for her. The little girl was very happy, and she thanked her mother for the doll.\n",
            "The little girl's mother told her that she would have to take care of the doll. She told the little girl that she would have to feed it, bathe it, and put it to bed.\n",
            "The little girl was\n",
            "\n",
            "\n",
            "Generation took\u001b[1m\u001b[92m 107.15 \u001b[0mseconds.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# gradio"
      ],
      "metadata": {
        "id": "9S7ZTF7_xzD5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from threading import Thread\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, TextIteratorStreamer\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch_dtype = torch.bfloat16 if torch.cuda.is_available() else torch.float32\n",
        "low_cpu_mem_usage = True if torch.cuda.is_available() else False\n",
        "\n",
        "checkpoint_tok = \"meta-llama/Llama-2-7b-hf\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint_tok)\n",
        "\n",
        "checkpoint = \"apple/OpenELM-270M\"\n",
        "model = AutoModelForCausalLM.from_pretrained(checkpoint, torch_dtype=torch_dtype, trust_remote_code=True, low_cpu_mem_usage=low_cpu_mem_usage)\n",
        "model.to(device)\n",
        "\n",
        "text_title = checkpoint.replace(\"/\", \" - \") + ' (' + str(model.device) + ') - Gradio Demo'\n"
      ],
      "metadata": {
        "id": "jPTkb1gduwzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QE9W-FVru4qE",
        "outputId": "6ba28ddc-7f97-4970-b865-0e9be9dd4cb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LlamaTokenizerFast(name_or_path='meta-llama/Llama-2-7b-hf', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
            "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if tokenizer.pad_token == None:\n",
        "  tokenizer.pad_token = tokenizer.eos_token\n",
        "  tokenizer.pad_token_id = tokenizer.eos_token_id\n"
      ],
      "metadata": {
        "id": "dsBq9o12u6Pm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rLBxrXXwza7",
        "outputId": "b5f908d7-be8a-4a7e-ffd7-45b667caf7df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LlamaTokenizerFast(name_or_path='meta-llama/Llama-2-7b-hf', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '</s>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
            "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from transformers import set_seed\n",
        "#set_seed(42)\n",
        "#Make sure we can generate text\n",
        "text =  \"Hello my name is Doron and I am\"\n",
        "inputs = tokenizer([text], return_tensors = \"pt\").input_ids.to(model.device)\n",
        "pred_ids = model.generate(input_ids=inputs, do_sample=True, max_new_tokens=64, repetition_penalty=1.2)\n",
        "#print(pred_ids)\n",
        "pred_text = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "print(pred_text[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V633RsGGvBNp",
        "outputId": "bc45e442-758d-4002-aeb6-cb8e03be1afc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello my name is Doron and I am a 20-year-old student of Mechanical Engineering, pursuing the degree of Bachelor in Industrial Design.\n",
            "I have always been passionate about cars and the latest trends are just waiting for me to dive in! Having read many different books (both theoretical and practical) on the subject\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gradio\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZwmVA_Tx_7N",
        "outputId": "c72cf913-8f06-4741-ee5c-765bd9917974"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.9/91.9 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.4/314.4 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "spacy 3.7.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n",
            "weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "########################################################################\n",
        "#                               Settings\n",
        "########################################################################\n",
        "import gradio as gr\n",
        "\n",
        "#Set the maximum number of tokens to generate\n",
        "max_new_tokens = 250\n",
        "\n",
        "#Set a the value of the repetition penalty\n",
        "#The higher the value, the less repetitive the generated text will be\n",
        "#Note that `repetition_penalty` has to be a strictly positive float\n",
        "repetition_penalty = 1.4\n",
        "\n",
        "#Set the text direction\n",
        "#For languages that are written from right to left (RTL), set rtl to True\n",
        "rtl = False\n",
        "\n",
        "########################################################################\n",
        "\n",
        "print(f\"Settings: max_new_tokens = {max_new_tokens}, repetition_penalty = {repetition_penalty}, rtl = {rtl}\")\n",
        "\n",
        "if rtl:\n",
        "    text_title += \" - RTL\"\n",
        "    text_align = 'right'\n",
        "    css = \"#output_text{direction: rtl} #input_text{direction: rtl}\"\n",
        "else:\n",
        "    text_align = 'left'\n",
        "    css = \"\"\n",
        "\n",
        "\n",
        "def generate(text = \"\"):\n",
        "    print(\"Create streamer\")\n",
        "    yield    \"[Please wait for an answer]\"\n",
        "\n",
        "    decode_kwargs = dict(skip_special_tokens = True, clean_up_tokenization_spaces = True)\n",
        "    streamer = TextIteratorStreamer(tokenizer, timeout = 5., decode_kwargs = decode_kwargs)\n",
        "\n",
        "    inputs = tokenizer([text], return_tensors = \"pt\").input_ids.to(model.device)\n",
        "    print(tokenizer.decode(inputs[0], skip_special_tokens=True))\n",
        "\n",
        "    generation_kwargs = dict(input_ids=inputs, streamer = streamer, max_new_tokens=max_new_tokens, repetition_penalty=repetition_penalty)\n",
        "\n",
        "    print(\"Create thread\")\n",
        "    thread = Thread(target = model.generate, kwargs = generation_kwargs)\n",
        "    thread.start()\n",
        "    generated_text = \"\"\n",
        "    for new_text in streamer:\n",
        "      if new_text == None:\n",
        "          continue\n",
        "      if tokenizer.eos_token not in new_text:\n",
        "          new_text = new_text.replace(tokenizer.pad_token, \"\").replace(tokenizer.bos_token, \"\")\n",
        "          yield generated_text + new_text\n",
        "          print(new_text, end =\"\")\n",
        "          generated_text += new_text\n",
        "      else:\n",
        "          new_text = new_text.replace(tokenizer.eos_token, \"\\n\")\n",
        "          print(new_text, end =\"\")\n",
        "          generated_text += new_text\n",
        "          return generated_text\n",
        "    return generated_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKl77ZwJzWPv",
        "outputId": "5ca2d3be-a2a9-44ca-bc22-1531bfedc9de"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Settings: max_new_tokens = 250, repetition_penalty = 1.4, rtl = False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "demo = gr.Interface(\n",
        "        title = text_title,\n",
        "        fn = generate,\n",
        "        inputs = gr.Textbox(label = \"Enter your prompt here\", elem_id = \"input_text\", text_align = text_align, rtl = rtl),\n",
        "        outputs = gr.Textbox(type = \"text\", label = \"Generated text will appear here\", elem_id = \"output_text\", text_align = text_align, rtl = rtl),\n",
        "        css = css,\n",
        "        allow_flagging = 'never'\n",
        ")\n",
        "\n",
        "demo.queue()\n",
        "demo.launch(debug = True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        },
        "id": "GM__OO0OxycK",
        "outputId": "77acafb6-1422-403b-90fc-153f13286a67"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Settings: max_new_tokens = 250, repetition_penalty = 1.4, rtl = False\n",
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://eedeb7dd82d4be9114.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://eedeb7dd82d4be9114.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create streamer\n",
            "hi\n",
            "Create thread\n",
            " hi, i'm a 20 year old female and have been on T for about 3 months now. I was diagnosed with PCOS in my early 20's but it wasn't until recently that i realized how much of a difference it made in my life.\n",
            "\n",
            "i started taking testosterone at the beginning of this month (1st week) because i wanted to see if i could get some more energy out of my body. i also noticed that my libido has increased significantly since starting T. i am not sure why or how it happened but i think it might be due to the fact that i feel like i can do anything i want when i take testosterone. i don't know what else to say other than that i love being able to go from day to day without having to worry about whether i will pass out or something.\n",
            "\n",
            "my biggest concern is that i still have trouble sleeping. i wake up feeling tired all the time and sometimes even after i've taken my pill i just lay there for hours. i've tried everything to help me fall asleep but nothing seems to work. i've had nightmares before but they are usuallyKeyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://eedeb7dd82d4be9114.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = \"apple/OpenELM-3B\"\n",
        "model = AutoModelForCausalLM.from_pretrained(checkpoint, torch_dtype=torch_dtype, trust_remote_code=True, low_cpu_mem_usage=low_cpu_mem_usage)\n",
        "model.to(device)\n",
        "\n",
        "text_title = checkpoint.replace(\"/\", \" - \") + ' (' + str(model.device) + ') - Gradio Demo'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "aff8e4a2b48a484eb9b53cb7699b0b7e",
            "e14a66bd8873431fbd301c7c961c8340",
            "706341fc7ab546098c3539d2610d3197",
            "c2ac07b5f4c245d6b6eb960a7ad1e49b",
            "cb762987ef1343d1960f86f2eab0888b",
            "0685835ad658441fbed6373df8d0c1be",
            "9639c1c675d14824af653d86d246bb87",
            "6f8f5d65dce44937816dd0f11f07bad3",
            "1e53ecb30c474dd7b5e9d2b187bec4e7",
            "d8666eb5495f45818b8cedb5b3a47d13",
            "6dde9942fddd4bf5b567f0c97ba60bab"
          ]
        },
        "id": "rr7ikLRty8Mj",
        "outputId": "fa2aed22-135e-46f2-ea4b-f05abd985ee6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aff8e4a2b48a484eb9b53cb7699b0b7e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "demo = gr.Interface(\n",
        "        title = text_title,\n",
        "        fn = generate,\n",
        "        inputs = gr.Textbox(label = \"Enter your prompt here\", elem_id = \"input_text\", text_align = text_align, rtl = rtl),\n",
        "        outputs = gr.Textbox(type = \"text\", label = \"Generated text will appear here\", elem_id = \"output_text\", text_align = text_align, rtl = rtl),\n",
        "        css = css,\n",
        "        allow_flagging = 'never'\n",
        ")\n",
        "\n",
        "demo.queue()\n",
        "demo.launch(debug = True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "E9e9XnRuz8bl",
        "outputId": "1df72fb2-2aea-4bdd-bac5-b3f4cb688ddf"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://5e6144c78cf1dbed62.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://5e6144c78cf1dbed62.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create streamer\n",
            "hi\n",
            "Create thread\n",
            " hi, i'm a 20 year old female and i have been having this problem for about 3 years now. it started when i was in the 7th grade (i'm currently in the 11th grade). my period is irregular but usually comes every 3 months or so. however, sometimes it will come every month or even twice in one month. i also get cramps that are very painful and last for days. they start off as mild cramps then become more intense until they are unbearable. i can't take any pain medication because i am allergic to most of them. i have tried taking tylenol with codeine which helps somewhat but not completely. i have also tried advil and motrin which do not help at all. i have seen several doctors over the years and they have never been able to find out what is wrong with me. some of the doctors have said that i may have endometriosis but i don't think that is the case because i haven't had surgery yet. i have also been tested for everything else under the sun including thyroid problems, diabetes, etc. nothing has"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create streamer\n",
            "what you name?\n",
            "Create thread\n",
            " what you name?\n",
            "I'm not sure if I should call it a \"favorite\" or a \"least favorite.\" It's hard to say. But, for the sake of this post, I'll go with least favorite.\n",
            "The first time I saw The Notebook was in 2004 when I was still in high school. My mom and I went to see it "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create streamer\n",
            "who are you?\n",
            "Create thread\n",
            " who are you?\n",
            "I'm a 20-something year old girl from the UK. I love to read, write, and draw. I also like to play video games (mostly RPGs), watch anime, and listen to music. My favourite bands include The Beatles, Queen, Muse, Radiohead, Coldplay, and many more.\n",
            "what do you do?\n",
            "I work as a freelance writer for various websites and blogs. You can find my articles on this site or at other sites such as Blogcritics, PopMatters, and others.\n",
            "how did you get into writing?\n",
            "I started writing when I was about 13 years old. I wrote fanfiction in the Harry Potter fandom, which is where I got the idea to start writing original fiction. It wasn't until I was 16 that I actually began writing original fiction.\n",
            "where do you get your ideas?\n",
            "Most of my ideas come from dreams. Sometimes they just pop into my head while I'm awake, but most of the time they come from dreams. Other times, I'll be reading a book or watching a movie and think \"I wishKeyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://5e6144c78cf1dbed62.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation\n"
      ],
      "metadata": {
        "id": "w_lfF3X2qKnT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "# install public lm-eval-harness\n",
        "\n",
        "harness_repo=\"public-lm-eval-harness\"\n",
        "git clone https://github.com/EleutherAI/lm-evaluation-harness ${harness_repo}\n",
        "cd ${harness_repo}\n",
        "# use main branch on 03-15-2024, SHA is dc90fec\n",
        "git checkout dc90fec\n",
        "pip install -e .\n",
        "cd ..\n",
        "\n",
        "# 66d6242 is the main branch on 2024-04-01\n",
        "pip install datasets@git+https://github.com/huggingface/datasets.git@66d6242\n",
        "pip install tokenizers>=0.15.2 transformers>=4.38.2 sentencepiece>=0.2.0\n"
      ],
      "metadata": {
        "id": "Dm6MJlUeqKLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "\n",
        "# OpenELM-270M-Instruct\n",
        "hf_model=OpenELM-270M-Instruct\n",
        "\n",
        "# this flag is needed because lm-eval-harness set add_bos_token to False by default, but OpenELM uses LLaMA tokenizer which requires add_bos_token to be True\n",
        "tokenizer=meta-llama/Llama-2-7b-hf\n",
        "add_bos_token=True\n",
        "batch_size=1\n",
        "\n",
        "mkdir lm_eval_output\n",
        "\n",
        "shot=0\n",
        "task=arc_challenge,arc_easy,boolq,hellaswag,piqa,race,winogrande,sciq,truthfulqa_mc2\n",
        "lm_eval --model hf \\\n",
        "        --model_args pretrained=${hf_model},trust_remote_code=True,add_bos_token=${add_bos_token},tokenizer=${tokenizer} \\\n",
        "        --tasks ${task} \\\n",
        "        --device cuda:0 \\\n",
        "        --num_fewshot ${shot} \\\n",
        "        --output_path ./lm_eval_output/${hf_model//\\//_}_${task//,/_}-${shot}shot \\\n",
        "        --batch_size ${batch_size} 2>&1 | tee ./lm_eval_output/eval-${hf_model//\\//_}_${task//,/_}-${shot}shot.log\n",
        "\n",
        "shot=5\n",
        "task=mmlu,winogrande\n",
        "lm_eval --model hf \\\n",
        "        --model_args pretrained=${hf_model},trust_remote_code=True,add_bos_token=${add_bos_token},tokenizer=${tokenizer} \\\n",
        "        --tasks ${task} \\\n",
        "        --device cuda:0 \\\n",
        "        --num_fewshot ${shot} \\\n",
        "        --output_path ./lm_eval_output/${hf_model//\\//_}_${task//,/_}-${shot}shot \\\n",
        "        --batch_size ${batch_size} 2>&1 | tee ./lm_eval_output/eval-${hf_model//\\//_}_${task//,/_}-${shot}shot.log\n",
        "\n",
        "shot=25\n",
        "task=arc_challenge,crows_pairs_english\n",
        "lm_eval --model hf \\\n",
        "        --model_args pretrained=${hf_model},trust_remote_code=True,add_bos_token=${add_bos_token},tokenizer=${tokenizer} \\\n",
        "        --tasks ${task} \\\n",
        "        --device cuda:0 \\\n",
        "        --num_fewshot ${shot} \\\n",
        "        --output_path ./lm_eval_output/${hf_model//\\//_}_${task//,/_}-${shot}shot \\\n",
        "        --batch_size ${batch_size} 2>&1 | tee ./lm_eval_output/eval-${hf_model//\\//_}_${task//,/_}-${shot}shot.log\n",
        "\n",
        "shot=10\n",
        "task=hellaswag\n",
        "lm_eval --model hf \\\n",
        "        --model_args pretrained=${hf_model},trust_remote_code=True,add_bos_token=${add_bos_token},tokenizer=${tokenizer} \\\n",
        "        --tasks ${task} \\\n",
        "        --device cuda:0 \\\n",
        "        --num_fewshot ${shot} \\\n",
        "        --output_path ./lm_eval_output/${hf_model//\\//_}_${task//,/_}-${shot}shot \\\n",
        "        --batch_size ${batch_size} 2>&1 | tee ./lm_eval_output/eval-${hf_model//\\//_}_${task//,/_}-${shot}shot.log\n"
      ],
      "metadata": {
        "id": "Ls-CJYDdqeN2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}