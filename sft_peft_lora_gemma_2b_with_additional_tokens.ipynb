{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weedge/doraemon-nb/blob/main/sft_peft_lora_gemma_2b_with_additional_tokens.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f239612-620e-4430-8685-9fdc6b179b41",
      "metadata": {
        "id": "5f239612-620e-4430-8685-9fdc6b179b41"
      },
      "source": [
        "# 训练 PEFT 模型时添加新标记到嵌入层和分词器\n",
        "\n",
        "\n",
        "在这个示例中，我们将学习如何在向 tokenizer 和模型添加新标记时训练 LoRA 模型。\n",
        "这是一个常见的用例，用于以下情况：\n",
        "1. 使用新增标记进行指令微调，例如  `<|user|>`, `<|assistant|>`, `<|system|>`, `</s>`, `<s>`，以正确格式化对话。\n",
        "2. 在特定语言上微调，在该语言的数据集上微调LLM时，添加语言特定的标记，例如添加韩语标记到词汇表中。\n",
        "3. 在指令微调中返回特定格式的输出，以启用代理行为，例如新增标记 `<|FUNCTIONS|>`, `<|BROWSE|>`, `<|TEXT2IMAGE|>`, `<|ASR|>`, `<|TTS|>`, `<|GENERATECODE|>`, `<|RAG|>`。\n",
        "\n",
        "在这种情况下，您需要将嵌入模块添加到 LORA 的 `target_modules` 中。PEFT 将负责保存嵌入层，其中包含新添加标记的权重，以及在特定初始化的嵌入层权重上训练的适配器权重。"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q peft transformers datasets accelerate wandb dataclass_csv"
      ],
      "metadata": {
        "id": "-wiW-lJnzy-O"
      },
      "id": "-wiW-lJnzy-O",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "6f864c90",
      "metadata": {
        "id": "6f864c90"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "os.environ[\"WANDB_PROJECT\"] = \"PeftExamples\"\n",
        "#os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "import transformers\n",
        "from peft import (\n",
        "    LoraConfig,\n",
        "    PeftConfig,\n",
        "    PeftModel,\n",
        "    get_peft_model,\n",
        "    prepare_model_for_kbit_training,\n",
        ")\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    HfArgumentParser,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    default_data_collator,\n",
        ")\n",
        "import torch\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Optional\n",
        "from dataclass_csv import DataclassReader\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from enum import Enum"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74950a3f-bb63-4ce5-9e2b-1b83f92b13a2",
      "metadata": {
        "id": "74950a3f-bb63-4ce5-9e2b-1b83f92b13a2"
      },
      "source": [
        "## Prepare Model and Tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76763f5e-64b2-409b-8845-ae5589f8a4e0",
      "metadata": {
        "id": "76763f5e-64b2-409b-8845-ae5589f8a4e0"
      },
      "source": [
        "现在，我们将添加 27 个新标记，并替换模型中现有的 pad、bos 和 eos 标记。\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "fd0498ea-547e-418d-bf13-c9abafdd5476",
      "metadata": {
        "id": "fd0498ea-547e-418d-bf13-c9abafdd5476"
      },
      "outputs": [],
      "source": [
        "class SpecialTokens(str, Enum):\n",
        "    begin_target = \"<|begintarget|>\"\n",
        "    end_target = \"<|endtarget|>\"\n",
        "    begin_context = \"<|begincontext|>\"\n",
        "    end_context = \"<|endcontext|>\"\n",
        "    system = \"<|system|>\"\n",
        "    user = \"<|user|>\"\n",
        "    begin_last_user_utterance = \"<|beginlastuserutterance|>\"\n",
        "    end_last_user_utterance = \"<|endlastuserutterance|>\"\n",
        "    begin_dsts = \"<|begindsts|>\"\n",
        "    end_dsts = \"<|enddsts|>\"\n",
        "    begin_dst = \"<|begindst|>\"\n",
        "    end_dst = \"<|enddst|>\"\n",
        "    begin_belief = \"<|beginbelief|>\"\n",
        "    end_belief = \"<|endbelief|>\"\n",
        "    begin_response = \"<|beginresponse|>\"\n",
        "    end_response = \"<|endresponse|>\"\n",
        "    begin_action = \"<|beginaction|>\"\n",
        "    end_action = \"<|endaction|>\"\n",
        "    begin_user_action = \"<|beginuseraction|>\"\n",
        "    end_user_action = \"<|enduseraction|>\"\n",
        "    sys_actions = \"<|sysactions|>\"\n",
        "    begin_intent = \"<|beginintent|>\"\n",
        "    end_intent = \"<|endintent|>\"\n",
        "    begin_requested_slots = \"<|beginrequestedslots|>\"\n",
        "    end_requested_slots = \"<|endrequestedslots|>\"\n",
        "    pad_token = \"<|pad|>\"\n",
        "    bos_token = \"<|startoftext|>\"\n",
        "\n",
        "    @classmethod\n",
        "    def list(cls):\n",
        "        return [c.value for c in cls]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae4a4255-5f13-4eef-a024-4f1de0f2173b",
      "metadata": {
        "id": "ae4a4255-5f13-4eef-a024-4f1de0f2173b"
      },
      "source": [
        "我们将微调 Mistral-7B 模型。让我们加载分词器并添加特殊标记，然后加载基础模型并调整嵌入层大小以容纳新增标记。"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-T2F_gC35Wx",
        "outputId": "b5e010aa-cc12-4bc3-e616-8c172ffe6dac"
      },
      "id": "D-T2F_gC35Wx",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "f0eedef9",
      "metadata": {
        "id": "f0eedef9",
        "outputId": "5cf6fe72-78aa-44e4-fdce-e8b3387f1531",
        "colab": {
          "referenced_widgets": [
            "afcc07fa4ddb4b788d47a5b35da7fecb",
            "5bc4eb089b9947d78835fd32423fea23",
            "fa8b4cb96b0841b7ba8de13fb1c64ac1",
            "fc7e3421e9a04153832af2ca70a38be7",
            "f189cc170f004decb79fc4afc5cfac4d",
            "478b06815ce645bc9b7171651bae1281",
            "dacdf665e77b49c685720f5e6093e7f3",
            "0a3ecd68abe640caa542809e63c03564",
            "3f571e511bc842cca5c0248edf2ce60a",
            "f65d27ab85fb499eb740688b61e9b8e5",
            "7a22a430ea0c411ba642fa2b572c00f5"
          ],
          "base_uri": "https://localhost:8080/",
          "height": 518
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "afcc07fa4ddb4b788d47a5b35da7fecb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GemmaForCausalLM(\n",
            "  (model): GemmaModel(\n",
            "    (embed_tokens): Embedding(256000, 2048, padding_idx=0)\n",
            "    (layers): ModuleList(\n",
            "      (0-17): 18 x GemmaDecoderLayer(\n",
            "        (self_attn): GemmaSdpaAttention(\n",
            "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
            "          (k_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
            "          (v_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
            "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
            "          (rotary_emb): GemmaRotaryEmbedding()\n",
            "        )\n",
            "        (mlp): GemmaMLP(\n",
            "          (gate_proj): Linear(in_features=2048, out_features=16384, bias=False)\n",
            "          (up_proj): Linear(in_features=2048, out_features=16384, bias=False)\n",
            "          (down_proj): Linear(in_features=16384, out_features=2048, bias=False)\n",
            "          (act_fn): GELUActivation()\n",
            "        )\n",
            "        (input_layernorm): GemmaRMSNorm()\n",
            "        (post_attention_layernorm): GemmaRMSNorm()\n",
            "      )\n",
            "    )\n",
            "    (norm): GemmaRMSNorm()\n",
            "  )\n",
            "  (lm_head): Linear(in_features=2048, out_features=256000, bias=False)\n",
            ")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(256027, 2048)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "model_name = \"google/gemma-2b\"\n",
        "#model_name = \"google/gemman-2b-it\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model_name,\n",
        "    pad_token=SpecialTokens.pad_token.value,\n",
        "    bos_token=SpecialTokens.bos_token.value,\n",
        "    eos_token=SpecialTokens.end_target.value,\n",
        "    additional_special_tokens=SpecialTokens.list(),\n",
        ")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    low_cpu_mem_usage=True\n",
        "    # use_flash_attention_2=True, # leading to an error\n",
        ").to(device)\n",
        "print(model)\n",
        "model.resize_token_embeddings(len(tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHqeI8038aIR",
        "outputId": "b3089b8b-7272-48ae-c36d-d3ab3ef3b3b8"
      },
      "id": "sHqeI8038aIR",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GemmaForCausalLM(\n",
            "  (model): GemmaModel(\n",
            "    (embed_tokens): Embedding(256027, 2048)\n",
            "    (layers): ModuleList(\n",
            "      (0-17): 18 x GemmaDecoderLayer(\n",
            "        (self_attn): GemmaSdpaAttention(\n",
            "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
            "          (k_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
            "          (v_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
            "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
            "          (rotary_emb): GemmaRotaryEmbedding()\n",
            "        )\n",
            "        (mlp): GemmaMLP(\n",
            "          (gate_proj): Linear(in_features=2048, out_features=16384, bias=False)\n",
            "          (up_proj): Linear(in_features=2048, out_features=16384, bias=False)\n",
            "          (down_proj): Linear(in_features=16384, out_features=2048, bias=False)\n",
            "          (act_fn): GELUActivation()\n",
            "        )\n",
            "        (input_layernorm): GemmaRMSNorm()\n",
            "        (post_attention_layernorm): GemmaRMSNorm()\n",
            "      )\n",
            "    )\n",
            "    (norm): GemmaRMSNorm()\n",
            "  )\n",
            "  (lm_head): Linear(in_features=2048, out_features=256027, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhGqSSm67aBK",
        "outputId": "162b2809-1132-406b-b11d-d9a443435af2"
      },
      "id": "dhGqSSm67aBK",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GemmaTokenizerFast(name_or_path='google/gemma-2b', vocab_size=256000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<|startoftext|>', 'eos_token': '<|endtarget|>', 'unk_token': '<unk>', 'pad_token': '<|pad|>', 'additional_special_tokens': ['<|begintarget|>', '<|endtarget|>', '<|begincontext|>', '<|endcontext|>', '<|system|>', '<|user|>', '<|beginlastuserutterance|>', '<|endlastuserutterance|>', '<|begindsts|>', '<|enddsts|>', '<|begindst|>', '<|enddst|>', '<|beginbelief|>', '<|endbelief|>', '<|beginresponse|>', '<|endresponse|>', '<|beginaction|>', '<|endaction|>', '<|beginuseraction|>', '<|enduseraction|>', '<|sysactions|>', '<|beginintent|>', '<|endintent|>', '<|beginrequestedslots|>', '<|endrequestedslots|>', '<|pad|>', '<|startoftext|>']}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
            "\t0: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t1: AddedToken(\"<eos>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t2: AddedToken(\"<bos>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t256000: AddedToken(\"<|startoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t256001: AddedToken(\"<|endtarget|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t256002: AddedToken(\"<|pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t256003: AddedToken(\"<|begintarget|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t256004: AddedToken(\"<|begincontext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t256005: AddedToken(\"<|endcontext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t256006: AddedToken(\"<|system|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t256007: AddedToken(\"<|user|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t256008: AddedToken(\"<|beginlastuserutterance|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t256009: AddedToken(\"<|endlastuserutterance|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t256010: AddedToken(\"<|begindsts|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t256011: AddedToken(\"<|enddsts|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t256012: AddedToken(\"<|begindst|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t256013: AddedToken(\"<|enddst|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t256014: AddedToken(\"<|beginbelief|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t256015: AddedToken(\"<|endbelief|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t256016: AddedToken(\"<|beginresponse|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t256017: AddedToken(\"<|endresponse|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t256018: AddedToken(\"<|beginaction|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t256019: AddedToken(\"<|endaction|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t256020: AddedToken(\"<|beginuseraction|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t256021: AddedToken(\"<|enduseraction|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t256022: AddedToken(\"<|sysactions|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t256023: AddedToken(\"<|beginintent|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t256024: AddedToken(\"<|endintent|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t256025: AddedToken(\"<|beginrequestedslots|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t256026: AddedToken(\"<|endrequestedslots|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88439ed6-9974-4918-80df-ec78b05b4185",
      "metadata": {
        "id": "88439ed6-9974-4918-80df-ec78b05b4185"
      },
      "source": [
        "## Apply LoRA\n",
        "\n",
        "**注**：IA3和LoRA差不多，增加了前馈层的参数权重微调，LoRA关注在embedding,self attention， lm_head层"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "80967087",
      "metadata": {
        "id": "80967087",
        "outputId": "95d8da5d-45a3-45b5-df3c-fdb405d39ecc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path=None, revision=None, task_type=None, inference_mode=False, r=64, target_modules={'lm_head', 'q_proj', 'v_proj', 'embed_tokens'}, lora_alpha=128, lora_dropout=0.0, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None)\n",
            "trainable params: 40,406,400 || all params: 2,546,634,112 || trainable%: 1.5866590261082625\n",
            "None\n",
            "PeftModel(\n",
            "  (base_model): LoraModel(\n",
            "    (model): GemmaForCausalLM(\n",
            "      (model): GemmaModel(\n",
            "        (embed_tokens): lora.Embedding(\n",
            "          (base_layer): Embedding(256027, 2048)\n",
            "          (lora_dropout): ModuleDict(\n",
            "            (default): Identity()\n",
            "          )\n",
            "          (lora_A): ModuleDict()\n",
            "          (lora_B): ModuleDict()\n",
            "          (lora_embedding_A): ParameterDict(  (default): Parameter containing: [torch.FloatTensor of size 64x256027])\n",
            "          (lora_embedding_B): ParameterDict(  (default): Parameter containing: [torch.FloatTensor of size 2048x64])\n",
            "        )\n",
            "        (layers): ModuleList(\n",
            "          (0-17): 18 x GemmaDecoderLayer(\n",
            "            (self_attn): GemmaSdpaAttention(\n",
            "              (q_proj): lora.Linear(\n",
            "                (base_layer): Linear(in_features=2048, out_features=2048, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Identity()\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=2048, out_features=64, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=64, out_features=2048, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "              )\n",
            "              (k_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
            "              (v_proj): lora.Linear(\n",
            "                (base_layer): Linear(in_features=2048, out_features=256, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Identity()\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=2048, out_features=64, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=64, out_features=256, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "              )\n",
            "              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
            "              (rotary_emb): GemmaRotaryEmbedding()\n",
            "            )\n",
            "            (mlp): GemmaMLP(\n",
            "              (gate_proj): Linear(in_features=2048, out_features=16384, bias=False)\n",
            "              (up_proj): Linear(in_features=2048, out_features=16384, bias=False)\n",
            "              (down_proj): Linear(in_features=16384, out_features=2048, bias=False)\n",
            "              (act_fn): GELUActivation()\n",
            "            )\n",
            "            (input_layernorm): GemmaRMSNorm()\n",
            "            (post_attention_layernorm): GemmaRMSNorm()\n",
            "          )\n",
            "        )\n",
            "        (norm): GemmaRMSNorm()\n",
            "      )\n",
            "      (lm_head): lora.Linear(\n",
            "        (base_layer): Linear(in_features=2048, out_features=256027, bias=False)\n",
            "        (lora_dropout): ModuleDict(\n",
            "          (default): Identity()\n",
            "        )\n",
            "        (lora_A): ModuleDict(\n",
            "          (default): Linear(in_features=2048, out_features=64, bias=False)\n",
            "        )\n",
            "        (lora_B): ModuleDict(\n",
            "          (default): Linear(in_features=64, out_features=256027, bias=False)\n",
            "        )\n",
            "        (lora_embedding_A): ParameterDict()\n",
            "        (lora_embedding_B): ParameterDict()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "config = LoraConfig(\n",
        "    r=64, lora_alpha=128, lora_dropout=0.0, target_modules=[\"embed_tokens\", \"lm_head\", \"q_proj\", \"v_proj\"]\n",
        ")\n",
        "#config = IA3Config(task_type=TaskType.SEQ_CLS, target_modules=[\"embed_tokens\", \"lm_head\", \"q_proj\", \"v_proj\"], feedforward_modules=[\"down_proj\"])\n",
        "\n",
        "print(config)\n",
        "model = get_peft_model(model, config)\n",
        "print(model.print_trainable_parameters())\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`LoraConfig` 的配置，用于配置 LoRA（Low-Rank Adaptation）的相关选项。LoRA 是一种低秩适应技术，用于减少大型语言模型的参数量，并提高模型的效率和性能。以下是各个参数的含义解释：\n",
        "\n",
        "1. `peft_type`: PEFT（Parameter-Efficient Fine-Tuning）类型。在这里，设置为 `PeftType.LORA`，表示使用 LoRA 进行微调。\n",
        "\n",
        "2. `auto_mapping`: 自动映射。用于指定是否自动映射预训练模型的参数以适应新任务。\n",
        "\n",
        "3. `base_model_name_or_path`: 基础模型名称或路径。用于指定要微调的基础语言模型的名称或路径。\n",
        "\n",
        "4. `revision`: 模型修订版本。\n",
        "\n",
        "5. `task_type`: 任务类型。在这里，未指定任务类型。\n",
        "\n",
        "6. `inference_mode`: 推理模式。用于指定是否在推理时使用 LoRA。\n",
        "\n",
        "7. `r`: LoRA 中的秩（rank）参数。用于控制低秩适应的参数量。\n",
        "\n",
        "8. `target_modules`: 目标模块。指定了要应用低秩适应的模块名称集合。\n",
        "\n",
        "9. `lora_alpha`: LoRA 中的 alpha 参数。用于控制低秩适应的强度。\n",
        "\n",
        "10. `lora_dropout`: LoRA 中的 dropout 参数。用于控制低秩适应的正则化。\n",
        "\n",
        "11. `fan_in_fan_out`: 是否使用扇入/扇出初始化。\n",
        "\n",
        "12. `bias`: 偏置类型。指定了在低秩适应中使用的偏置类型。\n",
        "\n",
        "13. `use_rslora`: 是否使用 RSLora。\n",
        "\n",
        "14. `modules_to_save`: 要保存的模块列表。\n",
        "\n",
        "15. `init_lora_weights`: 是否初始化 LoRA 权重。\n",
        "\n",
        "16. `layers_to_transform`: 要转换的层列表。\n",
        "\n",
        "17. `layers_pattern`: 层模式。\n",
        "\n",
        "18. `rank_pattern`: 秩模式。\n",
        "\n",
        "19. `alpha_pattern`: Alpha 模式。\n",
        "\n",
        "20. `megatron_config`: Megatron 配置。\n",
        "\n",
        "21. `megatron_core`: Megatron 核心。\n",
        "\n",
        "22. `loftq_config`: LoFTQ 配置。\n",
        "\n",
        "23. `use_dora`: 是否使用 DoRA。\n",
        "\n",
        "24. `layer_replication`: 层复制。\n",
        "\n",
        "这些参数用于配置 LoRA 过程中的各个方面，包括秩参数、模块选择、初始化方法等。通过调整这些参数，可以控制 LoRA 的行为，以满足特定任务和硬件环境的需求。"
      ],
      "metadata": {
        "id": "T8OnrB42xmrZ"
      },
      "id": "T8OnrB42xmrZ"
    },
    {
      "cell_type": "markdown",
      "id": "15ac9945-4fcb-45f4-9478-d99a25a519cc",
      "metadata": {
        "id": "15ac9945-4fcb-45f4-9478-d99a25a519cc"
      },
      "source": [
        "## Preapre Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "c6980d59-42d4-4a27-84cc-a9719302088b",
      "metadata": {
        "id": "c6980d59-42d4-4a27-84cc-a9719302088b",
        "outputId": "bff8a7d3-b6ab-451d-8a27-892961648f99",
        "colab": {
          "referenced_widgets": [
            "a6b13234b84a4ef1ad16585d0200bfa8",
            "d18f1dffab624866b32fa4ff2421d6d6",
            "611640227b4341079c44c7403ac02c7f",
            "024db3ab7fdd49fea529003ad1674386",
            "a26535c17ef347c996914430d9613034",
            "bda2f747d6e04c139277477f2f2c6d98",
            "3057c01eeb3f420481cb36f51ba09e61",
            "3b6e1d7fa07e432592aef14e5ce00181",
            "dc3ee27d9984446aa0ff744e94686e5a",
            "beec1aae84074a5faccfcca22d53eb17",
            "cd1d31ae00df470ca72f1ef54486a187",
            "427fadea4057456c830c64ad637fadb9",
            "87266692e5a24b18bb7ca2ba9db799d7",
            "507f6c6a2be64f44bc8bacb43e32cb56",
            "5c157c909f8142f181c857c5027f7f0c",
            "46abc1ff1b614683b9705a472a354561",
            "fcfbfc20d34f472a95598b532991988a",
            "f4ddca50db844ccb99e627f16dbb5207",
            "789c6bef74d046f9a11bede2340a1e80",
            "5bb018febbab4d74a409a1c7da15f1d0",
            "843f294e02cc40f09eddce4f020752c3",
            "3123c65b9e7a4b539c8e0a29de4885ba"
          ],
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Running tokenizer on dataset:   0%|          | 0/986 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a6b13234b84a4ef1ad16585d0200bfa8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Running tokenizer on dataset:   0%|          | 0/247 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "427fadea4057456c830c64ad637fadb9"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"smangrul/assistant_chatbot_dataset\")\n",
        "dataset = dataset[\"train\"].train_test_split(0.2)\n",
        "\n",
        "text_column = \"context\"\n",
        "label_column = \"target\"\n",
        "max_length = 512\n",
        "\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    batch_size = len(examples[text_column])\n",
        "    targets = [str(x) for x in examples[label_column]]\n",
        "    model_inputs = tokenizer(examples[text_column])\n",
        "    labels = tokenizer(text_target=targets, add_special_tokens=False)  # don't add bos token because we concatenate with inputs\n",
        "    for i in range(batch_size):\n",
        "        sample_input_ids = model_inputs[\"input_ids\"][i]\n",
        "        label_input_ids = labels[\"input_ids\"][i] + [tokenizer.eos_token_id]\n",
        "        # print(i, sample_input_ids, label_input_ids)\n",
        "        model_inputs[\"input_ids\"][i] = sample_input_ids + label_input_ids\n",
        "        labels[\"input_ids\"][i] = [-100] * len(sample_input_ids) + label_input_ids\n",
        "        model_inputs[\"attention_mask\"][i] = [1] * len(model_inputs[\"input_ids\"][i])\n",
        "    # print(model_inputs)\n",
        "    for i in range(batch_size):\n",
        "        sample_input_ids = model_inputs[\"input_ids\"][i]\n",
        "        label_input_ids = labels[\"input_ids\"][i]\n",
        "        model_inputs[\"input_ids\"][i] = [tokenizer.pad_token_id] * (\n",
        "            max_length - len(sample_input_ids)\n",
        "        ) + sample_input_ids\n",
        "        model_inputs[\"attention_mask\"][i] = [0] * (max_length - len(sample_input_ids)) + model_inputs[\n",
        "            \"attention_mask\"\n",
        "        ][i]\n",
        "        labels[\"input_ids\"][i] = [-100] * (max_length - len(sample_input_ids)) + label_input_ids\n",
        "        model_inputs[\"input_ids\"][i] = model_inputs[\"input_ids\"][i][:max_length]\n",
        "        model_inputs[\"attention_mask\"][i] = model_inputs[\"attention_mask\"][i][:max_length]\n",
        "        labels[\"input_ids\"][i] = labels[\"input_ids\"][i][:max_length]\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "\n",
        "processed_datasets = dataset.map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        "    num_proc=1,\n",
        "    remove_columns=dataset[\"train\"].column_names,\n",
        "    load_from_cache_file=False,\n",
        "    desc=\"Running tokenizer on dataset\",\n",
        ")\n",
        "\n",
        "train_dataset = processed_datasets[\"train\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset,train_dataset)\n",
        "print(dataset[\"train\"][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjwlMXSVCZCO",
        "outputId": "0f6ff040-1c8c-4e22-d923-ab875debd97d"
      },
      "id": "VjwlMXSVCZCO",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['dialog_id', 'turn_id', 'context', 'target'],\n",
            "        num_rows: 986\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['dialog_id', 'turn_id', 'context', 'target'],\n",
            "        num_rows: 247\n",
            "    })\n",
            "}) Dataset({\n",
            "    features: ['input_ids', 'attention_mask', 'labels'],\n",
            "    num_rows: 986\n",
            "})\n",
            "{'dialog_id': '1_00081', 'turn_id': 9, 'context': '<|begincontext|><|user|>I have a date later and I am looking for a good place to eat.<|system|>What type of cuisine are you in the mood for? Which city will you be going to eat?<|user|>I will be in Berkeley and am in the mood for some Breakfast type of food.<|system|>I found 1 match called the Venus Restaurant in Berkeley.<|user|>Can you give me their address?<|system|>You can find them at 2327 Shattuck Avenue.<|user|>That works out great.<|system|>Would you like to go ahead and make a reservation?<|user|>Yes please. Go ahead and place the reservation.<|system|>What time did you have in mind?<|user|>It is for 1 person at 12:15 in the afternoon.<|system|>You would like to book a table for 1 at 12:15 pm today at the Venus Restaurant in Berkeley. Is that correct?<|user|>Actually I changed my mind, make it at evening 6:45.<|system|>You would like a reservation for 1 at 6:45 pm, is that correct?<|user|>Yes that is what I want. Can I have a contact number?<|system|>I apologize but I was unable to confirm the reservation. You can reach them at 510-540-5950. Should I try a reservation for 1 person today at 7 pm at the Venus Restaurant?<|beginlastuserutterance|>Yes please.<|endlastuserutterance|><|endcontext|>', 'target': '<|begintarget|><|begindsts|><|begindst|><|beginintent|>ReserveRestaurant<|endintent|><|beginbelief|>Restaurants^city->Berkeley|Restaurants^cuisine->Breakfast|Restaurants^date->today|Restaurants^party_size->1|Restaurants^restaurant_name->Venus Restaurant|Restaurants^time->7 pm<|endbelief|><|enddst|><|enddsts|><|beginuseraction|>AFFIRM->Restaurants^~<|enduseraction|><|beginaction|>NOTIFY_SUCCESS->Restaurants^~<|endaction|><|beginresponse|>Your table was successfully booked.<|endresponse|><|endtarget|>'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "3f38888e-4382-415b-869d-7202a816606a",
      "metadata": {
        "id": "3f38888e-4382-415b-869d-7202a816606a"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(\n",
        "    train_dataset, shuffle=True, collate_fn=default_data_collator, batch_size=8, pin_memory=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "53b9e552-4c5d-43e8-a9cd-8073af8d4280",
      "metadata": {
        "id": "53b9e552-4c5d-43e8-a9cd-8073af8d4280",
        "outputId": "4acc52db-5ec3-490d-e133-75fc9dd467cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[256002, 256002, 256002,  ..., 256017, 256001, 256001],\n",
              "         [256002, 256002, 256002,  ..., 256017, 256001, 256001],\n",
              "         [256002, 256002, 256002,  ..., 256017, 256001, 256001],\n",
              "         ...,\n",
              "         [256002, 256002, 256002,  ..., 256017, 256001, 256001],\n",
              "         [256002, 256002, 256002,  ..., 256017, 256001, 256001],\n",
              "         [256002, 256002, 256002,  ..., 256017, 256001, 256001]]),\n",
              " 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
              "         [0, 0, 0,  ..., 1, 1, 1],\n",
              "         [0, 0, 0,  ..., 1, 1, 1],\n",
              "         ...,\n",
              "         [0, 0, 0,  ..., 1, 1, 1],\n",
              "         [0, 0, 0,  ..., 1, 1, 1],\n",
              "         [0, 0, 0,  ..., 1, 1, 1]]),\n",
              " 'labels': tensor([[  -100,   -100,   -100,  ..., 256017, 256001, 256001],\n",
              "         [  -100,   -100,   -100,  ..., 256017, 256001, 256001],\n",
              "         [  -100,   -100,   -100,  ..., 256017, 256001, 256001],\n",
              "         ...,\n",
              "         [  -100,   -100,   -100,  ..., 256017, 256001, 256001],\n",
              "         [  -100,   -100,   -100,  ..., 256017, 256001, 256001],\n",
              "         [  -100,   -100,   -100,  ..., 256017, 256001, 256001]])}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "next(iter(train_dataloader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "7de31ee2-185e-4658-9ad1-ae5f6bc3a611",
      "metadata": {
        "id": "7de31ee2-185e-4658-9ad1-ae5f6bc3a611",
        "outputId": "f5d937c7-5fd0-4b22-c1fb-2d9ac1d1eb9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|startoftext|><|begincontext|><|user|>I have a date later and I am looking for a good place to eat.<|system|>What type of cuisine are you in the mood for? Which city will you be going to eat?<|user|>I will be in Berkeley and am in the mood for some Breakfast type of food.<|system|>I found 1 match called the Venus Restaurant in Berkeley.<|user|>Can you give me their address?<|system|>You can find them at 2327 Shattuck Avenue.<|user|>That works out great.<|system|>Would you like to go ahead and make a reservation?<|user|>Yes please. Go ahead and place the reservation.<|system|>What time did you have in mind?<|user|>It is for 1 person at 12:15 in the afternoon.<|system|>You would like to book a table for 1 at 12:15 pm today at the Venus Restaurant in Berkeley. Is that correct?<|user|>Actually I changed my mind, make it at evening 6:45.<|system|>You would like a reservation for 1 at 6:45 pm, is that correct?<|user|>Yes that is what I want. Can I have a contact number?<|system|>I apologize but I was unable to confirm the reservation. You can reach them at 510-540-5950. Should I try a reservation for 1 person today at 7 pm at the Venus Restaurant?<|beginlastuserutterance|>Yes please.<|endlastuserutterance|><|endcontext|><|begintarget|><|begindsts|><|begindst|><|beginintent|>ReserveRestaurant<|endintent|><|beginbelief|>Restaurants^city->Berkeley|Restaurants^cuisine->Breakfast|Restaurants^date->today|Restaurants^party_size->1|Restaurants^restaurant_name->Venus Restaurant|Restaurants^time->7 pm<|endbelief|><|enddst|><|enddsts|><|beginuseraction|>AFFIRM->Restaurants^~<|enduseraction|><|beginaction|>NOTIFY_SUCCESS->Restaurants^~<|endaction|><|beginresponse|>Your table was successfully booked.<|endresponse|><|endtarget|><|endtarget|>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "tokenizer.decode(train_dataset[0][\"input_ids\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "239d1c83-196d-471e-9bf7-5f36dafa9894",
      "metadata": {
        "id": "239d1c83-196d-471e-9bf7-5f36dafa9894"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "ec80d6ee",
      "metadata": {
        "id": "ec80d6ee",
        "outputId": "ea27c6b8-0fea-4cb0-c78f-6a87fce6e0c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240403_093510-ra9f217n</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/weege007/PeftExamples/runs/ra9f217n/workspace' target=\"_blank\">lively-dust-2</a></strong> to <a href='https://wandb.ai/weege007/PeftExamples' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/weege007/PeftExamples' target=\"_blank\">https://wandb.ai/weege007/PeftExamples</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/weege007/PeftExamples/runs/ra9f217n/workspace' target=\"_blank\">https://wandb.ai/weege007/PeftExamples/runs/ra9f217n/workspace</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='246' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  3/246 06:23 < 25:51:15, 0.00 it/s, Epoch 0.02/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-c7cd29932742>\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m )\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# model.config.use_cache = False\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1613\u001b[0m                 \u001b[0;31m# Disable progress bars when uploading models during checkpoints to avoid polluting stdout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1614\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1615\u001b[0;31m                 return inner_training_loop(\n\u001b[0m\u001b[1;32m   1616\u001b[0m                     \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1617\u001b[0m                     \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1961\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1962\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m                 if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2902\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2904\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2923\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2924\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2925\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2926\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2927\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_peft_forward_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial_peft_forward_args\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_base_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"sft_peft_lora_gemma_2b_with_added_tokens\",\n",
        "    num_train_epochs=2,\n",
        "    save_total_limit=5,\n",
        "    per_device_train_batch_size=8,\n",
        "    warmup_steps=10,\n",
        "    weight_decay=0.0001,\n",
        "    dataloader_drop_last=True,\n",
        "    #bf16=True,\n",
        "    bf16=False,\n",
        "    logging_steps=10,\n",
        "    learning_rate=1e-5,\n",
        "    gradient_checkpointing=True,\n",
        "    gradient_checkpointing_kwargs={\"use_reentrant\": False},\n",
        "    remove_unused_columns=False,\n",
        "    hub_model_id=\"smangrul/mistral_lora_clm_with_added_tokens\",\n",
        "    push_to_hub=True,\n",
        "    hub_private_repo=True,\n",
        ")\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    data_collator=default_data_collator,\n",
        ")\n",
        "# model.config.use_cache = False\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bc1cbed-4eb9-4aaa-ab5f-5b91bf432307",
      "metadata": {
        "id": "7bc1cbed-4eb9-4aaa-ab5f-5b91bf432307"
      },
      "source": [
        "# 在评估数据集的样本上检查模型输出"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71851793",
      "metadata": {
        "id": "71851793",
        "outputId": "58660733-94fb-496f-99c8-7edc11716807"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "context=\"<|begincontext|><|user|>Can you find me a place to eat please?<|system|>Where at? And what kind of cuisine are you craving?<|user|>Somewhere in SF, and I am really craving Thai food at the moment!<|system|>I found a bunch of restaurants, there's actually 10 that you might like in San Francisco, one of them being Baan Thai House & Wine Bar<|user|>How can I reach them? And what's their address?<|system|>You can reach them by phone at 415-379-4505 and visit them at 534 Irving Street<|beginlastuserutterance|>Great, that restaurant sounds good<|endlastuserutterance|><|endcontext|>\" \n",
            "\n",
            " target_predicted='<|begintarget|><|begindsts|><|begindst|><|beginintent|> FindRestaurants<|endintent|><|beginbelief|> Restaurants^city->SF~San Francisco|Restaurants^cuisine->Thai|Restaurants^restaurant_name->Baan Thai House & Wine Bar<|endbelief|><|enddst|><|enddsts|><|beginuseraction|> REQUEST->Restaurants^phone_number~|REQUEST->Restaurants^street_address~<|enduseraction|><|beginaction|> INFORM->Restaurants^phone_number~415-379-4505|INFORM->Restaurants^street_address~534 Irving Street<|endaction|><|beginresponse|> Great, the phone number is 415-379-4505 and the address is 534 Irving Street<|endresponse|><|endtarget|>' \n",
            "\n",
            " target='<|begintarget|><|begindsts|><|begindst|><|beginintent|>FindRestaurants<|endintent|><|beginbelief|>Restaurants^city->SF~San Francisco|Restaurants^cuisine->Thai|Restaurants^restaurant_name->Baan Thai House & Wine Bar<|endbelief|><|enddst|><|enddsts|><|beginuseraction|>SELECT->Restaurants^~<|enduseraction|><|beginaction|>OFFER_INTENT->Restaurants^intent~ReserveRestaurant<|endaction|><|beginresponse|>Want me to book a table?<|endresponse|><|endtarget|>'\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "i = random.randint(0, len(dataset[\"test\"]))\n",
        "context = dataset[\"test\"][i][\"context\"]\n",
        "\n",
        "batch = tokenizer(context, return_tensors=\"pt\")\n",
        "batch = {k: v.to(device) for k, v in batch.items()}\n",
        "model.eval()\n",
        "output_tokens = model.generate(\n",
        "    **batch,\n",
        "    max_new_tokens=256,\n",
        "    do_sample=True,\n",
        "    temperature=0.2,\n",
        "    top_p=0.95,\n",
        "    top_k=50,\n",
        "    eos_token_id=tokenizer.eos_token_id,\n",
        "    pad_token_id=tokenizer.pad_token_id,\n",
        ")\n",
        "target_predicted = tokenizer.decode(output_tokens[0], skip_special_tokens=False).split(\"<|endcontext|>\")[1]\n",
        "target = dataset[\"test\"][i][\"target\"]\n",
        "print(f\"{context=} \\n\\n {target_predicted=} \\n\\n {target=}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f940a660-2f7c-4a3a-b412-3f037aedb890",
      "metadata": {
        "id": "f940a660-2f7c-4a3a-b412-3f037aedb890"
      },
      "source": [
        "# 保存适配器模型"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ebe05e9-9b93-42f6-bba8-46b8cc3d100f",
      "metadata": {
        "id": "7ebe05e9-9b93-42f6-bba8-46b8cc3d100f"
      },
      "source": [
        "当lora层应用于嵌入层时，相应的基础模型嵌入层也会被保存。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d7459ba-caa8-4f10-aa70-89be4541cbdf",
      "metadata": {
        "id": "3d7459ba-caa8-4f10-aa70-89be4541cbdf"
      },
      "outputs": [],
      "source": [
        "trainer.push_to_hub()\n",
        "trainer.model.push_to_hub(training_args.output_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66812cc4-f9a3-46c4-bcee-0cba03950685",
      "metadata": {
        "id": "66812cc4-f9a3-46c4-bcee-0cba03950685"
      },
      "source": [
        "# 检查模型是否按预期加载并生成合理的输出"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "589c46d7-d567-40b4-ab7d-e0a9e1cab40e",
      "metadata": {
        "id": "589c46d7-d567-40b4-ab7d-e0a9e1cab40e",
        "outputId": "7d8f3323-de78-45ef-b22e-558cbb708d9b",
        "colab": {
          "referenced_widgets": [
            "f98524da95b64a29a9016c6067313b2b",
            "aaae3bc0f52f45bbaab60687b71fc4cf",
            "1fc5754f41784d1aba00b93551894579"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f98524da95b64a29a9016c6067313b2b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aaae3bc0f52f45bbaab60687b71fc4cf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "adapter_config.json:   0%|          | 0.00/637 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1fc5754f41784d1aba00b93551894579",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "adapter_model.safetensors:   0%|          | 0.00/1.18G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "context=\"<|begincontext|><|user|>Can you find me a place to eat please?<|system|>Where at? And what kind of cuisine are you craving?<|user|>Somewhere in SF, and I am really craving Thai food at the moment!<|system|>I found a bunch of restaurants, there's actually 10 that you might like in San Francisco, one of them being Baan Thai House & Wine Bar<|user|>How can I reach them? And what's their address?<|system|>You can reach them by phone at 415-379-4505 and visit them at 534 Irving Street<|beginlastuserutterance|>Great, that restaurant sounds good<|endlastuserutterance|><|endcontext|>\" \n",
            "\n",
            " target_predicted='<|begintarget|><|begindsts|><|begindst|><|beginintent|> FindRestaurant<|endintent|><|beginbelief|> Restaurants^city->SF~San Francisco|Restaurants^cuisine->Thai|Restaurants^restaurant_name->Baan Thai House & Wine Bar<|endbelief|><|enddst|><|enddsts|><|beginuseraction|> REQUEST->Restaurants^phone_number~|REQUEST->Restaurants^street_address~<|enduseraction|><|beginaction|> INFORM->Restaurants^phone_number~415-379-4505|INFORM->Restaurants^street_address~534 Irving Street<|endaction|><|beginresponse|> The phone number is 415-379-4505 and the address is 534 Irving Street<|endresponse|><|endtarget|>' \n",
            "\n",
            " target='<|begintarget|><|begindsts|><|begindst|><|beginintent|>FindRestaurants<|endintent|><|beginbelief|>Restaurants^city->SF~San Francisco|Restaurants^cuisine->Thai|Restaurants^restaurant_name->Baan Thai House & Wine Bar<|endbelief|><|enddst|><|enddsts|><|beginuseraction|>SELECT->Restaurants^~<|enduseraction|><|beginaction|>OFFER_INTENT->Restaurants^intent~ReserveRestaurant<|endaction|><|beginresponse|>Want me to book a table?<|endresponse|><|endtarget|>'\n"
          ]
        }
      ],
      "source": [
        "from peft import PeftModel\n",
        "\n",
        "inference_model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    low_cpu_mem_usage=True,\n",
        "    # use_flash_attention_2=True,\n",
        ")\n",
        "inference_model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "inference_model = PeftModel.from_pretrained(inference_model, \"weege007/sft_peft_lora_gemma_2b_with_added_tokens\")\n",
        "inference_model.to(device)\n",
        "inference_model.eval()\n",
        "\n",
        "output_tokens = inference_model.generate(\n",
        "    **batch,\n",
        "    max_new_tokens=256,\n",
        "    do_sample=True,\n",
        "    temperature=0.2,\n",
        "    top_p=0.95,\n",
        "    top_k=50,\n",
        "    eos_token_id=tokenizer.eos_token_id,\n",
        "    pad_token_id=tokenizer.pad_token_id,\n",
        ")\n",
        "\n",
        "target_predicted = tokenizer.decode(output_tokens[0], skip_special_tokens=False).split(\"<|endcontext|>\")[1]\n",
        "print(f\"{context=} \\n\\n {target_predicted=} \\n\\n {target=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd57f6e8-761f-4e0b-941c-f6973e13b186",
      "metadata": {
        "id": "fd57f6e8-761f-4e0b-941c-f6973e13b186"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 使用llama.cpp 测试下 gguf 支持\n",
        "\n",
        "需要把新的 tokenizer.json tokenizer.model 格式化到 gguf中"
      ],
      "metadata": {
        "id": "qjJ2-FaqVHi2"
      },
      "id": "qjJ2-FaqVHi2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 使用 gemma.cpp 测试下\n",
        "\n",
        "gemma.cpp 模型权重和分词器加载"
      ],
      "metadata": {
        "id": "Aqiq1JpAxuDA"
      },
      "id": "Aqiq1JpAxuDA"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "afcc07fa4ddb4b788d47a5b35da7fecb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5bc4eb089b9947d78835fd32423fea23",
              "IPY_MODEL_fa8b4cb96b0841b7ba8de13fb1c64ac1",
              "IPY_MODEL_fc7e3421e9a04153832af2ca70a38be7"
            ],
            "layout": "IPY_MODEL_f189cc170f004decb79fc4afc5cfac4d"
          }
        },
        "5bc4eb089b9947d78835fd32423fea23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_478b06815ce645bc9b7171651bae1281",
            "placeholder": "​",
            "style": "IPY_MODEL_dacdf665e77b49c685720f5e6093e7f3",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "fa8b4cb96b0841b7ba8de13fb1c64ac1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a3ecd68abe640caa542809e63c03564",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3f571e511bc842cca5c0248edf2ce60a",
            "value": 2
          }
        },
        "fc7e3421e9a04153832af2ca70a38be7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f65d27ab85fb499eb740688b61e9b8e5",
            "placeholder": "​",
            "style": "IPY_MODEL_7a22a430ea0c411ba642fa2b572c00f5",
            "value": " 2/2 [00:14&lt;00:00,  6.04s/it]"
          }
        },
        "f189cc170f004decb79fc4afc5cfac4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "478b06815ce645bc9b7171651bae1281": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dacdf665e77b49c685720f5e6093e7f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a3ecd68abe640caa542809e63c03564": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f571e511bc842cca5c0248edf2ce60a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f65d27ab85fb499eb740688b61e9b8e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a22a430ea0c411ba642fa2b572c00f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6b13234b84a4ef1ad16585d0200bfa8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d18f1dffab624866b32fa4ff2421d6d6",
              "IPY_MODEL_611640227b4341079c44c7403ac02c7f",
              "IPY_MODEL_024db3ab7fdd49fea529003ad1674386"
            ],
            "layout": "IPY_MODEL_a26535c17ef347c996914430d9613034"
          }
        },
        "d18f1dffab624866b32fa4ff2421d6d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bda2f747d6e04c139277477f2f2c6d98",
            "placeholder": "​",
            "style": "IPY_MODEL_3057c01eeb3f420481cb36f51ba09e61",
            "value": "Running tokenizer on dataset: 100%"
          }
        },
        "611640227b4341079c44c7403ac02c7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b6e1d7fa07e432592aef14e5ce00181",
            "max": 986,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dc3ee27d9984446aa0ff744e94686e5a",
            "value": 986
          }
        },
        "024db3ab7fdd49fea529003ad1674386": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_beec1aae84074a5faccfcca22d53eb17",
            "placeholder": "​",
            "style": "IPY_MODEL_cd1d31ae00df470ca72f1ef54486a187",
            "value": " 986/986 [00:00&lt;00:00, 2268.09 examples/s]"
          }
        },
        "a26535c17ef347c996914430d9613034": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bda2f747d6e04c139277477f2f2c6d98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3057c01eeb3f420481cb36f51ba09e61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b6e1d7fa07e432592aef14e5ce00181": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc3ee27d9984446aa0ff744e94686e5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "beec1aae84074a5faccfcca22d53eb17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd1d31ae00df470ca72f1ef54486a187": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "427fadea4057456c830c64ad637fadb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_87266692e5a24b18bb7ca2ba9db799d7",
              "IPY_MODEL_507f6c6a2be64f44bc8bacb43e32cb56",
              "IPY_MODEL_5c157c909f8142f181c857c5027f7f0c"
            ],
            "layout": "IPY_MODEL_46abc1ff1b614683b9705a472a354561"
          }
        },
        "87266692e5a24b18bb7ca2ba9db799d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fcfbfc20d34f472a95598b532991988a",
            "placeholder": "​",
            "style": "IPY_MODEL_f4ddca50db844ccb99e627f16dbb5207",
            "value": "Running tokenizer on dataset: 100%"
          }
        },
        "507f6c6a2be64f44bc8bacb43e32cb56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_789c6bef74d046f9a11bede2340a1e80",
            "max": 247,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5bb018febbab4d74a409a1c7da15f1d0",
            "value": 247
          }
        },
        "5c157c909f8142f181c857c5027f7f0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_843f294e02cc40f09eddce4f020752c3",
            "placeholder": "​",
            "style": "IPY_MODEL_3123c65b9e7a4b539c8e0a29de4885ba",
            "value": " 247/247 [00:00&lt;00:00, 1907.34 examples/s]"
          }
        },
        "46abc1ff1b614683b9705a472a354561": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcfbfc20d34f472a95598b532991988a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4ddca50db844ccb99e627f16dbb5207": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "789c6bef74d046f9a11bede2340a1e80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bb018febbab4d74a409a1c7da15f1d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "843f294e02cc40f09eddce4f020752c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3123c65b9e7a4b539c8e0a29de4885ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}