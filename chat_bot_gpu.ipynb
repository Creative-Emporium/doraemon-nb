{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyOWnt68FgL4QGhogexOyMJe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weedge/doraemon-nb/blob/main/chat_bot_gpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version\n"
      ],
      "metadata": {
        "id": "AF3w7_cxZGwD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content"
      ],
      "metadata": {
        "id": "aTHYo9EhzGkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfmcAQMns6aV"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/weedge/chat-bot.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/chat-bot"
      ],
      "metadata": {
        "id": "5a1qIXxQdJvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "id": "DyoccO88zO6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git checkout ."
      ],
      "metadata": {
        "id": "NeaEO_jZSOrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git checkout fix/stream"
      ],
      "metadata": {
        "id": "pmU-SU7t7vgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### install dependencies"
      ],
      "metadata": {
        "id": "jMvKdwJHlvhS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip"
      ],
      "metadata": {
        "id": "FwKwMQL9RNE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install python3-pyaudio && pip -q install pyannote.audio"
      ],
      "metadata": {
        "id": "PNTGOdhEkXDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pyaudio pydub redis"
      ],
      "metadata": {
        "id": "cGEdDL-QhXLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# asr whisper\n",
        "!pip install -q openai-whisper whisper-timestamped faster-whisper"
      ],
      "metadata": {
        "id": "dbujgZGJlJwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "id": "20XKp7O6ayTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# llamacpp https://github.com/abetlen/llama-cpp-python?tab=readme-ov-file#installation\n",
        "# cpu\n",
        "#!pip install llama-cpp-python\n",
        "#!pip install llama-cpp-python --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cpu\n",
        "#!CMAKE_ARGS=\"-DLLAMA_BLAS=ON -DLLAMA_BLAS_VENDOR=OpenBLAS\" pip install llama-cpp-python\n",
        "\n",
        "# gpu\n",
        "#!CMAKE_ARGS=\"-DLLAMA_CUDA=on\" pip install llama-cpp-python\n",
        "!pip uninstall llama-cpp-python\n",
        "!pip install llama-cpp-python \\\n",
        "  --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu122"
      ],
      "metadata": {
        "id": "7wKEoTuwRZiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!# ChatTTS\n",
        "!git submodule update --init --recursive\n",
        "!pip install -q vocos\n",
        "!pip install vector_quantize_pytorch"
      ],
      "metadata": {
        "id": "tHi3wGoeVwtT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CoquiTTS\n",
        "#!pip uninstall TTS\n",
        "!pip install coqui-tts\n"
      ],
      "metadata": {
        "id": "vRxSM036dUuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.25.0"
      ],
      "metadata": {
        "id": "ibm0av4Sd2Lr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list | grep torch"
      ],
      "metadata": {
        "id": "ybwIxsrknMlO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate optimum"
      ],
      "metadata": {
        "id": "iQz0z4yTg9JF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show omegaconf einops IPython ctranslate2 numpy TTS transformers accelerate optimum llama-cpp-python coqui-tts"
      ],
      "metadata": {
        "id": "UXUdeKJPtvV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### download models"
      ],
      "metadata": {
        "id": "HkXuo0PSlriI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# asr openai whisper pt\n",
        "!wget https://openaipublic.azureedge.net/main/whisper/models/65147644a518d12f04e32d6f3b26facc3f8dd46e5390956a9424a650c0ce22b9/tiny.pt -O ./models/tiny.pt\n",
        "!wget https://openaipublic.azureedge.net/main/whisper/models/ed3a0b6b1c0edf879ad9b11b1af5a0e6ab5db9205f891f668f8b0e6c6326e34e/base.pt -O ./models/base.pt\n",
        "!wget https://openaipublic.azureedge.net/main/whisper/models/9ecf779972d90ba49c06d968637d720dd632c55bbf19d441fb42bf17a411e794/small.pt -O ./models/small.pt\n",
        "!wget https://openaipublic.azureedge.net/main/whisper/models/345ae4da62f9b3d59415adc60127b97c714f32e89e936602e85993674d08dcb1/medium.pt -O ./models/medium.pt\n",
        "!wget https://openaipublic.azureedge.net/main/whisper/models/e4b87e7e0bf463eb8e6956e646f1e277e901512310def2c24bf0e11bd3c28e9a/large-v1.pt -O ./models/large-v1.pt\n",
        "!wget https://openaipublic.azureedge.net/main/whisper/models/81f7c96c852ee8fc832187b0132e569d6c3065a3252ed18e56effd0b6a73e524/large-v2.pt -O ./models/large-v2.pt\n",
        "!wget https://openaipublic.azureedge.net/main/whisper/models/e5b1a55b89c1367dacf97e3e19bfd829a01529dbfdeefa8caeb59b3f1b81dadb/large-v3.pt -O ./models/large-v3.pt\n"
      ],
      "metadata": {
        "id": "3ZrfUOTGi6_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# asr hf openai whisper\n",
        "!huggingface-cli download openai/whisper-base  --local-dir ./models/openai/whisper-base --local-dir-use-symlinks False\n",
        "# faster-whisper\n",
        "!huggingface-cli download Systran/faster-whisper-tiny  --local-dir ./models/Systran/faster-whisper-tiny --local-dir-use-symlinks False\n",
        "!huggingface-cli download Systran/faster-whisper-base  --local-dir ./models/Systran/faster-whisper-base --local-dir-use-symlinks False\n",
        "!huggingface-cli download Systran/faster-whisper-small  --local-dir ./models/Systran/faster-whisper-small --local-dir-use-symlinks False\n",
        "!huggingface-cli download Systran/faster-whisper-medium  --local-dir ./models/Systran/faster-whisper-medium --local-dir-use-symlinks False\n",
        "!huggingface-cli download Systran/faster-whisper-large-v1  --local-dir ./models/Systran/faster-whisper-large-v1 --local-dir-use-symlinks False\n",
        "!huggingface-cli download Systran/faster-whisper-large-v2  --local-dir ./models/Systran/faster-whisper-large-v2 --local-dir-use-symlinks False\n",
        "!huggingface-cli download Systran/faster-whisper-large-v3  --local-dir ./models/Systran/faster-whisper-large-v3 --local-dir-use-symlinks False\n",
        "!huggingface-cli download Systran/faster-distil-whisper-large-v2  --local-dir ./models/Systran/faster-distil-whisper-large-v2 --local-dir-use-symlinks False\n",
        "!huggingface-cli download Systran/faster-distil-whisper-large-v3  --local-dir ./models/Systran/faster-distil-whisper-large-v3 --local-dir-use-symlinks False"
      ],
      "metadata": {
        "id": "sUBGxsNH9Y1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -f ./models/qwen2-57b-a14b-instruct-*"
      ],
      "metadata": {
        "id": "-I6wRCQ-jy31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# llm llamacpp phi-3-mini-4k-instruct\n",
        "!huggingface-cli download microsoft/Phi-3-mini-4k-instruct-gguf Phi-3-mini-4k-instruct-q4.gguf --local-dir ./models --local-dir-use-symlinks False\n",
        "# llm llamacpp Qwen1.5-chat\n",
        "!huggingface-cli download Qwen/Qwen1.5-7B-Chat-GGUF qwen1_5-7b-chat-q8_0.gguf  --local-dir ./models --local-dir-use-symlinks False\n",
        "!huggingface-cli download Qwen/Qwen1.5-14B-Chat-GGUF qwen1_5-14b-chat-q8_0.gguf  --local-dir ./models --local-dir-use-symlinks False\n",
        "# llm llamacpp Qwen2-Instruct\n",
        "!huggingface-cli download Qwen/Qwen2-1.5B-Instruct-GGUF qwen2-1_5b-instruct-q8_0.gguf  --local-dir ./models --local-dir-use-symlinks False\n",
        "!huggingface-cli download Qwen/Qwen2-1.5B-Instruct-GGUF qwen2-1_5b-instruct-fp16.gguf  --local-dir ./models --local-dir-use-symlinks False\n",
        "!huggingface-cli download Qwen/Qwen2-7B-Instruct-GGUF qwen2-7b-instruct-q8_0.gguf  --local-dir ./models --local-dir-use-symlinks False\n",
        "!huggingface-cli download Qwen/Qwen2-7B-Instruct-GGUF qwen2-7b-instruct-fp16.gguf  --local-dir ./models --local-dir-use-symlinks False\n",
        "#!huggingface-cli download Qwen/Qwen2-57B-A14B-Instruct-GGUF qwen2-57b-a14b-instruct-q3_k_m.gguf  --local-dir ./models --local-dir-use-symlinks False\n",
        "#!huggingface-cli download Qwen/Qwen2-57B-A14B-Instruct-GGUF --include qwen2-57b-a14b-instruct-q8_0-*.gguf  --local-dir ./models --local-dir-use-symlinks False\n",
        "\n",
        "\n",
        "# llm chatglmcpp chatGLM"
      ],
      "metadata": {
        "id": "ELUVP0Gx9qAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#/content/llamacpp/llama-gguf-split --merge qwen2-57b-a14b-instruct-q8_0-00001-of-00002.gguf qwen2-57b-a14b-instruct-q8_0.gguf"
      ],
      "metadata": {
        "id": "awkt1LIzP4bj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tts chatTTS\n",
        "!huggingface-cli download 2Noise/ChatTTS  --local-dir ./models/2Noise/ChatTTS --local-dir-use-symlinks False"
      ],
      "metadata": {
        "id": "dIf4oBlZmH9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tts coquiTTS\n",
        "!huggingface-cli download coqui/XTTS-v2  --local-dir ./models/coqui/XTTS-v2 --local-dir-use-symlinks False"
      ],
      "metadata": {
        "id": "Xgw6Xbu_dIY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### test\n"
      ],
      "metadata": {
        "id": "GZoE-J3rWNKc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ASR"
      ],
      "metadata": {
        "id": "OHREfyc4pDRz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ASR_TAG=whisper_asr MODEL_NAME_OR_PATH=tiny \\\n",
        "  python -m unittest test.modules.speech.asr.test_whisper_asr.TestWhisperASR.test_transcribe\n",
        "\n",
        "!ASR_TAG=whisper_asr MODEL_NAME_OR_PATH=base \\\n",
        "  python -m unittest test.modules.speech.asr.test_whisper_asr.TestWhisperASR.test_transcribe\n",
        "\n",
        "!ASR_TAG=whisper_asr MODEL_NAME_OR_PATH=small \\\n",
        "  python -m unittest test.modules.speech.asr.test_whisper_asr.TestWhisperASR.test_transcribe\n",
        "\n",
        "!ASR_TAG=whisper_asr MODEL_NAME_OR_PATH=medium \\\n",
        "  python -m unittest test.modules.speech.asr.test_whisper_asr.TestWhisperASR.test_transcribe\n",
        "\n",
        "!ASR_TAG=whisper_asr MODEL_NAME_OR_PATH=large-v1 \\\n",
        "  python -m unittest test.modules.speech.asr.test_whisper_asr.TestWhisperASR.test_transcribe\n",
        "\n",
        "!ASR_TAG=whisper_asr MODEL_NAME_OR_PATH=large-v2 \\\n",
        "  python -m unittest test.modules.speech.asr.test_whisper_asr.TestWhisperASR.test_transcribe\n",
        "\n",
        "!ASR_TAG=whisper_asr MODEL_NAME_OR_PATH=large-v3 \\\n",
        "  python -m unittest test.modules.speech.asr.test_whisper_asr.TestWhisperASR.test_transcribe\n"
      ],
      "metadata": {
        "id": "pUzTTh5Ih1aU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ASR_TAG=whisper_transformers_asr MODEL_NAME_OR_PATH=./models/openai/whisper-base \\\n",
        "  python -m unittest test.modules.speech.asr.test_whisper_asr.TestWhisperASR.test_transcribe"
      ],
      "metadata": {
        "id": "8lIDdVPcWT6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!MODEL_NAME_OR_PATH=./models/Systran/faster-whisper-tiny ASR_VERBOSE=False ASR_TAG=whisper_faster_asr \\\n",
        "  python -m unittest test.modules.speech.asr.test_whisper_asr.TestWhisperASR.test_transcribe\n",
        "\n",
        "!MODEL_NAME_OR_PATH=./models/Systran/faster-whisper-base ASR_VERBOSE=False ASR_TAG=whisper_faster_asr \\\n",
        "  python -m unittest test.modules.speech.asr.test_whisper_asr.TestWhisperASR.test_transcribe\n",
        "\n",
        "!MODEL_NAME_OR_PATH=./models/Systran/faster-whisper-small ASR_VERBOSE=False ASR_TAG=whisper_faster_asr \\\n",
        "  python -m unittest test.modules.speech.asr.test_whisper_asr.TestWhisperASR.test_transcribe\n",
        "\n",
        "!MODEL_NAME_OR_PATH=./models/Systran/faster-whisper-medium ASR_VERBOSE=False ASR_TAG=whisper_faster_asr \\\n",
        "  python -m unittest test.modules.speech.asr.test_whisper_asr.TestWhisperASR.test_transcribe\n",
        "\n",
        "!MODEL_NAME_OR_PATH=./models/Systran/faster-whisper-large-v1 ASR_VERBOSE=False ASR_TAG=whisper_faster_asr \\\n",
        "  python -m unittest test.modules.speech.asr.test_whisper_asr.TestWhisperASR.test_transcribe\n",
        "\n",
        "!MODEL_NAME_OR_PATH=./models/Systran/faster-whisper-large-v2 ASR_VERBOSE=False ASR_TAG=whisper_faster_asr \\\n",
        "  python -m unittest test.modules.speech.asr.test_whisper_asr.TestWhisperASR.test_transcribe\n",
        "\n",
        "!MODEL_NAME_OR_PATH=./models/Systran/faster-whisper-large-v3 ASR_VERBOSE=False ASR_TAG=whisper_faster_asr \\\n",
        "  python -m unittest test.modules.speech.asr.test_whisper_asr.TestWhisperASR.test_transcribe"
      ],
      "metadata": {
        "id": "aS_6JzlKcHFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### llm"
      ],
      "metadata": {
        "id": "5WvK58CTSqzD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!MODEL_TYPE=generate  python -m unittest test.core.llm.test_llamacpp.TestLLamacppLLM.test_generate"
      ],
      "metadata": {
        "id": "MzHPvCgDSqRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!MODEL_TYPE=generate N_GPU_LAYERS=29 FLASH_ATTN=1 python -m unittest test.core.llm.test_llamacpp.TestLLamacppLLM.test_generate"
      ],
      "metadata": {
        "id": "bNnKlnf3TvuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!MODEL_TYPE=generate N_GPU_LAYERS=33 FLASH_ATTN=1 \\\n",
        "  MODEL_PATH=./models/qwen1_5-7b-chat-q8_0.gguf \\\n",
        "  python -m unittest test.core.llm.test_llamacpp.TestLLamacppLLM.test_generate"
      ],
      "metadata": {
        "id": "aN6jKobNmHkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!MODEL_TYPE=generate N_GPU_LAYERS=33 FLASH_ATTN=1 \\\n",
        "  MODEL_PATH=./models/qwen1_5-14b-chat-q8_0.gguf \\\n",
        "  python -m unittest test.core.llm.test_llamacpp.TestLLamacppLLM.test_generate"
      ],
      "metadata": {
        "id": "AndKovj4mqnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!MODEL_TYPE=generate N_GPU_LAYERS=29 FLASH_ATTN=1 \\\n",
        "  MODEL_PATH=./models/qwen2-1_5b-instruct-fp16.gguf \\\n",
        "  python -m unittest test.core.llm.test_llamacpp.TestLLamacppLLM.test_generate"
      ],
      "metadata": {
        "id": "uLUnbvLWcFwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!MODEL_TYPE=generate \\\n",
        "  MODEL_PATH=./models/qwen2-7b-instruct-q8_0.gguf \\\n",
        "  python -m unittest test.core.llm.test_llamacpp.TestLLamacppLLM.test_generate"
      ],
      "metadata": {
        "id": "3sc6CoSNUw0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!MODEL_TYPE=generate \\\n",
        "  MODEL_PATH=./models/qwen2-7b-instruct-fp16.gguf \\\n",
        "  python -m unittest test.core.llm.test_llamacpp.TestLLamacppLLM.test_generate"
      ],
      "metadata": {
        "id": "sTDeOkPIX0Ap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!MODEL_TYPE=generate \\\n",
        "  MODEL_PATH=./models/qwen2-7b-instruct-fp16.gguf \\\n",
        "  python -m unittest test.core.llm.test_llamacpp.TestLLamacppLLM.test_generate\n"
      ],
      "metadata": {
        "id": "pQtYFLcMWt4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### run chat bot BE"
      ],
      "metadata": {
        "id": "b2IgjS7bmDzV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "redis_pwd = userdata.get('REDIS_PASSWORD')"
      ],
      "metadata": {
        "id": "NIzdOsCZfmQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p log"
      ],
      "metadata": {
        "id": "T2dP-UcWgCT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!REDIS_PASSWORD=$redis_pwd RUN_OP=be TQDM_DISABLE=True python -m src.cmd.remote-queue-chat.generate_audio2audio > ./log/be_std_out.log"
      ],
      "metadata": {
        "id": "Ei6CpMWhdhAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ASR_TAG=whisper_faster_asr \\\n",
        "  ASR_MODEL_NAME_OR_PATH=./models/Systran/faster-whisper-base \\\n",
        "  REDIS_PASSWORD=$redis_pwd \\\n",
        "  RUN_OP=be \\\n",
        "  TQDM_DISABLE=True \\\n",
        "  python -m src.cmd.remote-queue-chat.generate_audio2audio > ./log/be_std_out.log"
      ],
      "metadata": {
        "id": "-ReK0i0OZy7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ASR_TAG=whisper_faster_asr \\\n",
        "  ASR_MODEL_NAME_OR_PATH=./models/Systran/faster-whisper-base \\\n",
        "  REDIS_PASSWORD=$redis_pwd \\\n",
        "  RUN_OP=be \\\n",
        "  TQDM_DISABLE=True \\\n",
        "  TTS_TAG=tts_coqui \\\n",
        "  N_GPU_LAYERS=33 FLASH_ATTN=1 \\\n",
        "  LLM_MODEL_NAME=qwen \\\n",
        "  LLM_MODEL_PATH=./models/qwen1_5-7b-chat-q8_0.gguf \\\n",
        "  python -m src.cmd.remote-queue-chat.generate_audio2audio > ./log/be_std_out.log"
      ],
      "metadata": {
        "id": "L257V1Zmld04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ASR_TAG=whisper_faster_asr \\\n",
        "  ASR_MODEL_NAME_OR_PATH=./models/Systran/faster-whisper-base \\\n",
        "  REDIS_PASSWORD=$redis_pwd \\\n",
        "  RUN_OP=be \\\n",
        "  TQDM_DISABLE=True \\\n",
        "  TTS_TAG=tts_coqui TTS_STREAM=1 \\\n",
        "  N_GPU_LAYERS=33 FLASH_ATTN=1 \\\n",
        "  LLM_MODEL_NAME=qwen \\\n",
        "  LLM_MODEL_PATH=./models/qwen1_5-7b-chat-q8_0.gguf \\\n",
        "  python -m src.cmd.remote-queue-chat.generate_audio2audio > ./log/be_std_out.log"
      ],
      "metadata": {
        "id": "CBbtEC-robGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ASR_TAG=whisper_faster_asr \\\n",
        "  ASR_MODEL_NAME_OR_PATH=./models/Systran/faster-whisper-base \\\n",
        "  REDIS_PASSWORD=$redis_pwd \\\n",
        "  RUN_OP=be \\\n",
        "  TQDM_DISABLE=True \\\n",
        "  TTS_TAG=tts_coqui \\\n",
        "  N_GPU_LAYERS=33 FLASH_ATTN=1 \\\n",
        "  LLM_MODEL_NAME=qwen \\\n",
        "  LLM_MODEL_PATH=./models/qwen1_5-14b-chat-q8_0.gguf \\\n",
        "  python -m src.cmd.remote-queue-chat.generate_audio2audio > ./log/be_std_out.log"
      ],
      "metadata": {
        "id": "J535-FVImimq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ASR_TAG=whisper_faster_asr \\\n",
        "  ASR_MODEL_NAME_OR_PATH=./models/Systran/faster-whisper-base \\\n",
        "  REDIS_PASSWORD=$redis_pwd \\\n",
        "  RUN_OP=be \\\n",
        "  TQDM_DISABLE=True \\\n",
        "  TTS_TAG=tts_coqui \\\n",
        "  N_GPU_LAYERS=29 FLASH_ATTN=1 \\\n",
        "  LLM_MODEL_NAME=qwen \\\n",
        "  LLM_MODEL_PATH=./models/qwen2-1_5b-instruct-q8_0.gguf \\\n",
        "  python -m src.cmd.remote-queue-chat.generate_audio2audio > ./log/be_std_out.log"
      ],
      "metadata": {
        "id": "mNCEuSXgNrM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ASR_TAG=whisper_faster_asr \\\n",
        "  ASR_MODEL_NAME_OR_PATH=./models/Systran/faster-whisper-base \\\n",
        "  REDIS_PASSWORD=$redis_pwd \\\n",
        "  RUN_OP=be \\\n",
        "  TQDM_DISABLE=True \\\n",
        "  TTS_TAG=tts_coqui \\\n",
        "  N_GPU_LAYERS=29 FLASH_ATTN=1 \\\n",
        "  LLM_MODEL_NAME=qwen \\\n",
        "  LLM_MODEL_PATH=./models/qwen2-1_5b-instruct-fp16.gguf \\\n",
        "  python -m src.cmd.remote-queue-chat.generate_audio2audio > ./log/be_std_out.log"
      ],
      "metadata": {
        "id": "Y9_sP2HRNy8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ASR_TAG=whisper_faster_asr \\\n",
        "  ASR_MODEL_NAME_OR_PATH=./models/Systran/faster-whisper-base \\\n",
        "  REDIS_PASSWORD=$redis_pwd \\\n",
        "  RUN_OP=be \\\n",
        "  TQDM_DISABLE=True \\\n",
        "  TTS_TAG=tts_coqui \\\n",
        "  LLM_MODEL_NAME=qwen \\\n",
        "  LLM_MODEL_PATH=./models/qwen2-7b-instruct-q8_0.gguf \\\n",
        "  python -m src.cmd.remote-queue-chat.generate_audio2audio > ./log/be_std_out.log"
      ],
      "metadata": {
        "id": "wEENM5t5LC7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ASR_TAG=whisper_faster_asr \\\n",
        "  ASR_MODEL_NAME_OR_PATH=./models/Systran/faster-whisper-base \\\n",
        "  REDIS_PASSWORD=$redis_pwd \\\n",
        "  RUN_OP=be \\\n",
        "  TQDM_DISABLE=True \\\n",
        "  TTS_TAG=tts_coqui \\\n",
        "  LLM_MODEL_NAME=qwen \\\n",
        "  LLM_MODEL_PATH=./models/qwen2-7b-instruct-fp16.gguf \\\n",
        "  python -m src.cmd.remote-queue-chat.generate_audio2audio > ./log/be_std_out.log"
      ],
      "metadata": {
        "id": "vfCMzS1VRIYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# qwen2-57b moe\n",
        "!ASR_TAG=whisper_faster_asr \\\n",
        "  ASR_MODEL_NAME_OR_PATH=./models/Systran/faster-whisper-base \\\n",
        "  REDIS_PASSWORD=$redis_pwd \\\n",
        "  RUN_OP=be \\\n",
        "  TQDM_DISABLE=True \\\n",
        "  TTS_TAG=tts_coqui \\\n",
        "  LLM_MODEL_NAME=qwen \\\n",
        "  LLM_MODEL_PATH=./models/qwen2-57b-a14b-instruct-q3_k_m.gguf \\\n",
        "  python -m src.cmd.remote-queue-chat.generate_audio2audio > ./log/be_std_out.log"
      ],
      "metadata": {
        "id": "ru5774K1b1Yg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### opt"
      ],
      "metadata": {
        "id": "1Enfif0_th1y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "todo:\n",
        "- batch stream tts\n",
        "- use more gpu memory to parallel computing for model tensor weight\n",
        "- sft asr whisper model, llm, tts gen model\n"
      ],
      "metadata": {
        "id": "_026sUOStj51"
      }
    }
  ]
}