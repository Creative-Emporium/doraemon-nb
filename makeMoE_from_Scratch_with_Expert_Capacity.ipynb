{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weedge/doraemon-nb/blob/main/makeMoE_from_Scratch_with_Expert_Capacity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "8e9b80fc-12cf-41a9-a0de-354f678b412b",
          "showTitle": false,
          "title": ""
        },
        "id": "90vgVgmDkRJQ"
      },
      "source": [
        "#### 从头开始的稀疏专家混合语言模型，灵感来源于（并在很大程度上基于）[Andrej Karpathy的makemore项目](https://github.com/karpathy/makemore) :)\n",
        "\n",
        "这是一个从头开始实现的稀疏专家混合语言模型。这受到了Andrej Karpathy项目'makemore'的启发，并且大部分重用的组件都来自于该实现。就像makemore一样，makeMoE也是一个自回归的字符级语言模型，但是使用了上述稀疏专家的架构。\n",
        "\n",
        "与makemore体系结构相比，有显着的变化\n",
        "\n",
        "- 稀疏专家混合而不是孤立的前馈神经网络。\n",
        "- 使用了top-k门控和嘈杂的top-k门控实现。\n",
        "- 初始化 - 这里使用了Kaiming He初始化，但这个笔记本的重点是可hack性，所以你可以替换为Xavier Glorot等，并进行尝试。\n",
        "\n",
        "与makemore不变的部分\n",
        "\n",
        "- Andrej最初选择的数据集、预处理（tokenizer）和语言建模任务 - 生成类似莎士比亚的文本\n",
        "- 自注意力因果实现\n",
        "- 训练循环\n",
        "- 推断逻辑\n",
        "\n",
        "在此实现中大量引用的论文：\n",
        "\n",
        "- 专家混合：https://arxiv.org/pdf/2401.04088.pdf\n",
        "- 巨大的神经网络：稀疏门控专家混合层：https://arxiv.org/pdf/1701.06538.pdf\n",
        "\n",
        "这个笔记本演示了整个模型架构的直觉以及所有内容是如何相互关联的。\n",
        "\n",
        "代码完全在Databricks上开发，使用单个A100进行计算。如果您在Databricks上运行此代码，可以在您选择的云提供商中轻松扩展到任意大的GPU集群上。\n",
        "\n",
        "我选择使用mlflow（在Databricks中预先安装了该库。您可以在其他地方轻松pip安装）是因为我发现它有助于跟踪和记录所有必要的指标。这完全是可选的。\n",
        "\n",
        "请注意，该实现强调易读性和可hack性而不是性能，因此有许多方法可以改进此实现。请尝试并告诉我。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "2f4a58a8-bd4c-40de-a4a9-95457842db0b",
          "showTitle": false,
          "title": ""
        },
        "id": "hywLNfb0kRJT"
      },
      "source": [
        "![mixture of experts overview](https://raw.githubusercontent.com/AviSoori1x/makeMoE/main/images/moe.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "35b3daa3-3b3b-47af-b3e7-be95878f9e06",
          "showTitle": false,
          "title": ""
        },
        "id": "RQAnP6_RkRJU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee615614-e7f8-4707-80ef-8e8888158a92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mlflow\n",
            "  Downloading mlflow-2.10.0-py3-none-any.whl (19.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.1)\n",
            "Collecting databricks-cli<1,>=0.8.7 (from mlflow)\n",
            "  Downloading databricks_cli-0.18.0-py2.py3-none-any.whl (150 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.3/150.3 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints<1 in /usr/local/lib/python3.10/dist-packages (from mlflow) (0.4)\n",
            "Collecting gitpython<4,>=2.1.0 (from mlflow)\n",
            "  Downloading GitPython-3.1.41-py3-none-any.whl (196 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.4/196.4 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.10/dist-packages (from mlflow) (6.0.1)\n",
            "Requirement already satisfied: protobuf<5,>=3.12.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.20.3)\n",
            "Requirement already satisfied: pytz<2024 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2023.3.post1)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.31.0)\n",
            "Requirement already satisfied: packaging<24 in /usr/local/lib/python3.10/dist-packages (from mlflow) (23.2)\n",
            "Requirement already satisfied: importlib-metadata!=4.7.0,<8,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (7.0.1)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (0.4.4)\n",
            "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker<8,>=4.0.0 (from mlflow)\n",
            "  Downloading docker-7.0.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.6/147.6 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Flask<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.5)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.23.5)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.11.4)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.5.3)\n",
            "Collecting querystring-parser<2 (from mlflow)\n",
            "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.0.24)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.2.2)\n",
            "Requirement already satisfied: pyarrow<16,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (10.0.1)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.5.2)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.7.1)\n",
            "Collecting gunicorn<22 (from mlflow)\n",
            "  Downloading gunicorn-21.2.0-py3-none-any.whl (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.2/80.2 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.1.3)\n",
            "Collecting Mako (from alembic!=1.10.0,<2->mlflow)\n",
            "  Downloading Mako-1.3.0-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic!=1.10.0,<2->mlflow) (4.5.0)\n",
            "Requirement already satisfied: pyjwt>=1.7.0 in /usr/lib/python3/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (2.3.0)\n",
            "Requirement already satisfied: oauthlib>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (3.2.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (0.9.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (1.16.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.7 in /usr/local/lib/python3.10/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (2.0.7)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (3.0.1)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (2.1.2)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython<4,>=2.1.0->mlflow)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata!=4.7.0,<8,>=3.7.0->mlflow) (3.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2<4,>=2.11->mlflow) (2.1.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow) (2023.11.17)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (3.2.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.0.3)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=2.1.0->mlflow)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, querystring-parser, Mako, gunicorn, gitdb, docker, databricks-cli, alembic, gitpython, mlflow\n",
            "Successfully installed Mako-1.3.0 alembic-1.13.1 databricks-cli-0.18.0 docker-7.0.0 gitdb-4.0.11 gitpython-3.1.41 gunicorn-21.2.0 mlflow-2.10.0 querystring-parser-1.2.4 smmap-5.0.1\n"
          ]
        }
      ],
      "source": [
        "#Using mlflow is entirely optional. I personally like to use MLFlow to track and log everything. If you're using Databricks, it comes pre-installed.\n",
        "%pip install mlflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "5e1a3e38-8717-42ec-9bbc-71d3712c1c68",
          "showTitle": false,
          "title": ""
        },
        "id": "V521QQ_qkRJV"
      },
      "outputs": [],
      "source": [
        "#Import the necessary packages and set seed for reproducibility. For this notebook, pytorch is all you need\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "torch.manual_seed(42)\n",
        "#Optional\n",
        "import mlflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "faf99ef2-39bb-46fc-b772-05d6d0482bbc",
          "showTitle": false,
          "title": ""
        },
        "id": "-4r_QNRRkRJV"
      },
      "source": [
        "接下来的几个部分，下载数据、预处理数据和自注意力直接来自makemore。我稍微详细说明了自注意力，并添加了一些可视化辅助，以便更好地理解这个过程。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "45143d84-28c7-463d-9fb5-e21122842600",
          "showTitle": false,
          "title": ""
        },
        "id": "2GhDw0yWkRJV",
        "outputId": "38688807-55a2-4e75-a966-124e000dc29c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-08 07:56:02--  https://raw.githubusercontent.com/AviSoori1x/makeMoE/main/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2024-04-08 07:56:03 (58.9 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Downloading the tiny shakespeare dataset\n",
        "!wget https://raw.githubusercontent.com/AviSoori1x/makeMoE/main/input.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "192e830a-762d-4573-9484-70a58deb1fec",
          "showTitle": false,
          "title": ""
        },
        "id": "3sPAL1AKkRJW"
      },
      "outputs": [],
      "source": [
        "# read it in to inspect it\n",
        "with open('input.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "2d7181b7-f5e5-4ab5-bdd8-74c507c798ad",
          "showTitle": false,
          "title": ""
        },
        "id": "wNkF3RYLkRJX",
        "outputId": "d442f356-5e32-4146-87ca-a5ab30415dba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of dataset in characters:  1115394\n"
          ]
        }
      ],
      "source": [
        "print(\"length of dataset in characters: \", len(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "68032e07-8625-4750-a340-bc8f4eed2458",
          "showTitle": false,
          "title": ""
        },
        "id": "AHIwr-yxkRJX",
        "outputId": "b3b8a965-eeae-4ed7-f40f-3a5e8f0d64ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us kill him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be done: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor citizens, the patricians good.\n",
            "What authority surfeits on would relieve us: if they\n",
            "would yield us but the superfluity, while it were\n",
            "wholesome, we might guess they relieved us humanely;\n",
            "but they think we are too dear: the leanness that\n",
            "afflicts us, the object of our misery, is as an\n",
            "inventory to particularise their abundance; our\n",
            "sufferance is a gain to them Let us revenge this with\n",
            "our pikes, ere we become rakes: for the gods know I\n",
            "speak this in hunger for bread, not in thirst for revenge.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# let's look at the first 1000 characters\n",
        "print(text[:1000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "b6995ad6-c9ac-4a21-9da0-ebbd3273c991",
          "showTitle": false,
          "title": ""
        },
        "id": "DHGayz7mkRJY",
        "outputId": "8713c0a6-0d6b-4e98-8d45-f8104fc090c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
            "65\n"
          ]
        }
      ],
      "source": [
        "# here are all the unique characters that occur in this text\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "print(''.join(chars))\n",
        "print(vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "43002fa3-ffd3-416c-9aaf-0a03b19c7bc1",
          "showTitle": false,
          "title": ""
        },
        "id": "pzn11WJckRJY",
        "outputId": "ad458ac2-6b30-4c8a-d123-f18f03279cbd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[46, 47, 47, 1, 58, 46, 43, 56, 43]\n",
            "hii there\n"
          ]
        }
      ],
      "source": [
        "# create a mapping from characters to integers\n",
        "stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "itos = { i:ch for i,ch in enumerate(chars) }\n",
        "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
        "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
        "\n",
        "print(encode(\"hii there\"))\n",
        "print(decode(encode(\"hii there\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "b4609fc4-09c7-4a39-8367-e9ee39d440ed",
          "showTitle": false,
          "title": ""
        },
        "id": "YbBGz0O2kRJY",
        "outputId": "974e20b9-4c45-4e15-8cf3-9369e6f7dd55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1115394]) torch.int64\n",
            "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
            "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
            "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
            "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
            "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
            "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
            "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
            "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
            "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
            "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
            "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
            "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
            "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
            "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
            "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
            "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
            "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
            "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
            "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
            "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
            "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
            "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
            "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
            "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
            "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
            "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
            "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
            "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
            "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
            "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
            "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
            "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
            "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
            "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
            "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
            "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
            "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
            "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
            "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
            "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
            "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
            "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
            "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
            "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
            "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
            "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
            "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
            "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
            "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
            "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
            "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
            "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
            "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
            "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
            "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
            "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
          ]
        }
      ],
      "source": [
        "# let's now encode the entire text dataset and store it into a torch.Tensor\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "print(data.shape, data.dtype)\n",
        "print(data[:1000]) # the 1000 characters we looked at earier will to the GPT look like this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "88f7cb0d-02ff-42b0-92a5-a505dc3f8f25",
          "showTitle": false,
          "title": ""
        },
        "id": "hoLIeA7YkRJZ"
      },
      "outputs": [],
      "source": [
        "# Let's now split up the data into train and validation sets\n",
        "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "6b554ddf-50f4-441b-8acf-10b81a508b7e",
          "showTitle": false,
          "title": ""
        },
        "id": "VY55nr6EkRJZ",
        "outputId": "4cfbc61f-c42b-41f2-f44f-7f041b963304",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "block_size = 8\n",
        "train_data[:block_size+1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "22ba4512-309d-4895-a908-2ef3efa317bc",
          "showTitle": false,
          "title": ""
        },
        "id": "5YbgrB9HkRJZ",
        "outputId": "b2fa5f69-3976-4a5e-c11c-f8e07bfb7d96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when input is tensor([18]) the target: 47\n",
            "when input is tensor([18, 47]) the target: 56\n",
            "when input is tensor([18, 47, 56]) the target: 57\n",
            "when input is tensor([18, 47, 56, 57]) the target: 58\n",
            "when input is tensor([18, 47, 56, 57, 58]) the target: 1\n",
            "when input is tensor([18, 47, 56, 57, 58,  1]) the target: 15\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15]) the target: 47\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target: 58\n"
          ]
        }
      ],
      "source": [
        "x = train_data[:block_size]\n",
        "y = train_data[1:block_size+1]\n",
        "for t in range(block_size):\n",
        "    context = x[:t+1]\n",
        "    target = y[t]\n",
        "    print(f\"when input is {context} the target: {target}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "bf386bff-0f63-4358-82fc-6c7d02c37321",
          "showTitle": false,
          "title": ""
        },
        "id": "Oaxhage8kRJZ"
      },
      "outputs": [],
      "source": [
        "batch_size = 4 # how many independent sequences will we process in parallel?\n",
        "block_size = 8 # what is the maximum context length for predictions?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "99acd85c-233f-4f2d-a062-028dbcde9960",
          "showTitle": false,
          "title": ""
        },
        "id": "HfpkIUNdkRJZ",
        "outputId": "002c3e84-8202-43bd-ce47-efcb3902ef5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([250930, 237205, 974116, 383898])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "ix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "e46dc826-9f39-4aed-b2d2-f9ea401136de",
          "showTitle": false,
          "title": ""
        },
        "id": "faoGVPG3kRJa",
        "outputId": "af6c79b1-2d1e-4bd9-aba4-e3b97c62619f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[42,  1, 58, 46, 59, 57,  1, 21],\n",
              "        [54, 56, 47, 43, 57, 58, 11,  0],\n",
              "        [49, 47, 52, 45, 12,  1, 58, 46],\n",
              "        [58, 46, 53, 59, 58,  1, 56, 43]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "2886aedf-200e-40bd-9a9d-4658cf6c509b",
          "showTitle": false,
          "title": ""
        },
        "id": "hkllYFCPkRJa",
        "outputId": "ff36ce7a-9629-41d7-aaac-8149faf51527",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1, 58, 46, 59, 57,  1, 21,  1],\n",
              "        [56, 47, 43, 57, 58, 11,  0, 37],\n",
              "        [47, 52, 45, 12,  1, 58, 46, 53],\n",
              "        [46, 53, 59, 58,  1, 56, 43, 42]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "a486fc04-ed29-456f-918b-5f8395e455cb",
          "showTitle": false,
          "title": ""
        },
        "id": "tWrajECBkRJa"
      },
      "source": [
        "以下代码块清楚地展示了预测的自回归性质，以及上下文是对token（在本例中是字符）的一维排列的滚动窗口。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "49a86e10-ac37-4b92-8f18-775cd4853fdc",
          "showTitle": false,
          "title": ""
        },
        "id": "xjgtxxztkRJa",
        "outputId": "0fe8ca95-6e94-4a3d-dc99-c49f39c37390",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs:\n",
            "torch.Size([4, 8])\n",
            "tensor([[ 6,  0, 14, 43, 44, 53, 56, 43],\n",
            "        [39,  1, 42, 59, 43,  1, 39, 52],\n",
            "        [47, 41, 43,  1, 39, 52, 42,  1],\n",
            "        [53, 44,  1, 50, 43, 58,  1, 58]])\n",
            "targets:\n",
            "torch.Size([4, 8])\n",
            "tensor([[ 0, 14, 43, 44, 53, 56, 43,  1],\n",
            "        [ 1, 42, 59, 43,  1, 39, 52, 42],\n",
            "        [41, 43,  1, 39, 52, 42,  1, 42],\n",
            "        [44,  1, 50, 43, 58,  1, 58, 46]])\n",
            "----\n",
            "when input is [6] the target: 0\n",
            "when input is [6, 0] the target: 14\n",
            "when input is [6, 0, 14] the target: 43\n",
            "when input is [6, 0, 14, 43] the target: 44\n",
            "when input is [6, 0, 14, 43, 44] the target: 53\n",
            "when input is [6, 0, 14, 43, 44, 53] the target: 56\n",
            "when input is [6, 0, 14, 43, 44, 53, 56] the target: 43\n",
            "when input is [6, 0, 14, 43, 44, 53, 56, 43] the target: 1\n",
            "when input is [39] the target: 1\n",
            "when input is [39, 1] the target: 42\n",
            "when input is [39, 1, 42] the target: 59\n",
            "when input is [39, 1, 42, 59] the target: 43\n",
            "when input is [39, 1, 42, 59, 43] the target: 1\n",
            "when input is [39, 1, 42, 59, 43, 1] the target: 39\n",
            "when input is [39, 1, 42, 59, 43, 1, 39] the target: 52\n",
            "when input is [39, 1, 42, 59, 43, 1, 39, 52] the target: 42\n",
            "when input is [47] the target: 41\n",
            "when input is [47, 41] the target: 43\n",
            "when input is [47, 41, 43] the target: 1\n",
            "when input is [47, 41, 43, 1] the target: 39\n",
            "when input is [47, 41, 43, 1, 39] the target: 52\n",
            "when input is [47, 41, 43, 1, 39, 52] the target: 42\n",
            "when input is [47, 41, 43, 1, 39, 52, 42] the target: 1\n",
            "when input is [47, 41, 43, 1, 39, 52, 42, 1] the target: 42\n",
            "when input is [53] the target: 44\n",
            "when input is [53, 44] the target: 1\n",
            "when input is [53, 44, 1] the target: 50\n",
            "when input is [53, 44, 1, 50] the target: 43\n",
            "when input is [53, 44, 1, 50, 43] the target: 58\n",
            "when input is [53, 44, 1, 50, 43, 58] the target: 1\n",
            "when input is [53, 44, 1, 50, 43, 58, 1] the target: 58\n",
            "when input is [53, 44, 1, 50, 43, 58, 1, 58] the target: 46\n"
          ]
        }
      ],
      "source": [
        "def get_batch(split):\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    return x, y\n",
        "\n",
        "xb, yb = get_batch('train')\n",
        "print('inputs:')\n",
        "print(xb.shape)\n",
        "print(xb)\n",
        "print('targets:')\n",
        "print(yb.shape)\n",
        "print(yb)\n",
        "\n",
        "print('----')\n",
        "\n",
        "for b in range(batch_size): # batch dimension\n",
        "    for t in range(block_size): # time dimension\n",
        "        context = xb[b, :t+1]\n",
        "        target = yb[b,t]\n",
        "        print(f\"when input is {context.tolist()} the target: {target}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "dde3273f-0519-4108-ba84-dfd99e020722",
          "showTitle": false,
          "title": ""
        },
        "id": "RlON_gNikRJa"
      },
      "source": [
        "### Understanding the intuition of Causal Scaled Dot Product Self Attention\n",
        "\n",
        "这段代码来自于Andrej Karpathy出色的makemore代码库，链接在仓库中。\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "e435d0cf-1383-446a-9026-cd80b4266019",
          "showTitle": false,
          "title": ""
        },
        "id": "uBVWP40SkRJa"
      },
      "source": [
        "![scaled dot product self attention](https://raw.githubusercontent.com/AviSoori1x/makeMoE/main/images/self_attention.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "97660589-1719-48c0-ad6f-4f7c2888348a",
          "showTitle": false,
          "title": ""
        },
        "id": "i-jFgMntkRJa"
      },
      "source": [
        "提供的代码演示了自注意力的机制和基本概念，特别是关注经典的缩放点积自注意力。在这个变体中，查询、键和值矩阵都来自同一个输入序列。为了确保自回归语言生成过程的完整性，特别是在仅包含解码器的模型中，代码实现了掩码。这种掩码技术至关重要，因为它隐藏了当前标记位置后面的任何信息，从而将模型的注意力引导到序列的前面部分。这样的注意力机制称为因果自注意力。值得注意的是，稀疏专家混合模型并不局限于仅包含解码器的Transformer架构。事实上，在这个领域的许多重要工作，特别是由Shazeer等人完成的工作，都围绕着T5架构展开，该架构包含了Transformer模型中的编码器和解码器组件。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "6f82ca41-a301-4a92-aed9-ba7ac3a2bf88",
          "showTitle": false,
          "title": ""
        },
        "id": "lxMSgZWGkRJb",
        "outputId": "2fe00069-2655-4c57-c197-3b2204378d12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "torch.manual_seed(1337)\n",
        "B,T,C = 4,8,32 # batch, time, channels\n",
        "x = torch.randn(B,T,C)\n",
        "\n",
        "# let's see a single Head perform self-attention\n",
        "head_size = 16\n",
        "key = nn.Linear(C, head_size, bias=False)\n",
        "query = nn.Linear(C, head_size, bias=False)\n",
        "value = nn.Linear(C, head_size, bias=False)\n",
        "k = key(x)   # (B, T, 16)\n",
        "q = query(x) # (B, T, 16)\n",
        "wei =  q @ k.transpose(-2, -1) # (B, T, 16) @ (B, 16, T) ---> (B, T, T)\n",
        "\n",
        "tril = torch.tril(torch.ones(T, T))\n",
        "#wei = torch.zeros((T,T))\n",
        "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "wei = F.softmax(wei, dim=-1) #B,T,T\n",
        "\n",
        "v = value(x) #B,T,H\n",
        "out = wei @ v # (B,T,T) @ (B,T,H) -> (B,T,H)\n",
        "#The output from this final matrix product is subsequently passsed through a linear layer as shown in the diagram above\n",
        "\n",
        "out.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "49c278ec-19db-4c5d-b4a3-3bdc45c5a443",
          "showTitle": false,
          "title": ""
        },
        "id": "cA3iXggEkRJb"
      },
      "source": [
        "对因果自注意力和多头因果自注意力的代码进行泛化和模块化。多头自注意力将多个注意力头并行应用，每个注意力头专注于通道的不同部分（嵌入维度）。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "608c6c9f-fb93-43ed-9580-5e782fd90d61",
          "showTitle": false,
          "title": ""
        },
        "id": "909nX3PHkRJb"
      },
      "outputs": [],
      "source": [
        "#Causal scaled dot product self-Attention Head\n",
        "\n",
        "n_embd = 64\n",
        "n_head = 4\n",
        "n_layer = 4\n",
        "head_size = 16\n",
        "dropout = 0.1\n",
        "\n",
        "class Head(nn.Module):\n",
        "    \"\"\" one head of self-attention \"\"\"\n",
        "\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B,T,C = x.shape\n",
        "        k = self.key(x)   # (B,T,C)\n",
        "        q = self.query(x) # (B,T,C)\n",
        "        # compute attention scores (\"affinities\")\n",
        "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
        "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
        "        wei = self.dropout(wei)\n",
        "        # perform the weighted aggregation of the values\n",
        "        v = self.value(x) # (B,T,C)\n",
        "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "6e8b31af-f45a-4066-8288-fb0d9c8e2aff",
          "showTitle": false,
          "title": ""
        },
        "id": "T3MoVK_WkRJb"
      },
      "outputs": [],
      "source": [
        "#Multi-Headed Self Attention\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
        "\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(n_embd, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "16267e9a-008b-46e3-82ce-2ae41396a1a1",
          "showTitle": false,
          "title": ""
        },
        "id": "T-w53_mSkRJb",
        "outputId": "e4089ca7-3859-41eb-f474-1c90b3d6da85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "#Confirming that what's output from multi head attention is the original embedding size\n",
        "B,T,C = 4,8,64 # batch, time, channels\n",
        "x = torch.randn(B,T,C)\n",
        "mha = MultiHeadAttention(4,16)\n",
        "mha(x).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "5f7ff128-7fe5-4a91-b9f2-208e2132e505",
          "showTitle": false,
          "title": ""
        },
        "id": "wNlJTtfhkRJb"
      },
      "source": [
        "### Creating an Expert module i.e. a simple Multi Layer Perceptron"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "f6e422a5-57c1-4b2f-b7b9-2757e109848a",
          "showTitle": false,
          "title": ""
        },
        "id": "zv3fGRpbkRJb"
      },
      "source": [
        "在稀疏专家（MoE）架构中，每个Transformer块内部的自注意力机制保持不变。然而，每个块的结构发生了显著变化：标准的前馈神经网络被替换为几个稀疏激活的前馈网络，称为专家。 \"稀疏激活\" 指的是序列中的每个标记仅被路由到总池中的有限数量的这些专家之一或两个 - 通常是一个或两个。这种修改允许对输入数据的不同部分进行专门处理，使模型能够有效地处理更广泛的复杂性。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "efe9fdcc-82eb-4047-9233-ad3cfe8759b1",
          "showTitle": false,
          "title": ""
        },
        "id": "7Kz0Y_P0kRJc"
      },
      "source": [
        "![experts](https://raw.githubusercontent.com/AviSoori1x/makeMoE/main/images/experts.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "a2f0f382-ab4a-45e1-9dce-27ae0d3da641",
          "showTitle": false,
          "title": ""
        },
        "id": "a-9CYWXgkRJc"
      },
      "outputs": [],
      "source": [
        "#Expert module\n",
        "class Expert(nn.Module):\n",
        "    \"\"\" An MLP is a simple linear layer followed by a non-linearity i.e. each Expert \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "a7764385-26e9-4d75-9aa7-ce011023e24e",
          "showTitle": false,
          "title": ""
        },
        "id": "qderdEuykRJc"
      },
      "source": [
        "### Top-k Gating Intuition through an Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "d3fca4df-4c47-4e9a-98cd-08cf8ccf7726",
          "showTitle": false,
          "title": ""
        },
        "id": "VxJv5y44kRJc"
      },
      "source": [
        "![top k gating](https://raw.githubusercontent.com/AviSoori1x/makeMoE/main/images/topk.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "8e494b86-cdb2-4f2a-8824-5fa2ef4b2606",
          "showTitle": false,
          "title": ""
        },
        "id": "n6DuhY0DkRJc"
      },
      "source": [
        "门控网络，也称为路由器，确定每个token从多头注意力中由哪个专家网络接收输出。让我们考虑一个简单的例子：假设有4个专家，并且要将标记路由到前2个专家。最初，我们通过一个线性层将token输入到门控网络中。这个层将输入张量从形状为（2，4，32）——表示（批量大小，tokens，n_embed，其中n_embed是输入的通道维度）——投影到一个新形状为（2，4，4）的张量，对应于（批量大小，tokens，num_experts），其中num_experts是专家网络的数量。接下来，我们确定最后一维中前k=2个最高值及其相应的索引。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "621916ff-2290-4e2f-9fd7-5181ed98d540",
          "showTitle": false,
          "title": ""
        },
        "id": "pNAuFDDvkRJc",
        "outputId": "7f9de5be-e792-4eb1-e9e3-31388b58bf0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[ 0.9558,  0.1610],\n",
              "          [ 0.8659, -0.1494],\n",
              "          [ 0.8765,  0.7202],\n",
              "          [ 0.9496, -0.6609]],\n",
              " \n",
              "         [[ 0.4419, -0.2500],\n",
              "          [ 1.2602,  0.8430],\n",
              "          [ 0.8570,  0.7822],\n",
              "          [ 0.7376,  0.2561]]], grad_fn=<TopkBackward0>),\n",
              " tensor([[[2, 0],\n",
              "          [3, 2],\n",
              "          [3, 0],\n",
              "          [1, 2]],\n",
              " \n",
              "         [[1, 3],\n",
              "          [1, 2],\n",
              "          [1, 2],\n",
              "          [0, 1]]]))"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "#Understanding how gating works\n",
        "num_experts = 4\n",
        "top_k=2\n",
        "n_embed=32\n",
        "\n",
        "\n",
        "#Example multi-head attention output for a simple illustrative example, consider n_embed=32, context_length=4 and batch_size=2\n",
        "mh_output = torch.randn(2, 4, n_embed)\n",
        "\n",
        "topkgate_linear = nn.Linear(n_embed, num_experts) # nn.Linear(32, 4)\n",
        "\n",
        "logits = topkgate_linear(mh_output)\n",
        "top_k_logits, top_k_indices = logits.topk(top_k, dim=-1)  # Get top-k experts\n",
        "top_k_logits, top_k_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "0f135ff7-0aa3-4b6d-ab5e-42399c48427b",
          "showTitle": false,
          "title": ""
        },
        "id": "EKwAyJxrkRJd"
      },
      "source": [
        "通过仅保留沿着最后一个维度的各自索引处的前k个值，获取稀疏门控输出。用'-inf'填充其余部分，并通过softmax激活函数传递。这将'-inf'值推向零，使前两个值更加突出，并且总和为1。这种总和为1有助于对专家输出进行加权。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "735e160a-ef1e-424d-b6d9-09f63ea99ec1",
          "showTitle": false,
          "title": ""
        },
        "id": "IiVejzOpkRJd",
        "outputId": "67fd7b89-89ec-4146-aa54-bdcb209a2b92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.1610,    -inf,  0.9558,    -inf],\n",
              "         [   -inf,    -inf, -0.1494,  0.8659],\n",
              "         [ 0.7202,    -inf,    -inf,  0.8765],\n",
              "         [   -inf,  0.9496, -0.6609,    -inf]],\n",
              "\n",
              "        [[   -inf,  0.4419,    -inf, -0.2500],\n",
              "         [   -inf,  1.2602,  0.8430,    -inf],\n",
              "         [   -inf,  0.8570,  0.7822,    -inf],\n",
              "         [ 0.7376,  0.2561,    -inf,    -inf]]], grad_fn=<ScatterBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "zeros = torch.full_like(logits, float('-inf')) #full_like clones a tensor and fills it with a specified value (like infinity) for masking or calculations.\n",
        "sparse_logits = zeros.scatter(-1, top_k_indices, top_k_logits)\n",
        "sparse_logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "9146e6f9-4eee-4a8b-8338-55072719ed59",
          "showTitle": false,
          "title": ""
        },
        "id": "HFgRxDF4kRJh",
        "outputId": "73b6cd21-8807-4056-8675-58f555369a41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.3111, 0.0000, 0.6889, 0.0000],\n",
              "         [0.0000, 0.0000, 0.2660, 0.7340],\n",
              "         [0.4610, 0.0000, 0.0000, 0.5390],\n",
              "         [0.0000, 0.8335, 0.1665, 0.0000]],\n",
              "\n",
              "        [[0.0000, 0.6664, 0.0000, 0.3336],\n",
              "         [0.0000, 0.6028, 0.3972, 0.0000],\n",
              "         [0.0000, 0.5187, 0.4813, 0.0000],\n",
              "         [0.6181, 0.3819, 0.0000, 0.0000]]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "gating_output= F.softmax(sparse_logits, dim=-1)\n",
        "gating_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "fe558b12-e443-4b62-9a85-c59120456352",
          "showTitle": false,
          "title": ""
        },
        "id": "dGJrq2uqkRJh"
      },
      "source": [
        "### Generalizing and Modularizing above code and adding noisy top-k Gating for load balancing\n",
        "泛化和模块化上述代码，并添加嘈杂的top-k门控以实现负载平衡。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "45516b59-d814-4853-a34e-d36aae9f04eb",
          "showTitle": false,
          "title": ""
        },
        "id": "TKp4DqwYkRJh"
      },
      "outputs": [],
      "source": [
        "# First define the top k router module\n",
        "class TopkRouter(nn.Module):\n",
        "    def __init__(self, n_embed, num_experts, top_k):\n",
        "        super(TopkRouter, self).__init__()\n",
        "        self.top_k = top_k\n",
        "        self.linear =nn.Linear(n_embed, num_experts)\n",
        "\n",
        "    def forward(self, mh_ouput):\n",
        "        # mh_ouput is the output tensor from multihead self attention block\n",
        "        logits = self.linear(mh_output)\n",
        "        top_k_logits, indices = logits.topk(self.top_k, dim=-1)\n",
        "        zeros = torch.full_like(logits, float('-inf'))\n",
        "        sparse_logits = zeros.scatter(-1, indices, top_k_logits)\n",
        "        router_output = F.softmax(sparse_logits, dim=-1)\n",
        "        return router_output, indices\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "c500844f-0866-4bbf-acef-c0c1d4979721",
          "showTitle": false,
          "title": ""
        },
        "id": "KjkouzwkkRJh",
        "outputId": "7d5c81fb-d795-4643-c5a6-b60b06e03034",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([2, 4, 4]),\n",
              " tensor([[[0.0000, 0.4249, 0.5751, 0.0000],\n",
              "          [0.3467, 0.6533, 0.0000, 0.0000],\n",
              "          [0.3970, 0.0000, 0.6030, 0.0000],\n",
              "          [0.0000, 0.0000, 0.7713, 0.2287]],\n",
              " \n",
              "         [[0.4043, 0.5957, 0.0000, 0.0000],\n",
              "          [0.0000, 0.5281, 0.0000, 0.4719],\n",
              "          [0.7053, 0.0000, 0.2947, 0.0000],\n",
              "          [0.0000, 0.4602, 0.5398, 0.0000]]], grad_fn=<SoftmaxBackward0>),\n",
              " tensor([[[2, 1],\n",
              "          [1, 0],\n",
              "          [2, 0],\n",
              "          [2, 3]],\n",
              " \n",
              "         [[1, 0],\n",
              "          [1, 3],\n",
              "          [0, 2],\n",
              "          [2, 1]]]))"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "#Testing this out:\n",
        "num_experts = 4\n",
        "top_k = 2\n",
        "n_embd = 32\n",
        "\n",
        "mh_output = torch.randn(2, 4, n_embd)  # Example input\n",
        "top_k_gate = TopkRouter(n_embd, num_experts, top_k)\n",
        "gating_output, indices = top_k_gate(mh_output)\n",
        "gating_output.shape, gating_output, indices\n",
        "#And it works!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "9fa02d0c-3688-4d01-811d-d0b2b851ab33",
          "showTitle": false,
          "title": ""
        },
        "id": "tAouN-GwkRJi"
      },
      "source": [
        "虽然最近发布的Mixtral论文没有提到，但我认为嘈杂的top-k门控是训练MoE模型的重要工具。基本上，您不希望所有的token都被发送到同一组“偏爱”的专家中。您希望在开发和探索之间达到良好的平衡。为此，为门控线性层的logits添加标准正态噪声有助于负载平衡，使训练更加高效。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "e05b3306-b89f-4ebc-901b-f16398a925c2",
          "showTitle": false,
          "title": ""
        },
        "id": "aWeueE83kRJi"
      },
      "source": [
        "![noisy top-k gating](https://raw.githubusercontent.com/AviSoori1x/makeMoE/main/images/noisytopkgating.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "dda4d805-373c-48f7-9037-da08fbc06e64",
          "showTitle": false,
          "title": ""
        },
        "id": "ZBrN-w3JkRJi"
      },
      "outputs": [],
      "source": [
        "#Changing the above to accomodate noisy top-k gating\n",
        "class NoisyTopkRouter(nn.Module):\n",
        "    def __init__(self, n_embed, num_experts, top_k):\n",
        "        super(NoisyTopkRouter, self).__init__()\n",
        "        self.top_k = top_k\n",
        "        #layer for router logits\n",
        "        self.topkroute_linear = nn.Linear(n_embed, num_experts)\n",
        "        self.noise_linear =nn.Linear(n_embed, num_experts)\n",
        "\n",
        "\n",
        "    def forward(self, mh_output):\n",
        "        # mh_ouput is the output tensor from multihead self attention block\n",
        "        logits = self.topkroute_linear(mh_output)\n",
        "\n",
        "        #Noise logits\n",
        "        noise_logits = self.noise_linear(mh_output)\n",
        "\n",
        "        #Adding scaled unit gaussian noise to the logits\n",
        "        noise = torch.randn_like(logits)*F.softplus(noise_logits)\n",
        "        noisy_logits = logits + noise\n",
        "\n",
        "        top_k_logits, indices = noisy_logits.topk(self.top_k, dim=-1)\n",
        "        zeros = torch.full_like(noisy_logits, float('-inf'))\n",
        "        sparse_logits = zeros.scatter(-1, indices, top_k_logits)\n",
        "        router_output = F.softmax(sparse_logits, dim=-1)\n",
        "        return router_output, indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "a01a9d6b-fedb-427d-b0da-c3b2a75a8643",
          "showTitle": false,
          "title": ""
        },
        "id": "7Q6KcH9AkRJi",
        "outputId": "84b6f374-c19d-44c1-a9ae-e63318d57209",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([2, 4, 8]),\n",
              " tensor([[[0.7014, 0.0000, 0.0000, 0.0000, 0.2986, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.6619, 0.0000, 0.0000, 0.0000, 0.3381, 0.0000],\n",
              "          [0.4658, 0.5342, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.4156, 0.0000, 0.0000, 0.0000, 0.5844, 0.0000]],\n",
              " \n",
              "         [[0.0000, 0.0000, 0.0000, 0.5861, 0.0000, 0.0000, 0.0000, 0.4139],\n",
              "          [0.4014, 0.0000, 0.0000, 0.0000, 0.0000, 0.5986, 0.0000, 0.0000],\n",
              "          [0.5216, 0.0000, 0.0000, 0.0000, 0.4784, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.3432, 0.6568, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]],\n",
              "        grad_fn=<SoftmaxBackward0>),\n",
              " tensor([[[0, 4],\n",
              "          [2, 6],\n",
              "          [1, 0],\n",
              "          [6, 2]],\n",
              " \n",
              "         [[3, 7],\n",
              "          [5, 0],\n",
              "          [0, 4],\n",
              "          [2, 1]]]))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "#Testing this out, again:\n",
        "num_experts = 8\n",
        "top_k = 2\n",
        "n_embd = 16\n",
        "\n",
        "mh_output = torch.randn(2, 4, n_embd)  # Example input\n",
        "noisy_top_k_gate = NoisyTopkRouter(n_embd, num_experts, top_k)\n",
        "gating_output, indices = noisy_top_k_gate(mh_output)\n",
        "gating_output.shape, gating_output, indices\n",
        "#It works!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "076fa004-a165-42a7-b729-0bca8ad39418",
          "showTitle": false,
          "title": ""
        },
        "id": "XyKjpR-dkRJi"
      },
      "source": [
        "\n",
        "### Creating a sparse Mixture of Experts module\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "6747b8de-0086-4cb0-8fbd-46ee95457eb9",
          "showTitle": false,
          "title": ""
        },
        "id": "UsRCy7i3kRJi"
      },
      "source": [
        "这个过程的主要方面涉及门控网络的输出。在获得这些结果后，会选择性地将前k个值与相应的前k个专家的输出相乘，以获得给定token的结果。这种选择性的乘法形成了加权求和，构成了SparseMoe块的输出。这个过程中的关键和具有挑战性的部分是避免不必要的乘法。只对前k个专家进行前向传播，然后计算这个加权和是至关重要的。对每个专家都进行前向传播会违背使用稀疏MoE的初衷，因为它将不再是稀疏的。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "d6809b3f-4be9-4859-b39e-24fcdd6c8d86",
          "showTitle": false,
          "title": ""
        },
        "id": "7dDUHU_IkRJi"
      },
      "outputs": [],
      "source": [
        "class SparseMoE(nn.Module):\n",
        "    def __init__(self, n_embed, num_experts, top_k):\n",
        "        super(SparseMoE, self).__init__()\n",
        "        self.router = NoisyTopkRouter(n_embed, num_experts, top_k)\n",
        "        self.experts = nn.ModuleList([Expert(n_embed) for _ in range(num_experts)])\n",
        "        self.top_k = top_k\n",
        "\n",
        "    def forward(self, x):\n",
        "        gating_output, indices = self.router(x)\n",
        "        final_output = torch.zeros_like(x)\n",
        "\n",
        "        # Reshape inputs for batch processing\n",
        "        flat_x = x.view(-1, x.size(-1))\n",
        "        flat_gating_output = gating_output.view(-1, gating_output.size(-1))\n",
        "\n",
        "        # Process each expert in parallel\n",
        "        for i, expert in enumerate(self.experts):\n",
        "            # Create a mask for the inputs where the current expert is in top-k\n",
        "            expert_mask = (indices == i).any(dim=-1)\n",
        "            flat_mask = expert_mask.view(-1)\n",
        "\n",
        "            if flat_mask.any():\n",
        "                expert_input = flat_x[flat_mask]\n",
        "                expert_output = expert(expert_input)\n",
        "\n",
        "                # Extract and apply gating scores\n",
        "                gating_scores = flat_gating_output[flat_mask, i].unsqueeze(1)\n",
        "                weighted_output = expert_output * gating_scores\n",
        "\n",
        "                # Update final output\n",
        "                # We need to scatter_add the weighted outputs to their original positions in the batch\n",
        "                final_output.masked_scatter_(expert_mask.unsqueeze(-1), weighted_output)\n",
        "\n",
        "        return final_output.view_as(x)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "06239630-0a1c-47c9-976c-7770f3d82e18",
          "showTitle": false,
          "title": ""
        },
        "id": "q8kDLI1ukRJj",
        "outputId": "9220fd38-b9de-475d-cf08-78bacbe555ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the final output: torch.Size([4, 8, 16])\n",
            "tensor([[[ 6.1727e-02, -1.1298e-01, -4.1579e-02, -2.8002e-03,  0.0000e+00,\n",
            "           7.7357e-02,  3.6960e-02, -1.0697e-01,  1.2526e-02,  1.0065e-02,\n",
            "           2.5494e-02,  5.7258e-02,  3.1733e-02, -1.2904e-01,  3.1911e-02,\n",
            "          -9.2942e-02],\n",
            "         [-2.6267e-02, -2.1804e-01,  0.0000e+00,  0.0000e+00,  2.9232e-01,\n",
            "           2.2580e-01,  0.0000e+00, -2.6606e-01, -6.0905e-02, -6.9949e-03,\n",
            "           1.9965e-01,  2.1709e-01, -1.2841e-01, -2.2774e-01,  9.0908e-02,\n",
            "          -0.0000e+00],\n",
            "         [-9.4502e-02, -3.3213e-01,  4.8503e-02,  2.1059e-02,  2.4934e-01,\n",
            "           6.4678e-02, -9.2514e-02, -7.5233e-02,  1.4475e-01,  0.0000e+00,\n",
            "          -5.1047e-02, -7.9036e-02,  4.8226e-02, -0.0000e+00, -1.0702e-01,\n",
            "           2.8969e-03],\n",
            "         [ 1.3531e-01, -2.6609e-02,  0.0000e+00,  2.2722e-01, -1.2779e-01,\n",
            "           3.2449e-02,  2.2538e-03, -6.9114e-02,  9.8225e-02, -8.9362e-02,\n",
            "           1.6459e-01,  1.1035e-01,  7.0970e-02, -2.5286e-01,  7.3624e-02,\n",
            "           3.3992e-02],\n",
            "         [ 2.3093e-02, -1.6634e-01,  1.3268e-01, -3.7955e-02,  0.0000e+00,\n",
            "           5.8076e-02, -2.8576e-01, -3.8680e-01,  2.9840e-01, -7.4842e-02,\n",
            "           0.0000e+00,  1.4650e-01, -2.5771e-01,  8.3264e-02,  2.7305e-01,\n",
            "          -3.3373e-01],\n",
            "         [-5.5540e-02, -1.0644e-01,  9.2521e-02, -8.3701e-03,  3.3946e-02,\n",
            "           6.7005e-02,  1.3334e-01, -2.6413e-01,  5.5404e-02, -3.2691e-02,\n",
            "          -6.4163e-02,  8.9473e-02,  2.4871e-03, -9.4274e-02,  0.0000e+00,\n",
            "          -9.0755e-02],\n",
            "         [-1.5643e-01, -1.0924e-01,  5.8004e-02, -8.1961e-02,  9.0717e-02,\n",
            "           2.1321e-02,  1.6205e-01, -2.0858e-01, -8.1745e-02, -6.7670e-03,\n",
            "          -9.1852e-02,  1.1013e-01,  6.3894e-02,  0.0000e+00,  1.1903e-01,\n",
            "           2.8461e-02],\n",
            "         [ 1.9714e-01, -1.7787e-01, -8.0113e-03, -0.0000e+00,  1.1284e-01,\n",
            "           1.1682e-01, -1.6858e-01, -1.6523e-01,  9.9874e-02,  1.0447e-02,\n",
            "           0.0000e+00, -4.8994e-02, -7.2435e-02, -1.4833e-01,  1.3172e-01,\n",
            "          -0.0000e+00]],\n",
            "\n",
            "        [[ 6.0492e-02, -3.7522e-01,  3.7519e-02,  3.4758e-01, -0.0000e+00,\n",
            "          -8.1673e-02,  1.6996e-01, -1.2347e-01,  1.2231e-01,  4.6503e-02,\n",
            "          -2.1363e-01,  1.5122e-01,  1.0582e-01, -1.9945e-01,  1.2250e-01,\n",
            "           8.4910e-02],\n",
            "         [ 3.8122e-01,  1.8659e-01, -3.6525e-01, -1.8369e-01, -1.5873e-01,\n",
            "          -3.5122e-01,  2.1092e-01,  3.2503e-01,  2.7202e-01,  5.1146e-01,\n",
            "          -1.8837e-01,  1.2664e-01, -5.4119e-01, -1.0808e-01,  2.9885e-01,\n",
            "           2.6700e-01],\n",
            "         [ 0.0000e+00, -4.8438e-02, -4.6959e-02,  3.4773e-02,  1.4037e-01,\n",
            "          -1.6253e-01, -1.7464e-02, -5.6658e-02, -5.7714e-02,  5.1319e-02,\n",
            "           2.8324e-02, -1.1714e-01,  3.2928e-02,  1.9608e-02,  4.6926e-02,\n",
            "          -1.3237e-01],\n",
            "         [ 1.8322e-01, -4.5841e-02,  1.3811e-01, -7.8621e-02, -2.7854e-02,\n",
            "          -0.0000e+00, -6.3355e-02, -1.0999e-01,  2.2661e-01,  7.0362e-03,\n",
            "          -5.4486e-02, -7.8047e-02,  5.8757e-02,  1.8977e-01,  0.0000e+00,\n",
            "          -1.1398e-01],\n",
            "         [ 2.6847e-01,  1.6882e-01, -1.2736e-01,  8.4343e-02, -2.8952e-01,\n",
            "           1.2636e-01, -1.3666e-01, -3.7900e-01,  2.5832e-01, -1.8161e-01,\n",
            "           3.8750e-02,  0.0000e+00, -2.3959e-01, -1.2203e-01, -1.8529e-02,\n",
            "          -2.2042e-01],\n",
            "         [-1.6425e-01,  7.1375e-02,  4.7564e-02,  1.2458e-01, -7.7593e-02,\n",
            "           0.0000e+00,  2.4707e-02, -1.2113e-01, -1.1380e-01, -7.9187e-02,\n",
            "          -7.4101e-02,  4.4952e-02, -3.2598e-02, -1.7394e-01, -2.2042e-01,\n",
            "          -5.0890e-02],\n",
            "         [-0.0000e+00, -0.0000e+00,  2.6136e-02,  1.2570e-01,  2.1911e-01,\n",
            "           1.5705e-01, -1.6143e-01, -3.1784e-01,  0.0000e+00, -3.5266e-02,\n",
            "          -1.3237e-01,  3.3679e-01, -2.0042e-01,  1.3785e-01,  3.9561e-01,\n",
            "          -1.5747e-01],\n",
            "         [-1.1279e-01, -1.5219e-01,  9.7801e-02,  4.0813e-02,  2.8426e-02,\n",
            "           5.7654e-02, -4.3734e-02, -6.2298e-02, -6.5968e-02, -1.2167e-01,\n",
            "          -0.0000e+00,  6.4849e-02,  8.1602e-02, -0.0000e+00,  1.1272e-01,\n",
            "           1.3997e-02]],\n",
            "\n",
            "        [[ 1.9909e-01, -5.4632e-02, -1.4232e-01,  6.1973e-02,  5.8835e-02,\n",
            "          -5.9725e-02, -1.1966e-02,  7.0928e-02,  1.4189e-02,  1.7160e-01,\n",
            "          -3.9293e-02,  2.3533e-01, -4.8959e-02, -8.9088e-02,  1.3334e-01,\n",
            "           0.0000e+00],\n",
            "         [ 4.2767e-01,  2.7467e-01,  1.1543e-01,  1.0651e-01, -3.1467e-01,\n",
            "          -1.7216e-01,  5.8124e-02, -4.9138e-02,  0.0000e+00, -2.5793e-01,\n",
            "          -7.2218e-02,  7.3251e-02,  1.7469e-01, -3.5495e-01,  2.6203e-01,\n",
            "          -1.0456e-01],\n",
            "         [ 7.3780e-02, -1.8110e-01,  1.1546e-01,  0.0000e+00,  8.7258e-02,\n",
            "           7.0264e-02,  5.7631e-02, -8.8231e-02,  0.0000e+00,  6.0426e-02,\n",
            "          -0.0000e+00, -8.3655e-03,  1.1609e-02, -8.8824e-02,  0.0000e+00,\n",
            "           1.8684e-02],\n",
            "         [ 2.2075e-01, -9.0875e-02, -8.1975e-02, -4.4590e-01,  1.2736e-01,\n",
            "          -3.8408e-01,  1.6883e-01, -8.1663e-02, -2.6414e-01, -1.1203e-02,\n",
            "          -6.6625e-02,  1.4614e-01, -2.6727e-01,  1.0728e-01, -1.5723e-01,\n",
            "          -1.0395e-01],\n",
            "         [ 3.2236e-01, -4.8543e-02,  0.0000e+00,  1.1211e-01, -0.0000e+00,\n",
            "           3.0373e-01, -2.0155e-01, -3.6753e-01,  0.0000e+00, -2.7637e-01,\n",
            "           2.8463e-02,  1.8800e-01, -1.8429e-01, -1.4010e-02,  3.2368e-02,\n",
            "          -3.1250e-02],\n",
            "         [ 5.5584e-02, -1.9622e-01,  1.6490e-01,  1.6134e-01,  1.4218e-01,\n",
            "           1.8202e-01,  1.5735e-01, -3.6390e-01,  4.0004e-01,  1.8040e-01,\n",
            "           0.0000e+00,  9.4588e-02, -0.0000e+00, -1.2893e-01,  0.0000e+00,\n",
            "          -2.1900e-01],\n",
            "         [ 1.3247e-01,  4.7056e-02, -5.9244e-02,  1.5523e-01, -1.5450e-01,\n",
            "           3.1071e-02, -4.1701e-02, -1.4273e-01,  0.0000e+00, -3.8381e-02,\n",
            "           2.2025e-02,  0.0000e+00,  1.2512e-01, -1.8569e-01, -1.7355e-02,\n",
            "          -2.0517e-01],\n",
            "         [ 6.1876e-03, -4.8337e-04, -1.3895e-02,  4.5648e-04,  6.9341e-02,\n",
            "          -3.0030e-02, -4.4299e-03,  0.0000e+00, -8.0032e-03, -1.3502e-02,\n",
            "          -5.4373e-02, -5.9949e-02, -1.7037e-02, -3.1270e-02,  0.0000e+00,\n",
            "           6.7240e-03]],\n",
            "\n",
            "        [[ 1.2959e-01, -1.2541e-02,  2.7352e-01,  1.0319e-01,  3.4183e-02,\n",
            "           1.4690e-01, -1.5753e-02, -0.0000e+00,  4.2970e-02,  2.0017e-02,\n",
            "           2.6292e-01, -5.6960e-02, -9.7878e-02,  1.7441e-02,  1.7064e-01,\n",
            "          -3.0773e-02],\n",
            "         [-2.0723e-03, -1.8928e-01,  2.8115e-02,  6.3876e-02, -1.8837e-02,\n",
            "           9.6531e-02,  8.4911e-02, -1.4311e-01,  7.8583e-02,  5.2936e-03,\n",
            "          -1.5147e-01,  3.4100e-02,  1.8769e-01, -8.0730e-02,  5.1632e-02,\n",
            "           1.5155e-02],\n",
            "         [ 5.6422e-02, -3.7680e-02,  1.6322e-02, -5.6848e-02, -1.1438e-02,\n",
            "          -9.8330e-02, -6.7698e-02,  5.5775e-02, -1.6767e-01, -2.1067e-02,\n",
            "           1.1903e-01, -4.2821e-02, -8.2958e-02, -5.2251e-02, -4.2243e-02,\n",
            "           2.0221e-02],\n",
            "         [ 1.1304e-01, -1.4280e-01, -1.6565e-02, -4.5399e-01,  8.9314e-02,\n",
            "          -2.4449e-01,  1.1644e-01,  1.4552e-02, -2.8777e-01,  0.0000e+00,\n",
            "           5.6823e-02,  2.0142e-02, -2.7195e-01, -2.6189e-02,  6.0583e-02,\n",
            "          -4.9517e-02],\n",
            "         [-7.6577e-02, -3.9720e-02, -2.2520e-02,  1.0873e-01,  4.3109e-02,\n",
            "           0.0000e+00,  4.7761e-03, -2.8717e-01,  2.3731e-01, -3.0243e-02,\n",
            "           7.0338e-02,  0.0000e+00, -1.9702e-01, -5.6139e-02,  3.6643e-01,\n",
            "          -2.0759e-01],\n",
            "         [ 1.8061e-01, -1.6184e-01,  7.3507e-02, -2.4058e-01,  1.7651e-01,\n",
            "           0.0000e+00,  4.4814e-02, -1.7293e-01,  8.4796e-02, -2.1808e-01,\n",
            "           2.7839e-01,  1.2503e-01,  4.9513e-02, -2.0789e-01, -2.3729e-01,\n",
            "          -1.9982e-01],\n",
            "         [ 2.4804e-01, -1.4328e-01, -1.5655e-01, -2.3366e-01,  6.7683e-02,\n",
            "          -2.4412e-01,  2.8363e-02,  6.0197e-02, -2.8017e-01,  2.1936e-02,\n",
            "          -1.0630e-01, -1.4266e-01, -1.4755e-01,  2.1167e-01, -3.1427e-02,\n",
            "          -5.1615e-02],\n",
            "         [ 0.0000e+00, -0.0000e+00, -1.3070e-01,  3.1359e-02, -5.5229e-02,\n",
            "          -2.0509e-01, -0.0000e+00,  1.1720e-02,  2.4307e-03,  1.2226e-01,\n",
            "          -3.0287e-02,  6.5225e-02, -1.9175e-01, -2.9577e-03,  1.0795e-02,\n",
            "           1.4123e-01]]], grad_fn=<ViewBackward0>)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "#Let's test this out\n",
        "num_experts = 8\n",
        "top_k = 2\n",
        "n_embd = 16\n",
        "dropout=0.1\n",
        "\n",
        "mh_output = torch.randn(4, 8, n_embd)  # Example multi-head attention output\n",
        "sparse_moe = SparseMoE(n_embd, num_experts, top_k)\n",
        "final_output = sparse_moe(mh_output)\n",
        "print(\"Shape of the final output:\", final_output.shape)\n",
        "print(final_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "7476ca07-a315-4108-aa77-46173a703ca2",
          "showTitle": false,
          "title": ""
        },
        "id": "l7GoxCi2kRJj"
      },
      "source": [
        "强调一下，需要认识到路由器/门控网络输出的前k个专家的幅值，正如上面的代码所示，也是非常重要的。这些前k个索引确定了被激活的专家，而在这些前k个维度中数值的大小决定了它们各自的权重。这种加权求和的概念在下面的图示中进一步强调了。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "d99b5dce-301e-4380-8263-b5cfb4136ab2",
          "showTitle": false,
          "title": ""
        },
        "id": "e9a_oQ2akRJj"
      },
      "source": [
        "![sparse MoE](https://raw.githubusercontent.com/AviSoori1x/makeMoE/main/images/sparseMoEfinal.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 引入专家容量 （Expert Capacity factor）\n",
        "\n",
        "from: https://huggingface.co/blog/AviSoori1x/makemoe2\n",
        "\n",
        "\n",
        "\n",
        "在预训练混合专家语言模型或任何大型语言模型时，该过程通常跨越多个GPU，并且通常涉及许多机器。跨这些硬件资源并行训练的方式对于平衡计算负载至关重要。然而，如果某些专家或一组专家过度受到偏爱——反映出对开发的偏好超过探索——它不仅可能导致模型中的性能问题，还可能导致集群中的计算负载不平衡。\n",
        "\n",
        "[Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity](https://arxiv.org/abs/2101.03961) 实现使用专家容量来规避这个问题。专家容量确定每个专家在训练或推理过程中负责处理多少个标记。它是基于批次中的标记数和可用专家的数量定义的，通常通过容量因子进行调整。该因子允许在分配中灵活性，提供缓冲区以考虑数据分布的变化，并确保没有单个专家由于过载而成为瓶颈。在训练这些大型模型时，硬件故障是很常见的，可能持续数周甚至数月，因此这一点非常重要。\n",
        "\n",
        "以下是专家容量通常计算的方式：\n",
        "\n",
        "专家容量 = （每批标记数 / 专家数量）× 容量因子 其中：\n",
        "```python\n",
        "expert_capacity = int((tokens_per_batch / self.num_experts) * self.capacity_factor)\n",
        "```\n",
        "\n",
        "- 每批标记数是需要处理的批次中存在的总标记数。\n",
        "- 专家数量是MoE层中可用于处理数据的专家总数。\n",
        "- 容量因子是用于调整基础容量（每批标记数除以专家数量）的乘数。大于1的容量因子允许每个专家处理超出均匀分配份额的缓冲区，适应标记分配的不平衡。该值的一般范围为1-1.25。\n",
        "\n",
        "以下代码块进行了轻微调整，以实现专家容量的简单版本。"
      ],
      "metadata": {
        "id": "Xzd2KhXDnHMl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SparseMoE(nn.Module):\n",
        "    def __init__(self, n_embed, num_experts, top_k, capacity_factor=1.0):\n",
        "        super(SparseMoE, self).__init__()\n",
        "        self.router = NoisyTopkRouter(n_embed, num_experts, top_k)\n",
        "        self.experts = nn.ModuleList([Expert(n_embed) for _ in range(num_experts)])\n",
        "        self.top_k = top_k\n",
        "        # add capacity_factor\n",
        "        self.capacity_factor = capacity_factor\n",
        "        self.num_experts = num_experts\n",
        "\n",
        "    def forward(self, x):\n",
        "    # Assuming x has shape [batch_size, seq_len, n_embd]\n",
        "        batch_size, seq_len, _ = x.shape\n",
        "        gating_output, indices = self.router(x)\n",
        "        final_output = torch.zeros_like(x)\n",
        "\n",
        "        # Flatten the batch and sequence dimensions to treat each token independently\n",
        "        flat_x = x.view(-1, x.size(-1))  # Now shape [batch_size * seq_len, n_embd]\n",
        "        flat_gating_output = gating_output.view(-1, gating_output.size(-1))\n",
        "\n",
        "        tokens_per_batch = batch_size * seq_len * self.top_k\n",
        "        expert_capacity = int((tokens_per_batch / self.num_experts) * self.capacity_factor)\n",
        "\n",
        "        updates = torch.zeros_like(flat_x)\n",
        "\n",
        "        for i, expert in enumerate(self.experts):\n",
        "            expert_mask = (indices == i).any(dim=-1)\n",
        "            flat_mask = expert_mask.view(-1)\n",
        "            selected_indices = torch.nonzero(flat_mask).squeeze(-1)\n",
        "\n",
        "            limited_indices = selected_indices[:expert_capacity] if selected_indices.numel() > expert_capacity else selected_indices\n",
        "            if limited_indices.numel() > 0:\n",
        "                expert_input = flat_x[limited_indices]\n",
        "                expert_output = expert(expert_input)\n",
        "\n",
        "                gating_scores = flat_gating_output[limited_indices, i].unsqueeze(1)\n",
        "                weighted_output = expert_output * gating_scores\n",
        "\n",
        "                updates.index_add_(0, limited_indices, weighted_output)\n",
        "\n",
        "        # Reshape updates to match the original dimensions of x\n",
        "        final_output += updates.view(batch_size, seq_len, -1)\n",
        "\n",
        "        return final_output\n"
      ],
      "metadata": {
        "id": "HjoVac7Rood3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "#Let's test this out\n",
        "num_experts = 8\n",
        "top_k = 2\n",
        "n_embd = 16\n",
        "dropout=0.1\n",
        "\n",
        "mh_output = torch.randn(4, 8, n_embd)  # Example multi-head attention output\n",
        "sparse_moe = SparseMoE(n_embd, num_experts, top_k)\n",
        "final_output = sparse_moe(mh_output)\n",
        "print(\"Shape of the final output:\", final_output.shape)\n",
        "print(final_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HelPhgxrosLK",
        "outputId": "28823777-ed8c-443a-f9f1-f87053467224"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the final output: torch.Size([4, 8, 16])\n",
            "tensor([[[-3.5722e-01, -1.3390e-01, -1.6325e-02,  1.7276e-01, -2.5636e-01,\n",
            "          -4.1547e-01, -1.8428e-01, -1.5751e-02,  2.9630e-01,  6.9809e-01,\n",
            "           2.3957e-01,  1.5463e-01,  6.6850e-02,  2.4940e-01,  4.2901e-02,\n",
            "           2.0160e-01],\n",
            "         [-2.0037e-02, -3.5741e-01,  1.5479e-02, -3.2197e-02, -1.2265e-01,\n",
            "          -3.1884e-01,  3.6934e-01,  1.3128e-01, -3.0285e-01,  6.5855e-02,\n",
            "           2.0220e-01,  2.2506e-01, -8.7406e-02,  6.8335e-02, -1.4265e-01,\n",
            "          -5.9764e-02],\n",
            "         [ 1.7053e-01, -2.3422e-01, -8.7309e-02,  1.5202e-02, -2.0610e-01,\n",
            "           3.6808e-02, -1.5263e-02,  1.3630e-01, -2.4305e-01,  2.5814e-01,\n",
            "           3.2146e-01,  1.4372e-01, -9.4800e-02,  2.6351e-01, -2.3752e-01,\n",
            "          -3.0728e-01],\n",
            "         [ 5.0747e-02,  1.5875e-01, -1.1585e-01,  2.4825e-01, -3.7508e-01,\n",
            "          -6.2614e-02, -1.1955e-01, -1.1710e-01, -1.1893e-01, -9.9588e-02,\n",
            "          -7.5261e-02, -1.3952e-01,  1.1587e-01, -1.6303e-02, -1.6832e-02,\n",
            "           6.3666e-02],\n",
            "         [-1.1854e-01, -9.5332e-02,  1.4992e-01, -2.6732e-02, -1.6122e-01,\n",
            "           7.3706e-02, -2.0557e-01, -1.3623e-01,  1.3443e-01,  1.0410e-02,\n",
            "          -1.2624e-02,  1.1136e-01,  2.9136e-01, -2.7448e-01, -6.6973e-02,\n",
            "          -1.2816e-01],\n",
            "         [-5.5494e-02, -4.0418e-02, -2.3583e-01, -3.6057e-01, -4.0295e-01,\n",
            "           4.5055e-01,  1.4961e-02, -1.6489e-01,  6.9823e-02,  0.0000e+00,\n",
            "          -1.6001e-01,  4.6828e-01,  2.2320e-01, -2.2072e-01,  2.2897e-01,\n",
            "           5.7887e-02],\n",
            "         [ 1.9105e-01,  0.0000e+00,  3.6134e-01,  9.3091e-03,  4.4369e-02,\n",
            "           1.0767e-01, -9.5551e-02, -1.1714e-01, -2.1449e-01, -1.7341e-01,\n",
            "           3.0770e-02,  1.1846e-01, -8.0314e-02,  3.7679e-02, -6.3963e-02,\n",
            "           3.0521e-01],\n",
            "         [ 1.8371e-01, -3.0597e-01,  2.7904e-02, -2.6637e-01, -3.8252e-01,\n",
            "           3.6903e-03, -2.2482e-01,  1.2493e-01, -2.2349e-02,  5.4330e-01,\n",
            "          -1.1874e-01, -8.8619e-02,  2.3384e-01, -3.7183e-01, -2.2391e-02,\n",
            "          -1.3880e-01]],\n",
            "\n",
            "        [[-1.2127e-03, -3.0186e-01, -3.9040e-02, -4.0261e-01,  2.7371e-01,\n",
            "           1.3510e-03, -2.2819e-01, -2.1938e-02, -9.8992e-02,  6.1104e-01,\n",
            "           4.8285e-01,  4.4269e-01, -2.0429e-01,  6.0879e-01,  5.0046e-02,\n",
            "          -1.3009e-02],\n",
            "         [ 6.8735e-02,  2.3016e-01,  5.7200e-01,  3.3122e-01, -5.5289e-02,\n",
            "          -4.7248e-01,  3.9311e-01,  2.0295e-01,  3.9140e-01,  5.5031e-01,\n",
            "          -1.5993e-01,  6.1971e-01,  8.6209e-02, -9.1343e-01,  2.8290e-01,\n",
            "          -2.2300e-01],\n",
            "         [ 2.0112e-01, -1.7303e-01, -1.8186e-01,  8.8711e-02,  9.9982e-02,\n",
            "           8.7868e-02,  9.5545e-02,  1.1347e-01, -3.4244e-02,  2.5857e-01,\n",
            "          -1.0059e-01,  1.6983e-01,  1.5058e-01, -2.4727e-01,  1.5176e-01,\n",
            "           3.9505e-03],\n",
            "         [ 2.1273e-01,  2.8651e-01, -2.4591e-01, -5.5826e-02,  2.1467e-01,\n",
            "           1.7581e-01, -3.6564e-01, -8.5423e-02,  1.3730e-02,  2.2598e-01,\n",
            "          -1.5183e-01,  3.0886e-01,  1.1180e-01, -9.0466e-02,  6.5236e-04,\n",
            "          -1.2481e-01],\n",
            "         [-9.0026e-02,  2.9133e-01,  1.6299e-01,  8.6368e-02,  3.4418e-01,\n",
            "          -2.7040e-02, -3.1690e-01,  4.3981e-02, -1.4976e-01,  1.9212e-01,\n",
            "          -2.6817e-01,  4.7925e-01,  2.4940e-01,  9.5155e-02,  1.2684e-01,\n",
            "          -3.5688e-01],\n",
            "         [-7.4826e-02,  7.8406e-02, -3.9308e-01, -2.0571e-01,  1.4417e-01,\n",
            "          -2.0751e-01,  2.3407e-01,  2.4087e-02, -1.3546e-01,  6.1515e-02,\n",
            "          -7.9608e-02,  4.7558e-01, -2.8759e-02,  1.3169e-01, -1.0208e-01,\n",
            "          -9.5407e-02],\n",
            "         [ 2.7498e-01,  3.5555e-01, -1.0802e-01, -6.6859e-02,  9.9755e-02,\n",
            "           2.7387e-01, -4.2974e-01,  1.7427e-03, -2.2620e-01, -1.0821e-01,\n",
            "          -2.1051e-01, -1.0743e-01,  1.6843e-01, -1.6166e-01,  1.4167e-01,\n",
            "          -9.9434e-03],\n",
            "         [ 6.2288e-02, -1.7645e-01, -1.9819e-02, -1.0577e-01, -4.0227e-01,\n",
            "          -5.9308e-02,  1.1494e-02, -9.5908e-02,  8.9023e-02,  1.6235e-02,\n",
            "          -7.3075e-02,  5.6287e-02,  5.8182e-02, -5.8441e-02, -4.7858e-02,\n",
            "           5.6381e-02]],\n",
            "\n",
            "        [[ 1.2070e-01,  3.6185e-01, -2.4380e-01,  2.8376e-02, -3.1915e-02,\n",
            "           3.7587e-01, -4.2807e-01,  1.7924e-01,  2.7197e-01,  6.1618e-02,\n",
            "          -4.2786e-02, -2.0876e-01,  9.0295e-02, -7.3400e-02,  6.3298e-02,\n",
            "           1.0727e-01],\n",
            "         [ 4.2535e-02, -3.8047e-01, -4.2227e-02,  3.5948e-02,  3.8296e-02,\n",
            "           3.4998e-01, -1.2004e-01,  1.8886e-01,  3.4236e-03,  4.0622e-02,\n",
            "          -2.8479e-01,  3.0352e-02,  2.0454e-01, -2.6564e-01,  1.1686e-01,\n",
            "          -2.1365e-01],\n",
            "         [ 8.3094e-02, -1.8512e-01,  1.6882e-01, -1.6071e-01,  1.2518e-02,\n",
            "           1.7868e-01,  7.3816e-02,  0.0000e+00, -2.8488e-01,  6.5212e-03,\n",
            "          -9.1533e-02,  0.0000e+00,  1.0976e-01,  1.0723e-01, -2.3036e-01,\n",
            "           0.0000e+00],\n",
            "         [ 2.0464e-01, -7.2604e-02,  1.4966e-03,  1.9504e-01, -2.4623e-02,\n",
            "           0.0000e+00,  4.9748e-02,  7.7617e-02, -1.6457e-01,  1.4470e-01,\n",
            "           1.8670e-01,  2.7692e-01, -5.6197e-02,  1.4130e-01, -4.0462e-01,\n",
            "           0.0000e+00],\n",
            "         [-5.5396e-02, -1.3821e-01,  2.4645e-02, -1.6429e-02, -1.0088e-02,\n",
            "          -8.7790e-03,  8.7217e-02,  3.8221e-02, -1.3725e-02, -1.0330e-02,\n",
            "           0.0000e+00,  4.3647e-02,  1.5756e-01,  2.8870e-02,  9.2301e-02,\n",
            "           1.1474e-01],\n",
            "         [-3.2187e-02, -1.8918e-02, -4.1884e-02,  2.7526e-02,  0.0000e+00,\n",
            "           9.6381e-02, -6.8566e-03, -3.2355e-02, -5.3716e-02,  5.6272e-02,\n",
            "          -1.0635e-02,  5.0553e-02,  3.4774e-02, -6.5077e-02,  1.8228e-02,\n",
            "           0.0000e+00],\n",
            "         [ 5.6278e-01,  1.5406e-01,  7.4496e-01,  4.5093e-01,  1.7307e-02,\n",
            "          -1.6672e-01,  1.3545e-01, -6.5974e-02, -1.0834e-01, -1.4784e-01,\n",
            "          -9.9336e-02,  8.9192e-03, -1.6672e-01, -4.7751e-01, -1.6136e-02,\n",
            "          -7.4218e-02],\n",
            "         [ 6.6047e-02, -2.4342e-02,  9.7768e-02, -2.7943e-01, -1.5360e-01,\n",
            "          -8.0265e-02,  1.5235e-02, -1.8867e-01,  1.8981e-01,  1.7080e-01,\n",
            "           1.1034e-01, -1.3866e-01,  3.5763e-02, -5.2839e-01,  3.3523e-02,\n",
            "           6.3563e-02]],\n",
            "\n",
            "        [[ 9.2417e-02, -6.8603e-02,  2.0491e-01, -1.2908e-01, -1.2395e-01,\n",
            "          -1.0440e-01,  2.9029e-01, -8.0500e-02, -1.3599e-01,  1.6580e-01,\n",
            "          -2.7816e-01, -2.0607e-01,  1.1956e-01, -2.8282e-01, -1.9947e-01,\n",
            "           1.3901e-01],\n",
            "         [-6.2829e-02, -4.6854e-01, -4.0450e-01,  1.3014e-03,  3.9803e-02,\n",
            "           1.3268e-01, -3.7377e-01,  1.7724e-01,  3.0351e-02, -4.7244e-02,\n",
            "          -3.5003e-01,  1.4385e-01,  2.6119e-01,  1.2266e-01, -4.4535e-02,\n",
            "          -4.7720e-01],\n",
            "         [ 4.7890e-02, -1.6649e-03,  1.6830e-01,  7.5287e-02,  3.7703e-02,\n",
            "          -5.7790e-02,  2.5756e-02, -8.8465e-02, -7.6484e-02,  0.0000e+00,\n",
            "           0.0000e+00,  2.7548e-02, -2.5429e-02, -1.0680e-02, -6.4151e-02,\n",
            "           1.6714e-01],\n",
            "         [ 4.8777e-02, -8.4127e-02, -3.9179e-02,  0.0000e+00,  0.0000e+00,\n",
            "           5.1292e-02, -6.6114e-03, -4.9745e-02, -1.2014e-01, -8.9618e-02,\n",
            "          -3.6761e-02, -5.9018e-02, -5.0422e-02,  6.9415e-03, -1.3764e-01,\n",
            "          -1.1773e-02],\n",
            "         [-9.0325e-02, -5.0812e-02,  3.4936e-02,  0.0000e+00, -1.3659e-01,\n",
            "           1.1808e-01,  4.7371e-02,  2.8594e-03, -4.3700e-04,  5.6052e-02,\n",
            "          -3.0543e-04, -7.1317e-04, -3.8340e-02, -1.5841e-02, -4.2449e-02,\n",
            "           5.0599e-03],\n",
            "         [ 2.1451e-01,  3.2898e-01, -3.5588e-01,  1.4907e-02,  0.0000e+00,\n",
            "           1.9728e-01,  3.4049e-02,  0.0000e+00, -2.7289e-01,  4.0811e-01,\n",
            "          -8.6127e-02,  6.6225e-02,  2.5166e-01,  1.5779e-01,  0.0000e+00,\n",
            "           1.0327e-01],\n",
            "         [-2.5066e-01,  1.3774e-02,  2.6317e-01, -2.9496e-02, -3.2117e-02,\n",
            "           2.1495e-03,  1.1495e-01,  6.4096e-02,  0.0000e+00, -1.1373e-01,\n",
            "          -1.1129e-02,  0.0000e+00,  8.8425e-02, -6.6171e-02,  5.3552e-02,\n",
            "          -8.3118e-02],\n",
            "         [-1.1944e-01,  2.7196e-02, -2.4482e-01, -4.9283e-02,  0.0000e+00,\n",
            "           1.9447e-01,  1.2467e-03, -4.0370e-03,  1.9032e-02, -6.0761e-03,\n",
            "          -1.3358e-02,  9.4730e-02, -3.8353e-02, -3.7244e-02, -1.2803e-01,\n",
            "           0.0000e+00]]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "da5f3be4-f155-4d6c-bcbd-2f88a088261f",
          "showTitle": false,
          "title": ""
        },
        "id": "vMZCda7dkRJj"
      },
      "source": [
        "## Putting it all together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "0eaf71cd-c77e-40c7-b5be-e364e91685cf",
          "showTitle": false,
          "title": ""
        },
        "id": "f8yczkFHkRJj"
      },
      "outputs": [],
      "source": [
        "#First defining hyperparameters and boiler plate code. Imports and data preparation code is repeated for convenience\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torch.nn import init\n",
        "\n",
        "# hyperparameters\n",
        "batch_size = 16 # how many independent sequences will we process in parallel?\n",
        "block_size = 32 # what is the maximum context length for predictions?\n",
        "max_iters = 5000\n",
        "eval_interval = 100\n",
        "learning_rate = 1e-3\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 400\n",
        "head_size = 16\n",
        "n_embed = 128\n",
        "n_head = 8\n",
        "n_layer = 8\n",
        "dropout = 0.1\n",
        "num_experts = 8\n",
        "top_k = 2\n",
        "# ------------\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "with open('input.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "\n",
        "# here are all the unique characters that occur in this text\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "# create a mapping from characters to integers\n",
        "stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "itos = { i:ch for i,ch in enumerate(chars) }\n",
        "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
        "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
        "\n",
        "# Train and test splits\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "# data loading\n",
        "def get_batch(split):\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "ee1180f7-5004-4425-87fe-9a81a17b9024",
          "showTitle": false,
          "title": ""
        },
        "id": "QfxJ6B2fkRJj"
      },
      "outputs": [],
      "source": [
        "class Head(nn.Module):\n",
        "    \"\"\" one head of self-attention \"\"\"\n",
        "\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embed, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embed, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embed, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B,T,C = x.shape\n",
        "        k = self.key(x)   # (B,T,C)\n",
        "        q = self.query(x) # (B,T,C)\n",
        "        # compute attention scores (\"affinities\")\n",
        "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
        "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
        "        wei = self.dropout(wei)\n",
        "        # perform the weighted aggregation of the values\n",
        "        v = self.value(x) # (B,T,C)\n",
        "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
        "        return out\n",
        "\n",
        "#Multi-Headed Self Attention\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
        "\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(n_embed, n_embed)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "03611a92-aaa2-4e0d-9755-cba56f96c794",
          "showTitle": false,
          "title": ""
        },
        "id": "y35jVCZYkRJk"
      },
      "outputs": [],
      "source": [
        "#Expert module\n",
        "class Expert(nn.Module):\n",
        "    \"\"\" An MLP is a simple linear layer followed by a non-linearity i.e. each Expert \"\"\"\n",
        "\n",
        "    def __init__(self, n_embed):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embed, 4 * n_embed),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embed, n_embed),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "#noisy top-k gating\n",
        "class NoisyTopkRouter(nn.Module):\n",
        "    def __init__(self, n_embed, num_experts, top_k):\n",
        "        super(NoisyTopkRouter, self).__init__()\n",
        "        self.top_k = top_k\n",
        "        #layer for router logits\n",
        "        self.topkroute_linear = nn.Linear(n_embed, num_experts)\n",
        "        self.noise_linear =nn.Linear(n_embed, num_experts)\n",
        "\n",
        "\n",
        "    def forward(self, mh_output):\n",
        "        # mh_ouput is the output tensor from multihead self attention block\n",
        "        logits = self.topkroute_linear(mh_output)\n",
        "\n",
        "        #Noise logits\n",
        "        noise_logits = self.noise_linear(mh_output)\n",
        "\n",
        "        #Adding scaled unit gaussian noise to the logits\n",
        "        noise = torch.randn_like(logits)*F.softplus(noise_logits)\n",
        "        noisy_logits = logits + noise\n",
        "\n",
        "        top_k_logits, indices = noisy_logits.topk(self.top_k, dim=-1)\n",
        "        zeros = torch.full_like(noisy_logits, float('-inf'))\n",
        "        sparse_logits = zeros.scatter(-1, indices, top_k_logits)\n",
        "        router_output = F.softmax(sparse_logits, dim=-1)\n",
        "        return router_output, indices\n",
        "\n",
        "#Now create the sparse mixture of experts module\n",
        "class SparseMoE(nn.Module):\n",
        "    def __init__(self, n_embed, num_experts, top_k, capacity_factor=1.0):\n",
        "        super(SparseMoE, self).__init__()\n",
        "        self.router = NoisyTopkRouter(n_embed, num_experts, top_k)\n",
        "        self.experts = nn.ModuleList([Expert(n_embed) for _ in range(num_experts)])\n",
        "        self.top_k = top_k\n",
        "        # add capacity_factor\n",
        "        self.capacity_factor = capacity_factor\n",
        "        self.num_experts = num_experts\n",
        "\n",
        "    def forward(self, x):\n",
        "    # Assuming x has shape [batch_size, seq_len, n_embd]\n",
        "        batch_size, seq_len, _ = x.shape\n",
        "        gating_output, indices = self.router(x)\n",
        "        final_output = torch.zeros_like(x)\n",
        "\n",
        "        # Flatten the batch and sequence dimensions to treat each token independently\n",
        "        flat_x = x.view(-1, x.size(-1))  # Now shape [batch_size * seq_len, n_embd]\n",
        "        flat_gating_output = gating_output.view(-1, gating_output.size(-1))\n",
        "\n",
        "        tokens_per_batch = batch_size * seq_len * self.top_k\n",
        "        expert_capacity = int((tokens_per_batch / self.num_experts) * self.capacity_factor)\n",
        "\n",
        "        updates = torch.zeros_like(flat_x)\n",
        "\n",
        "        for i, expert in enumerate(self.experts):\n",
        "            expert_mask = (indices == i).any(dim=-1)\n",
        "            flat_mask = expert_mask.view(-1)\n",
        "            selected_indices = torch.nonzero(flat_mask).squeeze(-1)\n",
        "\n",
        "            limited_indices = selected_indices[:expert_capacity] if selected_indices.numel() > expert_capacity else selected_indices\n",
        "            if limited_indices.numel() > 0:\n",
        "                expert_input = flat_x[limited_indices]\n",
        "                expert_output = expert(expert_input)\n",
        "\n",
        "                gating_scores = flat_gating_output[limited_indices, i].unsqueeze(1)\n",
        "                weighted_output = expert_output * gating_scores\n",
        "\n",
        "                updates.index_add_(0, limited_indices, weighted_output)\n",
        "\n",
        "        # Reshape updates to match the original dimensions of x\n",
        "        final_output += updates.view(batch_size, seq_len, -1)\n",
        "\n",
        "        return final_output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "bfdff2bb-092f-41c8-9a33-c84e6f8d6633",
          "showTitle": false,
          "title": ""
        },
        "id": "jGiuRsSgkRJk"
      },
      "outputs": [],
      "source": [
        "#First create a self attention + mixture of experts block, that may be repeated several number of times\n",
        "#Copy pasting key architecture variables for clarity\n",
        "\n",
        "class Block(nn.Module):\n",
        "    \"\"\" Mixture of Experts Transformer block: communication followed by computation (multi-head self attention + SparseMoE) \"\"\"\n",
        "\n",
        "    def __init__(self, n_embed, n_head, num_experts, top_k):\n",
        "        # n_embed: embedding dimension, n_head: the number of heads we'd like\n",
        "        super().__init__()\n",
        "        head_size = n_embed // n_head\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)\n",
        "        self.smoe = SparseMoE(n_embed, num_experts, top_k)\n",
        "        self.ln1 = nn.LayerNorm(n_embed)\n",
        "        self.ln2 = nn.LayerNorm(n_embed)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.sa(self.ln1(x))\n",
        "        x = x + self.smoe(self.ln2(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "2d32a276-d0cc-4808-90d7-62441771af44",
          "showTitle": false,
          "title": ""
        },
        "id": "RpyZBA71kRJk"
      },
      "outputs": [],
      "source": [
        "#Finally putting it all together to crease a sparse mixture of experts language model\n",
        "class SparseMoELanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # each token directly reads off the logits for the next token from a lookup table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embed)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embed)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embed, n_head=n_head, num_experts=num_experts,top_k=top_k) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embed) # final layer norm\n",
        "        self.lm_head = nn.Linear(n_embed, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
        "        x = tok_emb + pos_emb # (B,T,C)\n",
        "        x = self.blocks(x) # (B,T,C)\n",
        "        x = self.ln_f(x) # (B,T,C)\n",
        "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # crop idx to the last block_size tokens\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_cond)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "622ba7ce-3f20-4820-8982-93f3d3b7be09",
          "showTitle": false,
          "title": ""
        },
        "id": "bBzQXmfykRJk"
      },
      "source": [
        "这里使用Kaiming He初始化，因为专家中存在ReLU激活函数。可以随意尝试使用更常用于Transformer的Glorot初始化。Jeremy Howard的Fastai第2部分有一个非常出色的讲座，从零开始实现了这些初始化方法：https://course.fast.ai/Lessons/lesson17.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "a6d3c057-08ee-4c1b-8013-6a88b2eadac5",
          "showTitle": false,
          "title": ""
        },
        "id": "guGaJqHbkRJk"
      },
      "outputs": [],
      "source": [
        "\n",
        "def kaiming_init_weights(m):\n",
        "    if isinstance (m, (nn.Linear)):\n",
        "        init.kaiming_normal_(m.weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "5b4d9525-8405-4a51-adda-661aba004e57",
          "showTitle": false,
          "title": ""
        },
        "id": "nJGGkXz4kRJl",
        "outputId": "873b45f3-6731-4d8e-fff8-a711e105c9ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SparseMoELanguageModel(\n",
              "  (token_embedding_table): Embedding(65, 128)\n",
              "  (position_embedding_table): Embedding(32, 128)\n",
              "  (blocks): Sequential(\n",
              "    (0): Block(\n",
              "      (sa): MultiHeadAttention(\n",
              "        (heads): ModuleList(\n",
              "          (0-7): 8 x Head(\n",
              "            (key): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (query): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (value): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (smoe): SparseMoE(\n",
              "        (router): NoisyTopkRouter(\n",
              "          (topkroute_linear): Linear(in_features=128, out_features=8, bias=True)\n",
              "          (noise_linear): Linear(in_features=128, out_features=8, bias=True)\n",
              "        )\n",
              "        (experts): ModuleList(\n",
              "          (0-7): 8 x Expert(\n",
              "            (net): Sequential(\n",
              "              (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "              (1): ReLU()\n",
              "              (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "              (3): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (1): Block(\n",
              "      (sa): MultiHeadAttention(\n",
              "        (heads): ModuleList(\n",
              "          (0-7): 8 x Head(\n",
              "            (key): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (query): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (value): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (smoe): SparseMoE(\n",
              "        (router): NoisyTopkRouter(\n",
              "          (topkroute_linear): Linear(in_features=128, out_features=8, bias=True)\n",
              "          (noise_linear): Linear(in_features=128, out_features=8, bias=True)\n",
              "        )\n",
              "        (experts): ModuleList(\n",
              "          (0-7): 8 x Expert(\n",
              "            (net): Sequential(\n",
              "              (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "              (1): ReLU()\n",
              "              (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "              (3): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (2): Block(\n",
              "      (sa): MultiHeadAttention(\n",
              "        (heads): ModuleList(\n",
              "          (0-7): 8 x Head(\n",
              "            (key): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (query): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (value): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (smoe): SparseMoE(\n",
              "        (router): NoisyTopkRouter(\n",
              "          (topkroute_linear): Linear(in_features=128, out_features=8, bias=True)\n",
              "          (noise_linear): Linear(in_features=128, out_features=8, bias=True)\n",
              "        )\n",
              "        (experts): ModuleList(\n",
              "          (0-7): 8 x Expert(\n",
              "            (net): Sequential(\n",
              "              (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "              (1): ReLU()\n",
              "              (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "              (3): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (3): Block(\n",
              "      (sa): MultiHeadAttention(\n",
              "        (heads): ModuleList(\n",
              "          (0-7): 8 x Head(\n",
              "            (key): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (query): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (value): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (smoe): SparseMoE(\n",
              "        (router): NoisyTopkRouter(\n",
              "          (topkroute_linear): Linear(in_features=128, out_features=8, bias=True)\n",
              "          (noise_linear): Linear(in_features=128, out_features=8, bias=True)\n",
              "        )\n",
              "        (experts): ModuleList(\n",
              "          (0-7): 8 x Expert(\n",
              "            (net): Sequential(\n",
              "              (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "              (1): ReLU()\n",
              "              (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "              (3): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (4): Block(\n",
              "      (sa): MultiHeadAttention(\n",
              "        (heads): ModuleList(\n",
              "          (0-7): 8 x Head(\n",
              "            (key): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (query): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (value): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (smoe): SparseMoE(\n",
              "        (router): NoisyTopkRouter(\n",
              "          (topkroute_linear): Linear(in_features=128, out_features=8, bias=True)\n",
              "          (noise_linear): Linear(in_features=128, out_features=8, bias=True)\n",
              "        )\n",
              "        (experts): ModuleList(\n",
              "          (0-7): 8 x Expert(\n",
              "            (net): Sequential(\n",
              "              (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "              (1): ReLU()\n",
              "              (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "              (3): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (5): Block(\n",
              "      (sa): MultiHeadAttention(\n",
              "        (heads): ModuleList(\n",
              "          (0-7): 8 x Head(\n",
              "            (key): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (query): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (value): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (smoe): SparseMoE(\n",
              "        (router): NoisyTopkRouter(\n",
              "          (topkroute_linear): Linear(in_features=128, out_features=8, bias=True)\n",
              "          (noise_linear): Linear(in_features=128, out_features=8, bias=True)\n",
              "        )\n",
              "        (experts): ModuleList(\n",
              "          (0-7): 8 x Expert(\n",
              "            (net): Sequential(\n",
              "              (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "              (1): ReLU()\n",
              "              (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "              (3): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (6): Block(\n",
              "      (sa): MultiHeadAttention(\n",
              "        (heads): ModuleList(\n",
              "          (0-7): 8 x Head(\n",
              "            (key): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (query): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (value): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (smoe): SparseMoE(\n",
              "        (router): NoisyTopkRouter(\n",
              "          (topkroute_linear): Linear(in_features=128, out_features=8, bias=True)\n",
              "          (noise_linear): Linear(in_features=128, out_features=8, bias=True)\n",
              "        )\n",
              "        (experts): ModuleList(\n",
              "          (0-7): 8 x Expert(\n",
              "            (net): Sequential(\n",
              "              (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "              (1): ReLU()\n",
              "              (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "              (3): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (7): Block(\n",
              "      (sa): MultiHeadAttention(\n",
              "        (heads): ModuleList(\n",
              "          (0-7): 8 x Head(\n",
              "            (key): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (query): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (value): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (smoe): SparseMoE(\n",
              "        (router): NoisyTopkRouter(\n",
              "          (topkroute_linear): Linear(in_features=128, out_features=8, bias=True)\n",
              "          (noise_linear): Linear(in_features=128, out_features=8, bias=True)\n",
              "        )\n",
              "        (experts): ModuleList(\n",
              "          (0-7): 8 x Expert(\n",
              "            (net): Sequential(\n",
              "              (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "              (1): ReLU()\n",
              "              (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "              (3): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (ln_f): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "  (lm_head): Linear(in_features=128, out_features=65, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "model = SparseMoELanguageModel()\n",
        "model.apply(kaiming_init_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "6adf1d04-e668-4d14-b691-161ea4e4dccf",
          "showTitle": false,
          "title": ""
        },
        "id": "_cb1-L8ckRJl"
      },
      "source": [
        "我已经使用mlflow来跟踪和记录我关心的指标和训练超参数。下一个单元格中的训练循环包括了这个mlflow代码。如果您更愿意在不使用mlflow代码的情况下进行训练，后续的单元格中有没有mlflow代码的代码。然而，我发现跟踪参数和指标非常方便，特别是在进行实验时。\n",
        "\n",
        "tips: 这类监控训练过程的工具还有wandb，每次训练记录很方便，可以对比每次训练过程"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "b8968247-0d7b-4460-b96b-06743b31c55d",
          "showTitle": false,
          "title": ""
        },
        "id": "WTG1Fv4SkRJl",
        "outputId": "8d2a0e49-31f8-495c-ace2-1249e6b02b10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8.996545 M parameters\n",
            "step 0: train loss 5.3201, val loss 5.3154\n",
            "step 100: train loss 2.7364, val loss 2.7481\n",
            "step 200: train loss 2.5348, val loss 2.5318\n",
            "step 300: train loss 2.4289, val loss 2.4485\n",
            "step 400: train loss 2.3501, val loss 2.3630\n",
            "step 500: train loss 2.2789, val loss 2.2926\n",
            "step 600: train loss 2.2148, val loss 2.2323\n",
            "step 700: train loss 2.1566, val loss 2.1882\n",
            "step 800: train loss 2.1067, val loss 2.1496\n",
            "step 900: train loss 2.0497, val loss 2.1107\n",
            "step 1000: train loss 2.0178, val loss 2.0855\n",
            "step 1100: train loss 1.9949, val loss 2.0601\n",
            "step 1200: train loss 1.9490, val loss 2.0268\n",
            "step 1300: train loss 1.9402, val loss 2.0330\n",
            "step 1400: train loss 1.9035, val loss 2.0073\n",
            "step 1500: train loss 1.8766, val loss 1.9852\n",
            "step 1600: train loss 1.8536, val loss 1.9750\n",
            "step 1700: train loss 1.8252, val loss 1.9609\n",
            "step 1800: train loss 1.8165, val loss 1.9436\n",
            "step 1900: train loss 1.7959, val loss 1.9202\n",
            "step 2000: train loss 1.7802, val loss 1.9204\n",
            "step 2100: train loss 1.7701, val loss 1.8937\n",
            "step 2200: train loss 1.7615, val loss 1.8930\n",
            "step 2300: train loss 1.7408, val loss 1.8797\n",
            "step 2400: train loss 1.7328, val loss 1.8854\n",
            "step 2500: train loss 1.7226, val loss 1.8829\n",
            "step 2600: train loss 1.7148, val loss 1.8561\n",
            "step 2700: train loss 1.7045, val loss 1.8619\n",
            "step 2800: train loss 1.6921, val loss 1.8596\n",
            "step 2900: train loss 1.6811, val loss 1.8368\n",
            "step 3000: train loss 1.6746, val loss 1.8399\n",
            "step 3100: train loss 1.6831, val loss 1.8394\n",
            "step 3200: train loss 1.6659, val loss 1.8286\n",
            "step 3300: train loss 1.6624, val loss 1.8199\n",
            "step 3400: train loss 1.6445, val loss 1.8131\n",
            "step 3500: train loss 1.6486, val loss 1.8078\n",
            "step 3600: train loss 1.6366, val loss 1.7875\n",
            "step 3700: train loss 1.6322, val loss 1.7872\n",
            "step 3800: train loss 1.6305, val loss 1.7778\n",
            "step 3900: train loss 1.6175, val loss 1.7837\n",
            "step 4000: train loss 1.6119, val loss 1.7729\n",
            "step 4100: train loss 1.6085, val loss 1.7864\n",
            "step 4200: train loss 1.5996, val loss 1.7850\n",
            "step 4300: train loss 1.5990, val loss 1.7730\n",
            "step 4400: train loss 1.5892, val loss 1.7644\n",
            "step 4500: train loss 1.5855, val loss 1.7547\n",
            "step 4600: train loss 1.5842, val loss 1.7658\n",
            "step 4700: train loss 1.5795, val loss 1.7452\n",
            "step 4800: train loss 1.5780, val loss 1.7519\n",
            "step 4900: train loss 1.5732, val loss 1.7444\n",
            "step 4999: train loss 1.5699, val loss 1.7468\n"
          ]
        }
      ],
      "source": [
        "#Using MLFlow\n",
        "m = model.to(device)\n",
        "# print the number of parameters in the model\n",
        "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
        "\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "#mlflow.set_experiment(\"makeMoE\")\n",
        "with mlflow.start_run():\n",
        "    #If you use mlflow.autolog() this will be automatically logged. I chose to explicitly log here for completeness\n",
        "    params = {\"batch_size\": batch_size , \"block_size\" : block_size, \"max_iters\": max_iters, \"eval_interval\": eval_interval,\n",
        "              \"learning_rate\": learning_rate, \"device\": device, \"eval_iters\": eval_iters, \"dropout\" : dropout, \"num_experts\": num_experts, \"top_k\": top_k }\n",
        "    mlflow.log_params(params)\n",
        "    for iter in range(max_iters):\n",
        "\n",
        "        # every once in a while evaluate the loss on train and val sets\n",
        "        if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "            losses = estimate_loss()\n",
        "            print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "            metrics = {\"train_loss\": float(losses['train']), \"val_loss\": float(losses['val'])}\n",
        "            mlflow.log_metrics(metrics, step=iter)\n",
        "\n",
        "\n",
        "        # sample a batch of data\n",
        "        xb, yb = get_batch('train')\n",
        "\n",
        "        # evaluate the loss\n",
        "        logits, loss = model(xb, yb)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "1ed96085-c292-4624-a2cc-be8aad38df79",
          "showTitle": false,
          "title": ""
        },
        "id": "jFBVfgfekRJl"
      },
      "source": [
        "记录训练和验证损失可以很好地指示训练的进行情况。从图中可以看出，我可能应该在大约4500步时停止训练（当验证损失稍微上升时）。\n",
        "\n",
        "![mlflow_dash](https://raw.githubusercontent.com/AviSoori1x/makeMoE/main/images/mlflow_dash.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "6360e1b7-94c4-4ef1-a850-9bc93f49a083",
          "showTitle": false,
          "title": ""
        },
        "id": "WP_2lcRUkRJl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87fe0df0-b082-4ee2-fde4-16c7c3aa37af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8.996545 M parameters\n",
            "step 0: train loss 5.3552, val loss 5.3479\n",
            "step 100: train loss 2.7525, val loss 2.7736\n",
            "step 200: train loss 2.5523, val loss 2.5550\n",
            "step 300: train loss 2.4612, val loss 2.4580\n",
            "step 400: train loss 2.3730, val loss 2.3827\n",
            "step 500: train loss 2.3048, val loss 2.3181\n",
            "step 600: train loss 2.2294, val loss 2.2478\n",
            "step 700: train loss 2.1690, val loss 2.1955\n",
            "step 800: train loss 2.1177, val loss 2.1481\n",
            "step 900: train loss 2.0738, val loss 2.1403\n",
            "step 1000: train loss 2.0255, val loss 2.0911\n",
            "step 1100: train loss 1.9962, val loss 2.0733\n",
            "step 1200: train loss 1.9641, val loss 2.0472\n",
            "step 1300: train loss 1.9384, val loss 2.0331\n",
            "step 1400: train loss 1.9026, val loss 2.0157\n",
            "step 1500: train loss 1.8949, val loss 1.9966\n",
            "step 1600: train loss 1.8581, val loss 1.9857\n",
            "step 1700: train loss 1.8488, val loss 1.9719\n",
            "step 1800: train loss 1.8278, val loss 1.9528\n",
            "step 1900: train loss 1.8124, val loss 1.9621\n",
            "step 2000: train loss 1.7862, val loss 1.9346\n",
            "step 2100: train loss 1.7787, val loss 1.9316\n",
            "step 2200: train loss 1.7708, val loss 1.9130\n",
            "step 2300: train loss 1.7569, val loss 1.9206\n",
            "step 2400: train loss 1.7475, val loss 1.8879\n",
            "step 2500: train loss 1.7310, val loss 1.8834\n",
            "step 2600: train loss 1.7142, val loss 1.8605\n",
            "step 2700: train loss 1.7074, val loss 1.8784\n",
            "step 2800: train loss 1.7036, val loss 1.8659\n",
            "step 2900: train loss 1.6860, val loss 1.8584\n",
            "step 3000: train loss 1.6883, val loss 1.8537\n",
            "step 3100: train loss 1.6791, val loss 1.8366\n",
            "step 3200: train loss 1.6685, val loss 1.8455\n",
            "step 3300: train loss 1.6611, val loss 1.8146\n",
            "step 3400: train loss 1.6556, val loss 1.8127\n",
            "step 3500: train loss 1.6467, val loss 1.8172\n",
            "step 3600: train loss 1.6428, val loss 1.8097\n",
            "step 3700: train loss 1.6480, val loss 1.8142\n",
            "step 3800: train loss 1.6298, val loss 1.7940\n",
            "step 3900: train loss 1.6171, val loss 1.7921\n",
            "step 4000: train loss 1.6206, val loss 1.8008\n",
            "step 4100: train loss 1.6155, val loss 1.7896\n",
            "step 4200: train loss 1.6126, val loss 1.7892\n",
            "step 4300: train loss 1.6082, val loss 1.7895\n",
            "step 4400: train loss 1.5957, val loss 1.7725\n",
            "step 4500: train loss 1.5955, val loss 1.7819\n",
            "step 4600: train loss 1.5819, val loss 1.7706\n",
            "step 4700: train loss 1.5816, val loss 1.7621\n",
            "step 4800: train loss 1.5814, val loss 1.7790\n",
            "step 4900: train loss 1.5757, val loss 1.7675\n",
            "step 4999: train loss 1.5713, val loss 1.7645\n"
          ]
        }
      ],
      "source": [
        "#Not using MLflow\n",
        "m = model.to(device)\n",
        "# print the number of parameters in the model\n",
        "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
        "\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for iter in range(max_iters):\n",
        "\n",
        "    # every once in a while evaluate the loss on train and val sets\n",
        "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = model(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "8aa6e4c4-c688-4985-a3b8-e2af1f771e54",
          "showTitle": false,
          "title": ""
        },
        "id": "W4yshpXMkRJl",
        "outputId": "8f63ccba-fb6e-4c0b-8e2c-39bb2e938683",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ae\n",
            "old, buem neran dose: bo'ld bua woold nor may siver!\n",
            "\n",
            "LyYORTOLNSIA:\n",
            "you, what, recooatusan that thou mody!\n",
            "\n",
            "BuNhRUTUO SINE:\n",
            "\n",
            "Frotsef'O Rich Lenger:\n",
            "\n",
            "reemendsseou:\n",
            " groung at yo thes Eave hers how had? Whht blse\n",
            "the tronighnest with of that but mind son\n",
            "What a gentle, wo thave rear amore off this the poma thesrixe.\n",
            "\n",
            "FUY BLOKE VFIY BOLLUCVGge:Dlectst yook; a goad, them.\n",
            "\n",
            "COMINIALE:\n",
            "vilny an? with! Priviini modeisus!\n",
            "ThAsesd uproe--\n",
            "\n",
            "CORuTHy.\n",
            "FRray;\n",
            "Yoo,e sads yoush higher waslif you minhim! he'f over hrins miet.\n",
            "\n",
            "CAMILLO:\n",
            "Hase dost coe must nou, and live thoug fel!\n",
            "\n",
            "JuCeIvg:\n",
            "I o? no there, arm you. cand his cannow thmake a stopworn fothin aling:\n",
            "Sive lauge meot an to the sort uae: ne\n",
            "Ius ast begent agrody thugh. Some shimRs of dele, so now.\n",
            "Whot, Whut not hase one's presier broberes\n",
            "Thatt him sent my nainher's preself,\n",
            "Bouviu. Asfriet me mays server yet bew wall if wragaft its:\n",
            "But it lover faminzs, havH, livNa rhav,\n",
            "How shat add nobty quars that gost lamor.\n",
            "\n",
            "KING RICHARR LIEDWD IRDkRkol'Er,\n",
            "Mysolvilgoo- yeary, and cond me you pass: noth and never\n",
            "Fattion's your foARar-give.\n",
            "Buegh fortain asiumb, hisnow brou;\n",
            "Ore bleat at leedo'tung. Trius me so, god'd.\n",
            "\n",
            "FARUTIROza your Jausy. WOisPry, there\n",
            "come a Divitiove, in'these: ao shed thes\n",
            "as thessertiend too! and her, ses'gions to herr!\n",
            "\n",
            "GLOULEEEOTROMROEE:\n",
            "Bnoy, mad yot deed, maith, right--we and welcomm-not- manurse:\n",
            "I hast spinl give twake yor foe;\n",
            "Your and furteher? and velage gembe aman:\n",
            "Weat nonge show but but in wh eyer:\n",
            "Beoess\n",
            "pe'tion tha bpooe kew wikno bott\n",
            "Azgiven egefcer'd in latter of Llors\n",
            "Thers I, punibola birt sabeimiing,\n",
            "For men sticce the waatef hill wouth?\n",
            "Mishn!\n",
            "\n",
            "Kukest Lefeit:\n",
            "Have lest tomene it so\n",
            "And suppupoit; he wear ny anot in.\n",
            "\n",
            "LAOLY:\n",
            "Yet, as merry, I will dow, name, he  now;\n",
            "Whom hwse didg thee ? uts;\n",
            "Whurt, 'I,ow't, but cold oat colk.\n",
            "\n",
            "No OLeVTs Marniust:\n",
            "Didsioek'ill him!- then, spray;s,\n",
            "Clest thenou,denned friars andieggo. That Ise, be we thind tone, my courtague,\n",
            "And fever senp trout of the\n"
          ]
        }
      ],
      "source": [
        "# generate from the model. Not great. Not too bad either\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "print(decode(m.generate(context, max_new_tokens=2000)[0].tolist()))"
      ]
    }
  ],
  "metadata": {
    "application/vnd.databricks.v1+notebook": {
      "dashboards": [],
      "language": "python",
      "notebookMetadata": {
        "pythonIndentUnit": 4
      },
      "notebookName": "makeMoE_from_Scratch",
      "widgets": {}
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}