{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNXXZaDNX1BHSjtQDW9HzPE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weedge/doraemon-nb/blob/main/GLM_4_Voice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi && lscpu"
      ],
      "metadata": {
        "id": "ANqnIh_b6dmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GLM-4-Voice"
      ],
      "metadata": {
        "id": "hzWlu8YEZZjn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone --recurse-submodules https://github.com/weedge/GLM-4-Voice.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ig8oiScyXJH",
        "outputId": "e23cf920-93c1-4fd9-be68-0c85ee0d5e58"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'GLM-4-Voice'...\n",
            "remote: Enumerating objects: 210, done.\u001b[K\n",
            "remote: Counting objects: 100% (66/66), done.\u001b[K\n",
            "remote: Compressing objects: 100% (21/21), done.\u001b[K\n",
            "remote: Total 210 (delta 56), reused 46 (delta 45), pack-reused 144 (from 1)\u001b[K\n",
            "Receiving objects: 100% (210/210), 506.09 KiB | 25.30 MiB/s, done.\n",
            "Resolving deltas: 100% (90/90), done.\n",
            "Submodule 'third_party/Matcha-TTS' (https://github.com/shivammehta25/Matcha-TTS) registered for path 'third_party/Matcha-TTS'\n",
            "Cloning into '/content/GLM-4-Voice/third_party/Matcha-TTS'...\n",
            "remote: Enumerating objects: 921, done.        \n",
            "remote: Counting objects: 100% (406/406), done.        \n",
            "remote: Compressing objects: 100% (124/124), done.        \n",
            "remote: Total 921 (delta 336), reused 283 (delta 282), pack-reused 515 (from 1)        \n",
            "Receiving objects: 100% (921/921), 64.08 MiB | 16.93 MiB/s, done.\n",
            "Resolving deltas: 100% (421/421), done.\n",
            "Submodule path 'third_party/Matcha-TTS': checked out 'dd9105b34bf2be2230f4aa1e4769fb586a3c824e'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/GLM-4-Voice\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDZvTfQLyeSd",
        "outputId": "24609ed6-aa8c-4aeb-f173-c2532511e9ac"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/GLM-4-Voice\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat requirements.txt"
      ],
      "metadata": {
        "id": "kcwVGKUwylWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -r requirements.txt\n"
      ],
      "metadata": {
        "id": "Au6ExGVOyhxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "NGROK_TOKEN=userdata.get('NGROK_TOKEN')\n",
        "HF_TOKEN=userdata.get('HF_TOKEN')\n"
      ],
      "metadata": {
        "id": "QorOR2f3VUsP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# download model"
      ],
      "metadata": {
        "id": "ObcGHV-9U_7-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/GLM-4-Voice"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89yNhAaHSRTl",
        "outputId": "8af96b88-e709-425e-fb74-70dda2b40f9a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/GLM-4-Voice\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login --token $HF_TOKEN --add-to-git-credential"
      ],
      "metadata": {
        "id": "Cas1sCZNVIMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GLM-4-Voice-Tokenizer: Trained by adding vector quantization to the encoder part of Whisper,\n",
        "# converting continuous speech input into discrete tokens.\n",
        "# Each second of audio is converted into 12.5 discrete tokens.\n",
        "\n",
        "!huggingface-cli download THUDM/glm-4-voice-tokenizer --local-dir THUDM/glm-4-voice-tokenizer --local-dir-use-symlinks False"
      ],
      "metadata": {
        "id": "45nKFMSSYqf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GLM-4-Voice-9B: Pre-trained and aligned on speech modality based on GLM-4-9B,\n",
        "# enabling understanding and generation of discretized speech.\n",
        "\n",
        "!huggingface-cli download THUDM/glm-4-voice-9b --local-dir THUDM/glm-4-voice-9b --local-dir-use-symlinks False"
      ],
      "metadata": {
        "id": "vHy8iA09-Tox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GLM-4-Voice-Decoder: A speech decoder supporting streaming inference, retrained based on CosyVoice,\n",
        "# converting discrete speech tokens into continuous speech output.\n",
        "# Generation can start with as few as 10 audio tokens, reducing conversation latency.\n",
        "\n",
        "!git lfs install\n",
        "!git clone https://huggingface.co/THUDM/glm-4-voice-decoder /content/GLM-4-Voice/THUDM/glm-4-voice-decoder"
      ],
      "metadata": {
        "id": "ZxnauK3l0l4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# run server and gradio web ui"
      ],
      "metadata": {
        "id": "8fChnVkbXUdI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/GLM-4-Voice"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpoTdZ-gZmXk",
        "outputId": "ac807682-172e-442d-e9c3-5aa60e3fa44f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/GLM-4-Voice\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# need run on A100 GPU\n",
        "# u can run server on terminal\n",
        "!python model_server.py --host localhost --model-path THUDM/glm-4-voice-9b --port 10000 --dtype bfloat16 --device cuda:0"
      ],
      "metadata": {
        "id": "u5U3vohp1DY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run glm-4-voice-9b with int4 on T4 GPU\n",
        "# u can run server on terminal\n",
        "!python model_server.py --host 0.0.0.0 --model-path THUDM/glm-4-voice-9b --port 10000 --dtype int4 --device cuda:0"
      ],
      "metadata": {
        "id": "5kkeLHG7gQS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken $NGROK_TOKEN"
      ],
      "metadata": {
        "id": "5qrO4pW--XpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run glm-4-voice-9b with int4 on T4 GPU with ngrok proxy\n",
        "!python model_server.py --host 0.0.0.0 --model-path THUDM/glm-4-voice-9b --port 10000 --dtype int4 --device cuda:0 --ngrok 1"
      ],
      "metadata": {
        "id": "mKWs2A-c3vFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# open ngrok proxy url to run web gradio ui\n",
        "!python web_demo.py --tokenizer-path  THUDM/glm-4-voice-tokenizer --model-path THUDM/glm-4-voice-9b --flow-path THUDM/glm-4-voice-decoder --ngrok 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwKuUKfPHmCh",
        "outputId": "46d75271-b9a3-4aed-9e64-369af00f82f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: https://2c99-34-126-133-36.ngrok-free.app\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_jit_internal.py:739: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.\n",
            "  deprecate(\"LoRACompatibleLinear\", \"1.0.0\", deprecation_message)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
            "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n",
            "* Running on local URL:  http://0.0.0.0:8888\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv1d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv1d(input, weight, bias, self.stride,\n",
            "2024-11-09 06:10:16.671681: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-09 06:10:16.694862: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-09 06:10:16.701857: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-09 06:10:16.718052: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-11-09 06:10:17.915802: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/processing_utils.py:813: UserWarning: Trying to convert audio automatically from float32 to 16-bit int format.\n",
            "  warnings.warn(warning.format(data.dtype))\n"
          ]
        }
      ]
    }
  ]
}