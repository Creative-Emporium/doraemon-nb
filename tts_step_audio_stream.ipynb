{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "ZV4N6O_BJMse",
        "2H62StkAQ4AO",
        "RkKYn5vsL6-l"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNLvyaHK6bAbbuitfEB2YZO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weedge/doraemon-nb/blob/main/tts_step_audio_stream.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# install"
      ],
      "metadata": {
        "id": "dIBf62RTHm_i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AsXbWTupHeIR"
      },
      "outputs": [],
      "source": [
        "!git clone --recursive https://github.com/weedge/Step-Audio.git -b feat/stream"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Step-Audio"
      ],
      "metadata": {
        "id": "tUzyqez6IXu0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf50d233-6904-43a7-9078-aa88d38ef02d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Step-Audio\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git checkout . && git pull origin feat/stream"
      ],
      "metadata": {
        "id": "G73LieCizk9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "id": "n9jRNymQNYnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /usr/local/cuda-12.5/lib64/libcublasLt*"
      ],
      "metadata": {
        "id": "LKFsrBB4PrrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -r requirements.txt"
      ],
      "metadata": {
        "id": "xWS1_hc3IfEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show torch torchaudio torchvision"
      ],
      "metadata": {
        "id": "UnnJ2jWPTsHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install torch==2.3.1 torchvision==0.18.1 torchaudio==2.3.1 --index-url https://download.pytorch.org/whl/cu121"
      ],
      "metadata": {
        "id": "eN6Ss_8xTvJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnxruntime-gpu==1.20.1"
      ],
      "metadata": {
        "id": "2RTSNPJmNS2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show onnxruntime-gpu"
      ],
      "metadata": {
        "id": "LnUm7gijNUSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install -y sox"
      ],
      "metadata": {
        "id": "p4y9fTyiN8n0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# download ckpt\n"
      ],
      "metadata": {
        "id": "Dq81SvYfPbkE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "HF_TOKEN=userdata.get('HF_TOKEN')"
      ],
      "metadata": {
        "id": "6hhujTc_xuom"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login --token $HF_TOKEN --add-to-git-credential\n"
      ],
      "metadata": {
        "id": "c_j8AcMtyF0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli download stepfun-ai/Step-Audio-Tokenizer --quie --local-dir /content/models/stepfun-ai/Step-Audio-Tokenizer\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwhowytqImqn",
        "outputId": "0b7533cb-32e3-43d1-fb4a-4abb6687aad8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/stepfun-ai/Step-Audio-Tokenizer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli download stepfun-ai/Step-Audio-TTS-3B --quie --local-dir /content/models/stepfun-ai/Step-Audio-TTS-3B\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJW_a0mRO-xR",
        "outputId": "16768d03-7f38-4b84-fd79-716c07a6e970"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/stepfun-ai/Step-Audio-TTS-3B\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# tts static batch stream inference"
      ],
      "metadata": {
        "id": "VnP2lleDw7dh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Step-Audio"
      ],
      "metadata": {
        "id": "p88WFCbaxE6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tts without ref audio\n",
        "!TTS_TEXT=\"你好！\" python tts_inference_stream.py --model-path=/content/models/stepfun-ai/ --synthesis-type=tts --output-path=./ --stream=static_batch --stream-factor=2"
      ],
      "metadata": {
        "id": "V7bpSHdHxE6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tts without ref audio\n",
        "!python tts_inference_stream.py --model-path=/content/models/stepfun-ai/ --synthesis-type=tts --output-path=./ --stream=static_batch --stream-factor=4"
      ],
      "metadata": {
        "id": "dsHOt4N3Jxaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio\n",
        "Audio('./output_tts_stream.wav',autoplay=True)"
      ],
      "metadata": {
        "id": "4sFgESH0xSCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio\n",
        "Audio('examples/prompt_wav_yuqian.wav',autoplay=True)"
      ],
      "metadata": {
        "id": "u9D6ZPX9xSCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tts with ref audio\n",
        "!python tts_inference_stream.py --model-path=/content/models/stepfun-ai/ --synthesis-type=clone --output-path=./ --stream=static_batch --stream-factor=4"
      ],
      "metadata": {
        "id": "TpXJf1s_18se"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tts with ref audio\n",
        "!TTS_TEXT=\"你好！\" python tts_inference_stream.py --model-path=/content/models/stepfun-ai/ --synthesis-type=clone --output-path=./ --stream=static_batch --stream-factor=2"
      ],
      "metadata": {
        "id": "XLax4bXoKH52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio\n",
        "Audio('./output_clone_stream.wav',autoplay=True)"
      ],
      "metadata": {
        "id": "Q6m-iJDo5Y6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# text to speech"
      ],
      "metadata": {
        "id": "ZV4N6O_BJMse"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Step-Audio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImlT8xl0OUSz",
        "outputId": "2288ebda-71ac-4455-abef-a1eda192caf4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/Step-Audio'\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tts without ref audio\n",
        "!python tts_inference.py --model-path=/content/models/stepfun-ai/ --synthesis-type=tts --output-path=./"
      ],
      "metadata": {
        "id": "KSDNp0bNJQFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio\n",
        "Audio('./output_tts.wav',autoplay=True)"
      ],
      "metadata": {
        "id": "8egYGRvaSWk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio\n",
        "Audio('examples/prompt_wav_yuqian.wav',autoplay=True)"
      ],
      "metadata": {
        "id": "WqMHz6xtZOCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tts with ref audio\n",
        "!python tts_inference.py --model-path=/content/models/stepfun-ai/ --synthesis-type=clone --output-path=./"
      ],
      "metadata": {
        "id": "3BzKaftgJ0bE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio\n",
        "Audio('./output_clone.wav',autoplay=True)"
      ],
      "metadata": {
        "id": "xqpHUg1WZYrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# speech tokenizer\n",
        "a dual codebook speech tokenizer framework. like ARCON (from stepfun team);\n",
        "\n",
        "linguistic tokenizer use FunASR Paraformer(NAR) model;\n",
        "\n",
        "semantic tokenizer use CosyVoice speech tokenizer(from SenseVoice)\n",
        "\n",
        "- https://huggingface.co/stepfun-ai/Step-Audio-Tokenizer\n",
        "- ARCON: [Advancing Auto-Regressive Continuation for Video Frames](https://arxiv.org/abs/2412.03758)\n",
        "- linguistic tokenization: [Paraformer: Fast and Accurate Parallel Transformer for Non-autoregressive End-to-End Speech Recognition](https://arxiv.org/abs/2206.08317)\n",
        "- semantic tokenization: [CosyVoice: A Scalable Multilingual Zero-shot Text-to-speech Synthesizer based on Supervised Semantic Tokens](https://arxiv.org/abs/2407.05407)"
      ],
      "metadata": {
        "id": "WWnIsXxdeKuK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Step-Audio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnzJUbvSeY3d",
        "outputId": "3afa56c2-58b8-42e2-f7c4-f4ad8211774f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Step-Audio\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "sys.path.insert(1, \"/content/Step-Audio\")"
      ],
      "metadata": {
        "id": "6793B0GLeY3e"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tokenizer import StepAudioTokenizer\n",
        "\n",
        "speech_tokenizer = StepAudioTokenizer(f\"/content/models/stepfun-ai/Step-Audio-Tokenizer\")\n",
        "print(speech_tokenizer)\n"
      ],
      "metadata": {
        "id": "jUY2N6YxeaJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio\n",
        "Audio('examples/prompt_wav_yuqian.wav',autoplay=True)"
      ],
      "metadata": {
        "id": "QEUfsc2zfXuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encode speech: waveform -> token\n",
        "import torchaudio\n",
        "\n",
        "tensor_wav, wav_sr = torchaudio.load('examples/prompt_wav_yuqian.wav')\n",
        "print(tensor_wav.shape,wav_sr)\n",
        "wav_code, linguistic_vq02, semantic_vq06 = speech_tokenizer.wav2token(tensor_wav, wav_sr)\n",
        "print(wav_code)\n",
        "print(linguistic_vq02)\n",
        "print(semantic_vq06)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vArYc8prenOk",
        "outputId": "bbf9b584-cb2d-4ed1-bd96-5775e59de101"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 357120]) 44100\n",
            "[66077, 65847, 68466, 66862, 66593, 66026, 65755, 67633, 67783, 69628, 65722, 65722, 67800, 69811, 70323, 66027, 66274, 68272, 66609, 66609, 66107, 65560, 66609, 69129, 66661, 65796, 66274, 70160, 67424, 69897, 66224, 66224, 69897, 66862, 70300, 66224, 66237, 70167, 69713, 66644, 65703, 65703, 70507, 66600, 68724, 65703, 66486, 66789, 67440, 69681, 65838, 65838, 66829, 68696, 68414, 65838, 66472, 66753, 68220, 68213, 66066, 66379, 68220, 67824, 67184, 66379, 66472, 69404, 68665, 67314, 65810, 66304, 69143, 69206, 70616, 66304, 66472, 66829, 66814, 68029, 66304, 65724, 68534, 68959, 66765, 65724, 66472, 67418, 67600, 68659, 65724, 65724, 66568, 69865, 66570, 66167, 65977, 66570, 68866, 66682, 65967, 66167, 66682, 66567, 68425, 65919, 65840, 69139, 69139, 67288, 65545, 65690, 69419, 69139, 69139, 66184, 66184, 69139, 68726, 69450, 66014, 66014, 70133, 68130, 67816, 66014, 65977, 68295, 68295, 68295, 65992, 65861, 66647, 66647, 66647, 66277, 65750, 68439, 69622, 66666, 65716, 65829, 66725, 69907, 67418, 65956, 66048, 67061, 67906, 67658, 65969, 65959, 66661, 68969, 67696, 66552, 66552, 67092, 68663, 67360, 66374, 65545, 68160, 68160, 69853, 65924, 65750, 66829, 69834, 68820, 65639, 66553, 66596, 68618, 68127, 66402, 66292, 68265, 67021, 69032, 65830, 66224, 67676, 69642, 66862, 66224, 66237, 70167, 67318, 67128, 65703, 65703, 68800, 68724, 66789, 66402, 66035, 68315, 67418, 67604, 65540, 65838, 66928, 69642, 66862, 65838, 66472, 68414, 68732, 68220, 65645, 66338, 68213, 67824, 68711, 66364, 65977, 66905, 68289, 67415, 65967, 66167, 67853, 67150, 69486, 66520, 66391, 70458, 69453, 69453, 65690, 65690, 69453, 69244, 69244, 65796, 66086, 69244, 69244, 69264, 65705, 65994, 67424, 67682, 67415, 65994, 65750, 69810, 69810, 67600, 66067, 65545, 68734, 70242, 70482, 66083, 65601, 66946, 69681, 69486, 66323, 66323, 68178, 66889, 68258, 66257, 65977, 69206, 69574, 69139, 65545, 66132, 68726, 69139, 68726, 65924, 65924, 69897, 66862, 66935, 65770, 65786, 69295, 68345, 69524, 65786, 66387, 68521, 68700, 68509, 65730, 65730, 69622, 67487, 67660, 66402, 66387, 69305, 68722, 69972, 66441, 66441, 69798, 67129, 66907, 66402, 65548, 69295, 69295, 69295, 65596, 65754, 68139, 68534, 70111, 66167, 66012, 69450, 69139, 66575]\n",
            "[541, 311, 490, 219, 186, 186, 491, 738, 571, 24, 260, 738, 688, 688, 688, 701, 167, 167, 167, 950, 302, 302, 302, 936, 530, 843, 843, 936, 274, 768, 768, 936, 768, 188, 188, 936, 188, 188, 631, 441, 431, 631, 383, 304, 9, 154, 648, 648, 478, 478, 478, 441, 456, 325, 741, 214, 180, 293, 420, 512, 433, 423, 1016, 1016, 838, 9, 388, 214, 103, 1017, 866, 756, 294, 688, 688, 701, 167, 167, 866, 499, 4, 302, 302, 936, 109, 802, 828, 441, 431, 631, 984, 855, 154, 154, 260, 550, 169, 458, 458, 214, 531, 9, 547, 65, 787, 787, 721, 441, 9, 596, 388, 388, 234, 250, 250, 851, 194, 194, 866, 851, 905, 905, 866, 12, 60, 218, 631, 476]\n",
            "[1906, 302, 33, 1073, 1223, 3068, 1240, 3251, 3763, 1712, 49, 49, 49, 2569, 101, 3600, 864, 3337, 3337, 302, 3740, 3607, 3153, 84, 3947, 40, 2164, 229, 880, 3121, 269, 2136, 1854, 193, 1660, 1653, 1660, 1264, 624, 2844, 2105, 754, 2583, 2646, 4056, 269, 254, 1469, 1974, 2399, 205, 858, 1040, 2099, 8, 3305, 10, 10, 2306, 122, 122, 7, 1865, 2579, 2579, 728, 2859, 2579, 2579, 2579, 2166, 2890, 3573, 1570, 1256, 1735, 1735, 1735, 87, 87, 87, 1879, 3062, 106, 165, 3347, 858, 501, 1346, 1098, 101, 2409, 1136, 532, 2103, 800, 1600, 1600, 3293, 269, 3274, 2260, 36, 2058, 1567, 1705, 461, 2472, 1116, 3082, 302, 3607, 758, 568, 2240, 2164, 229, 1755, 858, 1044, 368, 3082, 302, 1854, 2172, 1660, 1653, 1264, 2151, 345, 1729, 855, 1293, 590, 2926, 3898, 2893, 2893, 2893, 2684, 2684, 2684, 2684, 2704, 864, 1122, 855, 3250, 3250, 1040, 2174, 3682, 3922, 386, 3121, 2926, 1618, 329, 1698, 2646, 3014, 2579, 2166, 2579, 2166, 3337, 302, 375, 2735, 1785, 2964, 1961, 2140, 1949, 3062, 927, 1100, 2745, 2162, 3412, 3238, 569, 347, 2735, 2735, 2735, 1579, 1974, 3551, 2890, 2579, 15, 7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# merge linguistic_vq02 semantic_vq06 to audio token (2*linguistic_token,3*semantic_token)\n",
        "audio_token = speech_tokenizer.merge_vq0206_to_token_str(linguistic_vq02,semantic_vq06)\n",
        "print(audio_token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImWCS9ucj7zy",
        "outputId": "f04f3c0d-afef-4ef8-e1f7-40e9282ca2ea"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<audio_541><audio_311><audio_2930><audio_1326><audio_1057><audio_490><audio_219><audio_2097><audio_2247><audio_4092><audio_186><audio_186><audio_2264><audio_4275><audio_4787><audio_491><audio_738><audio_2736><audio_1073><audio_1073><audio_571><audio_24><audio_1073><audio_3593><audio_1125><audio_260><audio_738><audio_4624><audio_1888><audio_4361><audio_688><audio_688><audio_4361><audio_1326><audio_4764><audio_688><audio_701><audio_4631><audio_4177><audio_1108><audio_167><audio_167><audio_4971><audio_1064><audio_3188><audio_167><audio_950><audio_1253><audio_1904><audio_4145><audio_302><audio_302><audio_1293><audio_3160><audio_2878><audio_302><audio_936><audio_1217><audio_2684><audio_2677><audio_530><audio_843><audio_2684><audio_2288><audio_1648><audio_843><audio_936><audio_3868><audio_3129><audio_1778><audio_274><audio_768><audio_3607><audio_3670><audio_5080><audio_768><audio_936><audio_1293><audio_1278><audio_2493><audio_768><audio_188><audio_2998><audio_3423><audio_1229><audio_188><audio_936><audio_1882><audio_2064><audio_3123><audio_188><audio_188><audio_1032><audio_4329><audio_1034><audio_631><audio_441><audio_1034><audio_3330><audio_1146><audio_431><audio_631><audio_1146><audio_1031><audio_2889><audio_383><audio_304><audio_3603><audio_3603><audio_1752><audio_9><audio_154><audio_3883><audio_3603><audio_3603><audio_648><audio_648><audio_3603><audio_3190><audio_3914><audio_478><audio_478><audio_4597><audio_2594><audio_2280><audio_478><audio_441><audio_2759><audio_2759><audio_2759><audio_456><audio_325><audio_1111><audio_1111><audio_1111><audio_741><audio_214><audio_2903><audio_4086><audio_1130><audio_180><audio_293><audio_1189><audio_4371><audio_1882><audio_420><audio_512><audio_1525><audio_2370><audio_2122><audio_433><audio_423><audio_1125><audio_3433><audio_2160><audio_1016><audio_1016><audio_1556><audio_3127><audio_1824><audio_838><audio_9><audio_2624><audio_2624><audio_4317><audio_388><audio_214><audio_1293><audio_4298><audio_3284><audio_103><audio_1017><audio_1060><audio_3082><audio_2591><audio_866><audio_756><audio_2729><audio_1485><audio_3496><audio_294><audio_688><audio_2140><audio_4106><audio_1326><audio_688><audio_701><audio_4631><audio_1782><audio_1592><audio_167><audio_167><audio_3264><audio_3188><audio_1253><audio_866><audio_499><audio_2779><audio_1882><audio_2068><audio_4><audio_302><audio_1392><audio_4106><audio_1326><audio_302><audio_936><audio_2878><audio_3196><audio_2684><audio_109><audio_802><audio_2677><audio_2288><audio_3175><audio_828><audio_441><audio_1369><audio_2753><audio_1879><audio_431><audio_631><audio_2317><audio_1614><audio_3950><audio_984><audio_855><audio_4922><audio_3917><audio_3917><audio_154><audio_154><audio_3917><audio_3708><audio_3708><audio_260><audio_550><audio_3708><audio_3708><audio_3728><audio_169><audio_458><audio_1888><audio_2146><audio_1879><audio_458><audio_214><audio_4274><audio_4274><audio_2064><audio_531><audio_9><audio_3198><audio_4706><audio_4946><audio_547><audio_65><audio_1410><audio_4145><audio_3950><audio_787><audio_787><audio_2642><audio_1353><audio_2722><audio_721><audio_441><audio_3670><audio_4038><audio_3603><audio_9><audio_596><audio_3190><audio_3603><audio_3190><audio_388><audio_388><audio_4361><audio_1326><audio_1399><audio_234><audio_250><audio_3759><audio_2809><audio_3988><audio_250><audio_851><audio_2985><audio_3164><audio_2973><audio_194><audio_194><audio_4086><audio_1951><audio_2124><audio_866><audio_851><audio_3769><audio_3186><audio_4436><audio_905><audio_905><audio_4262><audio_1593><audio_1371><audio_866><audio_12><audio_3759><audio_3759><audio_3759><audio_60><audio_218><audio_2603><audio_2998><audio_4575><audio_631><audio_476><audio_3914><audio_3603><audio_1039>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## voice clone wo lm gen, decode wav code: audio token ids (wav_code) -> flow(CFM) -> mel - vocoder(hifi) -> waveform\n",
        "\n",
        "skip to flow (CFM) generate mel spec from audio vq codes"
      ],
      "metadata": {
        "id": "PrSoPMdRsyTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## decode step1 lm speech token: token -> step1 lm tokenizer -> audio token ids (wav_code) -> flow(CFM) -> mel - vocoder(hifi) -> waveform\n",
        "\n",
        "skip to step1 LM tokenizer"
      ],
      "metadata": {
        "id": "Q-8FAdcls8iu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# step1 LM tokenizer"
      ],
      "metadata": {
        "id": "PRd4KskAATxZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Step-Audio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-X-Aext5Hu4y",
        "outputId": "1b3aa4b2-99bb-44bc-aff9-d05f2a49b04d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Step-Audio\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "sys.path.insert(1, \"/content/Step-Audio\")"
      ],
      "metadata": {
        "id": "rg0IKtsxGxhx"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tts import StepAudioTTS\n",
        "\n",
        "tts_engine = StepAudioTTS(f\"/content/models/stepfun-ai/Step-Audio-TTS-3B\", speech_tokenizer)\n",
        "print(tts_engine)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXqZd4GnGb8k",
        "outputId": "4884fd44-9cc8-49c6-b71c-4760442f4e29"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Registered speaker: TingtingRAP\n",
            "Registered speaker: Tingting哼唱\n",
            "Registered speaker: Tingting\n",
            "<tts.StepAudioTTS object at 0x781c88db6990>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wav_code=[66077, 65847, 68466, 66862, 66593, 66026, 65755, 67633, 67783, 69628, 65722, 65722, 67800, 69811, 70323, 66027, 66274, 68272, 66609, 66609, 66107, 65560, 66609, 69129, 66661, 65796, 66274, 70160, 67424, 69897, 66224, 66224, 69897, 66862, 70300, 66224, 66237, 70167, 69713, 66644, 65703, 65703, 70507, 66600, 68724, 65703, 66486, 66789, 67440, 69681, 65838, 65838, 66829, 68696, 68414, 65838, 66472, 66753, 68220, 68213, 66066, 66379, 68220, 67824, 67184, 66379, 66472, 69404, 68665, 67314, 65810, 66304, 69143, 69206, 70616, 66304, 66472, 66829, 66814, 68029, 66304, 65724, 68534, 68959, 66765, 65724, 66472, 67418, 67600, 68659, 65724, 65724, 66568, 69865, 66570, 66167, 65977, 66570, 68866, 66682, 65967, 66167, 66682, 66567, 68425, 65919, 65840, 69139, 69139, 67288, 65545, 65690, 69419, 69139, 69139, 66184, 66184, 69139, 68726, 69450, 66014, 66014, 70133, 68130, 67816, 66014, 65977, 68295, 68295, 68295, 65992, 65861, 66647, 66647, 66647, 66277, 65750, 68439, 69622, 66666, 65716, 65829, 66725, 69907, 67418, 65956, 66048, 67061, 67906, 67658, 65969, 65959, 66661, 68969, 67696, 66552, 66552, 67092, 68663, 67360, 66374, 65545, 68160, 68160, 69853, 65924, 65750, 66829, 69834, 68820, 65639, 66553, 66596, 68618, 68127, 66402, 66292, 68265, 67021, 69032, 65830, 66224, 67676, 69642, 66862, 66224, 66237, 70167, 67318, 67128, 65703, 65703, 68800, 68724, 66789, 66402, 66035, 68315, 67418, 67604, 65540, 65838, 66928, 69642, 66862, 65838, 66472, 68414, 68732, 68220, 65645, 66338, 68213, 67824, 68711, 66364, 65977, 66905, 68289, 67415, 65967, 66167, 67853, 67150, 69486, 66520, 66391, 70458, 69453, 69453, 65690, 65690, 69453, 69244, 69244, 65796, 66086, 69244, 69244, 69264, 65705, 65994, 67424, 67682, 67415, 65994, 65750, 69810, 69810, 67600, 66067, 65545, 68734, 70242, 70482, 66083, 65601, 66946, 69681, 69486, 66323, 66323, 68178, 66889, 68258, 66257, 65977, 69206, 69574, 69139, 65545, 66132, 68726, 69139, 68726, 65924, 65924, 69897, 66862, 66935, 65770, 65786, 69295, 68345, 69524, 65786, 66387, 68521, 68700, 68509, 65730, 65730, 69622, 67487, 67660, 66402, 66387, 69305, 68722, 69972, 66441, 66441, 69798, 67129, 66907, 66402, 65548, 69295, 69295, 69295, 65596, 65754, 68139, 68534, 70111, 66167, 66012, 69450, 69139, 66575]"
      ],
      "metadata": {
        "id": "MdjdQIT0p65o"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_token=\"<audio_541><audio_311><audio_2930><audio_1326><audio_1057><audio_490><audio_219><audio_2097><audio_2247><audio_4092><audio_186><audio_186><audio_2264><audio_4275><audio_4787><audio_491><audio_738><audio_2736><audio_1073><audio_1073><audio_571><audio_24><audio_1073><audio_3593><audio_1125><audio_260><audio_738><audio_4624><audio_1888><audio_4361><audio_688><audio_688><audio_4361><audio_1326><audio_4764><audio_688><audio_701><audio_4631><audio_4177><audio_1108><audio_167><audio_167><audio_4971><audio_1064><audio_3188><audio_167><audio_950><audio_1253><audio_1904><audio_4145><audio_302><audio_302><audio_1293><audio_3160><audio_2878><audio_302><audio_936><audio_1217><audio_2684><audio_2677><audio_530><audio_843><audio_2684><audio_2288><audio_1648><audio_843><audio_936><audio_3868><audio_3129><audio_1778><audio_274><audio_768><audio_3607><audio_3670><audio_5080><audio_768><audio_936><audio_1293><audio_1278><audio_2493><audio_768><audio_188><audio_2998><audio_3423><audio_1229><audio_188><audio_936><audio_1882><audio_2064><audio_3123><audio_188><audio_188><audio_1032><audio_4329><audio_1034><audio_631><audio_441><audio_1034><audio_3330><audio_1146><audio_431><audio_631><audio_1146><audio_1031><audio_2889><audio_383><audio_304><audio_3603><audio_3603><audio_1752><audio_9><audio_154><audio_3883><audio_3603><audio_3603><audio_648><audio_648><audio_3603><audio_3190><audio_3914><audio_478><audio_478><audio_4597><audio_2594><audio_2280><audio_478><audio_441><audio_2759><audio_2759><audio_2759><audio_456><audio_325><audio_1111><audio_1111><audio_1111><audio_741><audio_214><audio_2903><audio_4086><audio_1130><audio_180><audio_293><audio_1189><audio_4371><audio_1882><audio_420><audio_512><audio_1525><audio_2370><audio_2122><audio_433><audio_423><audio_1125><audio_3433><audio_2160><audio_1016><audio_1016><audio_1556><audio_3127><audio_1824><audio_838><audio_9><audio_2624><audio_2624><audio_4317><audio_388><audio_214><audio_1293><audio_4298><audio_3284><audio_103><audio_1017><audio_1060><audio_3082><audio_2591><audio_866><audio_756><audio_2729><audio_1485><audio_3496><audio_294><audio_688><audio_2140><audio_4106><audio_1326><audio_688><audio_701><audio_4631><audio_1782><audio_1592><audio_167><audio_167><audio_3264><audio_3188><audio_1253><audio_866><audio_499><audio_2779><audio_1882><audio_2068><audio_4><audio_302><audio_1392><audio_4106><audio_1326><audio_302><audio_936><audio_2878><audio_3196><audio_2684><audio_109><audio_802><audio_2677><audio_2288><audio_3175><audio_828><audio_441><audio_1369><audio_2753><audio_1879><audio_431><audio_631><audio_2317><audio_1614><audio_3950><audio_984><audio_855><audio_4922><audio_3917><audio_3917><audio_154><audio_154><audio_3917><audio_3708><audio_3708><audio_260><audio_550><audio_3708><audio_3708><audio_3728><audio_169><audio_458><audio_1888><audio_2146><audio_1879><audio_458><audio_214><audio_4274><audio_4274><audio_2064><audio_531><audio_9><audio_3198><audio_4706><audio_4946><audio_547><audio_65><audio_1410><audio_4145><audio_3950><audio_787><audio_787><audio_2642><audio_1353><audio_2722><audio_721><audio_441><audio_3670><audio_4038><audio_3603><audio_9><audio_596><audio_3190><audio_3603><audio_3190><audio_388><audio_388><audio_4361><audio_1326><audio_1399><audio_234><audio_250><audio_3759><audio_2809><audio_3988><audio_250><audio_851><audio_2985><audio_3164><audio_2973><audio_194><audio_194><audio_4086><audio_1951><audio_2124><audio_866><audio_851><audio_3769><audio_3186><audio_4436><audio_905><audio_905><audio_4262><audio_1593><audio_1371><audio_866><audio_12><audio_3759><audio_3759><audio_3759><audio_60><audio_218><audio_2603><audio_2998><audio_4575><audio_631><audio_476><audio_3914><audio_3603><audio_1039>\""
      ],
      "metadata": {
        "id": "__Yi3jtWqIBL"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_audio_token = tts_engine.tokenizer.decode(wav_code)\n",
        "print(decoded_audio_token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjp26sU8pF__",
        "outputId": "f294632e-c4f0-4458-8568-b6d0957f712f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<audio_541><audio_311><audio_2930><audio_1326><audio_1057><audio_490><audio_219><audio_2097><audio_2247><audio_4092><audio_186><audio_186><audio_2264><audio_4275><audio_4787><audio_491><audio_738><audio_2736><audio_1073><audio_1073><audio_571><audio_24><audio_1073><audio_3593><audio_1125><audio_260><audio_738><audio_4624><audio_1888><audio_4361><audio_688><audio_688><audio_4361><audio_1326><audio_4764><audio_688><audio_701><audio_4631><audio_4177><audio_1108><audio_167><audio_167><audio_4971><audio_1064><audio_3188><audio_167><audio_950><audio_1253><audio_1904><audio_4145><audio_302><audio_302><audio_1293><audio_3160><audio_2878><audio_302><audio_936><audio_1217><audio_2684><audio_2677><audio_530><audio_843><audio_2684><audio_2288><audio_1648><audio_843><audio_936><audio_3868><audio_3129><audio_1778><audio_274><audio_768><audio_3607><audio_3670><audio_5080><audio_768><audio_936><audio_1293><audio_1278><audio_2493><audio_768><audio_188><audio_2998><audio_3423><audio_1229><audio_188><audio_936><audio_1882><audio_2064><audio_3123><audio_188><audio_188><audio_1032><audio_4329><audio_1034><audio_631><audio_441><audio_1034><audio_3330><audio_1146><audio_431><audio_631><audio_1146><audio_1031><audio_2889><audio_383><audio_304><audio_3603><audio_3603><audio_1752><audio_9><audio_154><audio_3883><audio_3603><audio_3603><audio_648><audio_648><audio_3603><audio_3190><audio_3914><audio_478><audio_478><audio_4597><audio_2594><audio_2280><audio_478><audio_441><audio_2759><audio_2759><audio_2759><audio_456><audio_325><audio_1111><audio_1111><audio_1111><audio_741><audio_214><audio_2903><audio_4086><audio_1130><audio_180><audio_293><audio_1189><audio_4371><audio_1882><audio_420><audio_512><audio_1525><audio_2370><audio_2122><audio_433><audio_423><audio_1125><audio_3433><audio_2160><audio_1016><audio_1016><audio_1556><audio_3127><audio_1824><audio_838><audio_9><audio_2624><audio_2624><audio_4317><audio_388><audio_214><audio_1293><audio_4298><audio_3284><audio_103><audio_1017><audio_1060><audio_3082><audio_2591><audio_866><audio_756><audio_2729><audio_1485><audio_3496><audio_294><audio_688><audio_2140><audio_4106><audio_1326><audio_688><audio_701><audio_4631><audio_1782><audio_1592><audio_167><audio_167><audio_3264><audio_3188><audio_1253><audio_866><audio_499><audio_2779><audio_1882><audio_2068><audio_4><audio_302><audio_1392><audio_4106><audio_1326><audio_302><audio_936><audio_2878><audio_3196><audio_2684><audio_109><audio_802><audio_2677><audio_2288><audio_3175><audio_828><audio_441><audio_1369><audio_2753><audio_1879><audio_431><audio_631><audio_2317><audio_1614><audio_3950><audio_984><audio_855><audio_4922><audio_3917><audio_3917><audio_154><audio_154><audio_3917><audio_3708><audio_3708><audio_260><audio_550><audio_3708><audio_3708><audio_3728><audio_169><audio_458><audio_1888><audio_2146><audio_1879><audio_458><audio_214><audio_4274><audio_4274><audio_2064><audio_531><audio_9><audio_3198><audio_4706><audio_4946><audio_547><audio_65><audio_1410><audio_4145><audio_3950><audio_787><audio_787><audio_2642><audio_1353><audio_2722><audio_721><audio_441><audio_3670><audio_4038><audio_3603><audio_9><audio_596><audio_3190><audio_3603><audio_3190><audio_388><audio_388><audio_4361><audio_1326><audio_1399><audio_234><audio_250><audio_3759><audio_2809><audio_3988><audio_250><audio_851><audio_2985><audio_3164><audio_2973><audio_194><audio_194><audio_4086><audio_1951><audio_2124><audio_866><audio_851><audio_3769><audio_3186><audio_4436><audio_905><audio_905><audio_4262><audio_1593><audio_1371><audio_866><audio_12><audio_3759><audio_3759><audio_3759><audio_60><audio_218><audio_2603><audio_2998><audio_4575><audio_631><audio_476><audio_3914><audio_3603><audio_1039>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_audio_token_id = tts_engine.tokenizer.encode(audio_token)\n",
        "print(encoded_audio_token_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JG0ZwCduqFQc",
        "outputId": "2c230a76-949e-48b5-94a5-0bba675de1f6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 66077, 65847, 68466, 66862, 66593, 66026, 65755, 67633, 67783, 69628, 65722, 65722, 67800, 69811, 70323, 66027, 66274, 68272, 66609, 66609, 66107, 65560, 66609, 69129, 66661, 65796, 66274, 70160, 67424, 69897, 66224, 66224, 69897, 66862, 70300, 66224, 66237, 70167, 69713, 66644, 65703, 65703, 70507, 66600, 68724, 65703, 66486, 66789, 67440, 69681, 65838, 65838, 66829, 68696, 68414, 65838, 66472, 66753, 68220, 68213, 66066, 66379, 68220, 67824, 67184, 66379, 66472, 69404, 68665, 67314, 65810, 66304, 69143, 69206, 70616, 66304, 66472, 66829, 66814, 68029, 66304, 65724, 68534, 68959, 66765, 65724, 66472, 67418, 67600, 68659, 65724, 65724, 66568, 69865, 66570, 66167, 65977, 66570, 68866, 66682, 65967, 66167, 66682, 66567, 68425, 65919, 65840, 69139, 69139, 67288, 65545, 65690, 69419, 69139, 69139, 66184, 66184, 69139, 68726, 69450, 66014, 66014, 70133, 68130, 67816, 66014, 65977, 68295, 68295, 68295, 65992, 65861, 66647, 66647, 66647, 66277, 65750, 68439, 69622, 66666, 65716, 65829, 66725, 69907, 67418, 65956, 66048, 67061, 67906, 67658, 65969, 65959, 66661, 68969, 67696, 66552, 66552, 67092, 68663, 67360, 66374, 65545, 68160, 68160, 69853, 65924, 65750, 66829, 69834, 68820, 65639, 66553, 66596, 68618, 68127, 66402, 66292, 68265, 67021, 69032, 65830, 66224, 67676, 69642, 66862, 66224, 66237, 70167, 67318, 67128, 65703, 65703, 68800, 68724, 66789, 66402, 66035, 68315, 67418, 67604, 65540, 65838, 66928, 69642, 66862, 65838, 66472, 68414, 68732, 68220, 65645, 66338, 68213, 67824, 68711, 66364, 65977, 66905, 68289, 67415, 65967, 66167, 67853, 67150, 69486, 66520, 66391, 70458, 69453, 69453, 65690, 65690, 69453, 69244, 69244, 65796, 66086, 69244, 69244, 69264, 65705, 65994, 67424, 67682, 67415, 65994, 65750, 69810, 69810, 67600, 66067, 65545, 68734, 70242, 70482, 66083, 65601, 66946, 69681, 69486, 66323, 66323, 68178, 66889, 68258, 66257, 65977, 69206, 69574, 69139, 65545, 66132, 68726, 69139, 68726, 65924, 65924, 69897, 66862, 66935, 65770, 65786, 69295, 68345, 69524, 65786, 66387, 68521, 68700, 68509, 65730, 65730, 69622, 67487, 67660, 66402, 66387, 69305, 68722, 69972, 66441, 66441, 69798, 67129, 66907, 66402, 65548, 69295, 69295, 69295, 65596, 65754, 68139, 68534, 70111, 66167, 66012, 69450, 69139, 66575]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tts_engine.tokenizer.decode(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-FEhblaqq7Xf",
        "outputId": "dcc979bf-63b0-4362-9fde-371814b9953e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assert decoded_audio_token==audio_token, \"decoded_audio_token!=audio_token\""
      ],
      "metadata": {
        "id": "6-eO3DFSrEvv"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert encoded_audio_token_id[1:]==wav_code, \"encoded_audio_token_id!=wav_code\""
      ],
      "metadata": {
        "id": "XNjfIOiLraNx"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"本文介绍了Step-Audio，这是一个开源的智能语音交互框架，旨在解决现有开源模型在语音数据采集成本高、动态控制能力弱和智能水平有限等问题。\"\n",
        "text = \"君不见黄河之水天上来，奔流到海不复回。君不见高堂明镜悲白发，朝如青丝暮成雪。人生得意须尽欢，莫使金樽空对月。天生我材必有用，千金散尽还复来。\"\n",
        "#instruction_name = tts_engine.detect_instruction_name(text)\n",
        "prompt_speaker_info = tts_engine.speakers_info[\"Tingting\"]\n",
        "print(prompt_speaker_info)"
      ],
      "metadata": {
        "id": "72UMi9x_L-rp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_ids = tts_engine.tokenize(text,prompt_speaker_info[\"prompt_text\"],\"\",prompt_speaker_info[\"prompt_code\"])\n",
        "print(token_ids)"
      ],
      "metadata": {
        "id": "hckOXiqPNK4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = tts_engine.tokenizer.decode(token_ids)\n",
        "print(text)"
      ],
      "metadata": {
        "id": "mr8tf1muNQPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# step1 LM generate"
      ],
      "metadata": {
        "id": "o_R20-YmPBLb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## generate"
      ],
      "metadata": {
        "id": "lKDMIYXoQx7n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "from tts import LogitsProcessorList,RepetitionAwareLogitsProcessor\n",
        "\n",
        "output_ids = tts_engine.llm.generate(\n",
        "  torch.tensor([token_ids]).to(torch.long).to(\"cuda\"),\n",
        "  max_length=8192,\n",
        "  temperature=0.7,\n",
        "  do_sample=True,\n",
        "  logits_processor=LogitsProcessorList([RepetitionAwareLogitsProcessor()]),\n",
        ")\n",
        "print(output_ids)"
      ],
      "metadata": {
        "id": "jj-T_M8eOKiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = tts_engine.tokenizer.decode(output_ids[0])\n",
        "print(text)"
      ],
      "metadata": {
        "id": "HWS1itlGPXse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_token_ids = output_ids[0][len(token_ids):-1] # skip <|EOT|> token\n",
        "print(audio_token_ids)\n",
        "audio_token_text = tts_engine.tokenizer.decode(audio_token_ids)\n",
        "print(audio_token_text)"
      ],
      "metadata": {
        "id": "RCgaC5w1P0Lp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## stream generate"
      ],
      "metadata": {
        "id": "2H62StkAQ4AO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from queue import Queue\n",
        "\n",
        "from transformers.generation.streamers import BaseStreamer\n",
        "\n",
        "class TokenStreamer(BaseStreamer):\n",
        "    def __init__(self, skip_prompt: bool = False, timeout=None):\n",
        "        self.skip_prompt = skip_prompt\n",
        "\n",
        "        # variables used in the streaming process\n",
        "        self.token_queue = Queue()\n",
        "        self.stop_signal = None\n",
        "        self.next_tokens_are_prompt = True\n",
        "        self.timeout = timeout\n",
        "\n",
        "    def put(self, value):\n",
        "        if len(value.shape) > 1 and value.shape[0] > 1:\n",
        "            raise ValueError(\"TextStreamer only supports batch size 1\")\n",
        "        elif len(value.shape) > 1:\n",
        "            value = value[0]\n",
        "        #print(value)\n",
        "\n",
        "        if self.skip_prompt and self.next_tokens_are_prompt:\n",
        "            self.next_tokens_are_prompt = False\n",
        "            return\n",
        "\n",
        "        for token in value.tolist():\n",
        "            self.token_queue.put(token)\n",
        "\n",
        "    def end(self):\n",
        "        self.token_queue.put(self.stop_signal)\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        value = self.token_queue.get(timeout=self.timeout)\n",
        "        if value == self.stop_signal:\n",
        "            raise StopIteration()\n",
        "        else:\n",
        "            return value"
      ],
      "metadata": {
        "id": "j-Y_lTgJR7_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "streamer = TokenStreamer(skip_prompt=True)\n",
        "print(streamer)"
      ],
      "metadata": {
        "id": "2zzC0zzHS_Q-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from threading import Thread\n",
        "\n",
        "import torch\n",
        "\n",
        "from tts import LogitsProcessorList,RepetitionAwareLogitsProcessor\n",
        "\n",
        "generation_kwargs = dict(\n",
        "  input_ids=torch.tensor([token_ids]).to(torch.long).to(\"cuda\"),\n",
        "  eos_token_id=3,\n",
        "  streamer=streamer,\n",
        "  max_length=8192,\n",
        "  temperature=0.7,\n",
        "  do_sample=True,\n",
        "  logits_processor=LogitsProcessorList([RepetitionAwareLogitsProcessor()]),\n",
        ")\n",
        "print(\"generation_kwargs\", generation_kwargs)\n",
        "\n",
        "thread = Thread(target=tts_engine.llm.generate, kwargs=generation_kwargs)\n",
        "thread.start()\n",
        "\n",
        "generated_ids = []\n",
        "for token_id in streamer:\n",
        "  print(token_id, end=\",\", flush=True)\n",
        "  generated_ids.append(token_id)\n",
        "\n",
        "print(\"\\n\",generated_ids)"
      ],
      "metadata": {
        "id": "gq7rx3SQQ-jG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_token_text = tts_engine.tokenizer.decode(generated_ids)\n",
        "print(audio_token_text)"
      ],
      "metadata": {
        "id": "Fy94aK9bVnZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_token_text = tts_engine.tokenizer.decode(token_ids)\n",
        "print(prompt_token_text)"
      ],
      "metadata": {
        "id": "hwtex-UmXn6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_token_text = tts_engine.tokenizer.decode(3)\n",
        "print(audio_token_text)"
      ],
      "metadata": {
        "id": "BGuLSancYX7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_token_ids = generated_ids[:-1] # skip <|EOT|> token\n",
        "print(audio_token_ids)\n",
        "audio_token_text = tts_engine.tokenizer.decode(audio_token_ids)\n",
        "print(audio_token_text)"
      ],
      "metadata": {
        "id": "3gjNcAvXWe5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from threading import Thread\n",
        "import math\n",
        "\n",
        "import torch\n",
        "\n",
        "from tts import LogitsProcessorList,RepetitionAwareLogitsProcessor\n",
        "\n",
        "generation_kwargs = dict(\n",
        "  input_ids=torch.tensor([token_ids]).to(torch.long).to(\"cuda\"),\n",
        "  eos_token_id=3,\n",
        "  streamer=streamer,\n",
        "  max_length=8192,\n",
        "  temperature=0.7,\n",
        "  do_sample=True,\n",
        "  logits_processor=LogitsProcessorList([RepetitionAwareLogitsProcessor()]),\n",
        ")\n",
        "print(\"generation_kwargs\", generation_kwargs)\n",
        "\n",
        "thread = Thread(target=tts_engine.llm.generate, kwargs=generation_kwargs)\n",
        "thread.start()\n",
        "\n",
        "#batch_size = 30\n",
        "stream_factor=2 # >=2 increase for better speech quality, but rft slow (speech quality vs rft slow)\n",
        "batch_size = math.ceil(stream_factor*tts_engine.common_cosy_model.model.flow.input_frame_rate)\n",
        "print(batch_size)\n",
        "\n",
        "generated_ids = []\n",
        "for token_id in streamer:\n",
        "  #print(token_id, end=\",\", flush=True)\n",
        "  if token_id == 3:  # skip <|EOT|>, break\n",
        "    break\n",
        "  generated_ids.append(token_id)\n",
        "  if len(generated_ids) % batch_size == 0:\n",
        "    print(\"\\n\",generated_ids)\n",
        "    batch = (\n",
        "        torch.tensor(generated_ids)\n",
        "        .unsqueeze(0)\n",
        "        .to(tts_engine.common_cosy_model.model.device)\n",
        "    )  # [T] -> [1,T]\n",
        "    print(batch,batch.shape)\n",
        "    # Process each batch\n",
        "    sub_tts_speech = tts_engine.common_cosy_model.token_to_wav_offline(\n",
        "                    batch,\n",
        "                    prompt_speaker_info[\"cosy_speech_feat\"].to(torch.bfloat16),\n",
        "                    prompt_speaker_info[\"cosy_speech_feat_len\"],\n",
        "                    prompt_speaker_info[\"cosy_prompt_token\"],\n",
        "                    prompt_speaker_info[\"cosy_prompt_token_len\"],\n",
        "                    prompt_speaker_info[\"cosy_speech_embedding\"].to(torch.bfloat16),\n",
        "    )\n",
        "    print(sub_tts_speech,sub_tts_speech.shape)\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\n\",generated_ids)\n"
      ],
      "metadata": {
        "id": "zMgy3NnCAcMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# generate waveform from audio vq codes"
      ],
      "metadata": {
        "id": "VV0DjPrkkk9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(prompt_speaker_info)"
      ],
      "metadata": {
        "id": "zbAb1vNiik5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_speaker_info[\"cosy_speech_feat\"]"
      ],
      "metadata": {
        "id": "T1yg9sshixxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_speaker_info[\"cosy_speech_feat_len\"]"
      ],
      "metadata": {
        "id": "RzBxxjS4izSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_speaker_info[\"cosy_prompt_token\"].to(\"cuda\")"
      ],
      "metadata": {
        "id": "HMB7eBBFi3Vy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_speaker_info[\"cosy_prompt_token_len\"].to(\"cuda\")"
      ],
      "metadata": {
        "id": "-UKuepvli9D0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_speaker_info[\"cosy_speech_embedding\"]"
      ],
      "metadata": {
        "id": "f1874WjdjAcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 你好\n",
        "audio_token_ids = [66424, 65801, 66725, 66575, 68722, 65949, 66106, 67604, 69789, 69810, 65589, 65589, 69810, 68289, 68295, 66027, 66547, 68649, 68295, 67783, 66107, 66547, 67783, 67909, 67909, 65613, 65613, 66586, 66586, 70493]\n",
        "#audio_token_text = \"<audio_888><audio_265><audio_1189><audio_1039><audio_3186><audio_413><audio_570><audio_2068><audio_4253><audio_4274><audio_53><audio_53><audio_4274><audio_2753><audio_2759><audio_491><audio_1011><audio_3113><audio_2759><audio_2247><audio_571><audio_1011><audio_2247><audio_2373><audio_2373><audio_77><audio_77><audio_1050><audio_1050><audio_4957>\""
      ],
      "metadata": {
        "id": "R78jvKBZf8oS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 本文介绍了Step-Audio，这是一个开源的智能语音交互框架，旨在解决现有开源模型在语音数据采集成本高、动态控制能力弱和智能水平有限等问题。\n",
        "audio_token_ids=[\n",
        "        66077, 65712, 66725, 68670, 66614, 65949, 66185, 66609, 67812, 68014,\n",
        "        66185, 65607, 68130, 69827, 68810, 65607, 66486, 68076, 68813, 67130,\n",
        "        65645, 65972, 67597, 69622, 68175, 65767, 66486, 68803, 66903, 69492,\n",
        "        65557, 65557, 66885, 68443, 68139, 65754, 65977, 69097, 67816, 67816,\n",
        "        65621, 66547, 67816, 67778, 67587, 65613, 65840, 68294, 70458, 70458,\n",
        "        66471, 66361, 70458, 67445, 67526, 66029, 66029, 70476, 69264, 68622,\n",
        "        66381, 66133, 67460, 70160, 68708, 66177, 66217, 66669, 67075, 66679,\n",
        "        66041, 66041, 67021, 67260, 66762, 66447, 66486, 68272, 66885, 66885,\n",
        "        66502, 66502, 67300, 67878, 70160, 66502, 66309, 68466, 66629, 68200,\n",
        "        66284, 65811, 66992, 66992, 68073, 66167, 65977, 68073, 66940, 68064,\n",
        "        66167, 66061, 68064, 67250, 67250, 65840, 66283, 67587, 68006, 68064,\n",
        "        65684, 65684, 68029, 68175, 68803, 65682, 66035, 66594, 66601, 66588,\n",
        "        65795, 65795, 68258, 66619, 66619, 66279, 66486, 70112, 70576, 66561,\n",
        "        66279, 65911, 67092, 68610, 70576, 65911, 66237, 67966, 66580, 67753,\n",
        "        65735, 65735, 67130, 70321, 67277, 65735, 66254, 67049, 69206, 67333,\n",
        "        66336, 65821, 67333, 69559, 67633, 65897, 65897, 66592, 67963, 66907,\n",
        "        65973, 66215, 67129, 68959, 70153, 66215, 66472, 67333, 68130, 68115,\n",
        "        66241, 66241, 66946, 68128, 67945, 66402, 66536, 67945, 69666, 66600,\n",
        "        65549, 65829, 69181, 69346, 68810, 65847, 66472, 66829, 68813, 68806,\n",
        "        66366, 66366, 69492, 67328, 66794, 66402, 66429, 70507, 66633, 68815,\n",
        "        66443, 66402, 70052, 66794, 66885, 65554, 66048, 66946, 67801, 70114,\n",
        "        65792, 65792, 68800, 66679, 69418, 66167, 66012, 66568, 66568, 67587,\n",
        "        65967, 66167, 68064, 68064, 67250, 65840, 65840, 70458, 70458, 66613,\n",
        "        66132, 65705, 70209, 70209, 67526, 65617, 65750, 66605, 67129, 66566,\n",
        "        66040, 66040, 66566, 68076, 66661, 66360, 66315, 66981, 66679, 66593,\n",
        "        65947, 65947, 68076, 68813, 67913, 65972, 65972, 67851, 66829, 67352,\n",
        "        65972, 66335, 67945, 68200, 67049, 66379, 66379, 67736, 68800, 67206,\n",
        "        65877, 65877, 69404, 66753, 67261, 65899, 65899, 67130, 67604, 69401,\n",
        "        65899, 65911, 66992, 68356, 69524, 65911, 66472, 68847, 67966, 67572,\n",
        "        65735, 65735, 67658, 70321, 66592, 66160, 66472, 68038, 66569, 68989,\n",
        "        66160, 65969, 67362, 68169, 68803, 66421, 66472, 67184, 69404, 66753,\n",
        "        66466, 66290, 68220, 69980, 68747, 66167, 65840, 69624, 66682, 68768,\n",
        "        66167, 66471, 67526, 70458, 66613, 65840, 66283, 70209, 69538, 68076,\n",
        "        66102, 66360, 68254, 69559, 66981, 66402, 66035, 66669, 70616, 66619,\n",
        "        66241, 65549, 67945, 67945, 69666, 65549, 66472, 66600, 66619, 69181,\n",
        "        66335, 65970, 68128, 70639, 69798, 65970, 66472, 69798, 67318, 66644,\n",
        "        66137, 66137, 67502, 67054, 66935, 66402, 65615, 67277, 68364, 66829,\n",
        "        66538, 66538, 68254, 67966, 66580, 66402, 65554, 67071, 70616, 67803,\n",
        "        65964, 66335, 66889, 68220, 67877, 66423, 66472, 70328, 70209, 68624,\n",
        "        66127, 66127, 66881, 67440, 67314, 66402, 65669, 67633, 69436, 68248,\n",
        "        65987, 65987, 70576, 66614, 66918, 66402, 65977, 66918, 67783, 67070,\n",
        "        65967, 66167, 67070, 66940, 68867, 65545, 65840, 68064, 68064, 67250,\n",
        "        66471, 65705, 67250, 68064, 67424, 65752, 65750, 69897, 67873, 66765,\n",
        "        66539, 65932, 67128, 68069, 68663, 65932, 66486, 70160, 67966, 66580,\n",
        "        66335, 66443, 69834, 70474, 66962, 66443, 66237, 67442, 66794, 68069,\n",
        "        65938, 65938, 67935, 70328, 66588, 66215, 66486, 70153, 67764, 68847,\n",
        "        66215, 65968, 66618, 69853, 66663, 66257, 65668, 67906, 70321, 67502,\n",
        "        65714, 65714, 68127, 69825, 67100, 66402, 65977, 68959, 66622, 69998,\n",
        "        66066, 66167, 68162, 70111, 68867, 65654, 65840, 70458, 70458, 67582,\n",
        "        66109, 66109, 66586, 67250, 68847, 66109, 65897, 67221, 68866, 66592,\n",
        "        65973, 65973, 68067, 68278, 67129, 66215, 66156, 68803, 67333, 68139,\n",
        "        65651, 65814, 68115, 67590, 66946, 65814, 66486, 69798, 67487, 69064,\n",
        "        66460, 66460, 68144, 68670, 69571, 66460, 66035, 69666, 68128, 68597,\n",
        "        66384, 66384, 70049, 68866, 70172, 65601, 66048, 67403, 67206, 68665,\n",
        "        66062, 66306, 70049, 67130, 68054, 66306, 66472, 67801, 70160, 70142,\n",
        "        66185, 66185, 66618, 66618, 67229, 66402, 66048, 69827, 68883, 67963,\n",
        "        65959, 65959, 68428, 68732, 70404, 66167, 66012, 66928, 68220, 66619,\n",
        "        65967, 66167, 70616, 67851, 66746, 65654, 65840, 67677, 68064, 68064\n",
        "]\n",
        "#audio_token_text=\"<audio_541><audio_176><audio_1189><audio_3134><audio_1078><audio_413><audio_649><audio_1073><audio_2276><audio_2478><audio_649><audio_71><audio_2594><audio_4291><audio_3274><audio_71><audio_950><audio_2540><audio_3277><audio_1594><audio_109><audio_436><audio_2061><audio_4086><audio_2639><audio_231><audio_950><audio_3267><audio_1367><audio_3956><audio_21><audio_21><audio_1349><audio_2907><audio_2603><audio_218><audio_441><audio_3561><audio_2280><audio_2280><audio_85><audio_1011><audio_2280><audio_2242><audio_2051><audio_77><audio_304><audio_2758><audio_4922><audio_4922><audio_935><audio_825><audio_4922><audio_1909><audio_1990><audio_493><audio_493><audio_4940><audio_3728><audio_3086><audio_845><audio_597><audio_1924><audio_4624><audio_3172><audio_641><audio_681><audio_1133><audio_1539><audio_1143><audio_505><audio_505><audio_1485><audio_1724><audio_1226><audio_911><audio_950><audio_2736><audio_1349><audio_1349><audio_966><audio_966><audio_1764><audio_2342><audio_4624><audio_966><audio_773><audio_2930><audio_1093><audio_2664><audio_748><audio_275><audio_1456><audio_1456><audio_2537><audio_631><audio_441><audio_2537><audio_1404><audio_2528><audio_631><audio_525><audio_2528><audio_1714><audio_1714><audio_304><audio_747><audio_2051><audio_2470><audio_2528><audio_148><audio_148><audio_2493><audio_2639><audio_3267><audio_146><audio_499><audio_1058><audio_1065><audio_1052><audio_259><audio_259><audio_2722><audio_1083><audio_1083><audio_743><audio_950><audio_4576><audio_5040><audio_1025><audio_743><audio_375><audio_1556><audio_3074><audio_5040><audio_375><audio_701><audio_2430><audio_1044><audio_2217><audio_199><audio_199><audio_1594><audio_4785><audio_1741><audio_199><audio_718><audio_1513><audio_3670><audio_1797><audio_800><audio_285><audio_1797><audio_4023><audio_2097><audio_361><audio_361><audio_1056><audio_2427><audio_1371><audio_437><audio_679><audio_1593><audio_3423><audio_4617><audio_679><audio_936><audio_1797><audio_2594><audio_2579><audio_705><audio_705><audio_1410><audio_2592><audio_2409><audio_866><audio_1000><audio_2409><audio_4130><audio_1064><audio_13><audio_293><audio_3645><audio_3810><audio_3274><audio_311><audio_936><audio_1293><audio_3277><audio_3270><audio_830><audio_830><audio_3956><audio_1792><audio_1258><audio_866><audio_893><audio_4971><audio_1097><audio_3279><audio_907><audio_866><audio_4516><audio_1258><audio_1349><audio_18><audio_512><audio_1410><audio_2265><audio_4578><audio_256><audio_256><audio_3264><audio_1143><audio_3882><audio_631><audio_476><audio_1032><audio_1032><audio_2051><audio_431><audio_631><audio_2528><audio_2528><audio_1714><audio_304><audio_304><audio_4922><audio_4922><audio_1077><audio_596><audio_169><audio_4673><audio_4673><audio_1990><audio_81><audio_214><audio_1069><audio_1593><audio_1030><audio_504><audio_504><audio_1030><audio_2540><audio_1125><audio_824><audio_779><audio_1445><audio_1143><audio_1057><audio_411><audio_411><audio_2540><audio_3277><audio_2377><audio_436><audio_436><audio_2315><audio_1293><audio_1816><audio_436><audio_799><audio_2409><audio_2664><audio_1513><audio_843><audio_843><audio_2200><audio_3264><audio_1670><audio_341><audio_341><audio_3868><audio_1217><audio_1725><audio_363><audio_363><audio_1594><audio_2068><audio_3865><audio_363><audio_375><audio_1456><audio_2820><audio_3988><audio_375><audio_936><audio_3311><audio_2430><audio_2036><audio_199><audio_199><audio_2122><audio_4785><audio_1056><audio_624><audio_936><audio_2502><audio_1033><audio_3453><audio_624><audio_433><audio_1826><audio_2633><audio_3267><audio_885><audio_936><audio_1648><audio_3868><audio_1217><audio_930><audio_754><audio_2684><audio_4444><audio_3211><audio_631><audio_304><audio_4088><audio_1146><audio_3232><audio_631><audio_935><audio_1990><audio_4922><audio_1077><audio_304><audio_747><audio_4673><audio_4002><audio_2540><audio_566><audio_824><audio_2718><audio_4023><audio_1445><audio_866><audio_499><audio_1133><audio_5080><audio_1083><audio_705><audio_13><audio_2409><audio_2409><audio_4130><audio_13><audio_936><audio_1064><audio_1083><audio_3645><audio_799><audio_434><audio_2592><audio_5103><audio_4262><audio_434><audio_936><audio_4262><audio_1782><audio_1108><audio_601><audio_601><audio_1966><audio_1518><audio_1399><audio_866><audio_79><audio_1741><audio_2828><audio_1293><audio_1002><audio_1002><audio_2718><audio_2430><audio_1044><audio_866><audio_18><audio_1535><audio_5080><audio_2267><audio_428><audio_799><audio_1353><audio_2684><audio_2341><audio_887><audio_936><audio_4792><audio_4673><audio_3088><audio_591><audio_591><audio_1345><audio_1904><audio_1778><audio_866><audio_133><audio_2097><audio_3900><audio_2712><audio_451><audio_451><audio_5040><audio_1078><audio_1382><audio_866><audio_441><audio_1382><audio_2247><audio_1534><audio_431><audio_631><audio_1534><audio_1404><audio_3331><audio_9><audio_304><audio_2528><audio_2528><audio_1714><audio_935><audio_169><audio_1714><audio_2528><audio_1888><audio_216><audio_214><audio_4361><audio_2337><audio_1229><audio_1003><audio_396><audio_1592><audio_2533><audio_3127><audio_396><audio_950><audio_4624><audio_2430><audio_1044><audio_799><audio_907><audio_4298><audio_4938><audio_1426><audio_907><audio_701><audio_1906><audio_1258><audio_2533><audio_402><audio_402><audio_2399><audio_4792><audio_1052><audio_679><audio_950><audio_4617><audio_2228><audio_3311><audio_679><audio_432><audio_1082><audio_4317><audio_1127><audio_721><audio_132><audio_2370><audio_4785><audio_1966><audio_178><audio_178><audio_2591><audio_4289><audio_1564><audio_866><audio_441><audio_3423><audio_1086><audio_4462><audio_530><audio_631><audio_2626><audio_4575><audio_3331><audio_118><audio_304><audio_4922><audio_4922><audio_2046><audio_573><audio_573><audio_1050><audio_1714><audio_3311><audio_573><audio_361><audio_1685><audio_3330><audio_1056><audio_437><audio_437><audio_2531><audio_2742><audio_1593><audio_679><audio_620><audio_3267><audio_1797><audio_2603><audio_115><audio_278><audio_2579><audio_2054><audio_1410><audio_278><audio_950><audio_4262><audio_1951><audio_3528><audio_924><audio_924><audio_2608><audio_3134><audio_4035><audio_924><audio_499><audio_4130><audio_2592><audio_3061><audio_848><audio_848><audio_4513><audio_3330><audio_4636><audio_65><audio_512><audio_1867><audio_1670><audio_3129><audio_526><audio_770><audio_4513><audio_1594><audio_2518><audio_770><audio_936><audio_2265><audio_4624><audio_4606><audio_649><audio_649><audio_1082><audio_1082><audio_1693><audio_866><audio_512><audio_4291><audio_3347><audio_2427><audio_423><audio_423><audio_2892><audio_3196><audio_4868><audio_631><audio_476><audio_1392><audio_2684><audio_1083><audio_431><audio_631><audio_5080><audio_2315><audio_1210><audio_118><audio_304><audio_2141><audio_2528><audio_2528>\""
      ],
      "metadata": {
        "id": "UGmsOHU1P9vv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_token_text = tts_engine.tokenizer.decode(audio_token_ids)\n",
        "print(audio_token_text)"
      ],
      "metadata": {
        "id": "Y7Oa17prQquo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# audio vq codes\n",
        "tensor_audio_token_ids = torch.tensor([audio_token_ids]).to(torch.long).to(\"cuda\")-65536\n",
        "print(tensor_audio_token_ids)"
      ],
      "metadata": {
        "id": "piPgDgWMhtVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tts_speech = tts_engine.common_cosy_model.token_to_wav_offline(\n",
        "    tensor_audio_token_ids,\n",
        "    prompt_speaker_info[\"cosy_speech_feat\"].to(torch.bfloat16),\n",
        "    prompt_speaker_info[\"cosy_speech_feat_len\"],\n",
        "    prompt_speaker_info[\"cosy_prompt_token\"],\n",
        "    prompt_speaker_info[\"cosy_prompt_token_len\"],\n",
        "    prompt_speaker_info[\"cosy_speech_embedding\"].to(torch.bfloat16),\n",
        ")"
      ],
      "metadata": {
        "id": "rlDiYCXVhd0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tts_speech,tts_speech.shape)"
      ],
      "metadata": {
        "id": "KZ7AuBYJlvOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchaudio\n",
        "torchaudio.save(f\"/content/output_tts.wav\", tts_speech, 22050)"
      ],
      "metadata": {
        "id": "4QkaOrpvme9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio\n",
        "Audio('/content/output_tts.wav',autoplay=True)"
      ],
      "metadata": {
        "id": "jjfLMGrdm0DJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## flow (CFM) generate mel spec from audio vq codes"
      ],
      "metadata": {
        "id": "tLmvHPpGkvbm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 叫做秋风起蟹脚痒，啊，什么意思呢？就是说这秋风一起啊，螃蟹就该上市了。\n",
        "#wav_code=[66077, 65847, 68466, 66862, 66593, 66026, 65755, 67633, 67783, 69628, 65722, 65722, 67800, 69811, 70323, 66027, 66274, 68272, 66609, 66609, 66107, 65560, 66609, 69129, 66661, 65796, 66274, 70160, 67424, 69897, 66224, 66224, 69897, 66862, 70300, 66224, 66237, 70167, 69713, 66644, 65703, 65703, 70507, 66600, 68724, 65703, 66486, 66789, 67440, 69681, 65838, 65838, 66829, 68696, 68414, 65838, 66472, 66753, 68220, 68213, 66066, 66379, 68220, 67824, 67184, 66379, 66472, 69404, 68665, 67314, 65810, 66304, 69143, 69206, 70616, 66304, 66472, 66829, 66814, 68029, 66304, 65724, 68534, 68959, 66765, 65724, 66472, 67418, 67600, 68659, 65724, 65724, 66568, 69865, 66570, 66167, 65977, 66570, 68866, 66682, 65967, 66167, 66682, 66567, 68425, 65919, 65840, 69139, 69139, 67288, 65545, 65690, 69419, 69139, 69139, 66184, 66184, 69139, 68726, 69450, 66014, 66014, 70133, 68130, 67816, 66014, 65977, 68295, 68295, 68295, 65992, 65861, 66647, 66647, 66647, 66277, 65750, 68439, 69622, 66666, 65716, 65829, 66725, 69907, 67418, 65956, 66048, 67061, 67906, 67658, 65969, 65959, 66661, 68969, 67696, 66552, 66552, 67092, 68663, 67360, 66374, 65545, 68160, 68160, 69853, 65924, 65750, 66829, 69834, 68820, 65639, 66553, 66596, 68618, 68127, 66402, 66292, 68265, 67021, 69032, 65830, 66224, 67676, 69642, 66862, 66224, 66237, 70167, 67318, 67128, 65703, 65703, 68800, 68724, 66789, 66402, 66035, 68315, 67418, 67604, 65540, 65838, 66928, 69642, 66862, 65838, 66472, 68414, 68732, 68220, 65645, 66338, 68213, 67824, 68711, 66364, 65977, 66905, 68289, 67415, 65967, 66167, 67853, 67150, 69486, 66520, 66391, 70458, 69453, 69453, 65690, 65690, 69453, 69244, 69244, 65796, 66086, 69244, 69244, 69264, 65705, 65994, 67424, 67682, 67415, 65994, 65750, 69810, 69810, 67600, 66067, 65545, 68734, 70242, 70482, 66083, 65601, 66946, 69681, 69486, 66323, 66323, 68178, 66889, 68258, 66257, 65977, 69206, 69574, 69139, 65545, 66132, 68726, 69139, 68726, 65924, 65924, 69897, 66862, 66935, 65770, 65786, 69295, 68345, 69524, 65786, 66387, 68521, 68700, 68509, 65730, 65730, 69622, 67487, 67660, 66402, 66387, 69305, 68722, 69972, 66441, 66441, 69798, 67129, 66907, 66402, 65548, 69295, 69295, 69295, 65596, 65754, 68139, 68534, 70111, 66167, 66012, 69450, 69139, 66575]"
      ],
      "metadata": {
        "id": "Ew1UG3O_tY4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(wav_code)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "talovGS3tcv-",
        "outputId": "b6c7e03c-41dc-4f72-d3e4-faf6c191de52"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[66077, 65847, 68466, 66862, 66593, 66026, 65755, 67633, 67783, 69628, 65722, 65722, 67800, 69811, 70323, 66027, 66274, 68272, 66609, 66609, 66107, 65560, 66609, 69129, 66661, 65796, 66274, 70160, 67424, 69897, 66224, 66224, 69897, 66862, 70300, 66224, 66237, 70167, 69713, 66644, 65703, 65703, 70507, 66600, 68724, 65703, 66486, 66789, 67440, 69681, 65838, 65838, 66829, 68696, 68414, 65838, 66472, 66753, 68220, 68213, 66066, 66379, 68220, 67824, 67184, 66379, 66472, 69404, 68665, 67314, 65810, 66304, 69143, 69206, 70616, 66304, 66472, 66829, 66814, 68029, 66304, 65724, 68534, 68959, 66765, 65724, 66472, 67418, 67600, 68659, 65724, 65724, 66568, 69865, 66570, 66167, 65977, 66570, 68866, 66682, 65967, 66167, 66682, 66567, 68425, 65919, 65840, 69139, 69139, 67288, 65545, 65690, 69419, 69139, 69139, 66184, 66184, 69139, 68726, 69450, 66014, 66014, 70133, 68130, 67816, 66014, 65977, 68295, 68295, 68295, 65992, 65861, 66647, 66647, 66647, 66277, 65750, 68439, 69622, 66666, 65716, 65829, 66725, 69907, 67418, 65956, 66048, 67061, 67906, 67658, 65969, 65959, 66661, 68969, 67696, 66552, 66552, 67092, 68663, 67360, 66374, 65545, 68160, 68160, 69853, 65924, 65750, 66829, 69834, 68820, 65639, 66553, 66596, 68618, 68127, 66402, 66292, 68265, 67021, 69032, 65830, 66224, 67676, 69642, 66862, 66224, 66237, 70167, 67318, 67128, 65703, 65703, 68800, 68724, 66789, 66402, 66035, 68315, 67418, 67604, 65540, 65838, 66928, 69642, 66862, 65838, 66472, 68414, 68732, 68220, 65645, 66338, 68213, 67824, 68711, 66364, 65977, 66905, 68289, 67415, 65967, 66167, 67853, 67150, 69486, 66520, 66391, 70458, 69453, 69453, 65690, 65690, 69453, 69244, 69244, 65796, 66086, 69244, 69244, 69264, 65705, 65994, 67424, 67682, 67415, 65994, 65750, 69810, 69810, 67600, 66067, 65545, 68734, 70242, 70482, 66083, 65601, 66946, 69681, 69486, 66323, 66323, 68178, 66889, 68258, 66257, 65977, 69206, 69574, 69139, 65545, 66132, 68726, 69139, 68726, 65924, 65924, 69897, 66862, 66935, 65770, 65786, 69295, 68345, 69524, 65786, 66387, 68521, 68700, 68509, 65730, 65730, 69622, 67487, 67660, 66402, 66387, 69305, 68722, 69972, 66441, 66441, 69798, 67129, 66907, 66402, 65548, 69295, 69295, 69295, 65596, 65754, 68139, 68534, 70111, 66167, 66012, 69450, 69139, 66575]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "audio_token_ids=wav_code\n",
        "# audio vq codes\n",
        "tensor_audio_token_ids = torch.tensor([audio_token_ids]).to(torch.long).to(\"cuda\")-65536\n",
        "print(tensor_audio_token_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e2U2M_2r3aZ",
        "outputId": "e3276540-9652-4916-c5b5-5fcab9e8f5ee"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 541,  311, 2930, 1326, 1057,  490,  219, 2097, 2247, 4092,  186,  186,\n",
            "         2264, 4275, 4787,  491,  738, 2736, 1073, 1073,  571,   24, 1073, 3593,\n",
            "         1125,  260,  738, 4624, 1888, 4361,  688,  688, 4361, 1326, 4764,  688,\n",
            "          701, 4631, 4177, 1108,  167,  167, 4971, 1064, 3188,  167,  950, 1253,\n",
            "         1904, 4145,  302,  302, 1293, 3160, 2878,  302,  936, 1217, 2684, 2677,\n",
            "          530,  843, 2684, 2288, 1648,  843,  936, 3868, 3129, 1778,  274,  768,\n",
            "         3607, 3670, 5080,  768,  936, 1293, 1278, 2493,  768,  188, 2998, 3423,\n",
            "         1229,  188,  936, 1882, 2064, 3123,  188,  188, 1032, 4329, 1034,  631,\n",
            "          441, 1034, 3330, 1146,  431,  631, 1146, 1031, 2889,  383,  304, 3603,\n",
            "         3603, 1752,    9,  154, 3883, 3603, 3603,  648,  648, 3603, 3190, 3914,\n",
            "          478,  478, 4597, 2594, 2280,  478,  441, 2759, 2759, 2759,  456,  325,\n",
            "         1111, 1111, 1111,  741,  214, 2903, 4086, 1130,  180,  293, 1189, 4371,\n",
            "         1882,  420,  512, 1525, 2370, 2122,  433,  423, 1125, 3433, 2160, 1016,\n",
            "         1016, 1556, 3127, 1824,  838,    9, 2624, 2624, 4317,  388,  214, 1293,\n",
            "         4298, 3284,  103, 1017, 1060, 3082, 2591,  866,  756, 2729, 1485, 3496,\n",
            "          294,  688, 2140, 4106, 1326,  688,  701, 4631, 1782, 1592,  167,  167,\n",
            "         3264, 3188, 1253,  866,  499, 2779, 1882, 2068,    4,  302, 1392, 4106,\n",
            "         1326,  302,  936, 2878, 3196, 2684,  109,  802, 2677, 2288, 3175,  828,\n",
            "          441, 1369, 2753, 1879,  431,  631, 2317, 1614, 3950,  984,  855, 4922,\n",
            "         3917, 3917,  154,  154, 3917, 3708, 3708,  260,  550, 3708, 3708, 3728,\n",
            "          169,  458, 1888, 2146, 1879,  458,  214, 4274, 4274, 2064,  531,    9,\n",
            "         3198, 4706, 4946,  547,   65, 1410, 4145, 3950,  787,  787, 2642, 1353,\n",
            "         2722,  721,  441, 3670, 4038, 3603,    9,  596, 3190, 3603, 3190,  388,\n",
            "          388, 4361, 1326, 1399,  234,  250, 3759, 2809, 3988,  250,  851, 2985,\n",
            "         3164, 2973,  194,  194, 4086, 1951, 2124,  866,  851, 3769, 3186, 4436,\n",
            "          905,  905, 4262, 1593, 1371,  866,   12, 3759, 3759, 3759,   60,  218,\n",
            "         2603, 2998, 4575,  631,  476, 3914, 3603, 1039]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_speaker_info = tts_engine.speakers_info[\"Tingting\"]\n"
      ],
      "metadata": {
        "id": "3MSt0Bvgu3DO"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "tts_mel = tts_engine.common_cosy_model.model.flow.inference(\n",
        "    token=tensor_audio_token_ids.to(device),\n",
        "    token_len=torch.tensor([tensor_audio_token_ids.size(1)], dtype=torch.int32).to(device),\n",
        "    prompt_token=prompt_speaker_info[\"cosy_prompt_token\"].to(device),\n",
        "    prompt_token_len=prompt_speaker_info[\"cosy_prompt_token_len\"].to(device),\n",
        "    prompt_feat=prompt_speaker_info[\"cosy_speech_feat\"].to(torch.bfloat16).to(device),\n",
        "    prompt_feat_len=prompt_speaker_info[\"cosy_speech_feat_len\"].to(device),\n",
        "    embedding=prompt_speaker_info[\"cosy_speech_embedding\"].to(torch.bfloat16).to(device),\n",
        ")"
      ],
      "metadata": {
        "id": "t7F6GQrqkx_O"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tts_mel)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3zkRmh7k1U6",
        "outputId": "6df75d63-9001-4bdf-c443-f7e843c095a5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ -7.4688,  -7.7500,  -7.9375,  ...,  -7.9688,  -7.9375,  -7.9375],\n",
            "         [ -7.9062,  -8.7500,  -8.7500,  ...,  -8.5000,  -8.4375,  -8.6250],\n",
            "         [ -7.9375,  -8.6250,  -8.2500,  ...,  -8.5000,  -8.3125,  -8.7500],\n",
            "         ...,\n",
            "         [-10.5000,  -9.5625,  -9.0000,  ..., -10.8750, -10.8750, -11.0625],\n",
            "         [-11.0625, -10.8750, -10.1250,  ..., -10.9375, -11.0625, -11.3125],\n",
            "         [-10.5000, -10.3750,  -9.8750,  ..., -10.8750, -11.1250, -11.3750]]],\n",
            "       device='cuda:0', dtype=torch.bfloat16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## vocoder(hifi) generate waveform from mel spec"
      ],
      "metadata": {
        "id": "IDLo0Inzf9Ip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tts_speech_waveform = tts_engine.common_cosy_model.model.hift.inference(mel=tts_mel.float())[0].cpu()"
      ],
      "metadata": {
        "id": "BfXDfA_tlae9"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tts_speech_waveform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0i-QXfvlhtX",
        "outputId": "367896dd-2172-4155-bf54-b6aa4d753847"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 4.4956e-07, -4.7694e-05,  3.6056e-07,  ...,  9.2738e-05,\n",
            "          1.5299e-04,  1.9355e-04]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchaudio\n",
        "torchaudio.save(f\"/content/output_tts_again.wav\", tts_speech_waveform, 22050)"
      ],
      "metadata": {
        "id": "JVcouPC9nVbh"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio\n",
        "Audio('/content/output_tts_again.wav',autoplay=True)"
      ],
      "metadata": {
        "id": "JFjjqAeqnbLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## batch generate waveform from aduio vq codes"
      ],
      "metadata": {
        "id": "53DPvG-LrehZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor_audio_token_ids,tensor_audio_token_ids.shape)"
      ],
      "metadata": {
        "id": "yCFOhZWYsA0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: 将tensor_audio_token_ids 按 batch_size 批量 生成\n",
        "\n",
        "import torch\n",
        "\n",
        "# Assuming tensor_audio_token_ids is already defined as in your original code\n",
        "# and has shape (1, sequence_length)\n",
        "\n",
        "def batch_generate(tensor_audio_token_ids, batch_size):\n",
        "  \"\"\"\n",
        "  Generates batches of audio token IDs.\n",
        "\n",
        "  Args:\n",
        "    tensor_audio_token_ids: A tensor of audio token IDs.\n",
        "    batch_size: The desired batch size.\n",
        "\n",
        "  Returns:\n",
        "    A list of tensors, where each tensor is a batch of audio token IDs.\n",
        "  \"\"\"\n",
        "  sequence_length = tensor_audio_token_ids.shape[1]\n",
        "  num_batches = (sequence_length + batch_size - 1) // batch_size\n",
        "  batched_ids = []\n",
        "\n",
        "  for i in range(num_batches):\n",
        "      start_index = i * batch_size\n",
        "      end_index = min((i + 1) * batch_size, sequence_length)\n",
        "      batch = tensor_audio_token_ids[:, start_index:end_index]\n",
        "      batched_ids.append(batch)\n",
        "\n",
        "  return batched_ids"
      ],
      "metadata": {
        "id": "Pe0ddLherl51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "#batch_size = 30\n",
        "stream_factor=2 # >=2 increase for better speech quality, but rft slow (speech quality vs rft slow)\n",
        "batch_size = math.ceil(stream_factor*tts_engine.common_cosy_model.model.flow.input_frame_rate)\n",
        "print(batch_size)\n",
        "batched_tensor_audio_token_ids = batch_generate(tensor_audio_token_ids, batch_size)\n",
        "for batched_tensor_audio_token_id in batched_tensor_audio_token_ids:\n",
        "  print(batched_tensor_audio_token_id,batched_tensor_audio_token_id.shape)\n",
        "print(len(batched_tensor_audio_token_ids))"
      ],
      "metadata": {
        "id": "l6P8Rzzjr6DL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sub_tts_speechs = []\n",
        "# Now you can iterate through the batched_tensor_audio_token_ids and process each batch\n",
        "for batch in batched_tensor_audio_token_ids:\n",
        "    print(batch.shape) # Print the shape of each batch\n",
        "    # Process each batch with tts_engine.common_cosy_model.token_to_wav_offline()\n",
        "    sub_tts_speech = tts_engine.common_cosy_model.token_to_wav_offline(\n",
        "        batch,\n",
        "        prompt_speaker_info[\"cosy_speech_feat\"].to(torch.bfloat16),  # Pass the correct input for this function\n",
        "        prompt_speaker_info[\"cosy_speech_feat_len\"],\n",
        "        prompt_speaker_info[\"cosy_prompt_token\"],\n",
        "        prompt_speaker_info[\"cosy_prompt_token_len\"],\n",
        "        prompt_speaker_info[\"cosy_speech_embedding\"].to(torch.bfloat16),\n",
        "    )\n",
        "    print(sub_tts_speech.shape)\n",
        "    sub_tts_speechs.append(sub_tts_speech)\n"
      ],
      "metadata": {
        "id": "sRqJTf6gsLBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(sub_tts_speechs))"
      ],
      "metadata": {
        "id": "ALnaOFhvslVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: 将 sub_tts_speechs 合并成 一个 tensor\n",
        "\n",
        "import torch\n",
        "\n",
        "# Assuming sub_tts_speechs is a list of tensors\n",
        "# and all tensors in the list have the same number of channels\n",
        "# but possibly different lengths.\n",
        "\n",
        "def merge_tensors(sub_tts_speechs):\n",
        "  \"\"\"Merges a list of tensors into a single tensor.\n",
        "\n",
        "  Args:\n",
        "    sub_tts_speechs: A list of tensors.\n",
        "\n",
        "  Returns:\n",
        "    A single tensor with all the sub tensors concatenated along the time dimension.\n",
        "    Returns None if the input list is empty or contains tensors with inconsistent shapes.\n",
        "  \"\"\"\n",
        "  if not sub_tts_speechs:\n",
        "    return None\n",
        "\n",
        "  num_channels = sub_tts_speechs[0].shape[0]\n",
        "  total_length = sum(tensor.shape[1] for tensor in sub_tts_speechs)\n",
        "  merged_tensor = torch.empty(num_channels, total_length, dtype=sub_tts_speechs[0].dtype, device=sub_tts_speechs[0].device)\n",
        "  current_position = 0\n",
        "\n",
        "  for tensor in sub_tts_speechs:\n",
        "      if tensor.shape[0] != num_channels:\n",
        "          print(\"Error: Tensors have inconsistent number of channels.\")\n",
        "          return None\n",
        "\n",
        "      merged_tensor[:, current_position:current_position + tensor.shape[1]] = tensor\n",
        "      current_position += tensor.shape[1]\n",
        "\n",
        "  return merged_tensor\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rwLUCu_CswMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_speech = merge_tensors(sub_tts_speechs)\n",
        "print(merged_speech)\n",
        "\n",
        "if merged_speech is not None:\n",
        "    print(merged_speech.shape)\n",
        "    torchaudio.save(f\"/content/merged_output.wav\", merged_speech, 22050)\n",
        "    print(\"Merged audio saved to /content/merged_output.wav\")\n",
        "else:\n",
        "    print(\"Could not merge audio tensors.\")"
      ],
      "metadata": {
        "id": "Lq_wqJL4G0ZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio\n",
        "Audio('/content/merged_output.wav',autoplay=True)"
      ],
      "metadata": {
        "id": "zrCmMklmtmgN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}