{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNtFMU4nFzjLBbM4hXFuWUP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6de9a3e53010469eb8e34a61c4bc50e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_456be624e2594c4ba398aade96644fd4",
              "IPY_MODEL_aac07864c9c34f9b8845a9609855ba8b",
              "IPY_MODEL_d670cb9b68b442ee9c2b10ebf7fa5a85"
            ],
            "layout": "IPY_MODEL_a3ab23266ece4f3c9c77ff20639c5d71"
          }
        },
        "456be624e2594c4ba398aade96644fd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_546b66920aa747b980a3fb9b95dd3a87",
            "placeholder": "​",
            "style": "IPY_MODEL_f55018912b5f4baf9f7cab1f2a94b0a6",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "aac07864c9c34f9b8845a9609855ba8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3e2311e2c314fcd8d2f02f6a3765da0",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_23d452762dc04053a2f6f01c08e48362",
            "value": 29
          }
        },
        "d670cb9b68b442ee9c2b10ebf7fa5a85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5999d3abcd6455e8ae0c8b473aa0da8",
            "placeholder": "​",
            "style": "IPY_MODEL_06a62024277743299ab6d66c4745b69f",
            "value": " 29.0/29.0 [00:00&lt;00:00, 1.06kB/s]"
          }
        },
        "a3ab23266ece4f3c9c77ff20639c5d71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "546b66920aa747b980a3fb9b95dd3a87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f55018912b5f4baf9f7cab1f2a94b0a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3e2311e2c314fcd8d2f02f6a3765da0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23d452762dc04053a2f6f01c08e48362": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c5999d3abcd6455e8ae0c8b473aa0da8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06a62024277743299ab6d66c4745b69f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ebd8386725340c881248f589e5642c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_901a5a5414e34191a0a193e6505b4039",
              "IPY_MODEL_d6632a1013e74a6ab6a53c76078504aa",
              "IPY_MODEL_30a0560b585d4be79d7db42b6d925fad"
            ],
            "layout": "IPY_MODEL_53718df8c4d24c47b344309230f7fabc"
          }
        },
        "901a5a5414e34191a0a193e6505b4039": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28e2ed8a0837404f9b3429f16276e35d",
            "placeholder": "​",
            "style": "IPY_MODEL_e1b9d00fcf114fb090f9957286598a09",
            "value": "config.json: 100%"
          }
        },
        "d6632a1013e74a6ab6a53c76078504aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_560cf4483be04041b305de96e68a747f",
            "max": 624,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_69de831226334268a6af2a49b9f42d55",
            "value": 624
          }
        },
        "30a0560b585d4be79d7db42b6d925fad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51bcca07207949eaaaa106c7265c417d",
            "placeholder": "​",
            "style": "IPY_MODEL_b4cbfae071094e7ea56ef079c233300d",
            "value": " 624/624 [00:00&lt;00:00, 9.92kB/s]"
          }
        },
        "53718df8c4d24c47b344309230f7fabc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28e2ed8a0837404f9b3429f16276e35d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1b9d00fcf114fb090f9957286598a09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "560cf4483be04041b305de96e68a747f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69de831226334268a6af2a49b9f42d55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "51bcca07207949eaaaa106c7265c417d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4cbfae071094e7ea56ef079c233300d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0af98a1256a49abbcfd72114095bccf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1e9c7e86134d45e3971e2c61bd56b0b8",
              "IPY_MODEL_f6a8b8a51c814fbf99a135d57d28c602",
              "IPY_MODEL_ff0e318d0f5042cf8e1087f2797c8f6c"
            ],
            "layout": "IPY_MODEL_d0b8692281f242c7824ed96f7c066b6a"
          }
        },
        "1e9c7e86134d45e3971e2c61bd56b0b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8ef81b8d4814099ba593613a2dc1c0f",
            "placeholder": "​",
            "style": "IPY_MODEL_6440fd4a3cda4bac889c03685483d489",
            "value": "vocab.txt: 100%"
          }
        },
        "f6a8b8a51c814fbf99a135d57d28c602": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e83e5b3036d24cdb9a16fecbc3200788",
            "max": 109540,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8382a4aa88a64339aae9e73a717ca26e",
            "value": 109540
          }
        },
        "ff0e318d0f5042cf8e1087f2797c8f6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_daac90800d9c4551b50cdbbaae93b4bf",
            "placeholder": "​",
            "style": "IPY_MODEL_29280533b4814eb8b97a595741aa73fd",
            "value": " 110k/110k [00:00&lt;00:00, 756kB/s]"
          }
        },
        "d0b8692281f242c7824ed96f7c066b6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8ef81b8d4814099ba593613a2dc1c0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6440fd4a3cda4bac889c03685483d489": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e83e5b3036d24cdb9a16fecbc3200788": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8382a4aa88a64339aae9e73a717ca26e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "daac90800d9c4551b50cdbbaae93b4bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29280533b4814eb8b97a595741aa73fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e842db2edc464dbfafe9a7647cc77872": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_17e03aaee1104cee85287accf3151e7f",
              "IPY_MODEL_d67112adeff643be965f0ffc3e63289f",
              "IPY_MODEL_3c15c65908304a18ab20ccfedb4a1f24"
            ],
            "layout": "IPY_MODEL_835a8709023a4d71a9455cb86e8d5103"
          }
        },
        "17e03aaee1104cee85287accf3151e7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70b886b7a1094e96b73222d40bfe722c",
            "placeholder": "​",
            "style": "IPY_MODEL_4facbe326e224e65be9d8a2bbed1b2ec",
            "value": "tokenizer.json: 100%"
          }
        },
        "d67112adeff643be965f0ffc3e63289f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1f7566dca4f4a65923c7ffb7b150ab6",
            "max": 268943,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_248c866ac33240a2903ccf0038cc8d4a",
            "value": 268943
          }
        },
        "3c15c65908304a18ab20ccfedb4a1f24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f689dd18966d42509c5aa82ac3883320",
            "placeholder": "​",
            "style": "IPY_MODEL_1745eb420f8b4245af66f98061277906",
            "value": " 269k/269k [00:00&lt;00:00, 10.7MB/s]"
          }
        },
        "835a8709023a4d71a9455cb86e8d5103": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70b886b7a1094e96b73222d40bfe722c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4facbe326e224e65be9d8a2bbed1b2ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b1f7566dca4f4a65923c7ffb7b150ab6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "248c866ac33240a2903ccf0038cc8d4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f689dd18966d42509c5aa82ac3883320": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1745eb420f8b4245af66f98061277906": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "997e5081556f4f08bccfc533fa7ef1d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b1d319b09fed40cba8ec0831118cb6cd",
              "IPY_MODEL_ec4803cb90f04030bb01a2aba9c7df9c",
              "IPY_MODEL_5f03c55f6b564d77abe99df259150799"
            ],
            "layout": "IPY_MODEL_8df1ad747f814d3f867bdffcf888559b"
          }
        },
        "b1d319b09fed40cba8ec0831118cb6cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45b48b0251d54b3fb4fa6885c93d3b80",
            "placeholder": "​",
            "style": "IPY_MODEL_1a914fa9751446e2a1d194bebb430081",
            "value": "model.safetensors: 100%"
          }
        },
        "ec4803cb90f04030bb01a2aba9c7df9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4c9cdb7d8084db8a929b08917abc7f0",
            "max": 411553788,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ee0e76b2ede447029a6e9a6d364062d6",
            "value": 411553788
          }
        },
        "5f03c55f6b564d77abe99df259150799": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ce71e8d8ac24aeca5099b4d82830d10",
            "placeholder": "​",
            "style": "IPY_MODEL_2bd99885bab34821964a2e318886b704",
            "value": " 412M/412M [00:05&lt;00:00, 40.5MB/s]"
          }
        },
        "8df1ad747f814d3f867bdffcf888559b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45b48b0251d54b3fb4fa6885c93d3b80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a914fa9751446e2a1d194bebb430081": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f4c9cdb7d8084db8a929b08917abc7f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee0e76b2ede447029a6e9a6d364062d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6ce71e8d8ac24aeca5099b4d82830d10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bd99885bab34821964a2e318886b704": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3395283e01074d03830173b3e7821cab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dce7f3a42b9c4493af3cd5b7006eb983",
              "IPY_MODEL_bc72e29d166a405f900c1af0940d576a",
              "IPY_MODEL_c76e946b6f2d4da1a9aa6f6418bd8478"
            ],
            "layout": "IPY_MODEL_97b5bf2b5a0f40438933e1efa5eafb32"
          }
        },
        "dce7f3a42b9c4493af3cd5b7006eb983": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0774a5d2d03f4223a7f0b70dd61c205d",
            "placeholder": "​",
            "style": "IPY_MODEL_5abaf767b5004f5c99c19af0feca5658",
            "value": "100%"
          }
        },
        "bc72e29d166a405f900c1af0940d576a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffaa87295da7478c8b960c405e3bd4f3",
            "max": 300,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_33917196213348c486433f6c900da1fa",
            "value": 300
          }
        },
        "c76e946b6f2d4da1a9aa6f6418bd8478": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09fcc14696444356b43922f3d1a4cb43",
            "placeholder": "​",
            "style": "IPY_MODEL_67f6a5c1c86e48d7b68c6ef6b0627d7f",
            "value": " 300/300 [17:38&lt;00:00,  2.15s/it]"
          }
        },
        "97b5bf2b5a0f40438933e1efa5eafb32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0774a5d2d03f4223a7f0b70dd61c205d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5abaf767b5004f5c99c19af0feca5658": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ffaa87295da7478c8b960c405e3bd4f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33917196213348c486433f6c900da1fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "09fcc14696444356b43922f3d1a4cb43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67f6a5c1c86e48d7b68c6ef6b0627d7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weedge/doraemon-nb/blob/main/transformer_prompting_sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "参考：\n",
        "1. https://xiaosheng.blog/2022/09/10/what-is-prompt\n",
        "2. https://www.promptingguide.ai/zh/introduction/basics\n",
        "3. https://github.com/f/awesome-chatgpt-prompts\n"
      ],
      "metadata": {
        "id": "Fp_0JI2Vu9zb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 数据集\n",
        "中文情感分析语料库 ChnSentiCorp 作为数据集，其包含各类网络评论接近一万条；\n",
        "语料已经划分好了训练集、验证集、测试集（分别包含 9600、1200、1200 条评论），一行是一个样本，使用 TAB 分隔评论和对应的标签，“0”表示消极，“1”表示积极。\n",
        "\n",
        "tip:\n",
        "NLP 大多是分类问题，标注的数据集开始大部分是人工，后续机器标注\n"
      ],
      "metadata": {
        "id": "nL4zB39-1q0q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HGRsV49u5cP",
        "outputId": "feaf5bd6-393e-484a-816c-ba3d5bca0907"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-11 07:44:14--  https://ernie-github.cdn.bcebos.com/data-chnsenticorp.tar.gz\n",
            "Resolving ernie-github.cdn.bcebos.com (ernie-github.cdn.bcebos.com)... 111.170.27.1, 36.99.50.35, 113.219.142.35, ...\n",
            "Connecting to ernie-github.cdn.bcebos.com (ernie-github.cdn.bcebos.com)|111.170.27.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1753724 (1.7M) [application/x-gzip]\n",
            "Saving to: ‘data-chnsenticorp.tar.gz’\n",
            "\n",
            "data-chnsenticorp.t 100%[===================>]   1.67M   956KB/s    in 1.8s    \n",
            "\n",
            "2023-12-11 07:44:17 (956 KB/s) - ‘data-chnsenticorp.tar.gz’ saved [1753724/1753724]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://ernie-github.cdn.bcebos.com/data-chnsenticorp.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar zxvf data-chnsenticorp.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMWasGFv134T",
        "outputId": "b21e31ec-0774-48be-c671-79b4e0731300"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chnsenticorp/\n",
            "chnsenticorp/dev/\n",
            "chnsenticorp/dev/part.0\n",
            "chnsenticorp/test/\n",
            "chnsenticorp/test/part.0\n",
            "chnsenticorp/train/\n",
            "chnsenticorp/train/part.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -gh chnsenticorp/train/part.0\n",
        "!head chnsenticorp/train/part.0\n",
        "!ls -gh chnsenticorp/dev/part.0\n",
        "!head chnsenticorp/dev/part.0\n",
        "!ls -gh chnsenticorp/test/part.0\n",
        "!head chnsenticorp/test/part.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2zLpZTD2HJg",
        "outputId": "7aecdd50-398a-4ab8-8c98-9a2d33223151"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-rw-r-- 1 501 2.9M Jul  2  2019 chnsenticorp/train/part.0\n",
            "选择珠江花园的原因就是方便，有电动扶梯直接到达海边，周围餐馆、食廊、商场、超市、摊位一应俱全。酒店装修一般，但还算整洁。 泳池在大堂的屋顶，因此很小，不过女儿倒是喜欢。 包的早餐是西式的，还算丰富。 服务吗，一般\t1\n",
            "15.4寸笔记本的键盘确实爽，基本跟台式机差不多了，蛮喜欢数字小键盘，输数字特方便，样子也很美观，做工也相当不错\t1\n",
            "房间太小。其他的都一般。。。。。。。。。\t0\n",
            "1.接电源没有几分钟,电源适配器热的不行. 2.摄像头用不起来. 3.机盖的钢琴漆，手不能摸，一摸一个印. 4.硬盘分区不好办.\t0\n",
            "今天才知道这书还有第6卷,真有点郁闷:为什么同一套书有两种版本呢?当当网是不是该跟出版社商量商量,单独出个第6卷,让我们的孩子不会有所遗憾。\t1\n",
            "机器背面似乎被撕了张什么标签，残胶还在。但是又看不出是什么标签不见了，该有的都在，怪\t0\n",
            "呵呵，虽然表皮看上去不错很精致，但是我还是能看得出来是盗的。但是里面的内容真的不错，我妈爱看，我自己也学着找一些穴位。\t0\n",
            "这本书实在是太烂了,以前听浙大的老师说这本书怎么怎么不对,哪些地方都是误导的还不相信,终于买了一本看一下,发现真是~~~无语,这种书都写得出来\t0\n",
            "地理位置佳，在市中心。酒店服务好、早餐品种丰富。我住的商务数码房电脑宽带速度满意,房间还算干净，离湖南路小吃街近。\t1\n",
            "5.1期间在这住的，位置还可以，在市委市政府附近，要去商业区和步行街得打车，屋里有蚊子，虽然空间挺大，晚上熄灯后把窗帘拉上简直是伸手不见五指，很适合睡觉，但是会被该死的蚊子吵醒！打死了两只，第二天早上还是发现又没打死的，卫生间挺大，但是设备很老旧。\t1\n",
            "-rw-rw-r-- 1 501 366K Jul  2  2019 chnsenticorp/dev/part.0\n",
            "這間酒店環境和服務態度亦算不錯,但房間空間太小~~不宣容納太大件行李~~且房間格調還可以~~ 中餐廳的廣東點心不太好吃~~要改善之~~~~但算價錢平宜~~可接受~~ 西餐廳格調都很好~~但吃的味道一般且令人等得太耐了~~要改善之~~\t1\n",
            "<荐书> 推荐所有喜欢<红楼>的红迷们一定要收藏这本书,要知道当年我听说这本书的时候花很长时间去图书馆找和借都没能如愿,所以这次一看到当当有,马上买了,红迷们也要记得备货哦!\t1\n",
            "商品的不足暂时还没发现，京东的订单处理速度实在.......周二就打包完成，周五才发货...\t0\n",
            "２００１年来福州就住在这里，这次感觉房间就了点，温泉水还是有的．总的来说很满意．早餐简单了些．\t1\n",
            "不错的上网本，外形很漂亮，操作系统应该是个很大的 卖点，电池还可以。整体上讲，作为一个上网本的定位，还是不错的。\t1\n",
            "房间地毯太脏，临近火车站十分吵闹，还好是双层玻璃。服务一般，酒店门口的TAXI讲是酒店的长期合作关系，每月要交费给酒店。从酒店到机场讲得是打表147元，到了后非要200元，可能被小宰30-40元。\t0\n",
            "本来想没事的时候翻翻，可惜看不下去，还是和张没法比，他的书能畅销大部分还是受张的影响，对这个男人实在是没好感，不知道怎么买的，后悔\t0\n",
            "这台机外观十分好,本人喜欢,性能不错,是LED显示屏,无线网卡是: 5100AGN 无线网卡,如果装的是一条2G 800MHZ的内存就无敌了,本本发热很小,总体来说是十分值得买的,前提是这台机是4299买的.\t1\n",
            "全键盘带数字键的 显卡足够强大.N卡相对A卡,个人偏向N卡 GHOST XP很容易.除了指纹识别外.所有驱动都能装齐全了,指纹识别,非要在XP下使用的朋友,可以用替代驱动.贡献下驱动地址: http://dlsvr01.asus.com/pub/ASUS/nb/F9Dc/Fingerprints_XP_080530.zip (华硕官方地址,放心下吧)\t1\n",
            "做工很漂亮，老婆很喜欢。T4200足够了，性价比不错的机器。测试了一下很安逸。今天晚上准备TWOW溜达圈，再看看整机表现如何！\t1\n",
            "-rw-rw-r-- 1 501 362K Apr 22  2020 chnsenticorp/test/part.0\n",
            "这个宾馆比较陈旧了，特价的房间也很一般。总体来说一般\t1\n",
            "怀着十分激动的心情放映，可是看着看着发现，在放映完毕后，出现一集米老鼠的动画片！开始还怀疑是不是赠送的个别现象，可是后来发现每张DVD后面都有！真不知道生产商怎么想的，我想看的是猫和老鼠，不是米老鼠！如果厂家是想赠送的话，那就全套米老鼠和唐老鸭都赠送，只在每张DVD后面添加一集算什么？？简直是画蛇添足！！\t0\n",
            "还稍微重了点，可能是硬盘大的原故，还要再轻半斤就好了。其他要进一步验证。贴的几种膜气泡较多，用不了多久就要更换了，屏幕膜稍好点，但比没有要强多了。建议配赠几张膜让用用户自己贴。\t0\n",
            "交通方便；环境很好；服务态度很好 房间较小\t1\n",
            "不错，作者的观点很颠覆目前中国父母的教育方式，其实古人们对于教育已经有了很系统的体系了，可是现在的父母以及祖父母们更多的娇惯纵容孩子，放眼看去自私的孩子是大多数，父母觉得自己的孩子在外面只要不吃亏就是好事，完全把古人几千年总结的教育古训抛在的九霄云外。所以推荐准妈妈们可以在等待宝宝降临的时候，好好学习一下，怎么把孩子教育成一个有爱心、有责任心、宽容、大度的人。\t1\n",
            "有了第一本书的铺垫，读第二本的时候开始进入状态。基本上第二本就围绕主角们的能力训练展开，故事的主要发生场地设置在美洲的亚马逊丛林。心里一直疑惑这和西藏有什么关系，不过大概看完全书才能知道内里的线索。其中描述了很多热带雨林中特有的神秘动植物以及一些生存技巧和常识，受益匪浅。能够想像出要写这样一部书，融合这样许多的知识，作者需要花费多少心血来搜集和整理并成文。\t1\n",
            "前台接待太差，酒店有A B楼之分，本人check－in后，前台未告诉B楼在何处，并且B楼无明显指示；房间太小，根本不像4星级设施，下次不会再选择入住此店啦。\t0\n",
            "1. 白色的，很漂亮，做工还可以； 2. 网上的软件资源非常丰富，这是我买它的最主要原因； 3. 电池不错，昨天从下午两点到晚上十点还有25分钟的剩余时间（关闭摄像头，无线和蓝牙）主要拷贝东西，看起来正常使用八小时左右没问题； 4. 散热不错，CPU核心不过40~55度，很多小本要上到80度了； 5. 变压器很小巧，很多小本的电源都用的是大本的电源，本倒是很轻，可旅行重量还是比较重。\t1\n",
            "在当当上买了很多书，都懒于评论。但这套书真的很好，3册都非常精彩。我家小一的女儿，认字多，非常喜爱，每天睡前必读。她还告诉我，学校的语文课本中也有相同的文章。我还借给我的同事的女儿，我同事一直头疼她女儿不爱看书，但这套书，她女儿非常喜欢。两周就看完了。建议买。很少写评论，但忍不住为这套书写下。也给别的读者参考下。\t1\n",
            "19天硬盘就罢工了~~~算上运来的一周都没用上15天~~~可就是不能换了~~~唉~~~~你说这算什么事呀~~~\t0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 构造数据"
      ],
      "metadata": {
        "id": "Xd8xU3nd9Uyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class ChnSentiCorp(Dataset):\n",
        "    def __init__(self, data_file):\n",
        "        self.data = self.load_data(data_file)\n",
        "\n",
        "    def load_data(self, data_file):\n",
        "        Data = {}\n",
        "        with open(data_file, 'rt', encoding='utf-8') as f:\n",
        "            for idx, line in enumerate(f):\n",
        "                items = line.strip().split('\\t')\n",
        "                assert len(items) == 2\n",
        "                Data[idx] = {\n",
        "                    'comment': items[0],\n",
        "                    'label': items[1]\n",
        "                }\n",
        "        return Data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "train_data = ChnSentiCorp('chnsenticorp/train/part.0')\n",
        "valid_data = ChnSentiCorp('chnsenticorp/dev/part.0')\n",
        "test_data = ChnSentiCorp('chnsenticorp/test/part.0')\n"
      ],
      "metadata": {
        "id": "z8SpKwVF11vY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'train set size: {len(train_data)}')\n",
        "print(f'valid set size: {len(valid_data)}')\n",
        "print(f'test set size: {len(test_data)}')\n",
        "print(next(iter(train_data)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQZxn_ZF3FLx",
        "outputId": "93732600-b5ff-4f22-8b72-c25f55d4accb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set size: 9600\n",
            "valid set size: 1200\n",
            "test set size: 1200\n",
            "{'comment': '选择珠江花园的原因就是方便，有电动扶梯直接到达海边，周围餐馆、食廊、商场、超市、摊位一应俱全。酒店装修一般，但还算整洁。 泳池在大堂的屋顶，因此很小，不过女儿倒是喜欢。 包的早餐是西式的，还算丰富。 服务吗，一般', 'label': '1'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "最常见的 Prompting 方法就是借助模板将问题转换为 MLM 任务来解决。这里我们定义模板形式为“总体上来说很 [MASK]。x”，其中 x 表示评论文本，并且规定如果 [MASK]被预测为“好”就判定情感为“积极”，如果预测为“差”就判定为“消极”，即“积极”和“消极”标签对应的 label word 分别为“好 1”和“差 0”。\n",
        "\n"
      ],
      "metadata": {
        "id": "XNN18ydO4uhF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_prompt(x):\n",
        "    prompt = f'总体上来说很[MASK]。{x}'\n",
        "    return {\n",
        "        'prompt': prompt,\n",
        "        'mask_offset': prompt.find('[MASK]')\n",
        "    }\n",
        "\n",
        "def get_verbalizer(tokenizer):\n",
        "    return {\n",
        "        'pos': {'token': '好', 'id': tokenizer.convert_tokens_to_ids(\"好\")},\n",
        "        'neg': {'token': '差', 'id': tokenizer.convert_tokens_to_ids(\"差\")}\n",
        "    }\n"
      ],
      "metadata": {
        "id": "gUxsSGHY5It_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BERT 分词器正确地将“[MASK]”识别为一个 token，并且记录下 [MASK] token 在序列中的索引\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "checkpoint = \"bert-base-chinese\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "\n",
        "comment = '这个宾馆比较陈旧了，特价的房间也很一般。总体来说一般。'\n",
        "\n",
        "print('verbalizer:', get_verbalizer(tokenizer))\n",
        "\n",
        "prompt_data = get_prompt(comment)\n",
        "prompt, mask_offset = prompt_data['prompt'], prompt_data['mask_offset']\n",
        "\n",
        "encoding = tokenizer(prompt, truncation=True)\n",
        "tokens = encoding.tokens()\n",
        "mask_idx = encoding.char_to_token(mask_offset)\n",
        "\n",
        "print('prompt:', prompt)\n",
        "print('prompt tokens:', tokens)\n",
        "print('mask idx:', mask_idx)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234,
          "referenced_widgets": [
            "6de9a3e53010469eb8e34a61c4bc50e4",
            "456be624e2594c4ba398aade96644fd4",
            "aac07864c9c34f9b8845a9609855ba8b",
            "d670cb9b68b442ee9c2b10ebf7fa5a85",
            "a3ab23266ece4f3c9c77ff20639c5d71",
            "546b66920aa747b980a3fb9b95dd3a87",
            "f55018912b5f4baf9f7cab1f2a94b0a6",
            "f3e2311e2c314fcd8d2f02f6a3765da0",
            "23d452762dc04053a2f6f01c08e48362",
            "c5999d3abcd6455e8ae0c8b473aa0da8",
            "06a62024277743299ab6d66c4745b69f",
            "7ebd8386725340c881248f589e5642c6",
            "901a5a5414e34191a0a193e6505b4039",
            "d6632a1013e74a6ab6a53c76078504aa",
            "30a0560b585d4be79d7db42b6d925fad",
            "53718df8c4d24c47b344309230f7fabc",
            "28e2ed8a0837404f9b3429f16276e35d",
            "e1b9d00fcf114fb090f9957286598a09",
            "560cf4483be04041b305de96e68a747f",
            "69de831226334268a6af2a49b9f42d55",
            "51bcca07207949eaaaa106c7265c417d",
            "b4cbfae071094e7ea56ef079c233300d",
            "e0af98a1256a49abbcfd72114095bccf",
            "1e9c7e86134d45e3971e2c61bd56b0b8",
            "f6a8b8a51c814fbf99a135d57d28c602",
            "ff0e318d0f5042cf8e1087f2797c8f6c",
            "d0b8692281f242c7824ed96f7c066b6a",
            "d8ef81b8d4814099ba593613a2dc1c0f",
            "6440fd4a3cda4bac889c03685483d489",
            "e83e5b3036d24cdb9a16fecbc3200788",
            "8382a4aa88a64339aae9e73a717ca26e",
            "daac90800d9c4551b50cdbbaae93b4bf",
            "29280533b4814eb8b97a595741aa73fd",
            "e842db2edc464dbfafe9a7647cc77872",
            "17e03aaee1104cee85287accf3151e7f",
            "d67112adeff643be965f0ffc3e63289f",
            "3c15c65908304a18ab20ccfedb4a1f24",
            "835a8709023a4d71a9455cb86e8d5103",
            "70b886b7a1094e96b73222d40bfe722c",
            "4facbe326e224e65be9d8a2bbed1b2ec",
            "b1f7566dca4f4a65923c7ffb7b150ab6",
            "248c866ac33240a2903ccf0038cc8d4a",
            "f689dd18966d42509c5aa82ac3883320",
            "1745eb420f8b4245af66f98061277906"
          ]
        },
        "id": "KwjouCWb5J8b",
        "outputId": "69742d06-4340-46e7-ec19-a9e567e615b1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6de9a3e53010469eb8e34a61c4bc50e4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/624 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ebd8386725340c881248f589e5642c6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/110k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e0af98a1256a49abbcfd72114095bccf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/269k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e842db2edc464dbfafe9a7647cc77872"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "verbalizer: {'pos': {'token': '好', 'id': 1962}, 'neg': {'token': '差', 'id': 2345}}\n",
            "prompt: 总体上来说很[MASK]。这个宾馆比较陈旧了，特价的房间也很一般。总体来说一般。\n",
            "prompt tokens: ['[CLS]', '总', '体', '上', '来', '说', '很', '[MASK]', '。', '这', '个', '宾', '馆', '比', '较', '陈', '旧', '了', '，', '特', '价', '的', '房', '间', '也', '很', '一', '般', '。', '总', '体', '来', '说', '一', '般', '。', '[SEP]']\n",
            "mask idx: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "但是这种做法要求我们能够从词表中找到合适的 label word 来代表每一个类别，并且 label word 只能包含一个 token，而很多时候这是无法实现的。因此，另一种常见做法是为每个类别构建一个可学习的虚拟 token（又称伪 token），然后运用类别描述来初始化虚拟 token 的表示，最后使用这些虚拟 token 来扩展模型的 MLM 头。\n",
        "\n",
        "例如，这里我们可以为“积极”和“消极”构建专门的虚拟 token “[POS]”和“[NEG]”，并且设置对应的类别描述为“好的、优秀的、正面的评价、积极的态度”和“差的、糟糕的、负面的评价、消极的态度”。下面我们扩展一下上面的 verbalizer 函数，添加一个 vtype 参数来区分两种 verbalizer 类型："
      ],
      "metadata": {
        "id": "RwJj7gzA68SI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_verbalizer(tokenizer, vtype):\n",
        "    assert vtype in ['base', 'virtual']\n",
        "    return {\n",
        "        'pos': {'token': '好', 'id': tokenizer.convert_tokens_to_ids(\"好\")},\n",
        "        'neg': {'token': '差', 'id': tokenizer.convert_tokens_to_ids(\"差\")}\n",
        "    } if vtype == 'base' else {\n",
        "        'pos': {\n",
        "            'token': '[POS]', 'id': tokenizer.convert_tokens_to_ids(\"[POS]\"),\n",
        "            'description': '好的、优秀的、正面的评价、积极的态度'\n",
        "        },\n",
        "        'neg': {\n",
        "            'token': '[NEG]', 'id': tokenizer.convert_tokens_to_ids(\"[NEG]\"),\n",
        "            'description': '差的、糟糕的、负面的评价、消极的态度'\n",
        "        }\n",
        "    }\n",
        "\n",
        "vtype = 'virtual'\n",
        "# add label words\n",
        "if vtype == 'virtual':\n",
        "    tokenizer.add_special_tokens({'additional_special_tokens': ['[POS]', '[NEG]']})\n",
        "print('verbalizer:', get_verbalizer(tokenizer, vtype=vtype))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfhxJcVt6tYd",
        "outputId": "07a00e27-72d0-4ecb-c2cd-027f90d1205c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "verbalizer: {'pos': {'token': '[POS]', 'id': 21129, 'description': '好的、优秀的、正面的评价、积极的态度'}, 'neg': {'token': '[NEG]', 'id': 21128, 'description': '差的、糟糕的、负面的评价、消极的态度'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompting 方法实际输入的是转换后的模板，而不是原始文本，因此我们首先使用模板函数 get_prompt() 来更新数据集：\n",
        "class ChnSentiCorp(Dataset):\n",
        "    def __init__(self, data_file):\n",
        "        self.data = self.load_data(data_file)\n",
        "\n",
        "    def load_data(self, data_file):\n",
        "        Data = {}\n",
        "        with open(data_file, 'rt', encoding='utf-8') as f:\n",
        "            for idx, line in enumerate(f):\n",
        "                items = line.strip().split('\\t')\n",
        "                assert len(items) == 2\n",
        "                prompt_data = get_prompt(items[0])\n",
        "                Data[idx] = {\n",
        "                    'comment': items[0],\n",
        "                    'prompt': prompt_data['prompt'],\n",
        "                    'mask_offset': prompt_data['mask_offset'],\n",
        "                    'label': items[1]\n",
        "                }\n",
        "        return Data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "train_data = ChnSentiCorp('chnsenticorp/train/part.0')\n",
        "valid_data = ChnSentiCorp('chnsenticorp/dev/part.0')\n",
        "test_data = ChnSentiCorp('chnsenticorp/test/part.0')\n",
        "\n",
        "print(f'train set size: {len(train_data)}')\n",
        "print(f'valid set size: {len(valid_data)}')\n",
        "print(f'test set size: {len(test_data)}')\n",
        "print(next(iter(train_data)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWmzLw5H7wOX",
        "outputId": "562951ce-da85-4ca6-ed4b-a08842023f34"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set size: 9600\n",
            "valid set size: 1200\n",
            "test set size: 1200\n",
            "{'comment': '选择珠江花园的原因就是方便，有电动扶梯直接到达海边，周围餐馆、食廊、商场、超市、摊位一应俱全。酒店装修一般，但还算整洁。 泳池在大堂的屋顶，因此很小，不过女儿倒是喜欢。 包的早餐是西式的，还算丰富。 服务吗，一般', 'prompt': '总体上来说很[MASK]。选择珠江花园的原因就是方便，有电动扶梯直接到达海边，周围餐馆、食廊、商场、超市、摊位一应俱全。酒店装修一般，但还算整洁。 泳池在大堂的屋顶，因此很小，不过女儿倒是喜欢。 包的早餐是西式的，还算丰富。 服务吗，一般', 'mask_offset': 6, 'label': '1'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 数据预处理"
      ],
      "metadata": {
        "id": "p5VF5_c69XjM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "vtype = 'base'\n",
        "max_length = 512\n",
        "\n",
        "checkpoint = \"bert-base-chinese\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "if vtype == 'virtual':\n",
        "    tokenizer.add_special_tokens({'additional_special_tokens': ['[POS]', '[NEG]']})\n",
        "\n",
        "verbalizer = get_verbalizer(tokenizer, vtype='base')\n",
        "pos_id, neg_id = verbalizer['pos']['id'], verbalizer['neg']['id']\n",
        "\n",
        "def collate_fn(batch_samples):\n",
        "    batch_sentences, batch_mask_idxs, batch_labels  = [], [], []\n",
        "    for sample in batch_samples:\n",
        "        batch_sentences.append(sample['prompt'])\n",
        "        encoding = tokenizer(sample['prompt'], truncation=True)\n",
        "        mask_idx = encoding.char_to_token(sample['mask_offset'])\n",
        "        assert mask_idx is not None\n",
        "        batch_mask_idxs.append(mask_idx)\n",
        "        batch_labels.append(int(sample['label']))\n",
        "    batch_inputs = tokenizer(\n",
        "        batch_sentences,\n",
        "        max_length=max_length,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    label_word_id = [neg_id, pos_id]\n",
        "    return {\n",
        "        'batch_inputs': batch_inputs,\n",
        "        'batch_mask_idxs': batch_mask_idxs,\n",
        "        'label_word_id': label_word_id,\n",
        "        'labels': batch_labels\n",
        "    }\n",
        "\n",
        "train_dataloader = DataLoader(train_data, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
        "valid_dataloader = DataLoader(valid_data, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
        "test_dataloader = DataLoader(test_data, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "batch_data = next(iter(train_dataloader))\n",
        "print('batch_X shape:', {k: v.shape for k, v in batch_data['batch_inputs'].items()})\n",
        "print(batch_data['batch_inputs'])\n",
        "print(batch_data['batch_mask_idxs'])\n",
        "print(batch_data['label_word_id'])\n",
        "print(batch_data['labels'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BktNq2M9K35",
        "outputId": "21ff44ec-5305-4794-94d9-17f2bf933d7c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch_X shape: {'input_ids': torch.Size([4, 187]), 'token_type_ids': torch.Size([4, 187]), 'attention_mask': torch.Size([4, 187])}\n",
            "{'input_ids': tensor([[ 101, 2600,  860,  677, 3341, 6432, 2523,  103,  511, 5018,  671, 1921,\n",
            "         8264, 8653, 6843, 3341, 8024, 5018,  753, 1921, 2218, 8248, 8653,  749,\n",
            "         8024, 2552, 7027,  679, 2398, 6130,  511, 7721, 1220, 2190, 9847, 4638,\n",
            "         3118, 2898, 4696, 1962, 8024, 5632, 1220, 2218, 6163,  677,  749, 8024,\n",
            "          852, 3221,  100, 1377, 5736,  749, 2769,  749, 8024,  671,  702,  671,\n",
            "          702, 4638, 3043, 5164, 1557, 8024, 5310, 3362, 6820,  679, 4007, 2692,\n",
            "          511,  102,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0],\n",
            "        [ 101, 2600,  860,  677, 3341, 6432, 2523,  103,  511, 3297, 6818, 3300,\n",
            "         4157, 2564, 4684, 1168, 3219, 1921, 3241,  677, 6438, 2130,  749, 3146,\n",
            "         6956,  741, 8024, 2769, 7448, 3072,  749, 4294, 1166, 3221, 6438, 1168,\n",
            "         2207, 4331, 6206, 6206, 6810, 4919, 4638, 3198,  952, 8024, 2769, 2798,\n",
            "         3209, 4635,  784,  720, 3221,  949, 2487,  784,  720, 1373, 3422, 7748,\n",
            "          679, 7719, 6929, 1168, 2419, 3221,  671, 4905,  784,  720, 3416, 4638,\n",
            "         2595, 3419, 8024, 4684, 1168, 7357, 7357,  679, 2533,  679,  779, 2797,\n",
            "         3324, 3647, 2207, 4331, 4638, 3198,  952, 8024, 2769, 1126,  725,  738,\n",
            "         2345, 4157, 1526, 1139, 3341, 8024,  782, 4331, 8024, 6821, 3221,  671,\n",
            "         4905,  784,  720, 3416, 4638, 2697, 2658,  511, 2218, 1008, 1166,  782,\n",
            "         5314, 4638, 6397, 6389,  671, 3416, 8024, 4331, 1745, 5596, 6375,  782,\n",
            "          812, 1235,  754, 2824, 6371,  782,  812, 5632, 6716, 4052, 1762, 4638,\n",
            "         2483, 4157, 8024, 5445, 2496,  791, 4852,  833,  782,  812, 6833, 1147,\n",
            "         7444, 6206, 4638,  679, 3633, 3221, 2418, 6421, 1008, 4331, 6929, 3416,\n",
            "         4638, 2595, 3419, 1408, 8043, 6821, 4696, 3221,  671, 6956, 1936,  741,\n",
            "          511,  102,    0,    0,    0,    0,    0],\n",
            "        [ 101, 2600,  860,  677, 3341, 6432, 2523,  103,  511,  100, 1905, 4415,\n",
            "         1690, 6006, 4197, 3403, 4917, 7574, 4372, 3221,  122,  119,  100,  117,\n",
            "          852,  100, 4495, 5314, 7360, 1168,  122,  119,  100,  119,  119,  119,\n",
            "         6006, 4197,  122,  119,  100, 2130, 1059, 1916,  749, 8024,  852, 3221,\n",
            "          119,  119, 3857, 6589, 1557,  119,  119,  119,  122,  119,  129, 4638,\n",
            "         4801, 4669, 4802, 2141, 7444, 6206, 3300, 4157, 5447, 2552,  119,  119,\n",
            "          119,  102,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0],\n",
            "        [ 101, 2600,  860,  677, 3341, 6432, 2523,  103,  511,  809, 1184, 1762,\n",
            "         4997, 6413, 3125,  752,  704, 5314, 1957, 1036, 6382, 6814, 1154, 6929,\n",
            "         4316,  982, 7824, 4638, 3125,  752, 8024, 1961, 1420, 2533, 5471, 5125,\n",
            "          833, 4868, 8024, 4706, 4714, 4709, 4638, 1920, 1920, 4638, 8024, 2769,\n",
            "         4696, 2361, 3307, 3125,  752, 1166, 6821,  720, 5125, 2506, 8024, 6375,\n",
            "         1961, 2571, 4157, 4717, 6230, 8024, 1457, 1457,  511, 1400, 3341,  743,\n",
            "          749, 6821, 3315,  741, 8024, 1957, 1036, 2523, 1599, 3614, 1765, 4692,\n",
            "          749,  671, 3667, 3198, 7313, 8024,  671, 1168, 4717, 6230, 1184, 6382,\n",
            "         3125,  752, 4638, 3198,  952, 8024, 2218, 6206, 6382,  100, 1154, 6929,\n",
            "         4316,  100, 8024, 6821, 3221,  671, 1372, 1914,  720, 5473, 3209, 4638,\n",
            "         4316, 4329, 1557, 8024, 1599, 3614,  511, 4385, 1762, 1957, 1036, 1920,\n",
            "          749, 4157, 8024,  679, 2582,  720, 4692,  749,  511,  679, 6814, 6821,\n",
            "         3315,  741, 2372, 3341, 4638, 2571,  727, 3198, 1045, 8024, 3221, 3719,\n",
            "         6823,  738, 2563, 6381,  679,  749, 4638,  511, 6820, 3300, 6821, 1372,\n",
            "         1399, 1373, 1154, 6929, 4638, 4316, 4329, 8024, 2372, 5314, 2769,  812,\n",
            "         4638, 2571,  727, 3198, 1045,  511,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
            "[7, 7, 7, 7]\n",
            "[2345, 1962]\n",
            "[0, 1, 0, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 训练模型"
      ],
      "metadata": {
        "id": "8_ESQrFWCAgM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 构建模型"
      ],
      "metadata": {
        "id": "7-ONVlrNRgXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForMaskedLM\n",
        "\n",
        "checkpoint = \"bert-base-chinese\"\n",
        "model = AutoModelForMaskedLM.from_pretrained(checkpoint)\n",
        "\n",
        "text = \"总体上来说很[MASK]。这个宾馆比较陈旧了，特价的房间也很一般。总体来说一般。\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "token_logits = model(**inputs).logits\n",
        "# Find the location of [MASK] and extract its logits\n",
        "mask_token_index = torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)[1]\n",
        "mask_token_logits = token_logits[0, mask_token_index, :]\n",
        "# Pick the [MASK] candidates with the highest logits\n",
        "top_5_tokens = torch.topk(mask_token_logits, 5, dim=1).indices[0].tolist()\n",
        "\n",
        "\n",
        "for token in top_5_tokens:\n",
        "    print(f\"'>>> {text.replace(tokenizer.mask_token, tokenizer.decode([token]))}'\")\n",
        "\n",
        "# BERT 模型成功地将 [MASK] token 预测成了我们预期的表意词“好”。这里还打印出了其他几个大概率的预测词，大部分都具有积极的情感（“好”、“棒”、“赞”）"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208,
          "referenced_widgets": [
            "997e5081556f4f08bccfc533fa7ef1d6",
            "b1d319b09fed40cba8ec0831118cb6cd",
            "ec4803cb90f04030bb01a2aba9c7df9c",
            "5f03c55f6b564d77abe99df259150799",
            "8df1ad747f814d3f867bdffcf888559b",
            "45b48b0251d54b3fb4fa6885c93d3b80",
            "1a914fa9751446e2a1d194bebb430081",
            "f4c9cdb7d8084db8a929b08917abc7f0",
            "ee0e76b2ede447029a6e9a6d364062d6",
            "6ce71e8d8ac24aeca5099b4d82830d10",
            "2bd99885bab34821964a2e318886b704"
          ]
        },
        "id": "XhXYrI6xCCmy",
        "outputId": "5c96ea83-de8a-46b6-da55-152d79daa964"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/412M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "997e5081556f4f08bccfc533fa7ef1d6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'cls.seq_relationship.weight', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'>>> 总体上来说很好。这个宾馆比较陈旧了，特价的房间也很一般。总体来说一般。'\n",
            "'>>> 总体上来说很棒。这个宾馆比较陈旧了，特价的房间也很一般。总体来说一般。'\n",
            "'>>> 总体上来说很差。这个宾馆比较陈旧了，特价的房间也很一般。总体来说一般。'\n",
            "'>>> 总体上来说很般。这个宾馆比较陈旧了，特价的房间也很一般。总体来说一般。'\n",
            "'>>> 总体上来说很赞。这个宾馆比较陈旧了，特价的房间也很一般。总体来说一般。'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 直接使用bert模型不够灵活，基于bert重新构建模型BertForPrompt, 加入自定义的BertOnlyMLMHead进行推理\n",
        "from torch import nn\n",
        "from transformers.activations import ACT2FN\n",
        "from transformers import AutoConfig\n",
        "from transformers import BertPreTrainedModel, BertModel\n",
        "\n",
        "def batched_index_select(input, dim, index):\n",
        "    for i in range(1, len(input.shape)):\n",
        "        if i != dim:\n",
        "            index = index.unsqueeze(i)\n",
        "    expanse = list(input.shape)\n",
        "    expanse[0] = -1\n",
        "    expanse[dim] = -1\n",
        "    index = index.expand(expanse)\n",
        "    return torch.gather(input, dim, index)\n",
        "\n",
        "class BertPredictionHeadTransform(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
        "        if isinstance(config.hidden_act, str):\n",
        "            self.transform_act_fn = ACT2FN[config.hidden_act]\n",
        "        else:\n",
        "            self.transform_act_fn = config.hidden_act\n",
        "        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
        "\n",
        "    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:\n",
        "        hidden_states = self.dense(hidden_states)\n",
        "        hidden_states = self.transform_act_fn(hidden_states)\n",
        "        hidden_states = self.LayerNorm(hidden_states)\n",
        "        return hidden_states\n",
        "\n",
        "class BertLMPredictionHead(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.transform = BertPredictionHeadTransform(config)\n",
        "        self.decoder = nn.Linear(config.hidden_size, config.vocab_size, bias=False)\n",
        "        self.bias = nn.Parameter(torch.zeros(config.vocab_size))\n",
        "        self.decoder.bias = self.bias\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        hidden_states = self.transform(hidden_states)\n",
        "        hidden_states = self.decoder(hidden_states)\n",
        "        return hidden_states\n",
        "\n",
        "class BertOnlyMLMHead(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.predictions = BertLMPredictionHead(config)\n",
        "\n",
        "    def forward(self, sequence_output: torch.Tensor) -> torch.Tensor:\n",
        "        prediction_scores = self.predictions(sequence_output)\n",
        "        return prediction_scores\n",
        "\n",
        "class BertForPrompt(BertPreTrainedModel):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.bert = BertModel(config, add_pooling_layer=False)\n",
        "        self.cls = BertOnlyMLMHead(config)\n",
        "        # Initialize weights and apply final processing\n",
        "        self.post_init()\n",
        "\n",
        "    def get_output_embeddings(self):\n",
        "        return self.cls.predictions.decoder\n",
        "\n",
        "    def set_output_embeddings(self, new_embeddings):\n",
        "        self.cls.predictions.decoder = new_embeddings\n",
        "\n",
        "    def forward(self, batch_inputs, batch_mask_idxs, label_word_id, labels=None):\n",
        "        bert_output = self.bert(**batch_inputs)\n",
        "        sequence_output = bert_output.last_hidden_state\n",
        "        batch_mask_reps = batched_index_select(sequence_output, 1, batch_mask_idxs.unsqueeze(-1)).squeeze(1)\n",
        "        prediction_scores = self.cls(batch_mask_reps)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss_fn = nn.CrossEntropyLoss()\n",
        "            loss = loss_fn(prediction_scores, labels)\n",
        "        return loss, prediction_scores[:, label_word_id]\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Using {device} device')\n",
        "checkpoint = \"bert-base-chinese\"\n",
        "config = AutoConfig.from_pretrained(checkpoint)\n",
        "model = BertForPrompt.from_pretrained(checkpoint, config=config).to(device)\n",
        "if vtype == 'virtual':\n",
        "    model.resize_token_embeddings(len(tokenizer))\n",
        "    print(f\"initialize embeddings of {verbalizer['pos']['token']} and {verbalizer['neg']['token']}\")\n",
        "    with torch.no_grad():\n",
        "        pos_tokenized = tokenizer(verbalizer['pos']['description'])\n",
        "        pos_tokenized_ids = tokenizer.convert_tokens_to_ids(pos_tokenized)\n",
        "        neg_tokenized = tokenizer(verbalizer['neg']['description'])\n",
        "        neg_tokenized_ids = tokenizer.convert_tokens_to_ids(neg_tokenized)\n",
        "        new_embedding = model.bert.embeddings.word_embeddings.weight[pos_tokenized_ids].mean(axis=0)\n",
        "        model.bert.embeddings.word_embeddings.weight[pos_id, :] = new_embedding.clone().detach().requires_grad_(True)\n",
        "        new_embedding = model.bert.embeddings.word_embeddings.weight[neg_tokenized_ids].mean(axis=0)\n",
        "        model.bert.embeddings.word_embeddings.weight[neg_id, :] = new_embedding.clone().detach().requires_grad_(True)\n",
        "\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mLVi1dBJB2a",
        "outputId": "493ecd70-7fd3-4fd6-accb-2c94d45de400"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "BertForPrompt(\n",
            "  (bert): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (token_type_embeddings): Embedding(2, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0-11): 12 x BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (cls): BertOnlyMLMHead(\n",
            "    (predictions): BertLMPredictionHead(\n",
            "      (transform): BertPredictionHeadTransform(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (transform_act_fn): GELUActivation()\n",
            "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      )\n",
            "      (decoder): Linear(in_features=768, out_features=21128, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERT 自带的 MLM head 由两个部分组成：首先对所有 token 进行一个 768x768 的非线性映射（包括激活函数和 LayerNorm），然后使用一个 768x21128 的线性映射预测词表中每个 token 的分数。\n",
        "\n"
      ],
      "metadata": {
        "id": "7xOqsDwgOwem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 为了测试模型的操作是否符合预期，将一个 batch 的数据送入模型\n",
        "def to_device(batch_data):\n",
        "    new_batch_data = {}\n",
        "    for k, v in batch_data.items():\n",
        "        if k == 'batch_inputs':\n",
        "            new_batch_data[k] = {\n",
        "                k_: v_.to(device) for k_, v_ in v.items()\n",
        "            }\n",
        "        elif k == 'label_word_id':\n",
        "            new_batch_data[k] = v\n",
        "        else:\n",
        "            new_batch_data[k] = torch.tensor(v).to(device)\n",
        "    return new_batch_data\n",
        "\n",
        "batch_data = next(iter(train_dataloader))\n",
        "batch_data = to_device(batch_data)\n",
        "_, outputs = model(**batch_data)\n",
        "print(outputs.shape)\n",
        "\n",
        "# 模型对每个样本都应该输出“消极”和“积极”两个类别对应 label word 的预测 logits 值，因此这里模型的输出尺寸 4x2 符合预期。"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PKb74zxQ97v",
        "outputId": "d8e52f80-1128-4b9c-f364-a4e60f64cb50"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 优化模型参数\n",
        "\n",
        "每一轮 Epoch 分为“训练循环”和“验证/测试循环”，在训练循环中计算损失、优化模型参数，在验证/测试循环中评估模型性能"
      ],
      "metadata": {
        "id": "XQcYtv-gRivP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 首先实现训练循环。\n",
        "# 对标签词的预测实际上就是对类别的预测 损失是通过在类别预测和答案标签之间计算交叉熵：\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "def train_loop(dataloader, model, optimizer, lr_scheduler, epoch, total_loss):\n",
        "    progress_bar = tqdm(range(len(dataloader)))\n",
        "    progress_bar.set_description(f'loss: {0:>7f}')\n",
        "    finish_step_num = epoch * len(dataloader)\n",
        "\n",
        "    model.train()\n",
        "    for step, batch_data in enumerate(dataloader, start=1):\n",
        "        batch_data = to_device(batch_data)\n",
        "        outputs = model(**batch_data)\n",
        "        loss = outputs[0]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        progress_bar.set_description(f'loss: {total_loss/(finish_step_num + step):>7f}')\n",
        "        progress_bar.update(1)\n",
        "    return total_loss\n"
      ],
      "metadata": {
        "id": "VulrKY8ySCGy"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "验证/测试循环负责评估模型。对于分类任务最常见的就是通过精确率、召回率、F1值 (P / R / F1) 指标来评估每个类别的预测性能，然后再通过宏/微 F1 值 (Macro-F1/Micro-F1) 来评估整体分类性能。\n",
        "\n"
      ],
      "metadata": {
        "id": "M1xk2-YcS7vq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 借助机器学习包 sklearn 提供的 classification_report 函数来输出这些指标\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_true = [1, 1, 0, 1, 2, 1, 0, 2, 1, 1, 0, 1, 0]\n",
        "y_pred = [1, 0, 0, 1, 2, 0, 1, 1, 1, 0, 0, 1, 0]\n",
        "\n",
        "print(classification_report(y_true, y_pred, output_dict=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAUnSgGgTQ2L",
        "outputId": "ffc8bafd-593c-4ee8-b6ee-d4cdac57b6c9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.75      0.60         4\n",
            "           1       0.67      0.57      0.62         7\n",
            "           2       1.00      0.50      0.67         2\n",
            "\n",
            "    accuracy                           0.62        13\n",
            "   macro avg       0.72      0.61      0.63        13\n",
            "weighted avg       0.67      0.62      0.62        13\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 汇总模型对所有样本的预测结果和答案标签，然后送入到 classification_report 中计算各项分类指标\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def test_loop(dataloader, model):\n",
        "    true_labels, predictions = [], []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch_data in tqdm(dataloader):\n",
        "            true_labels += batch_data['labels']\n",
        "            batch_data = to_device(batch_data)\n",
        "            outputs = model(**batch_data)\n",
        "            pred = outputs[1]\n",
        "            predictions += pred.argmax(dim=-1).cpu().numpy().tolist()\n",
        "    metrics = classification_report(true_labels, predictions, output_dict=True)\n",
        "    pos_p, pos_r, pos_f1 = metrics['1']['precision'], metrics['1']['recall'], metrics['1']['f1-score']\n",
        "    neg_p, neg_r, neg_f1 = metrics['0']['precision'], metrics['0']['recall'], metrics['0']['f1-score']\n",
        "    macro_f1, micro_f1 = metrics['macro avg']['f1-score'], metrics['weighted avg']['f1-score']\n",
        "    print(f\"pos: {pos_p*100:>0.2f} / {pos_r*100:>0.2f} / {pos_f1*100:>0.2f}, neg: {neg_p*100:>0.2f} / {neg_r*100:>0.2f} / {neg_f1*100:>0.2f}\")\n",
        "    print(f\"Macro-F1: {macro_f1*100:>0.2f} Micro-F1: {micro_f1*100:>0.2f}\\n\")\n",
        "    return metrics\n"
      ],
      "metadata": {
        "id": "p7Pht6qfTWTh"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 保持模型\n",
        "\n",
        "根据模型在验证集上的性能来调整超参数以及选出最好的模型权重，然后将选出的模型应用于测试集以评估最终的性能"
      ],
      "metadata": {
        "id": "2ysYFv4LUKec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 在开始训练之前，我们先评估一下没有微调的 BERT 模型在测试集上的性能。\n",
        "\n",
        "test_data = ChnSentiCorp('chnsenticorp/test/part.0')\n",
        "test_dataloader = DataLoader(test_data, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "test_loop(test_dataloader, model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396,
          "referenced_widgets": [
            "3395283e01074d03830173b3e7821cab",
            "dce7f3a42b9c4493af3cd5b7006eb983",
            "bc72e29d166a405f900c1af0940d576a",
            "c76e946b6f2d4da1a9aa6f6418bd8478",
            "97b5bf2b5a0f40438933e1efa5eafb32",
            "0774a5d2d03f4223a7f0b70dd61c205d",
            "5abaf767b5004f5c99c19af0feca5658",
            "ffaa87295da7478c8b960c405e3bd4f3",
            "33917196213348c486433f6c900da1fa",
            "09fcc14696444356b43922f3d1a4cb43",
            "67f6a5c1c86e48d7b68c6ef6b0627d7f"
          ]
        },
        "id": "6VQma_raUoHv",
        "outputId": "5e7d2bc1-fcac-45d1-fb19-8fec986a473e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/300 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3395283e01074d03830173b3e7821cab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pos: 59.54 / 98.52 / 74.23, neg: 95.36 / 31.25 / 47.07\n",
            "Macro-F1: 60.65 Micro-F1: 60.83\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0': {'precision': 0.9536082474226805,\n",
              "  'recall': 0.3125,\n",
              "  'f1-score': 0.470737913486005,\n",
              "  'support': 592},\n",
              " '1': {'precision': 0.595427435387674,\n",
              "  'recall': 0.9851973684210527,\n",
              "  'f1-score': 0.7422552664188352,\n",
              "  'support': 608},\n",
              " 'accuracy': 0.6533333333333333,\n",
              " 'macro avg': {'precision': 0.7745178414051772,\n",
              "  'recall': 0.6488486842105263,\n",
              "  'f1-score': 0.6064965899524202,\n",
              "  'support': 1200},\n",
              " 'weighted avg': {'precision': 0.7721299693249438,\n",
              "  'recall': 0.6533333333333333,\n",
              "  'f1-score': 0.608306705638639,\n",
              "  'support': 1200}}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AdamW, get_scheduler\n",
        "\n",
        "learning_rate = 1e-5\n",
        "epoch_num = 3\n",
        "# 使用 AdamW 优化器，并且通过 get_scheduler() 函数定义学习率调度器\n",
        "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
        "lr_scheduler = get_scheduler(\n",
        "    \"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=epoch_num*len(train_dataloader),\n",
        ")\n",
        "\n",
        "total_loss = 0.\n",
        "best_f1_score = 0.\n",
        "for epoch in range(epoch_num):\n",
        "    print(f\"Epoch {epoch+1}/{epoch_num}\\n\" + 30 * \"-\")\n",
        "    total_loss = train_loop(train_dataloader, model, optimizer, lr_scheduler, epoch, total_loss)\n",
        "    valid_scores = test_loop(valid_dataloader, model)\n",
        "    macro_f1, micro_f1 = valid_scores['macro avg']['f1-score'], valid_scores['weighted avg']['f1-score']\n",
        "    f1_score = (macro_f1 + micro_f1) / 2\n",
        "    if f1_score > best_f1_score:\n",
        "        best_f1_score = f1_score\n",
        "        print('saving new weights...\\n')\n",
        "        torch.save(\n",
        "            model.state_dict(),\n",
        "            f'epoch_{epoch+1}_valid_macrof1_{(macro_f1*100):0.3f}_microf1_{(micro_f1*100):0.3f}_model_weights.bin'\n",
        "        )\n",
        "print(\"Done!\")\n"
      ],
      "metadata": {
        "id": "dljdpcxCURHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "可以看到，得益于 Prompt 方法，不断微调的 BERT 模型也已经具有初步的情感分析能力，在测试集上的 Macro-F1 和 Micro-F1 值分别为 43.02 和 43.37。有趣的是，“积极”类别的召回率和“消极”类别的准确率都为 100%，这说明 BERT 对大部分样本都倾向于判断为“积极”类（可能预训练时看到的积极性文本更多吧）。\n",
        "\n",
        "> tips:\n",
        "如果采用虚拟 label word（设置 vtype = 'virtual' ），模型是无法直接进行预测的。在扩展了词表之后，MLM head 的参数矩阵尺寸也会进行调整，新加入的参数都是随机初始化的，此时必须进行微调才能让 MLM head 正常工作。\n",
        "\n"
      ],
      "metadata": {
        "id": "6DjuOlEZVEaA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 完整代码：\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoConfig\n",
        "from transformers import BertPreTrainedModel, BertModel\n",
        "from transformers.activations import ACT2FN\n",
        "from transformers import AdamW, get_scheduler\n",
        "from sklearn.metrics import classification_report\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "vtype = 'base'\n",
        "max_length = 512\n",
        "batch_size = 4\n",
        "learning_rate = 1e-5\n",
        "epoch_num = 3\n",
        "\n",
        "def seed_everything(seed=1029):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "def get_prompt(x):\n",
        "    prompt = f'总体上来说很[MASK]。{x}'\n",
        "    return {\n",
        "        'prompt': prompt,\n",
        "        'mask_offset': prompt.find('[MASK]')\n",
        "    }\n",
        "\n",
        "def get_verbalizer(tokenizer, vtype):\n",
        "    assert vtype in ['base', 'virtual']\n",
        "    return {\n",
        "        'pos': {'token': '好', 'id': tokenizer.convert_tokens_to_ids(\"好\")},\n",
        "        'neg': {'token': '差', 'id': tokenizer.convert_tokens_to_ids(\"差\")}\n",
        "    } if vtype == 'base' else {\n",
        "        'pos': {\n",
        "            'token': '[POS]', 'id': tokenizer.convert_tokens_to_ids(\"[POS]\"),\n",
        "            'description': '好的、优秀的、正面的评价、积极的态度'\n",
        "        },\n",
        "        'neg': {\n",
        "            'token': '[NEG]', 'id': tokenizer.convert_tokens_to_ids(\"[NEG]\"),\n",
        "            'description': '差的、糟糕的、负面的评价、消极的态度'\n",
        "        }\n",
        "    }\n",
        "\n",
        "seed_everything(12)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Using {device} device')\n",
        "\n",
        "class ChnSentiCorp(Dataset):\n",
        "    def __init__(self, data_file):\n",
        "        self.data = self.load_data(data_file)\n",
        "\n",
        "    def load_data(self, data_file):\n",
        "        Data = {}\n",
        "        with open(data_file, 'rt', encoding='utf-8') as f:\n",
        "            for idx, line in enumerate(f):\n",
        "                items = line.strip().split('\\t')\n",
        "                assert len(items) == 2\n",
        "                prompt_data = get_prompt(items[0])\n",
        "                Data[idx] = {\n",
        "                    'prompt': prompt_data['prompt'],\n",
        "                    'mask_offset': prompt_data['mask_offset'],\n",
        "                    'label': items[1]\n",
        "                }\n",
        "        return Data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "train_data = ChnSentiCorp('chnsenticorp/train/part.0')\n",
        "valid_data = ChnSentiCorp('chnsenticorp/valid/part.0')\n",
        "test_data = ChnSentiCorp('chnsenticorp/test/part.0')\n",
        "\n",
        "checkpoint = \"bert-base-chinese\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "if vtype == 'virtual':\n",
        "    tokenizer.add_special_tokens({'additional_special_tokens': ['[POS]', '[NEG]']})\n",
        "\n",
        "verbalizer = get_verbalizer(tokenizer, vtype=vtype)\n",
        "pos_id, neg_id = verbalizer['pos']['id'], verbalizer['neg']['id']\n",
        "\n",
        "def collate_fn(batch_samples):\n",
        "    batch_sentences, batch_mask_idxs, batch_labels  = [], [], []\n",
        "    for sample in batch_samples:\n",
        "        batch_sentences.append(sample['prompt'])\n",
        "        encoding = tokenizer(sample['prompt'], truncation=True)\n",
        "        mask_idx = encoding.char_to_token(sample['mask_offset'])\n",
        "        assert mask_idx is not None\n",
        "        batch_mask_idxs.append(mask_idx)\n",
        "        batch_labels.append(int(sample['label']))\n",
        "    batch_inputs = tokenizer(\n",
        "        batch_sentences,\n",
        "        max_length=max_length,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    label_word_id = [neg_id, pos_id]\n",
        "    return {\n",
        "        'batch_inputs': batch_inputs,\n",
        "        'batch_mask_idxs': batch_mask_idxs,\n",
        "        'label_word_id': label_word_id,\n",
        "        'labels': batch_labels\n",
        "    }\n",
        "\n",
        "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "valid_dataloader = DataLoader(valid_data, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "def batched_index_select(input, dim, index):\n",
        "    for i in range(1, len(input.shape)):\n",
        "        if i != dim:\n",
        "            index = index.unsqueeze(i)\n",
        "    expanse = list(input.shape)\n",
        "    expanse[0] = -1\n",
        "    expanse[dim] = -1\n",
        "    index = index.expand(expanse)\n",
        "    return torch.gather(input, dim, index)\n",
        "\n",
        "class BertPredictionHeadTransform(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
        "        if isinstance(config.hidden_act, str):\n",
        "            self.transform_act_fn = ACT2FN[config.hidden_act]\n",
        "        else:\n",
        "            self.transform_act_fn = config.hidden_act\n",
        "        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
        "\n",
        "    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:\n",
        "        hidden_states = self.dense(hidden_states)\n",
        "        hidden_states = self.transform_act_fn(hidden_states)\n",
        "        hidden_states = self.LayerNorm(hidden_states)\n",
        "        return hidden_states\n",
        "\n",
        "class BertLMPredictionHead(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.transform = BertPredictionHeadTransform(config)\n",
        "        self.decoder = nn.Linear(config.hidden_size, config.vocab_size, bias=False)\n",
        "        self.bias = nn.Parameter(torch.zeros(config.vocab_size))\n",
        "        self.decoder.bias = self.bias\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        hidden_states = self.transform(hidden_states)\n",
        "        hidden_states = self.decoder(hidden_states)\n",
        "        return hidden_states\n",
        "\n",
        "class BertOnlyMLMHead(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.predictions = BertLMPredictionHead(config)\n",
        "\n",
        "    def forward(self, sequence_output: torch.Tensor) -> torch.Tensor:\n",
        "        prediction_scores = self.predictions(sequence_output)\n",
        "        return prediction_scores\n",
        "\n",
        "class BertForPrompt(BertPreTrainedModel):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.bert = BertModel(config, add_pooling_layer=False)\n",
        "        self.cls = BertOnlyMLMHead(config)\n",
        "        # Initialize weights and apply final processing\n",
        "        self.post_init()\n",
        "\n",
        "    def get_output_embeddings(self):\n",
        "        return self.cls.predictions.decoder\n",
        "\n",
        "    def set_output_embeddings(self, new_embeddings):\n",
        "        self.cls.predictions.decoder = new_embeddings\n",
        "\n",
        "    def forward(self, batch_inputs, batch_mask_idxs, label_word_id, labels=None):\n",
        "        bert_output = self.bert(**batch_inputs)\n",
        "        sequence_output = bert_output.last_hidden_state\n",
        "        batch_mask_reps = batched_index_select(sequence_output, 1, batch_mask_idxs.unsqueeze(-1)).squeeze(1)\n",
        "        pred_scores = self.cls(batch_mask_reps)[:, label_word_id]\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss_fn = nn.CrossEntropyLoss()\n",
        "            loss = loss_fn(pred_scores, labels)\n",
        "        return loss, pred_scores\n",
        "\n",
        "config = AutoConfig.from_pretrained(checkpoint)\n",
        "model = BertForPrompt.from_pretrained(checkpoint, config=config).to(device)\n",
        "if vtype == 'virtual':\n",
        "    model.resize_token_embeddings(len(tokenizer))\n",
        "    print(f\"initialize embeddings of {verbalizer['pos']['token']} and {verbalizer['neg']['token']}\")\n",
        "    with torch.no_grad():\n",
        "        pos_tokenized = tokenizer(verbalizer['pos']['description'])\n",
        "        pos_tokenized_ids = tokenizer.convert_tokens_to_ids(pos_tokenized)\n",
        "        neg_tokenized = tokenizer(verbalizer['neg']['description'])\n",
        "        neg_tokenized_ids = tokenizer.convert_tokens_to_ids(neg_tokenized)\n",
        "        new_embedding = model.bert.embeddings.word_embeddings.weight[pos_tokenized_ids].mean(axis=0)\n",
        "        model.bert.embeddings.word_embeddings.weight[pos_id, :] = new_embedding.clone().detach().requires_grad_(True)\n",
        "        new_embedding = model.bert.embeddings.word_embeddings.weight[neg_tokenized_ids].mean(axis=0)\n",
        "        model.bert.embeddings.word_embeddings.weight[neg_id, :] = new_embedding.clone().detach().requires_grad_(True)\n",
        "\n",
        "def to_device(batch_data):\n",
        "    new_batch_data = {}\n",
        "    for k, v in batch_data.items():\n",
        "        if k == 'batch_inputs':\n",
        "            new_batch_data[k] = {\n",
        "                k_: v_.to(device) for k_, v_ in v.items()\n",
        "            }\n",
        "        elif k == 'label_word_id':\n",
        "            new_batch_data[k] = v\n",
        "        else:\n",
        "            new_batch_data[k] = torch.tensor(v).to(device)\n",
        "    return new_batch_data\n",
        "\n",
        "def train_loop(dataloader, model, optimizer, lr_scheduler, epoch, total_loss):\n",
        "    progress_bar = tqdm(range(len(dataloader)))\n",
        "    progress_bar.set_description(f'loss: {0:>7f}')\n",
        "    finish_batch_num = epoch * len(dataloader)\n",
        "\n",
        "    model.train()\n",
        "    for step, batch_data in enumerate(dataloader, start=1):\n",
        "        batch_data = to_device(batch_data)\n",
        "        outputs = model(**batch_data)\n",
        "        loss = outputs[0]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        progress_bar.set_description(f'loss: {total_loss/(finish_batch_num + step):>7f}')\n",
        "        progress_bar.update(1)\n",
        "    return total_loss\n",
        "\n",
        "def test_loop(dataloader, model):\n",
        "    true_labels, predictions = [], []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch_data in tqdm(dataloader):\n",
        "            true_labels += batch_data['labels']\n",
        "            batch_data = to_device(batch_data)\n",
        "            outputs = model(**batch_data)\n",
        "            pred = outputs[1]\n",
        "            predictions += pred.argmax(dim=-1).cpu().numpy().tolist()\n",
        "    metrics = classification_report(true_labels, predictions, output_dict=True)\n",
        "    pos_p, pos_r, pos_f1 = metrics['1']['precision'], metrics['1']['recall'], metrics['1']['f1-score']\n",
        "    neg_p, neg_r, neg_f1 = metrics['0']['precision'], metrics['0']['recall'], metrics['0']['f1-score']\n",
        "    macro_f1, micro_f1 = metrics['macro avg']['f1-score'], metrics['weighted avg']['f1-score']\n",
        "    print(f\"pos: {pos_p*100:>0.2f} / {pos_r*100:>0.2f} / {pos_f1*100:>0.2f}, neg: {neg_p*100:>0.2f} / {neg_r*100:>0.2f} / {neg_f1*100:>0.2f}\")\n",
        "    print(f\"Macro-F1: {macro_f1*100:>0.2f} Micro-F1: {micro_f1*100:>0.2f}\\n\")\n",
        "    return metrics\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
        "lr_scheduler = get_scheduler(\n",
        "    \"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=epoch_num*len(train_dataloader),\n",
        ")\n",
        "\n",
        "total_loss = 0.\n",
        "best_f1_score = 0.\n",
        "for epoch in range(epoch_num):\n",
        "    print(f\"Epoch {epoch+1}/{epoch_num}\\n\" + 30 * \"-\")\n",
        "    total_loss = train_loop(train_dataloader, model, optimizer, lr_scheduler, epoch, total_loss)\n",
        "    valid_scores = test_loop(valid_dataloader, model)\n",
        "    macro_f1, micro_f1 = valid_scores['macro avg']['f1-score'], valid_scores['weighted avg']['f1-score']\n",
        "    f1_score = (macro_f1 + micro_f1) / 2\n",
        "    if f1_score > best_f1_score:\n",
        "        best_f1_score = f1_score\n",
        "        print('saving new weights...\\n')\n",
        "        torch.save(\n",
        "            model.state_dict(),\n",
        "            f'epoch_{epoch+1}_valid_macrof1_{(macro_f1*100):0.3f}_microf1_{(micro_f1*100):0.3f}_model_weights.bin'\n",
        "        )\n",
        "print(\"Done!\")\n"
      ],
      "metadata": {
        "id": "GcTNPtXkVnee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 测试模型"
      ],
      "metadata": {
        "id": "KgTd70XoWMQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "# 训练完成后，加载在验证集上性能最优的模型权重，汇报其在测试集上的性能\n",
        "model.load_state_dict(torch.load('epoch_2_valid_macrof1_94.999_microf1_95.000_model_weights.bin'))\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    print('evaluating on test set...')\n",
        "    true_labels, predictions, probs = [], [], []\n",
        "    for batch_data in tqdm(test_dataloader):\n",
        "        true_labels += batch_data['labels']\n",
        "        batch_data = to_device(batch_data)\n",
        "        outputs = model(**batch_data)\n",
        "        pred = outputs[1]\n",
        "        predictions += pred.argmax(dim=-1).cpu().numpy().tolist()\n",
        "        probs += torch.nn.functional.softmax(pred, dim=-1)\n",
        "    save_resluts = []\n",
        "    for s_idx in tqdm(range(len(test_data))):\n",
        "        save_resluts.append({\n",
        "            \"comment\": test_data[s_idx]['comment'],\n",
        "            \"label\": true_labels[s_idx],\n",
        "            \"pred\": predictions[s_idx],\n",
        "            \"prob\": {'neg': probs[s_idx][0].item(), 'pos': probs[s_idx][1].item()}\n",
        "        })\n",
        "    metrics = classification_report(true_labels, predictions, output_dict=True)\n",
        "    pos_p, pos_r, pos_f1 = metrics['1']['precision'], metrics['1']['recall'], metrics['1']['f1-score']\n",
        "    neg_p, neg_r, neg_f1 = metrics['0']['precision'], metrics['0']['recall'], metrics['0']['f1-score']\n",
        "    macro_f1, micro_f1 = metrics['macro avg']['f1-score'], metrics['weighted avg']['f1-score']\n",
        "    print(f\"pos: {pos_p*100:>0.2f} / {pos_r*100:>0.2f} / {pos_f1*100:>0.2f}, neg: {neg_p*100:>0.2f} / {neg_r*100:>0.2f} / {neg_f1*100:>0.2f}\")\n",
        "    print(f\"Macro-F1: {macro_f1*100:>0.2f} Micro-F1: {micro_f1*100:>0.2f}\\n\")\n",
        "    print('saving predicted results...')\n",
        "    with open('test_data_pred.json', 'wt', encoding='utf-8') as f:\n",
        "        for example_result in save_resluts:\n",
        "            f.write(json.dumps(example_result, ensure_ascii=False) + '\\n')\n"
      ],
      "metadata": {
        "id": "inDw9Kw0WRV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "可以看到，经过微调，模型在测试集上的 Macro-F1 值从 43.02 提升到 95.75，Micro-F1 值从 43.37 提升到 95.75，证明了我们对模型的微调是成功的。\n",
        "\n"
      ],
      "metadata": {
        "id": "o9BG-UCRW_9T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 打开保存预测结果的 test_data_pred.json，其中每一行对应一个样本，comment 对应评论，label 对应标注标签，pred 对应预测出的标签，prediction 对应具体预测出的概率值。\n",
        "!cat test_data_pred.json"
      ],
      "metadata": {
        "id": "tWqfptv6XKh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 封装预测函数\n",
        "训练模型的目的是为了能够给其他人提供服务。尤其对于不熟悉深度学习的普通开发者而言，需要的只是一个能够完成特定任务的接口。因此在大多数情况下，我们都应该将模型的预测过程封装为一个端到端 (End-to-End) 的函数：输入文本，输出结果"
      ],
      "metadata": {
        "id": "1tJqWm-rX1OS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, tokenizer, comment, verbalizer):\n",
        "    prompt_data = get_prompt(comment)\n",
        "    prompt = prompt_data['prompt']\n",
        "    encoding = tokenizer(prompt, truncation=True)\n",
        "    mask_idx = encoding.char_to_token(prompt_data['mask_offset'])\n",
        "    assert mask_idx is not None\n",
        "    inputs = tokenizer(\n",
        "        prompt,\n",
        "        max_length=max_length,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    inputs = {\n",
        "        'batch_inputs': inputs,\n",
        "        'batch_mask_idxs': [mask_idx],\n",
        "        'label_word_id': [verbalizer['neg']['id'], verbalizer['pos']['id']]\n",
        "    }\n",
        "    inputs = to_device(inputs)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs[1]\n",
        "        prob = torch.nn.functional.softmax(logits, dim=-1)\n",
        "    pred = logits.argmax(dim=-1)[0].item()\n",
        "    prob = prob[0][pred].item()\n",
        "    return pred, prob\n"
      ],
      "metadata": {
        "id": "ITt8vZwIX2Rz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.load_state_dict(torch.load('epoch_2_valid_macrof1_94.999_microf1_95.000_model_weights.bin'))\n",
        "\n",
        "# 输出模型对测试集前 5 条数据的预测结果\n",
        "for i in range(5):\n",
        "    data = test_data[i]\n",
        "    pred, prob = predict(model, tokenizer, data['comment'], verbalizer)\n",
        "    print(f\"{data['comment']}\\nlabel: {data['label']}\\tpred: {pred}\\tprob: {prob}\")\n"
      ],
      "metadata": {
        "id": "Y4KLT9VXYFX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/jsksxs360/How-to-use-Transformers/tree/main/src/text_cls_prompt_senti_chnsenticorp"
      ],
      "metadata": {
        "id": "vOjZkERzYUK1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/jsksxs360/How-to-use-Transformers.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iW1o-h7VY8Td",
        "outputId": "26a5c5bd-a911-4ef8-e07d-39df12b2d7d1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'How-to-use-Transformers'...\n",
            "remote: Enumerating objects: 515, done.\u001b[K\n",
            "remote: Counting objects: 100% (63/63), done.\u001b[K\n",
            "remote: Compressing objects: 100% (45/45), done.\u001b[K\n",
            "remote: Total 515 (delta 29), reused 34 (delta 18), pack-reused 452\u001b[K\n",
            "Receiving objects: 100% (515/515), 16.25 MiB | 15.38 MiB/s, done.\n",
            "Resolving deltas: 100% (217/217), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd How-to-use-Transformers/src/text_cls_prompt_senti_chnsenticorp && bash -x run_prompt_senti_bert.sh\n"
      ],
      "metadata": {
        "id": "Sp1BSikwZN4-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}