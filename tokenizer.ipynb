{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "toc_visible": true,
      "authorship_tag": "ABX9TyML/1JvSadySfkBCtiBRRaI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weedge/doraemon-nb/blob/main/tokenizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# tokenizer\n",
        "自然语言文本分词处理，进行tokenize成id, 以便模型进行训练推理"
      ],
      "metadata": {
        "id": "q8KRRlIubRHE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [sentencepiece](https://github.com/google/sentencepiece)\n",
        "- https://github.com/google/sentencepiece/blob/master/doc/options.md"
      ],
      "metadata": {
        "id": "-p_meQGzcSPb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 使用python sentencepiece 包"
      ],
      "metadata": {
        "id": "7SeTy9AUuMYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "KxrkOz-mcamV",
        "outputId": "eb255f1a-4fdc-4e29-8c74-646add172fb0"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentencepiece\n",
            "  Using cached sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "Installing collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.99\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "sentencepiece"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/shjwudp/shu/raw/master/books/红楼梦.txt  -P ./data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZUSgD25bTKG",
        "outputId": "432d78c8-c7e1-497c-80e6-7745ea09e093"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-01-24 14:15:25--  https://github.com/shjwudp/shu/raw/master/books/%E7%BA%A2%E6%A5%BC%E6%A2%A6.txt\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/shjwudp/shu/master/books/%E7%BA%A2%E6%A5%BC%E6%A2%A6.txt [following]\n",
            "--2024-01-24 14:15:25--  https://raw.githubusercontent.com/shjwudp/shu/master/books/%E7%BA%A2%E6%A5%BC%E6%A2%A6.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2622979 (2.5M) [text/plain]\n",
            "Saving to: ‘./data/红楼梦.txt’\n",
            "\n",
            "红楼梦.txt          100%[===================>]   2.50M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2024-01-24 14:15:26 (34.4 MB/s) - ‘./data/红楼梦.txt’ saved [2622979/2622979]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -f ./meng.*"
      ],
      "metadata": {
        "id": "uSvbav0MfMlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sentencepiece as spm\n",
        "import os\n",
        "\n",
        "# 用红楼梦.txt训练一个sentencepiece模型，模型前缀model_prefix=meng, 会生成meng.model, meng.vocab.\n",
        "# meng.vocab仅仅是一个参考，在分词中并未使用。\n",
        "#spm.SentencePieceTrainer.train('--input=./data/红楼梦.txt --model_prefix=meng --vocab_size=5000')\n",
        "spm.SentencePieceTrainer.train(input=\"./data/红楼梦.txt\",\n",
        "                               model_prefix=\"meng\",\n",
        "                               model_type=\"bpe\",\n",
        "                               vocab_size=5000,\n",
        "                               self_test_sample_size=0,\n",
        "                               input_format=\"text\",\n",
        "                               character_coverage=1.0,\n",
        "                               num_threads=os.cpu_count(),\n",
        "                               split_digits=True,\n",
        "                               allow_whitespace_only_pieces=True,\n",
        "                               byte_fallback=True,\n",
        "                               unk_surface=r\" \\342\\201\\207 \",\n",
        "                               normalization_rule_name=\"identity\")"
      ],
      "metadata": {
        "id": "IhHmI2enbc9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 使用spm_train命令"
      ],
      "metadata": {
        "id": "fCEg0vTOqU5n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install cmake build-essential pkg-config libgoogle-perftools-dev\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LqfW1X6qiog",
        "outputId": "af10af00-68c1-42c1-b2ae-99d23ed91b40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "build-essential is already the newest version (12.9ubuntu3).\n",
            "pkg-config is already the newest version (0.29.2-1ubuntu3).\n",
            "cmake is already the newest version (3.22.1-1ubuntu1.22.04.1).\n",
            "The following additional packages will be installed:\n",
            "  libunwind-dev\n",
            "The following NEW packages will be installed:\n",
            "  libgoogle-perftools-dev libunwind-dev\n",
            "0 upgraded, 2 newly installed, 0 to remove and 30 not upgraded.\n",
            "Need to get 2,353 kB of archives.\n",
            "After this operation, 9,822 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libunwind-dev amd64 1.3.2-2build2.1 [1,883 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgoogle-perftools-dev amd64 2.9.1-0ubuntu3 [470 kB]\n",
            "Fetched 2,353 kB in 0s (13.1 MB/s)\n",
            "Selecting previously unselected package libunwind-dev:amd64.\n",
            "(Reading database ... 121658 files and directories currently installed.)\n",
            "Preparing to unpack .../libunwind-dev_1.3.2-2build2.1_amd64.deb ...\n",
            "Unpacking libunwind-dev:amd64 (1.3.2-2build2.1) ...\n",
            "Selecting previously unselected package libgoogle-perftools-dev:amd64.\n",
            "Preparing to unpack .../libgoogle-perftools-dev_2.9.1-0ubuntu3_amd64.deb ...\n",
            "Unpacking libgoogle-perftools-dev:amd64 (2.9.1-0ubuntu3) ...\n",
            "Setting up libunwind-dev:amd64 (1.3.2-2build2.1) ...\n",
            "Setting up libgoogle-perftools-dev:amd64 (2.9.1-0ubuntu3) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/google/sentencepiece.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sn9i-bkJqtIU",
        "outputId": "095d2f3c-dacf-4ef9-be3e-682d44dfba63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'sentencepiece'...\n",
            "remote: Enumerating objects: 5050, done.\u001b[K\n",
            "remote: Counting objects: 100% (2082/2082), done.\u001b[K\n",
            "remote: Compressing objects: 100% (299/299), done.\u001b[K\n",
            "remote: Total 5050 (delta 1828), reused 1852 (delta 1772), pack-reused 2968\u001b[K\n",
            "Receiving objects: 100% (5050/5050), 26.79 MiB | 19.88 MiB/s, done.\n",
            "Resolving deltas: 100% (3481/3481), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!cd sentencepiece && cmake -B build -DCMAKE_BUILD_TYPE=Release -S . && make -j 4 -C build && make -C build install"
      ],
      "metadata": {
        "id": "jKs4PlTyq0k3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74b95275-f696-4d68-abb6-d925476fc7f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "\u001b[0mCMake Deprecation Warning at CMakeLists.txt:15 (cmake_minimum_required):\n",
            "  Compatibility with CMake < 3.5 will be removed from a future version of\n",
            "  CMake.\n",
            "\n",
            "  Update the VERSION argument <min> value or use a ...<max> suffix to tell\n",
            "  CMake that the project does not need compatibility with older versions.\n",
            "\n",
            "\u001b[0m\n",
            "-- VERSION: 0.2.0\n",
            "-- The C compiler identification is GNU 11.4.0\n",
            "-- The CXX compiler identification is GNU 11.4.0\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Check for working C compiler: /usr/bin/cc - skipped\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
            "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success\n",
            "-- Found Threads: TRUE  \n",
            "-- Found TCMalloc: /usr/lib/x86_64-linux-gnu/libtcmalloc_minimal.so\n",
            "-- Configuring done (1.1s)\n",
            "-- Generating done (0.0s)\n",
            "-- Build files have been written to: /content/sentencepiece/build\n",
            "make: Entering directory '/content/sentencepiece/build'\n",
            "make[1]: Entering directory '/content/sentencepiece/build'\n",
            "make[2]: Entering directory '/content/sentencepiece/build'\n",
            "make[2]: Entering directory '/content/sentencepiece/build'\n",
            "make[2]: Entering directory '/content/sentencepiece/build'\n",
            "make[2]: Leaving directory '/content/sentencepiece/build'\n",
            "make[2]: Leaving directory '/content/sentencepiece/build'\n",
            "make[2]: Leaving directory '/content/sentencepiece/build'\n",
            "make[2]: Entering directory '/content/sentencepiece/build'\n",
            "make[2]: Entering directory '/content/sentencepiece/build'\n",
            "make[2]: Entering directory '/content/sentencepiece/build'\n",
            "[  1%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train-static.dir/builder.cc.o\u001b[0m\n",
            "[  2%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train-static.dir/unicode_script.cc.o\u001b[0m\n",
            "[  2%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/arena.cc.o\u001b[0m\n",
            "[  3%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/arena.cc.o\u001b[0m\n",
            "[  4%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/arenastring.cc.o\u001b[0m\n",
            "[  5%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/arenastring.cc.o\u001b[0m\n",
            "[  6%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/bytestream.cc.o\u001b[0m\n",
            "[  7%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/bytestream.cc.o\u001b[0m\n",
            "[  8%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/coded_stream.cc.o\u001b[0m\n",
            "[  9%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/coded_stream.cc.o\u001b[0m\n",
            "[ 10%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/common.cc.o\u001b[0m\n",
            "[ 11%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/common.cc.o\u001b[0m\n",
            "[ 12%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train-static.dir/trainer_factory.cc.o\u001b[0m\n",
            "[ 13%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/extension_set.cc.o\u001b[0m\n",
            "[ 14%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train-static.dir/trainer_interface.cc.o\u001b[0m\n",
            "[ 15%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/extension_set.cc.o\u001b[0m\n",
            "[ 15%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train-static.dir/unigram_model_trainer.cc.o\u001b[0m\n",
            "[ 16%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/generated_enum_util.cc.o\u001b[0m\n",
            "[ 17%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/generated_enum_util.cc.o\u001b[0m\n",
            "[ 17%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/generated_message_table_driven_lite.cc.o\u001b[0m\n",
            "[ 18%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/generated_message_table_driven_lite.cc.o\u001b[0m\n",
            "[ 19%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train-static.dir/word_model_trainer.cc.o\u001b[0m\n",
            "[ 20%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/generated_message_util.cc.o\u001b[0m\n",
            "[ 20%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/generated_message_util.cc.o\u001b[0m\n",
            "[ 21%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train-static.dir/char_model_trainer.cc.o\u001b[0m\n",
            "[ 22%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train-static.dir/bpe_model_trainer.cc.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/implicit_weak_message.cc.o\u001b[0m\n",
            "[ 24%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train-static.dir/sentencepiece_trainer.cc.o\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/implicit_weak_message.cc.o\u001b[0m\n",
            "[ 26%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/int128.cc.o\u001b[0m\n",
            "[ 27%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/int128.cc.o\u001b[0m\n",
            "[ 28%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train-static.dir/pretokenizer_for_training.cc.o\u001b[0m\n",
            "[ 29%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/io_win32.cc.o\u001b[0m\n",
            "[ 30%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/message_lite.cc.o\u001b[0m\n",
            "[ 31%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/io_win32.cc.o\u001b[0m\n",
            "[ 32%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/message_lite.cc.o\u001b[0m\n",
            "[ 33%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/parse_context.cc.o\u001b[0m\n",
            "In file included from \u001b[01m\u001b[K/usr/include/string.h:535\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/sentencepiece/src/../third_party/protobuf-lite/google/protobuf/stubs/port.h:39\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/sentencepiece/src/../third_party/protobuf-lite/google/protobuf/stubs/macros.h:34\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/sentencepiece/src/../third_party/protobuf-lite/google/protobuf/stubs/common.h:46\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/sentencepiece/src/../third_party/protobuf-lite/google/protobuf/message_lite.h:45\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/sentencepiece/third_party/protobuf-lite/message_lite.cc:36\u001b[m\u001b[K:\n",
            "In function ‘\u001b[01m\u001b[Kvoid* memcpy(void*, const void*, size_t)\u001b[m\u001b[K’,\n",
            "    inlined from ‘\u001b[01m\u001b[Kgoogle::protobuf::uint8* google::protobuf::io::EpsCopyOutputStream::WriteRaw(const void*, int, google::protobuf::uint8*)\u001b[m\u001b[K’ at \u001b[01m\u001b[K/content/sentencepiece/src/../third_party/protobuf-lite/google/protobuf/io/coded_stream.h:699:16\u001b[m\u001b[K,\n",
            "    inlined from ‘\u001b[01m\u001b[Kvirtual google::protobuf::uint8* google::protobuf::internal::ImplicitWeakMessage::_InternalSerialize(google::protobuf::uint8*, google::protobuf::io::EpsCopyOutputStream*) const\u001b[m\u001b[K’ at \u001b[01m\u001b[K/content/sentencepiece/src/../third_party/protobuf-lite/google/protobuf/implicit_weak_message.h:85:28\u001b[m\u001b[K,\n",
            "    inlined from ‘\u001b[01m\u001b[Kbool google::protobuf::MessageLite::SerializePartialToZeroCopyStream(google::protobuf::io::ZeroCopyOutputStream*) const\u001b[m\u001b[K’ at \u001b[01m\u001b[K/content/sentencepiece/third_party/protobuf-lite/message_lite.cc:419:30\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/include/x86_64-linux-gnu/bits/string_fortified.h:29:33:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid* __builtin___memcpy_chk(void*, const void*, long unsigned int, long unsigned int)\u001b[m\u001b[K’ specified size between 18446744071562067968 and 18446744073709551615 exceeds maximum object size 9223372036854775807 [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wstringop-overflow=\u0007-Wstringop-overflow=\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   29 |   return \u001b[01;35m\u001b[K__builtin___memcpy_chk (__dest, __src, __len,\u001b[m\u001b[K\n",
            "      |          \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "   30 | \u001b[01;35m\u001b[K                                 __glibc_objsize0 (__dest))\u001b[m\u001b[K;\n",
            "      |                                  \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "[ 34%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/parse_context.cc.o\u001b[0m\n",
            "In file included from \u001b[01m\u001b[K/usr/include/string.h:535\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/sentencepiece/src/../third_party/protobuf-lite/google/protobuf/stubs/port.h:39\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/sentencepiece/src/../third_party/protobuf-lite/google/protobuf/stubs/macros.h:34\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/sentencepiece/src/../third_party/protobuf-lite/google/protobuf/stubs/common.h:46\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/sentencepiece/src/../third_party/protobuf-lite/google/protobuf/message_lite.h:45\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/sentencepiece/third_party/protobuf-lite/message_lite.cc:36\u001b[m\u001b[K:\n",
            "In function ‘\u001b[01m\u001b[Kvoid* memcpy(void*, const void*, size_t)\u001b[m\u001b[K’,\n",
            "    inlined from ‘\u001b[01m\u001b[Kgoogle::protobuf::uint8* google::protobuf::io::EpsCopyOutputStream::WriteRaw(const void*, int, google::protobuf::uint8*)\u001b[m\u001b[K’ at \u001b[01m\u001b[K/content/sentencepiece/src/../third_party/protobuf-lite/google/protobuf/io/coded_stream.h:699:16\u001b[m\u001b[K,\n",
            "    inlined from ‘\u001b[01m\u001b[Kvirtual google::protobuf::uint8* google::protobuf::internal::ImplicitWeakMessage::_InternalSerialize(google::protobuf::uint8*, google::protobuf::io::EpsCopyOutputStream*) const\u001b[m\u001b[K’ at \u001b[01m\u001b[K/content/sentencepiece/src/../third_party/protobuf-lite/google/protobuf/implicit_weak_message.h:85:28\u001b[m\u001b[K,\n",
            "    inlined from ‘\u001b[01m\u001b[Kbool google::protobuf::MessageLite::SerializePartialToZeroCopyStream(google::protobuf::io::ZeroCopyOutputStream*) const\u001b[m\u001b[K’ at \u001b[01m\u001b[K/content/sentencepiece/third_party/protobuf-lite/message_lite.cc:419:30\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/include/x86_64-linux-gnu/bits/string_fortified.h:29:33:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid* __builtin___memcpy_chk(void*, const void*, long unsigned int, long unsigned int)\u001b[m\u001b[K’ specified size between 18446744071562067968 and 18446744073709551615 exceeds maximum object size 9223372036854775807 [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wstringop-overflow=\u0007-Wstringop-overflow=\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   29 |   return \u001b[01;35m\u001b[K__builtin___memcpy_chk (__dest, __src, __len,\u001b[m\u001b[K\n",
            "      |          \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "   30 | \u001b[01;35m\u001b[K                                 __glibc_objsize0 (__dest))\u001b[m\u001b[K;\n",
            "      |                                  \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "[ 35%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/repeated_field.cc.o\u001b[0m\n",
            "[ 36%] \u001b[32m\u001b[1mLinking CXX static library libsentencepiece_train.a\u001b[0m\n",
            "[ 37%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/status.cc.o\u001b[0m\n",
            "make[2]: Leaving directory '/content/sentencepiece/build'\n",
            "[ 37%] Built target sentencepiece_train-static\n",
            "[ 37%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/statusor.cc.o\u001b[0m\n",
            "[ 38%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/repeated_field.cc.o\u001b[0m\n",
            "[ 39%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/stringpiece.cc.o\u001b[0m\n",
            "[ 40%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/stringprintf.cc.o\u001b[0m\n",
            "[ 41%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/structurally_valid.cc.o\u001b[0m\n",
            "[ 42%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/strutil.cc.o\u001b[0m\n",
            "[ 43%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/time.cc.o\u001b[0m\n",
            "[ 44%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/wire_format_lite.cc.o\u001b[0m\n",
            "[ 45%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/zero_copy_stream.cc.o\u001b[0m\n",
            "[ 46%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/status.cc.o\u001b[0m\n",
            "[ 46%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/zero_copy_stream_impl.cc.o\u001b[0m\n",
            "[ 46%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/statusor.cc.o\u001b[0m\n",
            "[ 47%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/zero_copy_stream_impl_lite.cc.o\u001b[0m\n",
            "[ 48%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/builtin_pb/sentencepiece.pb.cc.o\u001b[0m\n",
            "[ 49%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/stringpiece.cc.o\u001b[0m\n",
            "[ 50%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/builtin_pb/sentencepiece_model.pb.cc.o\u001b[0m\n",
            "[ 51%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/bpe_model.cc.o\u001b[0m\n",
            "[ 52%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/stringprintf.cc.o\u001b[0m\n",
            "[ 53%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/char_model.cc.o\u001b[0m\n",
            "[ 54%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/structurally_valid.cc.o\u001b[0m\n",
            "[ 55%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/strutil.cc.o\u001b[0m\n",
            "[ 56%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/error.cc.o\u001b[0m\n",
            "[ 57%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/filesystem.cc.o\u001b[0m\n",
            "[ 57%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/model_factory.cc.o\u001b[0m\n",
            "[ 58%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/model_interface.cc.o\u001b[0m\n",
            "[ 59%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/normalizer.cc.o\u001b[0m\n",
            "[ 60%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/time.cc.o\u001b[0m\n",
            "[ 61%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/sentencepiece_processor.cc.o\u001b[0m\n",
            "[ 62%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/unigram_model.cc.o\u001b[0m\n",
            "[ 63%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/wire_format_lite.cc.o\u001b[0m\n",
            "[ 64%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/util.cc.o\u001b[0m\n",
            "[ 65%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/zero_copy_stream.cc.o\u001b[0m\n",
            "[ 65%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/zero_copy_stream_impl.cc.o\u001b[0m\n",
            "[ 66%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/word_model.cc.o\u001b[0m\n",
            "[ 67%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/zero_copy_stream_impl_lite.cc.o\u001b[0m\n",
            "[ 68%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/builtin_pb/sentencepiece.pb.cc.o\u001b[0m\n",
            "[ 69%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/absl/flags/flag.cc.o\u001b[0m\n",
            "[ 70%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/builtin_pb/sentencepiece_model.pb.cc.o\u001b[0m\n",
            "[ 71%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/bpe_model.cc.o\u001b[0m\n",
            "[ 72%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/char_model.cc.o\u001b[0m\n",
            "[ 72%] \u001b[32m\u001b[1mLinking CXX shared library libsentencepiece.so\u001b[0m\n",
            "make[2]: Leaving directory '/content/sentencepiece/build'\n",
            "[ 72%] Built target sentencepiece\n",
            "make[2]: Entering directory '/content/sentencepiece/build'\n",
            "make[2]: Leaving directory '/content/sentencepiece/build'\n",
            "make[2]: Entering directory '/content/sentencepiece/build'\n",
            "[ 73%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train.dir/builder.cc.o\u001b[0m\n",
            "[ 74%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/error.cc.o\u001b[0m\n",
            "[ 75%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/filesystem.cc.o\u001b[0m\n",
            "[ 75%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/model_factory.cc.o\u001b[0m\n",
            "[ 76%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/model_interface.cc.o\u001b[0m\n",
            "[ 77%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/normalizer.cc.o\u001b[0m\n",
            "[ 78%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/sentencepiece_processor.cc.o\u001b[0m\n",
            "[ 79%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/unigram_model.cc.o\u001b[0m\n",
            "[ 80%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/util.cc.o\u001b[0m\n",
            "[ 81%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train.dir/unicode_script.cc.o\u001b[0m\n",
            "[ 82%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/word_model.cc.o\u001b[0m\n",
            "[ 83%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/absl/flags/flag.cc.o\u001b[0m\n",
            "[ 84%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train.dir/trainer_factory.cc.o\u001b[0m\n",
            "[ 85%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train.dir/trainer_interface.cc.o\u001b[0m\n",
            "[ 86%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train.dir/unigram_model_trainer.cc.o\u001b[0m\n",
            "[ 86%] \u001b[32m\u001b[1mLinking CXX static library libsentencepiece.a\u001b[0m\n",
            "make[2]: Leaving directory '/content/sentencepiece/build'\n",
            "[ 86%] Built target sentencepiece-static\n",
            "make[2]: Entering directory '/content/sentencepiece/build'\n",
            "make[2]: Leaving directory '/content/sentencepiece/build'\n",
            "make[2]: Entering directory '/content/sentencepiece/build'\n",
            "[ 87%] \u001b[32mBuilding CXX object src/CMakeFiles/spm_encode.dir/spm_encode_main.cc.o\u001b[0m\n",
            "[ 88%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train.dir/word_model_trainer.cc.o\u001b[0m\n",
            "[ 89%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train.dir/char_model_trainer.cc.o\u001b[0m\n",
            "[ 90%] \u001b[32m\u001b[1mLinking CXX executable spm_encode\u001b[0m\n",
            "make[2]: Leaving directory '/content/sentencepiece/build'\n",
            "[ 90%] Built target spm_encode\n",
            "make[2]: Entering directory '/content/sentencepiece/build'\n",
            "make[2]: Leaving directory '/content/sentencepiece/build'\n",
            "make[2]: Entering directory '/content/sentencepiece/build'\n",
            "[ 91%] \u001b[32mBuilding CXX object src/CMakeFiles/spm_decode.dir/spm_decode_main.cc.o\u001b[0m\n",
            "[ 91%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train.dir/bpe_model_trainer.cc.o\u001b[0m\n",
            "[ 92%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train.dir/sentencepiece_trainer.cc.o\u001b[0m\n",
            "[ 92%] \u001b[32m\u001b[1mLinking CXX executable spm_decode\u001b[0m\n",
            "make[2]: Leaving directory '/content/sentencepiece/build'\n",
            "[ 92%] Built target spm_decode\n",
            "make[2]: Entering directory '/content/sentencepiece/build'\n",
            "make[2]: Leaving directory '/content/sentencepiece/build'\n",
            "make[2]: Entering directory '/content/sentencepiece/build'\n",
            "[ 93%] \u001b[32mBuilding CXX object src/CMakeFiles/spm_export_vocab.dir/spm_export_vocab_main.cc.o\u001b[0m\n",
            "[ 94%] \u001b[32m\u001b[1mLinking CXX executable spm_export_vocab\u001b[0m\n",
            "make[2]: Leaving directory '/content/sentencepiece/build'\n",
            "[ 94%] Built target spm_export_vocab\n",
            "[ 95%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train.dir/pretokenizer_for_training.cc.o\u001b[0m\n",
            "[ 96%] \u001b[32m\u001b[1mLinking CXX shared library libsentencepiece_train.so\u001b[0m\n",
            "make[2]: Leaving directory '/content/sentencepiece/build'\n",
            "[ 96%] Built target sentencepiece_train\n",
            "make[2]: Entering directory '/content/sentencepiece/build'\n",
            "make[2]: Entering directory '/content/sentencepiece/build'\n",
            "make[2]: Leaving directory '/content/sentencepiece/build'\n",
            "make[2]: Leaving directory '/content/sentencepiece/build'\n",
            "make[2]: Entering directory '/content/sentencepiece/build'\n",
            "make[2]: Entering directory '/content/sentencepiece/build'\n",
            "[ 97%] \u001b[32mBuilding CXX object src/CMakeFiles/spm_normalize.dir/spm_normalize_main.cc.o\u001b[0m\n",
            "[ 98%] \u001b[32mBuilding CXX object src/CMakeFiles/spm_train.dir/spm_train_main.cc.o\u001b[0m\n",
            "[ 99%] \u001b[32m\u001b[1mLinking CXX executable spm_normalize\u001b[0m\n",
            "make[2]: Leaving directory '/content/sentencepiece/build'\n",
            "[ 99%] Built target spm_normalize\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX executable spm_train\u001b[0m\n",
            "make[2]: Leaving directory '/content/sentencepiece/build'\n",
            "[100%] Built target spm_train\n",
            "make[1]: Leaving directory '/content/sentencepiece/build'\n",
            "make: Leaving directory '/content/sentencepiece/build'\n",
            "make: Entering directory '/content/sentencepiece/build'\n",
            "make[1]: Entering directory '/content/sentencepiece/build'\n",
            "make[2]: Entering directory '/content/sentencepiece/build'\n",
            "make[2]: Leaving directory '/content/sentencepiece/build'\n",
            "[ 35%] Built target sentencepiece\n",
            "make[2]: Entering directory '/content/sentencepiece/build'\n",
            "make[2]: Leaving directory '/content/sentencepiece/build'\n",
            "[ 45%] Built target sentencepiece_train\n",
            "make[2]: Entering directory '/content/sentencepiece/build'\n",
            "make[2]: Leaving directory '/content/sentencepiece/build'\n",
            "[ 81%] Built target sentencepiece-static\n",
            "make[2]: Entering directory '/content/sentencepiece/build'\n",
            "make[2]: Leaving directory '/content/sentencepiece/build'\n",
            "[ 91%] Built target sentencepiece_train-static\n",
            "make[2]: Entering directory '/content/sentencepiece/build'\n",
            "make[2]: Leaving directory '/content/sentencepiece/build'\n",
            "[ 93%] Built target spm_encode\n",
            "make[2]: Entering directory '/content/sentencepiece/build'\n",
            "make[2]: Leaving directory '/content/sentencepiece/build'\n",
            "[ 94%] Built target spm_decode\n",
            "make[2]: Entering directory '/content/sentencepiece/build'\n",
            "make[2]: Leaving directory '/content/sentencepiece/build'\n",
            "[ 96%] Built target spm_normalize\n",
            "make[2]: Entering directory '/content/sentencepiece/build'\n",
            "make[2]: Leaving directory '/content/sentencepiece/build'\n",
            "[ 98%] Built target spm_train\n",
            "make[2]: Entering directory '/content/sentencepiece/build'\n",
            "make[2]: Leaving directory '/content/sentencepiece/build'\n",
            "[100%] Built target spm_export_vocab\n",
            "make[1]: Leaving directory '/content/sentencepiece/build'\n",
            "\u001b[36mInstall the project...\u001b[0m\n",
            "-- Install configuration: \"Release\"\n",
            "-- Installing: /usr/local/lib/pkgconfig/sentencepiece.pc\n",
            "-- Installing: /usr/local/lib/libsentencepiece.so.0.0.0\n",
            "-- Installing: /usr/local/lib/libsentencepiece.so.0\n",
            "-- Installing: /usr/local/lib/libsentencepiece.so\n",
            "-- Installing: /usr/local/lib/libsentencepiece_train.so.0.0.0\n",
            "-- Installing: /usr/local/lib/libsentencepiece_train.so.0\n",
            "-- Set runtime path of \"/usr/local/lib/libsentencepiece_train.so.0.0.0\" to \"\"\n",
            "-- Installing: /usr/local/lib/libsentencepiece_train.so\n",
            "-- Installing: /usr/local/lib/libsentencepiece.a\n",
            "-- Installing: /usr/local/lib/libsentencepiece_train.a\n",
            "-- Installing: /usr/local/bin/spm_encode\n",
            "-- Set runtime path of \"/usr/local/bin/spm_encode\" to \"\"\n",
            "-- Installing: /usr/local/bin/spm_decode\n",
            "-- Set runtime path of \"/usr/local/bin/spm_decode\" to \"\"\n",
            "-- Installing: /usr/local/bin/spm_normalize\n",
            "-- Set runtime path of \"/usr/local/bin/spm_normalize\" to \"\"\n",
            "-- Installing: /usr/local/bin/spm_train\n",
            "-- Set runtime path of \"/usr/local/bin/spm_train\" to \"\"\n",
            "-- Installing: /usr/local/bin/spm_export_vocab\n",
            "-- Set runtime path of \"/usr/local/bin/spm_export_vocab\" to \"\"\n",
            "-- Installing: /usr/local/include/sentencepiece_trainer.h\n",
            "-- Installing: /usr/local/include/sentencepiece_processor.h\n",
            "make: Leaving directory '/content/sentencepiece/build'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo ldconfig -v\n",
        "# OSX/macOS\n",
        "#sudo update_dyld_shared_cache"
      ],
      "metadata": {
        "id": "LPgz6Or9rD3V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f193a9f4-5d4e-4a32-9a64-5adfc4ea0379"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/sbin/ldconfig.real: Path `/usr/local/cuda-12/targets/x86_64-linux/lib' given more than once\n",
            "(from /etc/ld.so.conf.d/988_cuda-12.conf:1 and /etc/ld.so.conf.d/000_cuda.conf:1)\n",
            "/sbin/ldconfig.real: Path `/usr/local/cuda-12.2/targets/x86_64-linux/lib' given more than once\n",
            "(from /etc/ld.so.conf.d/gds-12-2.conf:1 and /etc/ld.so.conf.d/000_cuda.conf:1)\n",
            "/sbin/ldconfig.real: Path `/usr/local/lib' given more than once\n",
            "(from /etc/ld.so.conf.d/libc.conf:2 and /etc/ld.so.conf.d/colab.conf:1)\n",
            "/sbin/ldconfig.real: Can't stat /usr/local/nvidia/lib: No such file or directory\n",
            "/sbin/ldconfig.real: Can't stat /usr/local/nvidia/lib64: No such file or directory\n",
            "/sbin/ldconfig.real: Can't stat /usr/local/lib/x86_64-linux-gnu: No such file or directory\n",
            "/sbin/ldconfig.real: Path `/usr/lib/x86_64-linux-gnu' given more than once\n",
            "(from /etc/ld.so.conf.d/x86_64-linux-gnu.conf:4 and /etc/ld.so.conf.d/x86_64-linux-gnu.conf:3)\n",
            "/sbin/ldconfig.real: Path `/usr/lib32' given more than once\n",
            "(from /etc/ld.so.conf.d/zz_i386-biarch-compat.conf:3 and /etc/ld.so.conf.d/zz_i386-biarch-compat.conf:2)\n",
            "/sbin/ldconfig.real: Path `/lib/x86_64-linux-gnu' given more than once\n",
            "(from <builtin>:0 and /etc/ld.so.conf.d/x86_64-linux-gnu.conf:3)\n",
            "/sbin/ldconfig.real: Path `/usr/lib/x86_64-linux-gnu' given more than once\n",
            "(from <builtin>:0 and /etc/ld.so.conf.d/x86_64-linux-gnu.conf:3)\n",
            "/sbin/ldconfig.real: Path `/usr/lib' given more than once\n",
            "(from <builtin>:0 and <builtin>:0)\n",
            "/usr/local/cuda/targets/x86_64-linux/lib: (from /etc/ld.so.conf.d/000_cuda.conf:1)\n",
            "\tlibnvrtc-builtins.so.12.2 -> libnvrtc-builtins.so.12.2.140\n",
            "\tlibnvblas.so.12 -> libnvblas.so.12.2.5.6\n",
            "\tlibcusolverMg.so.11 -> libcusolverMg.so.11.5.2.141\n",
            "\tlibnppidei.so.12 -> libnppidei.so.12.2.1.4\n",
            "\tlibcublasLt.so.12 -> libcublasLt.so.12.2.5.6\n",
            "\tlibcufft.so.11 -> libcufft.so.11.0.8.103\n",
            "\tlibnvToolsExt.so.1 -> libnvToolsExt.so.1.0.0\n",
            "\tlibnvjpeg.so.12 -> libnvjpeg.so.12.2.2.4\n",
            "\tlibnppial.so.12 -> libnppial.so.12.2.1.4\n",
            "\tlibnppc.so.12 -> libnppc.so.12.2.1.4\n",
            "\tlibnppisu.so.12 -> libnppisu.so.12.2.1.4\n",
            "\tlibcufftw.so.11 -> libcufftw.so.11.0.8.103\n",
            "\tlibnppist.so.12 -> libnppist.so.12.2.1.4\n",
            "\tlibcufile.so.0 -> libcufile.so.1.7.2\n",
            "\tlibcurand.so.10 -> libcurand.so.10.3.3.141\n",
            "\tlibnppif.so.12 -> libnppif.so.12.2.1.4\n",
            "\tlibcusparse.so.12 -> libcusparse.so.12.1.2.141\n",
            "\tlibnppim.so.12 -> libnppim.so.12.2.1.4\n",
            "\tlibnppig.so.12 -> libnppig.so.12.2.1.4\n",
            "\tlibnvrtc.so.12 -> libnvrtc.so.12.2.140\n",
            "\tlibnppicc.so.12 -> libnppicc.so.12.2.1.4\n",
            "\tlibnpps.so.12 -> libnpps.so.12.2.1.4\n",
            "\tlibnvJitLink.so.12 -> libnvJitLink.so.12.2.140\n",
            "\tlibcufile_rdma.so.1 -> libcufile_rdma.so.1.7.2\n",
            "\tlibcusolver.so.11 -> libcusolver.so.11.5.2.141\n",
            "\tlibOpenCL.so.1 -> libOpenCL.so.1.0.0\n",
            "\tlibnppitc.so.12 -> libnppitc.so.12.2.1.4\n",
            "\tlibcublas.so.12 -> libcublas.so.12.2.5.6\n",
            "\tlibcheckpoint.so -> libcheckpoint.so\n",
            "\tlibpcsamplingutil.so -> libpcsamplingutil.so\n",
            "\tlibnvperf_target.so -> libnvperf_target.so\n",
            "\tlibaccinj64.so.12.2 -> libaccinj64.so.12.2.142\n",
            "\tlibnvperf_host.so -> libnvperf_host.so\n",
            "\tlibcuinj64.so.12.2 -> libcuinj64.so.12.2.142\n",
            "\tlibcupti.so.12 -> libcupti.so.2023.2.2\n",
            "\tlibcudart.so.12 -> libcudart.so.12.2.140\n",
            "/usr/local/lib: (from /etc/ld.so.conf.d/colab.conf:1)\n",
            "\tlibmkl_blacs_openmpi_ilp64.so.2 -> libmkl_blacs_openmpi_ilp64.so.2\n",
            "\tlibmkl_gnu_thread.so.2 -> libmkl_gnu_thread.so.2\n",
            "\tlibmkl_vml_avx.so.2 -> libmkl_vml_avx.so.2\n",
            "\tlibomptarget.rtl.level0.so -> libomptarget.rtl.level0.so\n",
            "\tlibmkl_vml_avx2.so.2 -> libmkl_vml_avx2.so.2\n",
            "\tlibmkl_gf_lp64.so.2 -> libmkl_gf_lp64.so.2\n",
            "\tlibmkl_rt.so.2 -> libmkl_rt.so.2\n",
            "\tlibiompstubs5.so -> libiompstubs5.so\n",
            "\tlibmkl_vml_cmpt.so.2 -> libmkl_vml_cmpt.so.2\n",
            "\tlibmkl_def.so.2 -> libmkl_def.so.2\n",
            "\tlibmkl_avx.so.2 -> libmkl_avx.so.2\n",
            "\tlibmkl_gf_ilp64.so.2 -> libmkl_gf_ilp64.so.2\n",
            "\tlibomptarget.so -> libomptarget.so\n",
            "\tlibmkl_vml_avx512.so.2 -> libmkl_vml_avx512.so.2\n",
            "\tlibmkl_pgi_thread.so.2 -> libmkl_pgi_thread.so.2\n",
            "\tlibmkl_mc3.so.2 -> libmkl_mc3.so.2\n",
            "\tlibmkl_mc.so.2 -> libmkl_mc.so.2\n",
            "\tlibmkl_sequential.so.2 -> libmkl_sequential.so.2\n",
            "\tlibmkl_vml_mc3.so.2 -> libmkl_vml_mc3.so.2\n",
            "\tlibiomp5_db.so -> libiomp5_db.so\n",
            "\tlibmkl_blacs_intelmpi_lp64.so.2 -> libmkl_blacs_intelmpi_lp64.so.2\n",
            "\tlibomptarget.rtl.opencl.so -> libomptarget.rtl.opencl.so\n",
            "\tlibmkl_blacs_openmpi_lp64.so.2 -> libmkl_blacs_openmpi_lp64.so.2\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "\tlibtbbbind_2_0.so.3 -> libtbbbind_2_0.so.3.11\n",
            "\tlibmkl_intel_lp64.so.2 -> libmkl_intel_lp64.so.2\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "\tlibtbbmalloc_proxy.so.2 -> libtbbmalloc_proxy.so.2.11\n",
            "\tlibmkl_core.so.2 -> libmkl_core.so.2\n",
            "\tlibmkl_scalapack_ilp64.so.2 -> libmkl_scalapack_ilp64.so.2\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "\tlibtbbbind_2_5.so.3 -> libtbbbind_2_5.so.3.11\n",
            "\tlibmkl_avx512.so.2 -> libmkl_avx512.so.2\n",
            "\tlibmkl_blacs_intelmpi_ilp64.so.2 -> libmkl_blacs_intelmpi_ilp64.so.2\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "\tlibtbbmalloc.so.2 -> libtbbmalloc.so.2.11\n",
            "\tlibmkl_intel_ilp64.so.2 -> libmkl_intel_ilp64.so.2\n",
            "\tlibmkl_tbb_thread.so.2 -> libmkl_tbb_thread.so.2\n",
            "\tlibiomp5.so -> libiomp5.so\n",
            "\tlibmkl_cdft_core.so.2 -> libmkl_cdft_core.so.2\n",
            "\tlibmkl_intel_thread.so.2 -> libmkl_intel_thread.so.2\n",
            "\tlibomptarget.sycl.wrap.so -> libomptarget.sycl.wrap.so\n",
            "\tlibmkl_avx2.so.2 -> libmkl_avx2.so.2\n",
            "\tlibmkl_vml_mc.so.2 -> libmkl_vml_mc.so.2\n",
            "\tlibmkl_scalapack_lp64.so.2 -> libmkl_scalapack_lp64.so.2\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "\tlibtbbbind.so.3 -> libtbbbind.so.3.11\n",
            "\tlibmkl_vml_def.so.2 -> libmkl_vml_def.so.2\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "\tlibtbb.so.12 -> libtbb.so.12.11\n",
            "\tlibomptarget.rtl.x86_64.so -> libomptarget.rtl.x86_64.so\n",
            "\tlibsentencepiece.so.0 -> libsentencepiece.so.0.0.0\n",
            "\tlibsentencepiece_train.so.0 -> libsentencepiece_train.so.0.0.0\n",
            "/lib/x86_64-linux-gnu: (from /etc/ld.so.conf.d/x86_64-linux-gnu.conf:3)\n",
            "\tliblber-2.5.so.0 -> liblber-2.5.so.0.1.11\n",
            "\tlibhistory.so.8 -> libhistory.so.8.1\n",
            "\tlibassuan.so.0 -> libassuan.so.0.8.5\n",
            "\tlibreadline.so.8 -> libreadline.so.8.1\n",
            "\tlibksba.so.8 -> libksba.so.8.14.0\n",
            "\tlibsasl2.so.2 -> libsasl2.so.2.0.25\n",
            "\tlibldap-2.5.so.0 -> libldap-2.5.so.0.1.11\n",
            "\tlibnpth.so.0 -> libnpth.so.0.1.2\n",
            "\tlibnccl.so.2 -> libnccl.so.2.19.3\n",
            "\tlibatomic.so.1 -> libatomic.so.1.2.0\n",
            "\tlibctf.so.0 -> libctf.so.0.0.0\n",
            "\tlibgdbm_compat.so.4 -> libgdbm_compat.so.4.0.0\n",
            "\tlibperl.so.5.34 -> libperl.so.5.34.0\n",
            "\tlibgdbm.so.6 -> libgdbm.so.6.0.0\n",
            "\tlibmpfr.so.6 -> libmpfr.so.6.1.0\n",
            "\tlibmpc.so.3 -> libmpc.so.3.2.1\n",
            "\tlibtsan.so.0 -> libtsan.so.0.0.0\n",
            "\tlibubsan.so.1 -> libubsan.so.1.0.0\n",
            "\tlibgomp.so.1 -> libgomp.so.1.0.0\n",
            "\tlibcc1.so.0 -> libcc1.so.0.0.0\n",
            "\tlibisl.so.23 -> libisl.so.23.1.0\n",
            "\tlibquadmath.so.0 -> libquadmath.so.0.0.0\n",
            "\tlibctf-nobfd.so.0 -> libctf-nobfd.so.0.0.0\n",
            "\tlibopcodes-2.38-system.so -> libopcodes-2.38-system.so\n",
            "\tlibasan.so.6 -> libasan.so.6.0.0\n",
            "\tliblsan.so.0 -> liblsan.so.0.0.0\n",
            "\tlibitm.so.1 -> libitm.so.1.0.0\n",
            "\tlibbfd-2.38-system.so -> libbfd-2.38-system.so\n",
            "\tlibcudnn_ops_train.so.8 -> libcudnn_ops_train.so.8.9.6\n",
            "\tlibcudnn_cnn_train.so.8 -> libcudnn_cnn_train.so.8.9.6\n",
            "\tlibcudnn_adv_train.so.8 -> libcudnn_adv_train.so.8.9.6\n",
            "\tlibcudnn.so.8 -> libcudnn.so.8.9.6\n",
            "\tlibcudnn_ops_infer.so.8 -> libcudnn_ops_infer.so.8.9.6\n",
            "\tlibcudnn_cnn_infer.so.8 -> libcudnn_cnn_infer.so.8.9.6\n",
            "\tlibcudnn_adv_infer.so.8 -> libcudnn_adv_infer.so.8.9.6\n",
            "\tlibboost_coroutine.so.1.74.0 -> libboost_coroutine.so.1.74.0\n",
            "\tlibndctl.so.6 -> libndctl.so.6.20.1\n",
            "\tlibgeos.so.3.10.2 -> libgeos.so.3.10.2\n",
            "\tlibmkl_avx2.so -> libmkl_avx2.so\n",
            "\tlibboost_numpy310.so.1.74.0 -> libboost_numpy310.so.1.74.0\n",
            "\tlibboost_unit_test_framework.so.1.74.0 -> libboost_unit_test_framework.so.1.74.0\n",
            "\tlibXau.so.6 -> libXau.so.6.0.0\n",
            "\tliblapack_atlas.so.3 -> liblapack_atlas.so.3.10.3\n",
            "\tlibgsttag-1.0.so.0 -> libgsttag-1.0.so.0.2001.0\n",
            "\tlibvtkFiltersTopology-9.1.so.1 -> libvtkFiltersTopology-9.1.so.9.1.0\n",
            "\tlibsmime3.so -> libsmime3.so\n",
            "\tlibmkl_gf_lp64.so -> libmkl_gf_lp64.so\n",
            "\tlibrtmp.so.1 -> librtmp.so.1\n",
            "\tlibboost_math_c99.so.1.74.0 -> libboost_math_c99.so.1.74.0\n",
            "\tlibexpatw.so.1 -> libexpatw.so.1.8.7\n",
            "\tlibnssutil3.so -> libnssutil3.so\n",
            "\tlibboost_context.so.1.74.0 -> libboost_context.so.1.74.0\n",
            "\tlibssh2.so.1 -> libssh2.so.1.0.1\n",
            "\tlibdeflate.so.0 -> libdeflate.so.0\n",
            "\tlibicuio.so.70 -> libicuio.so.70.1\n",
            "\tlibboost_python310.so.1.74.0 -> libboost_python310.so.1.74.0\n",
            "\tlibpango-1.0.so.0 -> libpango-1.0.so.0.5000.6\n",
            "\tlibvtkWrappingPythonCore3.10-9.1.so.1 -> libvtkWrappingPythonCore3.10-9.1.so.9.1.0\n",
            "\tlibvtkFiltersTexture-9.1.so.1 -> libvtkFiltersTexture-9.1.so.9.1.0\n",
            "\tlibargon2.so.1 -> libargon2.so.1\n",
            "\tlibcdt.so.5 -> libcdt.so.5.0.0\n",
            "\tlibxmlb.so.2 -> libxmlb.so.2.0.0\n",
            "\tlibboost_filesystem.so.1.74.0 -> libboost_filesystem.so.1.74.0\n",
            "\tlibgphoto2.so.6 -> libgphoto2.so.6.1.0\n",
            "\tlibx264.so.163 -> libx264.so.163\n",
            "\tlibopencv_mcc.so.4.5d -> libopencv_mcc.so.4.5.4d\n",
            "\tlibchromaprint.so.1 -> libchromaprint.so.1.5.1\n",
            "\tlibboost_atomic.so.1.74.0 -> libboost_atomic.so.1.74.0\n",
            "\tlibplds4.so -> libplds4.so\n",
            "\tlibexif.so.12 -> libexif.so.12.3.4\n",
            "\tlibboost_prg_exec_monitor.so.1.74.0 -> libboost_prg_exec_monitor.so.1.74.0\n",
            "\tlibopencv_dnn.so.4.5d -> libopencv_dnn.so.4.5.4d\n",
            "\tlibhdf5_serialhl_fortran.so.100 -> libhdf5_serialhl_fortran.so.100.0.6\n",
            "\tlibvidstab.so.1.1 -> libvidstab.so.1.1\n",
            "\tlibvtkpugixml-9.1.so.1 -> libvtkpugixml-9.1.so.9.1.0\n",
            "\tlibinfinipath.so.4 -> libinfinipath.so.4.0\n",
            "\tlibvtkIOMPIParallel-9.1.so.1 -> libvtkIOMPIParallel-9.1.so.9.1.0\n",
            "\tlibucp.so.0 -> libucp.so.0.0.0\n",
            "\tlibflite_cmu_indic_lex.so.1 -> libflite_cmu_indic_lex.so.2.2\n",
            "\tlibjson-c.so.5 -> libjson-c.so.5.1.0\n",
            "\tlibopencv_flann.so.4.5d -> libopencv_flann.so.4.5.4d\n",
            "\tlibboost_date_time.so.1.74.0 -> libboost_date_time.so.1.74.0\n",
            "\tlibvtkFiltersSources-9.1.so.1 -> libvtkFiltersSources-9.1.so.9.1.0\n",
            "\tlibmp3lame.so.0 -> libmp3lame.so.0.0.0\n",
            "\tlibboost_mpi.so.1.74.0 -> libboost_mpi.so.1.74.0\n",
            "\tliblab_gamut.so.1 -> liblab_gamut.so.1.0.0\n",
            "\tlibvtkCommonComputationalGeometry-9.1.so.1 -> libvtkCommonComputationalGeometry-9.1.so.9.1.0\n",
            "\tlibvtkFiltersHyperTree-9.1.so.1 -> libvtkFiltersHyperTree-9.1.so.9.1.0\n",
            "\tliburiparser.so.1 -> liburiparser.so.1.0.29\n",
            "\tlibXft.so.2 -> libXft.so.2.3.4\n",
            "\tlibglusterfs.so.0 -> libglusterfs.so.0.0.1\n",
            "\tlibopencv_hdf.so.4.5d -> libopencv_hdf.so.4.5.4d\n",
            "\tlibboost_fiber.so.1.74.0 -> libboost_fiber.so.1.74.0\n",
            "\tlibmkl_vml_avx512_mic.so -> libmkl_vml_avx512_mic.so\n",
            "\tlibvtkIONetCDF-9.1.so.1 -> libvtkIONetCDF-9.1.so.9.1.0\n",
            "\tlibvtkRenderingVolumeOpenGL2-9.1.so.1 -> libvtkRenderingVolumeOpenGL2-9.1.so.9.1.0\n",
            "\tlibopencv_datasets.so.4.5d -> libopencv_datasets.so.4.5.4d\n",
            "\tlibuchardet.so.0 -> libuchardet.so.0.0.7\n",
            "\tlibevent_pthreads-2.1.so.7 -> libevent_pthreads.so\n",
            "\tlibboost_nowide.so.1.74.0 -> libboost_nowide.so.1.74.0\n",
            "\tlibvtkIOPLY-9.1.so.1 -> libvtkIOPLY-9.1.so.9.1.0\n",
            "\tlibuct.so.0 -> libuct.so.0.0.0\n",
            "\tlibxcb-shape.so.0 -> libxcb-shape.so.0.0.0\n",
            "\tlibmd.so.0 -> libmd.so.0.0.5\n",
            "\tlibsqlite3.so.0 -> libsqlite3.so.0.8.6\n",
            "\tlibgdk_pixbuf-2.0.so.0 -> libgdk_pixbuf-2.0.so.0.4200.8\n",
            "\tlibopencv_videostab.so.4.5d -> libopencv_videostab.so.4.5.4d\n",
            "\tlibpipeline.so.1 -> libpipeline.so.1.5.5\n",
            "\tlibrdmacm.so.1 -> librdmacm.so.1.3.39.0\n",
            "\tlibvtkRenderingOpenGL2-9.1.so.1 -> libvtkRenderingOpenGL2-9.1.so.9.1.0\n",
            "\tlibmkl_gnu_thread.so -> libmkl_gnu_thread.so\n",
            "\tlibvtkFiltersStatistics-9.1.so.1 -> libvtkFiltersStatistics-9.1.so.9.1.0\n",
            "\tlibvtkIOParallel-9.1.so.1 -> libvtkIOParallel-9.1.so.9.1.0\n",
            "\tlibfreexl.so.1 -> libfreexl.so.1.1.0\n",
            "\tlibpng16.so.16 -> libpng16.so.16.37.0\n",
            "\tlibgdcmMSFF.so.3.0 -> libgdcmMSFF.so.3.0.10\n",
            "\tlibavcodec.so.58 -> libavcodec.so.58.134.100\n",
            "\tlibsoxr.so.0 -> libsoxr.so.0.1.2\n",
            "\tlibvtkGeovisCore-9.1.so.1 -> libvtkGeovisCore-9.1.so.9.1.0\n",
            "\tlibvtkPythonInterpreter-9.1.so.1 -> libvtkPythonInterpreter-9.1.so.9.1.0\n",
            "\tlibboost_regex.so.1.74.0 -> libboost_regex.so.1.74.0\n",
            "\tlibnuma.so.1 -> libnuma.so.1.0.0\n",
            "\tlibx265.so.199 -> libx265.so.199\n",
            "\tlibopencv_line_descriptor.so.4.5d -> libopencv_line_descriptor.so.4.5.4d\n",
            "\tlibboost_locale.so.1.74.0 -> libboost_locale.so.1.74.0\n",
            "\tlibSM.so.6 -> libSM.so.6.0.1\n",
            "\tlibmkl_mc3.so -> libmkl_mc3.so\n",
            "\tlibdecor-0.so.0 -> libdecor-0.so.0.100.0\n",
            "\tlibvtkFiltersParallelMPI-9.1.so.1 -> libvtkFiltersParallelMPI-9.1.so.9.1.0\n",
            "\tlibucm.so.0 -> libucm.so.0.0.0\n",
            "\tlibvtksys-9.1.so.1 -> libvtksys-9.1.so.9.1.0\n",
            "\tlibpangocairo-1.0.so.0 -> libpangocairo-1.0.so.0.5000.6\n",
            "\tlibbsd.so.0 -> libbsd.so.0.11.5\n",
            "\tlibopencv_text.so.4.5d -> libopencv_text.so.4.5.4d\n",
            "\tlibkadm5srv_mit.so.12 -> libkadm5srv_mit.so.12.0\n",
            "\tlibxslt.so.1 -> libxslt.so.1.1.34\n",
            "\tlibfido2.so.1 -> libfido2.so.1.10.0\n",
            "\tlibvtkIOChemistry-9.1.so.1 -> libvtkIOChemistry-9.1.so.9.1.0\n",
            "\tlibboost_type_erasure.so.1.74.0 -> libboost_type_erasure.so.1.74.0\n",
            "\tlibboost_math_c99f.so.1.74.0 -> libboost_math_c99f.so.1.74.0\n",
            "\tlibXmu.so.6 -> libXmu.so.6.2.0\n",
            "\tlibXaw.so.7 -> libXaw7.so.7.0.0\n",
            "\tlibopencv_intensity_transform.so.4.5d -> libopencv_intensity_transform.so.4.5.4d\n",
            "\tlibopencv_features2d.so.4.5d -> libopencv_features2d.so.4.5.4d\n",
            "\tlibssh.so.4 -> libssh.so.4.8.7\n",
            "\tlibvtkCommonMath-9.1.so.1 -> libvtkCommonMath-9.1.so.9.1.0\n",
            "\tlibqhull_r.so.8.0 -> libqhull_r.so.8.0.2\n",
            "\tlibopencv_wechat_qrcode.so.4.5d -> libopencv_wechat_qrcode.so.4.5.4d\n",
            "\tlibpmem.so.1 -> libpmem.so.1.0.0\n",
            "\tlibmpi_usempif08-gfortran.so.40 -> libmpi_usempif08-gfortran.so.40.30.0\n",
            "\tlibkmlxsd.so.1 -> libkmlxsd.so.1.3.0\n",
            "\tlibavformat.so.58 -> libavformat.so.58.76.100\n",
            "\tlibtheoraenc.so.1 -> libtheoraenc.so.1.1.2\n",
            "\tlibhttp_parser.so.2.9 -> libhttp_parser.so.2.9.4\n",
            "\tlibgvc.so.6 -> libgvc.so.6.0.0\n",
            "\tlibvtkRenderingContextOpenGL2-9.1.so.1 -> libvtkRenderingContextOpenGL2-9.1.so.9.1.0\n",
            "\tlibopen-rte.so.40 -> libopen-rte.so.40.30.2\n",
            "\tlibvtkCommonExecutionModel-9.1.so.1 -> libvtkCommonExecutionModel-9.1.so.9.1.0\n",
            "\tlibboost_mpi_python310.so.1.74.0 -> libboost_mpi_python310.so.1.74.0\n",
            "\tlibbrotlienc.so.1 -> libbrotlienc.so.1.0.9\n",
            "\tlibspatialite.so.7 -> libspatialite.so.7.1.2\n",
            "\tlibgpm.so.2 -> libgpm.so.2\n",
            "\tlibodbccr.so.2 -> libodbccr.so.2.0.0\n",
            "\tlibXfixes.so.3 -> libXfixes.so.3.1.0\n",
            "\tlibgdcmjpeg12.so.3.0 -> libgdcmjpeg12.so.3.0.10\n",
            "\tlibvtkImagingFourier-9.1.so.1 -> libvtkImagingFourier-9.1.so.9.1.0\n",
            "\tlibgl2ps.so.1.4 -> libgl2ps.so.1.4.2\n",
            "\tlibdbus-1.so.3 -> libdbus-1.so.3.19.13\n",
            "\tlibvtkIOMotionFX-9.1.so.1 -> libvtkIOMotionFX-9.1.so.9.1.0\n",
            "\tlibvtkIOCityGML-9.1.so.1 -> libvtkIOCityGML-9.1.so.9.1.0\n",
            "\tlibexslt.so.0 -> libexslt.so.0.8.20\n",
            "\tlibmkl_sequential.so -> libmkl_sequential.so\n",
            "\tlibpmix.so.2 -> libpmix.so.2.5.2\n",
            "\tlibgstreamer-1.0.so.0 -> libgstreamer-1.0.so.0.2003.0\n",
            "\tlibudunits2.so.0 -> libudunits2.so.0.1.0\n",
            "\tlibmkl_intel_ilp64.so -> libmkl_intel_ilp64.so\n",
            "\tlibompitrace.so.40 -> libompitrace.so.40.30.0\n",
            "\tlibpcre2-32.so.0 -> libpcre2-32.so.0.10.4\n",
            "\tlibboost_stacktrace_addr2line.so.1.74.0 -> libboost_stacktrace_addr2line.so.1.74.0\n",
            "\tlibatlas.so.3 -> libatlas.so.3.10.3\n",
            "\tlibopencv_plot.so.4.5d -> libopencv_plot.so.4.5.4d\n",
            "\tlibpython3.10.so.1.0 -> libpython3.10.so.1.0\n",
            "\tlibcolordprivate.so.2 -> libcolordprivate.so.2.0.5\n",
            "\tlibbpf.so.0 -> libbpf.so.0.5.0\n",
            "\tlibboost_math_tr1l.so.1.74.0 -> libboost_math_tr1l.so.1.74.0\n",
            "\tlibass.so.9 -> libass.so.9.1.3\n",
            "\tlibwayland-server.so.0 -> libwayland-server.so.0.20.0\n",
            "\tlibopencv_alphamat.so.4.5d -> libopencv_alphamat.so.4.5.4d\n",
            "\tlibhdf5_serial_fortran.so.102 -> libhdf5_serial_fortran.so.102.1.0\n",
            "\tlibopencv_objdetect.so.4.5d -> libopencv_objdetect.so.4.5.4d\n",
            "\tlibtiff.so.5 -> libtiff.so.5.7.0\n",
            "\tlibvtkIOLSDyna-9.1.so.1 -> libvtkIOLSDyna-9.1.so.9.1.0\n",
            "\tlibssl3.so -> libssl3.so\n",
            "\tlibrubberband.so.2 -> librubberband.so.2.1.5\n",
            "\tlibutempter.so.0 -> libutempter.so.1.2.1\n",
            "\tlibvtkFiltersPoints-9.1.so.1 -> libvtkFiltersPoints-9.1.so.9.1.0\n",
            "\tlibmkl_vml_mc.so -> libmkl_vml_mc.so\n",
            "\tlibboost_graph_parallel.so.1.74.0 -> libboost_graph_parallel.so.1.74.0\n",
            "\tlibflite_cmu_us_kal.so.1 -> libflite_cmu_us_kal.so.2.2\n",
            "\tlibsndio.so.7 -> libsndio.so.7.1\n",
            "\tlibcups.so.2 -> libcups.so.2\n",
            "\tlibmbedtls.so.14 -> libmbedtls.so.2.28.0\n",
            "\tlibicuuc.so.70 -> libicuuc.so.70.1\n",
            "\tlibpulse-simple.so.0 -> libpulse-simple.so.0.1.1\n",
            "\tlibgstcheck-1.0.so.0 -> libgstcheck-1.0.so.0.2003.0\n",
            "\tlibtbb.so.2 -> libtbb.so.2\n",
            "\tlibxcb-xfixes.so.0 -> libxcb-xfixes.so.0.0.0\n",
            "\tlibtbbmalloc_proxy.so.2 -> libtbbmalloc_proxy.so.2.5\n",
            "\tlibgfapi.so.0 -> libgfapi.so.0.0.0\n",
            "\tlibmca_common_monitoring.so.50 -> libmca_common_monitoring.so.50.20.0\n",
            "\tlibstemmer.so.0d -> libstemmer.so.0d.0.0\n",
            "\tlibXdamage.so.1 -> libXdamage.so.1.1.0\n",
            "\tlibopenmpt.so.0 -> libopenmpt.so.0.3.3\n",
            "\tlibheif.so.1 -> libheif.so.1.12.0\n",
            "\tlibtwolame.so.0 -> libtwolame.so.0.0.0\n",
            "\tlibmkl_vml_avx2.so -> libmkl_vml_avx2.so\n",
            "\tlibopencv_img_hash.so.4.5d -> libopencv_img_hash.so.4.5.4d\n",
            "\tlibboost_iostreams.so.1.74.0 -> libboost_iostreams.so.1.74.0\n",
            "\tlibnorm.so.1 -> libnorm.so.1\n",
            "\tlibqhullcpp.so.8.0 -> libqhullcpp.so.8.0.2\n",
            "\tlibvtkfmt-9.1.so.1 -> libvtkfmt-9.1.so.9.1.0\n",
            "\tlibcblas.so.3 -> libcblas.so.3.10.3\n",
            "\tlibvtkRenderingCore-9.1.so.1 -> libvtkRenderingCore-9.1.so.9.1.0\n",
            "\tlibnspr4.so -> libnspr4.so\n",
            "\tlibvorbisenc.so.2 -> libvorbisenc.so.2.0.12\n",
            "\tlibvtkFiltersHybrid-9.1.so.1 -> libvtkFiltersHybrid-9.1.so.9.1.0\n",
            "\tlibgstpbutils-1.0.so.0 -> libgstpbutils-1.0.so.0.2001.0\n",
            "\tlibboost_math_tr1f.so.1.74.0 -> libboost_math_tr1f.so.1.74.0\n",
            "\tlibmpi.so.40 -> libmpi.so.40.30.2\n",
            "\tlibucs.so.0 -> libucs.so.0.0.0\n",
            "\tlibvtkFiltersGeneric-9.1.so.1 -> libvtkFiltersGeneric-9.1.so.9.1.0\n",
            "\tlibFLAC.so.8 -> libFLAC.so.8.3.0\n",
            "\tlibxcb-shm.so.0 -> libxcb-shm.so.0.0.0\n",
            "\tlibvtkIOVideo-9.1.so.1 -> libvtkIOVideo-9.1.so.9.1.0\n",
            "\tlibvtkFiltersParallel-9.1.so.1 -> libvtkFiltersParallel-9.1.so.9.1.0\n",
            "\tlibvtkViewsInfovis-9.1.so.1 -> libvtkViewsInfovis-9.1.so.9.1.0\n",
            "\tlibgdcmDICT.so.3.0 -> libgdcmDICT.so.3.0.10\n",
            "\tlibGLdispatch.so.0 -> libGLdispatch.so.0.0.0\n",
            "\tlibvtkIOMPIImage-9.1.so.1 -> libvtkIOMPIImage-9.1.so.9.1.0\n",
            "\tlibmpi_mpifh-gfortran.so.40 -> libmpi_mpifh-gfortran.so.40.30.0\n",
            "\tlibgsm.so.1 -> libgsm.so.1.0.19\n",
            "\tlibplc4.so -> libplc4.so\n",
            "\tlibnss3.so -> libnss3.so\n",
            "\tlibcairo.so.2 -> libcairo.so.2.11600.0\n",
            "\tlibboost_program_options.so.1.74.0 -> libboost_program_options.so.1.74.0\n",
            "\tlibdconf.so.1 -> libdconf.so.1.0.0\n",
            "\tlibsndfile.so.1 -> libsndfile.so.1.0.31\n",
            "\tlibmpdec.so.3 -> libmpdec.so.2.5.1\n",
            "\tlibvtkImagingGeneral-9.1.so.1 -> libvtkImagingGeneral-9.1.so.9.1.0\n",
            "\tlibpcre32.so.3 -> libpcre32.so.3.13.3\n",
            "\tlibIex-2_5.so.25 -> libIex.so\n",
            "\tlibvtkWrappingTools-9.1.so.1 -> libvtkWrappingTools-9.1.so.9.1.0\n",
            "\tlibzvbi.so.0 -> libzvbi.so.0.13.2\n",
            "\tlibvdpau.so.1 -> libvdpau.so.1.0.0\n",
            "\tlibgstallocators-1.0.so.0 -> libgstallocators-1.0.so.0.2001.0\n",
            "\tlibdav1d.so.5 -> libdav1d.so.5.1.1\n",
            "\tlibvtkCommonTransforms-9.1.so.1 -> libvtkCommonTransforms-9.1.so.9.1.0\n",
            "\tlibopencv_dnn_superres.so.4.5d -> libopencv_dnn_superres.so.4.5.4d\n",
            "\tlibgssrpc.so.4 -> libgssrpc.so.4.2\n",
            "\tlibgtk-3.so.0 -> libgtk-3.so.0.2404.29\n",
            "\tlibdaxctl.so.1 -> libdaxctl.so.1.6.0\n",
            "\tlibopencv_saliency.so.4.5d -> libopencv_saliency.so.4.5.4d\n",
            "\tlibopencv_highgui.so.4.5d -> libopencv_highgui.so.4.5.4d\n",
            "\tliborc-test-0.4.so.0 -> liborc-test-0.4.so.0.32.0\n",
            "\tlibpcsclite.so.1 -> libpcsclite.so.1.0.0\n",
            "\tlibcaca.so.0 -> libcaca.so.0.99.19\n",
            "\tlibboost_timer.so.1.74.0 -> libboost_timer.so.1.74.0\n",
            "\tlibrabbitmq.so.4 -> librabbitmq.so.4.4.0\n",
            "\tlibaom.so.3 -> libaom.so.3.3.0\n",
            "\tlibevent-2.1.so.7 -> libevent.so\n",
            "\tlibmkl_avx512_mic.so -> libmkl_avx512_mic.so\n",
            "\tlibvtkRenderingFreeType-9.1.so.1 -> libvtkRenderingFreeType-9.1.so.9.1.0\n",
            "\tlibepoxy.so.0 -> libepoxy.so.0.0.0\n",
            "\tliblcms2.so.2 -> liblcms2.so.2.0.12\n",
            "\tlibraw1394.so.11 -> libraw1394.so.11.1.0\n",
            "\tlibvtkFiltersGeneral-9.1.so.1 -> libvtkFiltersGeneral-9.1.so.9.1.0\n",
            "\tlibvtkRenderingVtkJS-9.1.so.1 -> libvtkRenderingVtkJS-9.1.so.9.1.0\n",
            "\tlibopencv_surface_matching.so.4.5d -> libopencv_surface_matching.so.4.5.4d\n",
            "\tlibva.so.2 -> libva.so.2.1400.0\n",
            "\tlibvtkIOSegY-9.1.so.1 -> libvtkIOSegY-9.1.so.9.1.0\n",
            "\tlibvtkFiltersSelection-9.1.so.1 -> libvtkFiltersSelection-9.1.so.9.1.0\n",
            "\tlibblosc.so.1 -> libblosc.so.1.21.1\n",
            "\tlibtesseract.so.4 -> libtesseract.so.4.0.1\n",
            "\tlibvtkFiltersParallelGeometry-9.1.so.1 -> libvtkFiltersParallelGeometry-9.1.so.9.1.0\n",
            "\tlibedit.so.2 -> libedit.so.2.0.68\n",
            "\tliblilv-0.so.0 -> liblilv-0.so.0.24.12\n",
            "\tlibaio.so.1 -> libaio.so.1.0.1\n",
            "\tlibmpi_java.so.40 -> libmpi_java.so.40.30.0\n",
            "\tlibpsl.so.5 -> libpsl.so.5.3.2\n",
            "\tlibwebpdemux.so.2 -> libwebpdemux.so.2.0.9\n",
            "\tlibminizip.so.1 -> libminizip.so.1.0.0\n",
            "\tlibgdcmMEXD.so.3.0 -> libgdcmMEXD.so.3.0.10\n",
            "\tlibvtkFiltersProgrammable-9.1.so.1 -> libvtkFiltersProgrammable-9.1.so.9.1.0\n",
            "\tlibmysqlclient.so.21 -> libmysqlclient.so.21.2.35\n",
            "\tlibmkl_avx512.so -> libmkl_avx512.so\n",
            "\tlibvtkIOHDF-9.1.so.1 -> libvtkIOHDF-9.1.so.9.1.0\n",
            "\tlibmkl_avx.so -> libmkl_avx.so\n",
            "\tlibunwind.so.8 -> libunwind.so.8.0.1\n",
            "\tlibdrm_intel.so.1 -> libdrm_intel.so.1.0.0\n",
            "\tlibboost_chrono.so.1.74.0 -> libboost_chrono.so.1.74.0\n",
            "\tlibgstvideo-1.0.so.0 -> libgstvideo-1.0.so.0.2001.0\n",
            "\tlibopencv_tracking.so.4.5d -> libopencv_tracking.so.4.5.4d\n",
            "\tlibvtkIOTecplotTable-9.1.so.1 -> libvtkIOTecplotTable-9.1.so.9.1.0\n",
            "\tlibarpack.so.2 -> libarpack.so.2.1.0\n",
            "\tlibfontconfig.so.1 -> libfontconfig.so.1.12.0\n",
            "\tlibmca_common_sm.so.40 -> libmca_common_sm.so.40.30.0\n",
            "\tlibvtkFiltersGeometry-9.1.so.1 -> libvtkFiltersGeometry-9.1.so.9.1.0\n",
            "\tlibfabric.so.1 -> libfabric.so.1.14.0\n",
            "\tlibmca_common_ofi.so.10 -> libmca_common_ofi.so.10.0.2\n",
            "\tlibgstbase-1.0.so.0 -> libgstbase-1.0.so.0.2003.0\n",
            "\tlibXxf86vm.so.1 -> libXxf86vm.so.1.0.0\n",
            "\tlibpcre2-posix.so.3 -> libpcre2-posix.so.3.0.1\n",
            "\tlibgstapp-1.0.so.0 -> libgstapp-1.0.so.0.2001.0\n",
            "\tlibflite_usenglish.so.1 -> libflite_usenglish.so.2.2\n",
            "\tlibflite_cmulex.so.1 -> libflite_cmulex.so.2.2\n",
            "\tlibip4tc.so.2 -> libip4tc.so.2.0.0\n",
            "\tlibvtkFiltersParallelVerdict-9.1.so.1 -> libvtkFiltersParallelVerdict-9.1.so.9.1.0\n",
            "\tlibXv.so.1 -> libXv.so.1.0.0\n",
            "\tlibltdl.so.7 -> libltdl.so.7.3.1\n",
            "\tlibsphinxbase.so.3 -> libsphinxbase.so.3.0.0\n",
            "\tlibgccpp.so.1 -> libgccpp.so.1.4.1\n",
            "\tlibHalf-2_5.so.25 -> libHalf.so\n",
            "\tlibopencv_videoio.so.4.5d -> libopencv_videoio.so.4.5.4d\n",
            "\tlibopus.so.0 -> libopus.so.0.8.0\n",
            "\tlibxtables.so.12 -> libxtables.so.12.4.0\n",
            "\tlibgme.so.0 -> libgme.so.0.6.3\n",
            "\tlibaec.so.0 -> libaec.so.0.0.12\n",
            "\tlibpixman-1.so.0 -> libpixman-1.so.0.40.0\n",
            "\tlibhdf5_serial_hl.so.100 -> libhdf5_serial_hl.so.100.1.4\n",
            "\tlibf77blas.so.3 -> libf77blas.so.3.10.3\n",
            "\tlibvtkIOMINC-9.1.so.1 -> libvtkIOMINC-9.1.so.9.1.0\n",
            "\tlibboost_math_c99l.so.1.74.0 -> libboost_math_c99l.so.1.74.0\n",
            "\tlibgdcmjpeg16.so.3.0 -> libgdcmjpeg16.so.3.0.10\n",
            "\tlibbs2b.so.0 -> libbs2b.so.0.0.0\n",
            "\tlibunwind-ptrace.so.0 -> libunwind-ptrace.so.0.0.0\n",
            "\tlibvtkIOCore-9.1.so.1 -> libvtkIOCore-9.1.so.9.1.0\n",
            "\tlibvtkImagingColor-9.1.so.1 -> libvtkImagingColor-9.1.so.9.1.0\n",
            "\tlibXmuu.so.1 -> libXmuu.so.1.0.0\n",
            "\tlibgdk-3.so.0 -> libgdk-3.so.0.2404.29\n",
            "\tlibgthread-2.0.so.0 -> libgthread-2.0.so.0.7200.4\n",
            "\tlibatk-1.0.so.0 -> libatk-1.0.so.0.23609.1\n",
            "\tlibswresample.so.3 -> libswresample.so.3.9.100\n",
            "\tlibboost_thread.so.1.74.0 -> libboost_thread.so.1.74.0\n",
            "\tlibboost_log.so.1.74.0 -> libboost_log.so.1.74.0\n",
            "\tlibvtkImagingStencil-9.1.so.1 -> libvtkImagingStencil-9.1.so.9.1.0\n",
            "\tlibX11.so.6 -> libX11.so.6.4.0\n",
            "\tlibprotoc.so.23 -> libprotoc.so.23.0.4\n",
            "\tlibvtkDomainsChemistry-9.1.so.1 -> libvtkDomainsChemistry-9.1.so.9.1.0\n",
            "\tlibgirepository-1.0.so.1 -> libgirepository-1.0.so.1.0.0\n",
            "\tlibvtkIOImage-9.1.so.1 -> libvtkIOImage-9.1.so.9.1.0\n",
            "\tlibvtkParallelCore-9.1.so.1 -> libvtkParallelCore-9.1.so.9.1.0\n",
            "\tlibsz.so.2 -> libsz.so.2.0.1\n",
            "\tlibcdio.so.19 -> libcdio.so.19.0.0\n",
            "\tlibpaper.so.1 -> libpaper.so.1.1.2\n",
            "\tlibvtkRenderingImage-9.1.so.1 -> libvtkRenderingImage-9.1.so.9.1.0\n",
            "\tlibopencv_hfs.so.4.5d -> libopencv_hfs.so.4.5.4d\n",
            "\tlibboost_container.so.1.74.0 -> libboost_container.so.1.74.0\n",
            "\tlibmpi_usempif08.so.40 -> libmpi_usempif08.so.40.30.0\n",
            "\tlibvtkRenderingVolume-9.1.so.1 -> libvtkRenderingVolume-9.1.so.9.1.0\n",
            "\tlibxml2.so.2 -> libxml2.so.2.9.13\n",
            "\tlibyaml-0.so.2 -> libyaml-0.so.2.0.6\n",
            "\tlibvtkIOSQL-9.1.so.1 -> libvtkIOSQL-9.1.so.9.1.0\n",
            "\tlibvtkIOParallelXML-9.1.so.1 -> libvtkIOParallelXML-9.1.so.9.1.0\n",
            "\tlibpackagekit-glib2.so.18 -> libpackagekit-glib2.so.18.1.3\n",
            "\tlibefa.so.1 -> libefa.so.1.1.39.0\n",
            "\tlibxcb-dri3.so.0 -> libxcb-dri3.so.0.0.0\n",
            "\tlibatk-bridge-2.0.so.0 -> libatk-bridge-2.0.so.0.0.0\n",
            "\tlibopencv_bgsegm.so.4.5d -> libopencv_bgsegm.so.4.5.4d\n",
            "\tlibavahi-client.so.3 -> libavahi-client.so.3.2.9\n",
            "\tlibxcb-render.so.0 -> libxcb-render.so.0.0.0\n",
            "\tlibtiffxx.so.5 -> libtiffxx.so.5.7.0\n",
            "\tlibvtkRenderingLOD-9.1.so.1 -> libvtkRenderingLOD-9.1.so.9.1.0\n",
            "\tlibEGL.so.1 -> libEGL.so.1.1.0\n",
            "\tlibmkl_vml_avx512.so -> libmkl_vml_avx512.so\n",
            "\tlibpsm2.so.2 -> libpsm2.so.2.2\n",
            "\tlibGLX_mesa.so.0 -> libGLX_mesa.so.0.0.0\n",
            "\tlibcairo-gobject.so.2 -> libcairo-gobject.so.2.11600.0\n",
            "\tlibmkl_vml_def.so -> libmkl_vml_def.so\n",
            "\tlibatspi.so.0 -> libatspi.so.0.0.1\n",
            "\tlibvtkFiltersFlowPaths-9.1.so.1 -> libvtkFiltersFlowPaths-9.1.so.9.1.0\n",
            "\tlibflite_cmu_time_awb.so.1 -> libflite_cmu_time_awb.so.2.2\n",
            "\tlibtcmalloc.so.4 -> libtcmalloc.so.4.5.9\n",
            "\tlibfyut.so.0 -> libfyut.so.0.0.0\n",
            "\tlibvtkCommonPython-9.1.so.1 -> libvtkCommonPython-9.1.so.9.1.0\n",
            "\tlibvtkkissfft-9.1.so.1 -> libvtkkissfft-9.1.so.9.1.0\n",
            "\tlibmkl_pgi_thread.so -> libmkl_pgi_thread.so\n",
            "\tlibmagic.so.1 -> libmagic.so.1.0.0\n",
            "\tlibglib-2.0.so.0 -> libglib-2.0.so.0.7200.4\n",
            "\tlibjackserver.so.0 -> libjackserver.so.0.0.28\n",
            "\tlibspeex.so.1 -> libspeex.so.1.5.0\n",
            "\tlibIlmImfUtil-2_5.so.25 -> libIlmImfUtil.so\n",
            "\tlibwayland-egl.so.1 -> libwayland-egl.so.1.20.0\n",
            "\tlibmpi_usempi_ignore_tkr.so.40 -> libmpi_usempi_ignore_tkr.so.40.30.0\n",
            "\tlibulockmgr.so.1 -> libulockmgr.so.1.0.1\n",
            "\tlibkmlregionator.so.1 -> libkmlregionator.so.1.3.0\n",
            "\tlibgbm.so.1 -> libgbm.so.1.0.0\n",
            "\tlibSDL2-2.0.so.0 -> libSDL2-2.0.so.0.18.2\n",
            "\tlibvtkDICOMParser-9.1.so.1 -> libvtkDICOMParser-9.1.so.9.1.0\n",
            "\tlibXrender.so.1 -> libXrender.so.1.3.0\n",
            "\tlibmkl_tbb_thread.so -> libmkl_tbb_thread.so\n",
            "\tlibproj.so.22 -> libproj.so.22.2.1\n",
            "\tlibpopt.so.0 -> libpopt.so.0.0.1\n",
            "\tlibprofiler.so.0 -> libprofiler.so.0.5.4\n",
            "\tlibpcrecpp.so.0 -> libpcrecpp.so.0.0.1\n",
            "\tlibde265.so.0 -> libde265.so.0.1.1\n",
            "\tlibxcb-randr.so.0 -> libxcb-randr.so.0.1.0\n",
            "\tlibvtkIOVeraOut-9.1.so.1 -> libvtkIOVeraOut-9.1.so.9.1.0\n",
            "\tlibjbig.so.0 -> libjbig.so.0\n",
            "\tlibboost_stacktrace_noop.so.1.74.0 -> libboost_stacktrace_noop.so.1.74.0\n",
            "\tlibavutil.so.56 -> libavutil.so.56.70.100\n",
            "\tlibcdio_cdda.so.2 -> libcdio_cdda.so.2.0.0\n",
            "\tlibmkl_vml_cmpt.so -> libmkl_vml_cmpt.so\n",
            "\tlibvtkcgns-9.1.so.1 -> libvtkcgns-9.1.so.9.1.0\n",
            "\tlibXcomposite.so.1 -> libXcomposite.so.1.0.0\n",
            "\tlibopencv_viz.so.4.5d -> libopencv_viz.so.4.5.4d\n",
            "\tlibXext.so.6 -> libXext.so.6.4.0\n",
            "\tlibslang.so.2 -> libslang.so.2.3.2\n",
            "\tlibflite_cmu_us_rms.so.1 -> libflite_cmu_us_rms.so.2.2\n",
            "\tlibboost_stacktrace_basic.so.1.74.0 -> libboost_stacktrace_basic.so.1.74.0\n",
            "\tlibvtkChartsCore-9.1.so.1 -> libvtkChartsCore-9.1.so.9.1.0\n",
            "\tlibGLX.so.0 -> libGLX.so.0.0.0\n",
            "\tlibpolkit-agent-1.so.0 -> libpolkit-agent-1.so.0.0.0\n",
            "\tlibxshmfence.so.1 -> libxshmfence.so.1.0.0\n",
            "\tlibvtkIOCGNSReader-9.1.so.1 -> libvtkIOCGNSReader-9.1.so.9.1.0\n",
            "\tlibvtkInteractionStyle-9.1.so.1 -> libvtkInteractionStyle-9.1.so.9.1.0\n",
            "\tlibpolkit-gobject-1.so.0 -> libpolkit-gobject-1.so.0.0.0\n",
            "\tlibdouble-conversion.so.3 -> libdouble-conversion.so.3.1\n",
            "\tlibpangoft2-1.0.so.0 -> libpangoft2-1.0.so.0.5000.6\n",
            "\tlibnl-3.so.200 -> libnl-3.so.200.26.0\n",
            "\tlibvtkIOExportPDF-9.1.so.1 -> libvtkIOExportPDF-9.1.so.9.1.0\n",
            "\tlibXpm.so.4 -> libXpm.so.4.11.0\n",
            "\tlibvpx.so.7 -> libvpx.so.7.0.0\n",
            "\tlibvtkverdict-9.1.so.1 -> libvtkverdict-9.1.so.9.1.0\n",
            "\tlibtcmalloc_minimal.so.4 -> libtcmalloc_minimal.so.4.5.9\n",
            "\tlibopenjp2.so.7 -> libopenjp2.so.2.4.0\n",
            "\tlibvtkImagingStatistics-9.1.so.1 -> libvtkImagingStatistics-9.1.so.9.1.0\n",
            "\tlibvtkParallelMPI-9.1.so.1 -> libvtkParallelMPI-9.1.so.9.1.0\n",
            "\tlibglapi.so.0 -> libglapi.so.0.0.0\n",
            "\tlibcgraph.so.6 -> libcgraph.so.6.0.0\n",
            "\tlibvtkCommonSystem-9.1.so.1 -> libvtkCommonSystem-9.1.so.9.1.0\n",
            "\tlibnl-route-3.so.200 -> libnl-route-3.so.200.26.0\n",
            "\tlibtcmalloc_minimal_debug.so.4 -> libtcmalloc_minimal_debug.so.4.5.9\n",
            "\tlibvtkFiltersVerdict-9.1.so.1 -> libvtkFiltersVerdict-9.1.so.9.1.0\n",
            "\tlibvtkIOLegacy-9.1.so.1 -> libvtkIOLegacy-9.1.so.9.1.0\n",
            "\tlibgfrpc.so.0 -> libgfrpc.so.0.0.1\n",
            "\tlibevent_extra-2.1.so.7 -> libevent_extra.so\n",
            "\tlibicudata.so.70 -> libicudata.so.70.1\n",
            "\tlibopenal.so.1 -> libopenal.so.1.19.1\n",
            "\tlibgstaudio-1.0.so.0 -> libgstaudio-1.0.so.0.2001.0\n",
            "\tlibvtkFiltersImaging-9.1.so.1 -> libvtkFiltersImaging-9.1.so.9.1.0\n",
            "\tlibkdb5.so.10 -> libkdb5.so.10.0\n",
            "\tlibjpeg.so.8 -> libjpeg.so.8.2.2\n",
            "\tlibvtkIOExportGL2PS-9.1.so.1 -> libvtkIOExportGL2PS-9.1.so.9.1.0\n",
            "\tlibrbd.so.1 -> librbd.so.1.17.0\n",
            "\tliboshmem.so.40 -> liboshmem.so.40.30.1\n",
            "\tlibmfx.so.1 -> libmfx.so.1.35\n",
            "\tlibgobject-2.0.so.0 -> libgobject-2.0.so.0.7200.4\n",
            "\tlibcryptsetup.so.12 -> libcryptsetup.so.12.7.0\n",
            "\tlibdrm_amdgpu.so.1 -> libdrm_amdgpu.so.1.0.0\n",
            "\tlibBlocksRuntime.so.0 -> libBlocksRuntime.so.0.0.0\n",
            "\tlibnghttp2.so.14 -> libnghttp2.so.14.20.1\n",
            "\tlibvtkIOXML-9.1.so.1 -> libvtkIOXML-9.1.so.9.1.0\n",
            "\tlibcodec2.so.1.0 -> libcodec2.so.1.0\n",
            "\tlibXi.so.6 -> libXi.so.6.1.0\n",
            "\tlibclang-14.so.13 -> libclang-14.so.14.0.0\n",
            "\tlibvtkImagingMath-9.1.so.1 -> libvtkImagingMath-9.1.so.9.1.0\n",
            "\tlibvtkFiltersModeling-9.1.so.1 -> libvtkFiltersModeling-9.1.so.9.1.0\n",
            "\tlibgdcmDSED.so.3.0 -> libgdcmDSED.so.3.0.10\n",
            "\tlibann.so.0 -> libann.so.0.0.0\n",
            "\tlibxcb-present.so.0 -> libxcb-present.so.0.0.0\n",
            "\tlibmfxhw64.so.1 -> libmfxhw64.so.1.35\n",
            "\tlibpathplan.so.4 -> libpathplan.so.4.0.0\n",
            "\tlibpcre2-16.so.0 -> libpcre2-16.so.0.10.4\n",
            "\tlibjack.so.0 -> libjack.so.0.0.28\n",
            "\tlibgdcmCommon.so.3.0 -> libgdcmCommon.so.3.0.10\n",
            "\tlibxcb-dri2.so.0 -> libxcb-dri2.so.0.0.0\n",
            "\tlibwayland-client.so.0 -> libwayland-client.so.0.20.0\n",
            "\tlibpostproc.so.55 -> libpostproc.so.55.9.100\n",
            "\tlibkmlconvenience.so.1 -> libkmlconvenience.so.1.3.0\n",
            "\tlibmlx4.so.1 -> libmlx4.so.1.0.39.0\n",
            "\tlibopen-pal.so.40 -> libopen-pal.so.40.30.2\n",
            "\tlibvtklibharu-9.1.so.1 -> libvtklibharu-9.1.so.9.1.0\n",
            "\tlibopencv_quality.so.4.5d -> libopencv_quality.so.4.5.4d\n",
            "\tlibfribidi.so.0 -> libfribidi.so.0.4.0\n",
            "\tlibpulse.so.0 -> libpulse.so.0.24.1\n",
            "\tlibvtkImagingCore-9.1.so.1 -> libvtkImagingCore-9.1.so.9.1.0\n",
            "\tlibcdio_paranoia.so.2 -> libcdio_paranoia.so.2.0.0\n",
            "\tlibgstsdp-1.0.so.0 -> libgstsdp-1.0.so.0.2001.0\n",
            "\tlibkmod.so.2 -> libkmod.so.2.3.7\n",
            "\tlibelf.so.1 -> libelf-0.186.so\n",
            "\tlibcurl-gnutls.so.4 -> libcurl-gnutls.so.4.7.0\n",
            "\tlibasyncns.so.0 -> libasyncns.so.0.3.1\n",
            "\tlibflite_cmu_us_kal16.so.1 -> libflite_cmu_us_kal16.so.2.2\n",
            "\tlibshine.so.3 -> libshine.so.3.0.1\n",
            "\tlibicutu.so.70 -> libicutu.so.70.1\n",
            "\tlibopencv_fuzzy.so.4.5d -> libopencv_fuzzy.so.4.5.4d\n",
            "\tlibImath-2_5.so.25 -> libImath.so\n",
            "\tlibzmq.so.5 -> libzmq.so.5.2.4\n",
            "\tlibvtkImagingSources-9.1.so.1 -> libvtkImagingSources-9.1.so.9.1.0\n",
            "\tlibgit2.so.1.1 -> libgit2.so.1.1.0\n",
            "\tlibvtkCommonCore-9.1.so.1 -> libvtkCommonCore-9.1.so.9.1.0\n",
            "\tlibrhash.so.0 -> librhash.so.0\n",
            "\tlibgstnet-1.0.so.0 -> libgstnet-1.0.so.0.2003.0\n",
            "\tlibboost_math_tr1.so.1.74.0 -> libboost_math_tr1.so.1.74.0\n",
            "\tlibvtkRenderingGL2PSOpenGL2-9.1.so.1 -> libvtkRenderingGL2PSOpenGL2-9.1.so.9.1.0\n",
            "\tlibsamplerate.so.0 -> libsamplerate.so.0.2.2\n",
            "\tlibvtkFiltersSMP-9.1.so.1 -> libvtkFiltersSMP-9.1.so.9.1.0\n",
            "\tlibwebpmux.so.3 -> libwebpmux.so.3.0.8\n",
            "\tlibibverbs.so.1 -> libibverbs.so.1.14.39.0\n",
            "\tlibbrotlidec.so.1 -> libbrotlidec.so.1.0.9\n",
            "\tlibvtkFiltersAMR-9.1.so.1 -> libvtkFiltersAMR-9.1.so.9.1.0\n",
            "\tlibmca_common_ucx.so.40 -> libmca_common_ucx.so.40.30.1\n",
            "\tlibvtkInteractionImage-9.1.so.1 -> libvtkInteractionImage-9.1.so.9.1.0\n",
            "\tlibgd.so.3 -> libgd.so.3.0.8\n",
            "\tlibvtkViewsCore-9.1.so.1 -> libvtkViewsCore-9.1.so.9.1.0\n",
            "\tlibgstrtp-1.0.so.0 -> libgstrtp-1.0.so.0.2001.0\n",
            "\tlibvtkIOParallelNetCDF-9.1.so.1 -> libvtkIOParallelNetCDF-9.1.so.9.1.0\n",
            "\tlibboost_graph.so.1.74.0 -> libboost_graph.so.1.74.0\n",
            "\tlibcaca++.so.0 -> libcaca++.so.0.99.19\n",
            "\tlibxcb-glx.so.0 -> libxcb-glx.so.0.0.0\n",
            "\tlibfuse.so.2 -> libfuse.so.2.9.9\n",
            "\tlibX11-xcb.so.1 -> libX11-xcb.so.1.0.0\n",
            "\tlibmca_common_verbs.so.40 -> libmca_common_verbs.so.40.30.0\n",
            "\tliblept.so.5 -> liblept.so.5.0.4\n",
            "\tlibgstfft-1.0.so.0 -> libgstfft-1.0.so.0.2001.0\n",
            "\tlibopencv_imgproc.so.4.5d -> libopencv_imgproc.so.4.5.4d\n",
            "\tlibvtkIOAsynchronous-9.1.so.1 -> libvtkIOAsynchronous-9.1.so.9.1.0\n",
            "\tlibpocketsphinx.so.3 -> libpocketsphinx.so.3.0.0\n",
            "\tlibwebp.so.7 -> libwebp.so.7.1.3\n",
            "\tlibvtkTestingRendering-9.1.so.1 -> libvtkTestingRendering-9.1.so.9.1.0\n",
            "\tlibvtkPythonContext2D-9.1.so.1 -> libvtkPythonContext2D-9.1.so.9.1.0\n",
            "\tlibvtkIOAMR-9.1.so.1 -> libvtkIOAMR-9.1.so.9.1.0\n",
            "\tlibvtkRenderingAnnotation-9.1.so.1 -> libvtkRenderingAnnotation-9.1.so.9.1.0\n",
            "\tlibhdf5_serial_cpp.so.103 -> libhdf5_serial_cpp.so.103.3.0\n",
            "\tlibrsvg-2.so.2 -> librsvg-2.so.2.48.0\n",
            "\tlibogg.so.0 -> libogg.so.0.8.5\n",
            "\tlibdevmapper.so.1.02.1 -> libdevmapper.so.1.02.1\n",
            "\tlibva-x11.so.2 -> libva-x11.so.2.1400.0\n",
            "\tlibkmlengine.so.1 -> libkmlengine.so.1.3.0\n",
            "\tlibvtkIOEnSight-9.1.so.1 -> libvtkIOEnSight-9.1.so.9.1.0\n",
            "\tlibgif.so.7 -> libgif.so.7.1.0\n",
            "\tlibmpi_mpifh.so.40 -> libmpi_mpifh.so.40.30.0\n",
            "\tlibmkl_def.so -> libmkl_def.so\n",
            "\tlibopencv_superres.so.4.5d -> libopencv_superres.so.4.5.4d\n",
            "\tlibvtkInfovisCore-9.1.so.1 -> libvtkInfovisCore-9.1.so.9.1.0\n",
            "\tlibdrm_nouveau.so.2 -> libdrm_nouveau.so.2.0.0\n",
            "\tlibfyba.so.0 -> libfyba.so.0.0.0\n",
            "\tlibboost_log_setup.so.1.74.0 -> libboost_log_setup.so.1.74.0\n",
            "\tlibvtkexodusII-9.1.so.1 -> libvtkexodusII-9.1.so.9.1.0\n",
            "\tlibXinerama.so.1 -> libXinerama.so.1.0.0\n",
            "\tlibzvbi-chains.so.0 -> libzvbi-chains.so.0.0.0\n",
            "\tlibboost_random.so.1.74.0 -> libboost_random.so.1.74.0\n",
            "\tlibdrm_radeon.so.1 -> libdrm_radeon.so.1.0.1\n",
            "\tlibgstcontroller-1.0.so.0 -> libgstcontroller-1.0.so.0.2003.0\n",
            "\tlibjsoncpp.so.25 -> libjsoncpp.so.1.9.5\n",
            "\tlibsensors.so.5 -> libsensors.so.5.0.0\n",
            "\tlibvtkIOIOSS-9.1.so.1 -> libvtkIOIOSS-9.1.so.9.1.0\n",
            "\tlibtcl8.6.so -> libtcl8.6.so.0\n",
            "\tlibdatrie.so.1 -> libdatrie.so.1.4.0\n",
            "\tlibvtkFiltersPython-9.1.so.1 -> libvtkFiltersPython-9.1.so.9.1.0\n",
            "\tlibgvpr.so.2 -> libgvpr.so.2.0.0\n",
            "\tlibmkl_mc.so -> libmkl_mc.so\n",
            "\tlibboost_system.so.1.74.0 -> libboost_system.so.1.74.0\n",
            "\tlibmnl.so.0 -> libmnl.so.0.2.0\n",
            "\tlibgeotiff.so.5 -> libgeotiff.so.5.2.0\n",
            "\tlibmbedx509.so.1 -> libmbedx509.so.2.28.0\n",
            "\tlibopencv_imgcodecs.so.4.5d -> libopencv_imgcodecs.so.4.5.4d\n",
            "\tlibavfilter.so.7 -> libavfilter.so.7.110.100\n",
            "\tlibopencv_reg.so.4.5d -> libopencv_reg.so.4.5.4d\n",
            "\tlibodbc.so.2 -> libodbc.so.2.0.0\n",
            "\tlibsuperlu.so.5 -> libsuperlu.so.5.3.0\n",
            "\tlibflite_cmu_us_awb.so.1 -> libflite_cmu_us_awb.so.2.2\n",
            "\tlibapparmor.so.1 -> libapparmor.so.1.8.2\n",
            "\tlibkmlbase.so.1 -> libkmlbase.so.1.3.0\n",
            "\tlibmpi_cxx.so.40 -> libmpi_cxx.so.40.30.1\n",
            "\tlibboost_serialization.so.1.74.0 -> libboost_serialization.so.1.74.0\n",
            "\tlibvtkImagingHybrid-9.1.so.1 -> libvtkImagingHybrid-9.1.so.9.1.0\n",
            "\tlibxcb.so.1 -> libxcb.so.1.1.0\n",
            "\tlibtcmalloc_and_profiler.so.4 -> libtcmalloc_and_profiler.so.4.6.4\n",
            "\tlibGLESv2.so.2 -> libGLESv2.so.2.1.0\n",
            "\tlibboost_wserialization.so.1.74.0 -> libboost_wserialization.so.1.74.0\n",
            "\tlibtbbmalloc.so.2 -> libtbbmalloc.so.2.5\n",
            "\tlibobjc.so.4 -> libobjc.so.4.0.0\n",
            "\tlibGLEW.so.2.2 -> libGLEW.so.2.2.0\n",
            "\tlibvtkParallelDIY-9.1.so.1 -> libvtkParallelDIY-9.1.so.9.1.0\n",
            "\tlibLLVM-15.so.1 -> libLLVM-15.so.1\n",
            "\tlibvtkIOInfovis-9.1.so.1 -> libvtkIOInfovis-9.1.so.9.1.0\n",
            "\tlibopencv_calib3d.so.4.5d -> libopencv_calib3d.so.4.5.4d\n",
            "\tlibvtkDomainsChemistryOpenGL2-9.1.so.1 -> libvtkDomainsChemistryOpenGL2-9.1.so.9.1.0\n",
            "\tlibvtkViewsContext2D-9.1.so.1 -> libvtkViewsContext2D-9.1.so.9.1.0\n",
            "\tlibsnappy.so.1 -> libsnappy.so.1.1.8\n",
            "\tlibfreetype.so.6 -> libfreetype.so.6.18.1\n",
            "\tlibgts-0.7.so.5 -> libgts-0.7.so.5.0.1\n",
            "\tlibvtkRenderingContext2D-9.1.so.1 -> libvtkRenderingContext2D-9.1.so.9.1.0\n",
            "\tlibgmodule-2.0.so.0 -> libgmodule-2.0.so.0.7200.4\n",
            "\tlibopencv_barcode.so.4.5d -> libopencv_barcode.so.4.5.4d\n",
            "\tlibobjc_gc.so.4 -> libobjc_gc.so.4.0.0\n",
            "\tlibasound.so.2 -> libasound.so.2.0.0\n",
            "\tlibvtkRenderingTk-9.1.so.1 -> libvtkRenderingTk-9.1.so.9.1.0\n",
            "\tlibusb-1.0.so.0 -> libusb-1.0.so.0.3.0\n",
            "\tlibhdf5_serial_hl_cpp.so.100 -> libhdf5_serial_hl_cpp.so.100.1.5\n",
            "\tlibcolord.so.2 -> libcolord.so.2.0.5\n",
            "\tlibflite_cmu_grapheme_lex.so.1 -> libflite_cmu_grapheme_lex.so.2.2\n",
            "\tlibvtkIOExodus-9.1.so.1 -> libvtkIOExodus-9.1.so.9.1.0\n",
            "\tlibXss.so.1 -> libXss.so.1.0.0\n",
            "\tlibmpg123.so.0 -> libmpg123.so.0.46.7\n",
            "\tlibopencv_freetype.so.4.5d -> libopencv_freetype.so.4.5.4d\n",
            "\tlibopencv_aruco.so.4.5d -> libopencv_aruco.so.4.5.4d\n",
            "\tlibevent_core-2.1.so.7 -> libevent_core.so\n",
            "\tlibexpat.so.1 -> libexpat.so.1.8.7\n",
            "\tlibtbb.so.12 -> libtbb.so.12.5\n",
            "\tlibarchive.so.13 -> libarchive.so.13.6.0\n",
            "\tlibopencv_photo.so.4.5d -> libopencv_photo.so.4.5.4d\n",
            "\tlibIlmThread-2_5.so.25 -> libIlmThread.so\n",
            "\tlibopencv_ximgproc.so.4.5d -> libopencv_ximgproc.so.4.5.4d\n",
            "\tlibxvidcore.so.4 -> libxvidcore.so.4.3\n",
            "\tlibflite.so.1 -> libflite.so.2.2\n",
            "\tlibopencv_dpm.so.4.5d -> libopencv_dpm.so.4.5.4d\n",
            "\tlibvtkCommonColor-9.1.so.1 -> libvtkCommonColor-9.1.so.9.1.0\n",
            "\tlibopencv_rapid.so.4.5d -> libopencv_rapid.so.4.5.4d\n",
            "\tlibnetcdf.so.19 -> libnetcdf.so.19\n",
            "\tlibpciaccess.so.0 -> libpciaccess.so.0.11.1\n",
            "\tlibvtkRenderingLabel-9.1.so.1 -> libvtkRenderingLabel-9.1.so.9.1.0\n",
            "\tlibOpenCL.so.1 -> libOpenCL.so.1.0.0\n",
            "\tlibvtkIOMovie-9.1.so.1 -> libvtkIOMovie-9.1.so.9.1.0\n",
            "\tlibopencv_rgbd.so.4.5d -> libopencv_rgbd.so.4.5.4d\n",
            "\tlibgc.so.1 -> libgc.so.1.4.4\n",
            "\tlibmkl_vml_mc2.so -> libmkl_vml_mc2.so\n",
            "\tlibgio-2.0.so.0 -> libgio-2.0.so.0.7200.4\n",
            "\tlibdw.so.1 -> libdw-0.186.so\n",
            "\tlibopencv_xobjdetect.so.4.5d -> libopencv_xobjdetect.so.4.5.4d\n",
            "\tlibwayland-cursor.so.0 -> libwayland-cursor.so.0.20.0\n",
            "\tlibgstrtsp-1.0.so.0 -> libgstrtsp-1.0.so.0.2001.0\n",
            "\tlibsigsegv.so.2 -> libsigsegv.so.2.0.6\n",
            "\tlibICE.so.6 -> libICE.so.6.3.0\n",
            "\tlibavahi-common.so.3 -> libavahi-common.so.3.5.4\n",
            "\tlibevent_openssl-2.1.so.7 -> libevent_openssl.so\n",
            "\tlibmkl_core.so -> libmkl_core.so\n",
            "\tlibsrt-gnutls.so.1.4 -> libsrt-gnutls.so.1.4.4\n",
            "\tlibmkl_vml_mc3.so -> libmkl_vml_mc3.so\n",
            "\tlibrttopo.so.1 -> librttopo.so.1.1.0\n",
            "\tlibflite_cmu_us_slt.so.1 -> libflite_cmu_us_slt.so.2.2\n",
            "\tlibthai.so.0 -> libthai.so.0.3.1\n",
            "\tlibcurl.so.4 -> libcurl.so.4.7.0\n",
            "\tlibvtkFiltersCore-9.1.so.1 -> libvtkFiltersCore-9.1.so.9.1.0\n",
            "\tlibpq.so.5 -> libpq.so.5.14\n",
            "\tlibvtkRenderingSceneGraph-9.1.so.1 -> libvtkRenderingSceneGraph-9.1.so.9.1.0\n",
            "\tlibtcmalloc_debug.so.4 -> libtcmalloc_debug.so.4.5.9\n",
            "\tlibXcursor.so.1 -> libXcursor.so.1.0.2\n",
            "\tlibmpdec++.so.3 -> libmpdec++.so.2.5.1\n",
            "\tlibavc1394.so.0 -> libavc1394.so.0.3.0\n",
            "\tlibkadm5clnt_mit.so.12 -> libkadm5clnt_mit.so.12.0\n",
            "\tlibpcre16.so.3 -> libpcre16.so.3.13.3\n",
            "\tlibGL.so.1 -> libGL.so.1.7.0\n",
            "\tlibsodium.so.23 -> libsodium.so.23.3.0\n",
            "\tlibiec61883.so.0 -> libiec61883.so.0.1.1\n",
            "\tlibvtkioss-9.1.so.1 -> libvtkioss-9.1.so.9.1.0\n",
            "\tlibvtkInteractionWidgets-9.1.so.1 -> libvtkInteractionWidgets-9.1.so.9.1.0\n",
            "\tlibdc1394.so.25 -> libdc1394.so.25.0.0\n",
            "\tlibsratom-0.so.0 -> libsratom-0.so.0.6.8\n",
            "\tlibzimg.so.2 -> libzimg.so.2.0.0\n",
            "\tlibopencv_optflow.so.4.5d -> libopencv_optflow.so.4.5.4d\n",
            "\tlibmkl_gf_ilp64.so -> libmkl_gf_ilp64.so\n",
            "\tlibXt.so.6 -> libXt.so.6.0.0\n",
            "\tlibgfortran.so.5 -> libgfortran.so.5.0.0\n",
            "\tlibvtkIOImport-9.1.so.1 -> libvtkIOImport-9.1.so.9.1.0\n",
            "\tlibXNVCtrl.so.0 -> libXNVCtrl.so.0.0.0\n",
            "\tlibdrm.so.2 -> libdrm.so.2.4.0\n",
            "\tlibsord-0.so.0 -> libsord-0.so.0.16.8\n",
            "\tlibmpi_usempi_ignore_tkr-gfortran.so.40 -> libmpi_usempi_ignore_tkr-gfortran.so.40.30.0\n",
            "\tlibkmldom.so.1 -> libkmldom.so.1.3.0\n",
            "\tlibXdmcp.so.6 -> libXdmcp.so.6.0.0\n",
            "\tlibhdf5_serial.so.103 -> libhdf5_serial.so.103.3.0\n",
            "\tlibflite_cmu_grapheme_lang.so.1 -> libflite_cmu_grapheme_lang.so.2.2\n",
            "\tlibcbor.so.0.8 -> libcbor.so.0.8.0\n",
            "\tlibvtkloguru-9.1.so.1 -> libvtkloguru-9.1.so.9.1.0\n",
            "\tlibmkl_rt.so -> libmkl_rt.so\n",
            "\tlibvtkJava-9.1.so.1 -> libvtkJava-9.1.so.9.1.0\n",
            "\tlibswscale.so.5 -> libswscale.so.5.9.100\n",
            "\tlibxerces-c-3.2.so -> libxerces-c.so\n",
            "\tlibcharls.so.2 -> libcharls.so.2.3.4\n",
            "\tlibavdevice.so.58 -> libavdevice.so.58.13.100\n",
            "\tlibXrandr.so.2 -> libXrandr.so.2.2.0\n",
            "\tlibrom1394.so.0 -> librom1394.so.0.3.0\n",
            "\tlibgfxdr.so.0 -> libgfxdr.so.0.0.1\n",
            "\tliborc-0.4.so.0 -> liborc-0.4.so.0.32.0\n",
            "\tlibboost_stacktrace_backtrace.so.1.74.0 -> libboost_stacktrace_backtrace.so.1.74.0\n",
            "\tlibicutest.so.70 -> libicutest.so.70.1\n",
            "\tlibtheora.so.0 -> libtheora.so.0.3.10\n",
            "\tlibpmemobj.so.1 -> libpmemobj.so.1.0.0\n",
            "\tlibuv.so.1 -> libuv.so.1.0.0\n",
            "\tlibodbcinst.so.2 -> libodbcinst.so.2.0.0\n",
            "\tlibva-drm.so.2 -> libva-drm.so.2.1400.0\n",
            "\tlibvtkImagingMorphological-9.1.so.1 -> libvtkImagingMorphological-9.1.so.9.1.0\n",
            "\tlibserd-0.so.0 -> libserd-0.so.0.30.10\n",
            "\tlibgdcmjpeg8.so.3.0 -> libgdcmjpeg8.so.3.0.10\n",
            "\tlibIlmImf-2_5.so.25 -> libIlmImf.so\n",
            "\tlibopencv_face.so.4.5d -> libopencv_face.so.4.5.4d\n",
            "\tlibtheoradec.so.1 -> libtheoradec.so.1.1.4\n",
            "\tlibvtkFiltersExtraction-9.1.so.1 -> libvtkFiltersExtraction-9.1.so.9.1.0\n",
            "\tlibmfx-tracer.so.1 -> libmfx-tracer.so.1.35\n",
            "\tlibmkl_vml_avx.so -> libmkl_vml_avx.so\n",
            "\tlibopencv_phase_unwrapping.so.4.5d -> libopencv_phase_unwrapping.so.4.5.4d\n",
            "\tlibopencv_video.so.4.5d -> libopencv_video.so.4.5.4d\n",
            "\tlibappstream.so.4 -> libappstream.so.0.15.2\n",
            "\tlibssh-gcrypt.so.4 -> libssh-gcrypt.so.4.8.7\n",
            "\tlibvtkIOXMLParser-9.1.so.1 -> libvtkIOXMLParser-9.1.so.9.1.0\n",
            "\tlibLLVM-14.so.1 -> libLLVM-14.so.1\n",
            "\tlibprotobuf.so.23 -> libprotobuf.so.23.0.4\n",
            "\tlibmkl_intel_lp64.so -> libmkl_intel_lp64.so\n",
            "\tlibopencv_xphoto.so.4.5d -> libopencv_xphoto.so.4.5.4d\n",
            "\tlibvorbisfile.so.3 -> libvorbisfile.so.3.3.8\n",
            "\tlibvtkRenderingUI-9.1.so.1 -> libvtkRenderingUI-9.1.so.9.1.0\n",
            "\tlibturbojpeg.so.0 -> libturbojpeg.so.0.2.0\n",
            "\tlibopencv_ccalib.so.4.5d -> libopencv_ccalib.so.4.5.4d\n",
            "\tlibvtkCommonMisc-9.1.so.1 -> libvtkCommonMisc-9.1.so.9.1.0\n",
            "\tlibharfbuzz.so.0 -> libharfbuzz.so.0.20704.0\n",
            "\tlibgphoto2_port.so.12 -> libgphoto2_port.so.12.0.0\n",
            "\tlibopencv_stitching.so.4.5d -> libopencv_stitching.so.4.5.4d\n",
            "\tlibxcb-sync.so.1 -> libxcb-sync.so.1.0.0\n",
            "\tlibvtkInfovisLayout-9.1.so.1 -> libvtkInfovisLayout-9.1.so.9.1.0\n",
            "\tlibbluray.so.2 -> libbluray.so.2.4.1\n",
            "\tlibIexMath-2_5.so.25 -> libIexMath.so\n",
            "\tlibtk8.6.so -> libtk8.6.so.0\n",
            "\tlibvtkDomainsParallelChemistry-9.1.so.1 -> libvtkDomainsParallelChemistry-9.1.so.9.1.0\n",
            "\tlibOpenGL.so.0 -> libOpenGL.so.0.0.0\n",
            "\tlibopencv_core.so.4.5d -> libopencv_core.so.4.5.4d\n",
            "\tlibsphinxad.so.3 -> libsphinxad.so.3.0.0\n",
            "\tlibrados.so.2 -> librados.so.2.0.0\n",
            "\tlibsocket++.so.1 -> libsocket++.so.1.0.2\n",
            "\tlibpoppler.so.118 -> libpoppler.so.118.0.0\n",
            "\tlibvtkCommonDataModel-9.1.so.1 -> libvtkCommonDataModel-9.1.so.9.1.0\n",
            "\tlibflite_cmu_indic_lang.so.1 -> libflite_cmu_indic_lang.so.2.2\n",
            "\tlibvorbis.so.0 -> libvorbis.so.0.4.9\n",
            "\tlibopencv_bioinspired.so.4.5d -> libopencv_bioinspired.so.4.5.4d\n",
            "\tlibgraphite2.so.3 -> libgraphite2.so.3.2.1\n",
            "\tlibqhull.so.8.0 -> libqhull.so.8.0.2\n",
            "\tlibicui18n.so.70 -> libicui18n.so.70.1\n",
            "\tlibvtkIOCONVERGECFD-9.1.so.1 -> libvtkIOCONVERGECFD-9.1.so.9.1.0\n",
            "\tlibpmemblk.so.1 -> libpmemblk.so.1.0.0\n",
            "\tlibgdcmIOD.so.3.0 -> libgdcmIOD.so.3.0.10\n",
            "\tlibvtkmetaio-9.1.so.1 -> libvtkmetaio-9.1.so.9.1.0\n",
            "\tlibpgm-5.3.so.0 -> libpgm.so\n",
            "\tlibvtkIOOggTheora-9.1.so.1 -> libvtkIOOggTheora-9.1.so.9.1.0\n",
            "\tlibopencv_structured_light.so.4.5d -> libopencv_structured_light.so.4.5.4d\n",
            "\tlibfygm.so.0 -> libfygm.so.0.0.0\n",
            "\tlibvtkParallelMPI4Py-9.1.so.1 -> libvtkParallelMPI4Py-9.1.so.9.1.0\n",
            "\tlibmbedcrypto.so.7 -> libmbedcrypto.so.2.28.0\n",
            "\tlibmkl_intel_thread.so -> libmkl_intel_thread.so\n",
            "\tlibopencv_shape.so.4.5d -> libopencv_shape.so.4.5.4d\n",
            "\tlibboost_wave.so.1.74.0 -> libboost_wave.so.1.74.0\n",
            "\tlibudfread.so.0 -> libudfread.so.0.1.0\n",
            "\tlibopencv_stereo.so.4.5d -> libopencv_stereo.so.4.5.4d\n",
            "\tlibvtkIOExport-9.1.so.1 -> libvtkIOExport-9.1.so.9.1.0\n",
            "\tlibmysofa.so.1 -> libmysofa.so.1.1.0\n",
            "\tlibopencv_ml.so.4.5d -> libopencv_ml.so.4.5.4d\n",
            "\tlibxkbcommon.so.0 -> libxkbcommon.so.0.0.0\n",
            "\tlibgeos_c.so.1 -> libgeos_c.so.1.16.0\n",
            "\tlibmlx5.so.1 -> libmlx5.so.1.22.39.0\n",
            "\tlibbrotlicommon.so.1 -> libbrotlicommon.so.1.0.9\n",
            "\tlibopencv_dnn_objdetect.so.4.5d -> libopencv_dnn_objdetect.so.4.5.4d\n",
            "\tlibvtkFiltersParallelImaging-9.1.so.1 -> libvtkFiltersParallelImaging-9.1.so.9.1.0\n",
            "\tlibgstriff-1.0.so.0 -> libgstriff-1.0.so.0.2001.0\n",
            "\tlibEGL_mesa.so.0 -> libEGL_mesa.so.0.0.0\n",
            "\tlibcfitsio.so.9 -> libcfitsio.so.9.4.0.0\n",
            "\tlibmca_common_ompio.so.41 -> libmca_common_ompio.so.41.29.2\n",
            "\tlibhwloc.so.15 -> libhwloc.so.15.5.2\n",
            "\tlibvtkIOGeometry-9.1.so.1 -> libvtkIOGeometry-9.1.so.9.1.0\n",
            "\tlibunwind-coredump.so.0 -> libunwind-coredump.so.0.0.0\n",
            "\tlibcmark-gfm-extensions.so.0.29.0.gfm.3 -> libcmark-gfm-extensions.so.0.29.0.gfm.3\n",
            "\tlibcmark-gfm.so.0.29.0.gfm.3 -> libcmark-gfm.so.0.29.0.gfm.3\n",
            "\tlibunwind-x86_64.so.8 -> libunwind-x86_64.so.8.0.1\n",
            "\tlibnss_files.so.2 -> libnss_files.so.2\n",
            "\tlibpam_misc.so.0 -> libpam_misc.so.0.82.1\n",
            "\tlibnss_dns.so.2 -> libnss_dns.so.2\n",
            "/sbin/ldconfig.real: /lib/x86_64-linux-gnu/ld-linux-x86-64.so.2 is the dynamic linker, ignoring\n",
            "\n",
            "\tld-linux-x86-64.so.2 -> ld-linux-x86-64.so.2\n",
            "\tlibunistring.so.2 -> libunistring.so.2.2.0\n",
            "\tlibz.so.1 -> libz.so.1.2.11\n",
            "\tlibBrokenLocale.so.1 -> libBrokenLocale.so.1\n",
            "\tlibmemusage.so -> libmemusage.so\n",
            "\tlibdl.so.2 -> libdl.so.2\n",
            "\tlibsemanage.so.2 -> libsemanage.so.2\n",
            "\tlibzstd.so.1 -> libzstd.so.1.4.8\n",
            "\tlibtasn1.so.6 -> libtasn1.so.6.6.2\n",
            "\tlibpcre2-8.so.0 -> libpcre2-8.so.0.10.4\n",
            "\tlibudev.so.1 -> libudev.so.1.7.2\n",
            "\tlibresolv.so.2 -> libresolv.so.2\n",
            "\tlibc.so.6 -> libc.so.6\n",
            "\tlibpcreposix.so.3 -> libpcreposix.so.3.13.3\n",
            "\tlibseccomp.so.2 -> libseccomp.so.2.5.3\n",
            "\tlibnsl.so.2 -> libnsl.so.2.0.1\n",
            "\tlibprocps.so.8 -> libprocps.so.8.0.3\n",
            "\tlibkeyutils.so.1 -> libkeyutils.so.1.9\n",
            "\tlibutil.so.1 -> libutil.so.1\n",
            "\tlibrt.so.1 -> librt.so.1\n",
            "\tlibk5crypto.so.3 -> libk5crypto.so.3.1\n",
            "\tlibpanel.so.6 -> libpanel.so.6.3\n",
            "\tlibmenu.so.6 -> libmenu.so.6.3\n",
            "\tlibdebconfclient.so.0 -> libdebconfclient.so.0.0.0\n",
            "\tlibpamc.so.0 -> libpamc.so.0.82.1\n",
            "\tlibss.so.2 -> libss.so.2.0\n",
            "\tlibpam.so.0 -> libpam.so.0.85.1\n",
            "\tliblz4.so.1 -> liblz4.so.1.9.3\n",
            "\tlibkrb5.so.3 -> libkrb5.so.3.3\n",
            "\tlibdb-5.3.so -> libdb-5.3.so\n",
            "\tlibmenuw.so.6 -> libmenuw.so.6.3\n",
            "\tlibxxhash.so.0 -> libxxhash.so.0.8.1\n",
            "\tlibpanelw.so.6 -> libpanelw.so.6.3\n",
            "\tlibanl.so.1 -> libanl.so.1\n",
            "\tlibext2fs.so.2 -> libext2fs.so.2.4\n",
            "\tlibblkid.so.1 -> libblkid.so.1.1.0\n",
            "\tlibnettle.so.8 -> libnettle.so.8.4\n",
            "\tlibpthread.so.0 -> libpthread.so.0\n",
            "\tlibgmp.so.10 -> libgmp.so.10.4.1\n",
            "\tlibc_malloc_debug.so.0 -> libc_malloc_debug.so.0\n",
            "\tlibtirpc.so.3 -> libtirpc.so.3.0.0\n",
            "\tlibsmartcols.so.1 -> libsmartcols.so.1.1.0\n",
            "\tlibncurses.so.6 -> libncurses.so.6.3\n",
            "\tlibbz2.so.1.0 -> libbz2.so.1.0.4\n",
            "\tlibcrypto.so.3 -> libcrypto.so.3\n",
            "\tlibpcprofile.so -> libpcprofile.so\n",
            "\tlibselinux.so.1 -> libselinux.so.1\n",
            "\tlibkrb5support.so.0 -> libkrb5support.so.0.1\n",
            "\tlibgcrypt.so.20 -> libgcrypt.so.20.3.4\n",
            "\tlibnsl.so.1 -> libnsl.so.1\n",
            "\tlibffi.so.8 -> libffi.so.8.1.0\n",
            "\tlibgssapi_krb5.so.2 -> libgssapi_krb5.so.2.2\n",
            "\tlibcom_err.so.2 -> libcom_err.so.2.1\n",
            "\tlibnss_compat.so.2 -> libnss_compat.so.2\n",
            "\tlibacl.so.1 -> libacl.so.1.1.2301\n",
            "\tlibaudit.so.1 -> libaudit.so.1.0.0\n",
            "\tlibcap.so.2 -> libcap.so.2.44\n",
            "\tliblzma.so.5 -> liblzma.so.5.2.5\n",
            "\tlibattr.so.1 -> libattr.so.1.1.2501\n",
            "\tlibgpg-error.so.0 -> libgpg-error.so.0.32.1\n",
            "\tlibmount.so.1 -> libmount.so.1.1.0\n",
            "\tlibstdc++.so.6 -> libstdc++.so.6.0.30\n",
            "\tlibp11-kit.so.0 -> libp11-kit.so.0.3.0\n",
            "\tlibthread_db.so.1 -> libthread_db.so.1\n",
            "\tlibpcre.so.3 -> libpcre.so.3.13.3\n",
            "\tlibapt-pkg.so.6.0 -> libapt-pkg.so.6.0.0\n",
            "\tlibsepol.so.2 -> libsepol.so.2\n",
            "\tlibe2p.so.2 -> libe2p.so.2.3\n",
            "\tlibmvec.so.1 -> libmvec.so.1\n",
            "\tlibform.so.6 -> libform.so.6.3\n",
            "\tlibhogweed.so.6 -> libhogweed.so.6.4\n",
            "\tlibidn2.so.0 -> libidn2.so.0.3.7\n",
            "\tlibformw.so.6 -> libformw.so.6.3\n",
            "\tlibapt-private.so.0.0 -> libapt-private.so.0.0.0\n",
            "\tlibgnutls.so.30 -> libgnutls.so.30.31.0\n",
            "\tlibtic.so.6 -> libtic.so.6.3\n",
            "\tlibm.so.6 -> libm.so.6\n",
            "\tlibcrypt.so.1 -> libcrypt.so.1.1.0\n",
            "\tlibsystemd.so.0 -> libsystemd.so.0.32.0\n",
            "\tlibgcc_s.so.1 -> libgcc_s.so.1\n",
            "\tlibncursesw.so.6 -> libncursesw.so.6.3\n",
            "\tlibtinfo.so.6 -> libtinfo.so.6.3\n",
            "\tlibuuid.so.1 -> libuuid.so.1.3.0\n",
            "\tlibssl.so.3 -> libssl.so.3\n",
            "\tlibnss_hesiod.so.2 -> libnss_hesiod.so.2\n",
            "\tlibcap-ng.so.0 -> libcap-ng.so.0.0.0\n",
            "/lib32: (from /etc/ld.so.conf.d/zz_i386-biarch-compat.conf:2)\n",
            "\tlibnss_files.so.2 -> libnss_files.so.2\n",
            "\tlibnss_dns.so.2 -> libnss_dns.so.2\n",
            "\tlibBrokenLocale.so.1 -> libBrokenLocale.so.1\n",
            "\tlibmemusage.so -> libmemusage.so\n",
            "\tlibdl.so.2 -> libdl.so.2\n",
            "\tlibresolv.so.2 -> libresolv.so.2\n",
            "\tlibc.so.6 -> libc.so.6\n",
            "\tlibutil.so.1 -> libutil.so.1\n",
            "\tlibrt.so.1 -> librt.so.1\n",
            "/sbin/ldconfig.real: /lib32/ld-linux.so.2 is the dynamic linker, ignoring\n",
            "\n",
            "\tld-linux.so.2 -> ld-linux.so.2\n",
            "\tlibanl.so.1 -> libanl.so.1\n",
            "\tlibpthread.so.0 -> libpthread.so.0\n",
            "\tlibc_malloc_debug.so.0 -> libc_malloc_debug.so.0\n",
            "\tlibpcprofile.so -> libpcprofile.so\n",
            "\tlibnsl.so.1 -> libnsl.so.1\n",
            "\tlibnss_compat.so.2 -> libnss_compat.so.2\n",
            "\tlibstdc++.so.6 -> libstdc++.so.6.0.30\n",
            "\tlibthread_db.so.1 -> libthread_db.so.1\n",
            "\tlibm.so.6 -> libm.so.6\n",
            "\tlibgcc_s.so.1 -> libgcc_s.so.1\n",
            "\tlibnss_hesiod.so.2 -> libnss_hesiod.so.2\n",
            "/lib: (from <builtin>:0)\n",
            "\tlibBLT.2.5.so.8.6 -> libBLT.2.5.so.8.6\n",
            "\tlibmfhdfalt.so.0 -> libmfhdfalt.so.0.0.0\n",
            "\tlibogdi.so.4.1 -> libogdi.so.4.1\n",
            "\tlibgdal.so.30 -> libgdal.so.30.0.3\n",
            "\tlibdfalt.so.0 -> libdfalt.so.0.0.0\n",
            "\tlibBLTlite.2.5.so.8.6 -> libBLTlite.2.5.so.8.6\n",
            "\tlibarmadillo.so.10 -> libarmadillo.so.10.8.2\n",
            "\tlibvpf.so.4.1 -> libvpf.so.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!spm_train --help"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nr16xO_WsJLw",
        "outputId": "0841a4a1-fe85-4906-e51d-7df6063d053d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentencepiece\n",
            "\n",
            "Usage: spm_train [options] files\n",
            "\n",
            "   --help (show help)  type: bool default: false\n",
            "   --version (show version)  type: bool default: false\n",
            "   --minloglevel (Messages logged at a lower level than this don't actually get logged anywhere)  type: int default: 0\n",
            "   --input (comma separated list of input sentences)  type: std::string default: \"\"\n",
            "   --input_format (Input format. Supported format is `text` or `tsv`.)  type: std::string default: \"\"\n",
            "   --model_prefix (output model prefix)  type: std::string default: \"\"\n",
            "   --model_type (model algorithm: unigram, bpe, word or char)  type: std::string default: \"unigram\"\n",
            "   --vocab_size (vocabulary size)  type: int32 default: 8000\n",
            "   --accept_language (comma-separated list of languages this model can accept)  type: std::string default: \"\"\n",
            "   --self_test_sample_size (the size of self test samples)  type: int32 default: 0\n",
            "   --character_coverage (character coverage to determine the minimum symbols)  type: double default: 0.9995\n",
            "   --input_sentence_size (maximum size of sentences the trainer loads)  type: std::uint64_t default: 0\n",
            "   --shuffle_input_sentence (Randomly sample input sentences in advance. Valid when --input_sentence_size > 0)  type: bool default: true\n",
            "   --seed_sentencepiece_size (the size of seed sentencepieces)  type: int32 default: 1000000\n",
            "   --shrinking_factor (Keeps top shrinking_factor pieces with respect to the loss)  type: double default: 0.75\n",
            "   --num_threads (number of threads for training)  type: int32 default: 16\n",
            "   --num_sub_iterations (number of EM sub-iterations)  type: int32 default: 2\n",
            "   --max_sentencepiece_length (maximum length of sentence piece)  type: int32 default: 16\n",
            "   --max_sentence_length (maximum length of sentence in byte)  type: int32 default: 4192\n",
            "   --split_by_unicode_script (use Unicode script to split sentence pieces)  type: bool default: true\n",
            "   --split_by_number (split tokens by numbers (0-9))  type: bool default: true\n",
            "   --split_by_whitespace (use a white space to split sentence pieces)  type: bool default: true\n",
            "   --split_digits (split all digits (0-9) into separate pieces)  type: bool default: false\n",
            "   --pretokenization_delimiter (specifies the delimiter of pre-tokenization)  type: std::string default: \"\"\n",
            "   --treat_whitespace_as_suffix (treat whitespace marker as suffix instead of prefix.)  type: bool default: false\n",
            "   --allow_whitespace_only_pieces (allow pieces that only contain (consecutive) whitespace tokens)  type: bool default: false\n",
            "   --control_symbols (comma separated list of control symbols)  type: std::string default: \"\"\n",
            "   --control_symbols_file (load control_symbols from file.)  type: std::string default: \"\"\n",
            "   --user_defined_symbols (comma separated list of user defined symbols)  type: std::string default: \"\"\n",
            "   --user_defined_symbols_file (load user_defined_symbols from file.)  type: std::string default: \"\"\n",
            "   --required_chars (UTF8 characters in this flag are always used in the character set regardless of --character_coverage)  type: std::string default: \"\"\n",
            "   --required_chars_file (load required_chars from file.)  type: std::string default: \"\"\n",
            "   --byte_fallback (decompose unknown pieces into UTF-8 byte pieces)  type: bool default: false\n",
            "   --vocabulary_output_piece_score (Define score in vocab file)  type: bool default: true\n",
            "   --normalization_rule_name (Normalization rule name. Choose from nfkc or identity)  type: std::string default: \"nmt_nfkc\"\n",
            "   --normalization_rule_tsv (Normalization rule TSV file. )  type: std::string default: \"\"\n",
            "   --denormalization_rule_tsv (Denormalization rule TSV file.)  type: std::string default: \"\"\n",
            "   --add_dummy_prefix (Add dummy whitespace at the beginning of text)  type: bool default: true\n",
            "   --remove_extra_whitespaces (Removes leading, trailing, and duplicate internal whitespace)  type: bool default: true\n",
            "   --hard_vocab_limit (If set to false, --vocab_size is considered as a soft limit.)  type: bool default: true\n",
            "   --use_all_vocab (If set to true, use all tokens as vocab. Valid for word/char models.)  type: bool default: false\n",
            "   --unk_id (Override UNK (<unk>) id.)  type: int32 default: 0\n",
            "   --bos_id (Override BOS (<s>) id. Set -1 to disable BOS.)  type: int32 default: 1\n",
            "   --eos_id (Override EOS (</s>) id. Set -1 to disable EOS.)  type: int32 default: 2\n",
            "   --pad_id (Override PAD (<pad>) id. Set -1 to disable PAD.)  type: int32 default: -1\n",
            "   --unk_piece (Override UNK (<unk>) piece.)  type: std::string default: \"<unk>\"\n",
            "   --bos_piece (Override BOS (<s>) piece.)  type: std::string default: \"<s>\"\n",
            "   --eos_piece (Override EOS (</s>) piece.)  type: std::string default: \"</s>\"\n",
            "   --pad_piece (Override PAD (<pad>) piece.)  type: std::string default: \"<pad>\"\n",
            "   --unk_surface (Dummy surface string for <unk>. In decoding <unk> is decoded to `unk_surface`.)  type: std::string default: \" ⁇ \"\n",
            "   --train_extremely_large_corpus (Increase bit depth for unigram tokenization.)  type: bool default: false\n",
            "   --random_seed (Seed value for random generator.)  type: uint32 default: 4294967295\n",
            "   --enable_differential_privacy (Whether to add DP while training. Currently supported only by UNIGRAM model.)  type: bool default: false\n",
            "   --differential_privacy_noise_level (Amount of noise to add for DP)  type: float default: 0\n",
            "   --differential_privacy_clipping_threshold (Threshold for clipping the counts for DP)  type: std::uint64_t default: 0\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!spm_train \\\n",
        "  --input=\"./data/红楼梦.txt\" \\\n",
        "  --model_prefix=\"meng\" \\\n",
        "  --model_type=\"bpe\" \\\n",
        "  --vocab_size=5000 \\\n",
        "  --self_test_sample_size=0 \\\n",
        "  --input_format=\"text\" \\\n",
        "  --character_coverage=1.0 \\\n",
        "  --num_threads=$cpu_nums \\\n",
        "  --split_digits=True \\\n",
        "  --allow_whitespace_only_pieces=True \\\n",
        "  --byte_fallback=True \\\n",
        "  --unk_surface=\" \\342\\201\\207 \" \\\n",
        "  --normalization_rule_name=\"identity\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SR0l4Y5sOF5",
        "outputId": "78ac7911-6f40-4494-c3da-3e93637524d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
            "trainer_spec {\n",
            "  input: ./data/红楼梦.txt\n",
            "  input_format: text\n",
            "  model_prefix: meng\n",
            "  model_type: BPE\n",
            "  vocab_size: 5000\n",
            "  self_test_sample_size: 0\n",
            "  character_coverage: 1\n",
            "  input_sentence_size: 0\n",
            "  shuffle_input_sentence: 1\n",
            "  seed_sentencepiece_size: 1000000\n",
            "  shrinking_factor: 0.75\n",
            "  max_sentence_length: 4192\n",
            "  num_threads: 16\n",
            "  num_sub_iterations: 2\n",
            "  max_sentencepiece_length: 16\n",
            "  split_by_unicode_script: 1\n",
            "  split_by_number: 1\n",
            "  split_by_whitespace: 1\n",
            "  split_digits: 1\n",
            "  pretokenization_delimiter: \n",
            "  treat_whitespace_as_suffix: 0\n",
            "  allow_whitespace_only_pieces: 1\n",
            "  required_chars: \n",
            "  byte_fallback: 1\n",
            "  vocabulary_output_piece_score: 1\n",
            "  train_extremely_large_corpus: 0\n",
            "  hard_vocab_limit: 1\n",
            "  use_all_vocab: 0\n",
            "  unk_id: 0\n",
            "  bos_id: 1\n",
            "  eos_id: 2\n",
            "  pad_id: -1\n",
            "  unk_piece: <unk>\n",
            "  bos_piece: <s>\n",
            "  eos_piece: </s>\n",
            "  pad_piece: <pad>\n",
            "  unk_surface:  \\342\\201\\207 \n",
            "  enable_differential_privacy: 0\n",
            "  differential_privacy_noise_level: 0\n",
            "  differential_privacy_clipping_threshold: 0\n",
            "}\n",
            "normalizer_spec {\n",
            "  name: identity\n",
            "  add_dummy_prefix: 1\n",
            "  remove_extra_whitespaces: 1\n",
            "  escape_whitespaces: 1\n",
            "  normalization_rule_tsv: \n",
            "}\n",
            "denormalizer_spec {}\n",
            "trainer_interface.cc(348) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
            "trainer_interface.cc(180) LOG(INFO) Loading corpus: ./data/红楼梦.txt\n",
            "trainer_interface.cc(375) LOG(WARNING) Found too long line (4224 > 4192).\n",
            "trainer_interface.cc(377) LOG(WARNING) Too long lines are skipped in the training.\n",
            "trainer_interface.cc(378) LOG(WARNING) The maximum length can be changed with --max_sentence_length=<size> flag.\n",
            "trainer_interface.cc(404) LOG(INFO) Loaded all 3144 sentences\n",
            "trainer_interface.cc(411) LOG(INFO) Skipped 6 too long sentences.\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <unk>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <s>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: </s>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x00>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x01>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x02>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x03>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x04>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x05>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x06>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x07>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x08>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x09>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x0A>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x0B>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x0C>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x0D>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x0E>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x0F>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x10>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x11>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x12>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x13>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x14>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x15>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x16>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x17>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x18>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x19>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x1A>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x1B>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x1C>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x1D>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x1E>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x1F>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x20>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x21>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x22>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x23>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x24>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x25>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x26>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x27>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x28>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x29>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x2A>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x2B>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x2C>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x2D>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x2E>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x2F>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x30>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x31>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x32>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x33>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x34>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x35>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x36>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x37>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x38>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x39>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x3A>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x3B>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x3C>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x3D>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x3E>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x3F>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x40>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x41>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x42>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x43>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x44>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x45>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x46>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x47>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x48>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x49>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x4A>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x4B>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x4C>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x4D>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x4E>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x4F>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x50>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x51>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x52>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x53>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x54>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x55>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x56>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x57>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x58>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x59>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x5A>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x5B>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x5C>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x5D>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x5E>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x5F>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x60>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x61>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x62>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x63>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x64>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x65>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x66>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x67>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x68>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x69>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x6A>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x6B>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x6C>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x6D>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x6E>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x6F>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x70>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x71>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x72>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x73>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x74>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x75>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x76>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x77>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x78>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x79>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x7A>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x7B>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x7C>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x7D>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x7E>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x7F>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x80>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x81>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x82>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x83>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x84>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x85>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x86>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x87>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x88>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x89>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x8A>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x8B>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x8C>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x8D>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x8E>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x8F>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x90>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x91>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x92>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x93>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x94>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x95>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x96>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x97>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x98>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x99>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x9A>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x9B>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x9C>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x9D>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x9E>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x9F>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xA0>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xA1>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xA2>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xA3>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xA4>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xA5>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xA6>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xA7>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xA8>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xA9>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xAA>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xAB>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xAC>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xAD>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xAE>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xAF>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xB0>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xB1>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xB2>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xB3>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xB4>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xB5>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xB6>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xB7>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xB8>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xB9>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xBA>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xBB>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xBC>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xBD>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xBE>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xBF>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xC0>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xC1>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xC2>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xC3>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xC4>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xC5>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xC6>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xC7>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xC8>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xC9>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xCA>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xCB>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xCC>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xCD>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xCE>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xCF>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xD0>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xD1>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xD2>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xD3>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xD4>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xD5>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xD6>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xD7>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xD8>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xD9>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xDA>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xDB>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xDC>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xDD>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xDE>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xDF>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xE0>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xE1>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xE2>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xE3>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xE4>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xE5>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xE6>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xE7>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xE8>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xE9>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xEA>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xEB>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xEC>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xED>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xEE>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xEF>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xF0>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xF1>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xF2>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xF3>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xF4>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xF5>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xF6>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xF7>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xF8>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xF9>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xFA>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xFB>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xFC>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xFD>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xFE>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xFF>\n",
            "trainer_interface.cc(425) LOG(INFO) Normalizing sentences...\n",
            "trainer_interface.cc(534) LOG(INFO) all chars count=866686\n",
            "trainer_interface.cc(555) LOG(INFO) Alphabet size=4433\n",
            "trainer_interface.cc(556) LOG(INFO) Final character coverage=1\n",
            "trainer_interface.cc(587) LOG(INFO) Done! preprocessed 3144 sentences.\n",
            "trainer_interface.cc(593) LOG(INFO) Tokenizing input sentences with whitespace: 3144\n",
            "trainer_interface.cc(604) LOG(INFO) Done! 3253\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=10908 min_freq=12\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1062 size=20 all=143807 active=13182 piece=宝钗\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=830 size=40 all=149913 active=19288 piece=不是\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=557 size=60 all=156183 active=25558 piece=姐姐\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=439 size=80 all=161003 active=30378 piece=探春\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=366 size=100 all=165342 active=34717 piece=今日\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=365 min_freq=10\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=309 size=120 all=169145 active=11833 piece=打发\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=267 size=140 all=172596 active=15284 piece=到了\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=235 size=160 all=175613 active=18301 piece=方才\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=220 size=180 all=178819 active=21507 piece=小厮\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=204 size=200 all=181476 active=24164 piece=跟前\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=203 min_freq=9\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=192 size=220 all=183875 active=11340 piece=一声\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=179 size=240 all=186523 active=13988 piece=叫我\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=170 size=260 all=188885 active=16350 piece=不必\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=160 size=280 all=191060 active=18525 piece=不要\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=153 size=300 all=193464 active=20929 piece=妙玉\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=153 min_freq=8\n",
            "trainer_interface.cc(682) LOG(INFO) Saving model: meng.model\n",
            "trainer_interface.cc(694) LOG(INFO) Saving vocabs: meng.vocab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### check tokenizer model"
      ],
      "metadata": {
        "id": "gTswHsvbv5Mu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 实例化一个分词实例，然后加载训练好的meng.model\n",
        "sp = spm.SentencePieceProcessor()\n",
        "sp.load('meng.model')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsKJTh4xcvPG",
        "outputId": "9c4fd396-d9f0-44e2-9fde-f3455676c36b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sp.encode_as_pieces('满纸荒唐言，一把辛酸泪！都云作者痴，谁解其中味？'))\n",
        "# encode: text => id\n",
        "print(sp.encode_as_ids('满纸荒唐言，一把辛酸泪！都云作者痴，谁解其中味？'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pzsktBKhb3E",
        "outputId": "a956fc60-e9ed-48e4-c8f1-a1a469dd2f91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['▁', '满', '纸', '荒', '唐', '言', '，', '一', '把', '辛', '酸', '泪', '！', '都', '云', '作', '者', '痴', '，', '谁', '解', '其', '中', '味', '？']\n",
            "[616, 959, 1233, 1900, 1952, 813, 567, 572, 704, 1873, 1749, 906, 624, 626, 775, 699, 872, 1347, 567, 738, 881, 867, 663, 1407, 606]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sp.decode_pieces(['满', '纸', '荒', '唐', '言', '，', '一把', '辛', '酸', '泪']))\n",
        "# decode: id => text\n",
        "print(sp.decode_ids([616, 959, 1233, 1900, 1952, 813, 567, 572, 704, 1873, 1749, 906]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbFeP8GVd_SY",
        "outputId": "0bbe28a2-16b7-4dd4-8222-c8303d4f3660"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "满纸荒唐言，一把辛酸泪\n",
            "满纸荒唐言，一把辛酸泪\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 返回 vocab size\n",
        "print(f\"词表大小={sp.get_piece_size()}\")\n",
        "\n",
        "print(sp.encode_as_ids(\"宝玉\"))\n",
        "# id <=> piece conversion\n",
        "print(sp.id_to_piece(552))\n",
        "print(sp.piece_to_id('宝玉'))\n",
        "\n",
        "# id=0的位置留着给UNK token, 可对其进行修改\n",
        "print(sp.piece_to_id('__MUST_BE_UNKNOWN__'))\n",
        "\n",
        "# 控制符 unk, <s>, </s> 默认id对应（0,1,2）\n",
        "for id in range(3):\n",
        "      print(sp.id_to_piece(id), sp.is_control(id))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9NO7ZVklguF",
        "outputId": "114dba6a-39f4-47b4-ff61-9466b11c3909"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "词表大小=5000\n",
            "[552]\n",
            "▁宝玉\n",
            "261\n",
            "0\n",
            "<unk> False\n",
            "<s> True\n",
            "</s> True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/chenyangMl/llama2.c-zh.git"
      ],
      "metadata": {
        "id": "LOq84Yhi1Sz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/karpathy/llama2.c.git"
      ],
      "metadata": {
        "id": "djTANGXp1Ysr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 加载一个训练好的tokenizer对比下。\n",
        "\n",
        "from sentencepiece import SentencePieceProcessor\n",
        "#model_path = \"llama2.c/tokenizer.model\"\n",
        "model_path = \"llama2.c-zh/tokenizers/llama2enzh/tokenizer.model\"\n",
        "sp_model = SentencePieceProcessor(model_file=model_path)\n",
        "print(f\"Loaded SentencePiece model from {model_path}\")\n",
        "\n",
        "# BOS / EOS token IDs\n",
        "n_words: int = sp_model.vocab_size()\n",
        "bos_id: int = sp_model.bos_id()\n",
        "eos_id: int = sp_model.eos_id()\n",
        "pad_id: int = sp_model.pad_id()\n",
        "unk_id: int = sp_model.unk_id()\n",
        "print(f\"#words: {n_words} - BOS ID: {bos_id} - EOS ID: {eos_id} - PAD ID: {pad_id} - UNK ID : {unk_id}\")\n",
        "\n",
        "\n",
        "model_path = \"meng.model\"\n",
        "sp_model = SentencePieceProcessor(model_file=model_path)\n",
        "print(f\"Loaded SentencePiece model from {model_path}\")\n",
        "\n",
        "# BOS / EOS token IDs\n",
        "n_words: int = sp_model.vocab_size()\n",
        "bos_id: int = sp_model.bos_id()\n",
        "eos_id: int = sp_model.eos_id()\n",
        "pad_id: int = sp_model.pad_id()\n",
        "print(f\"#words: {n_words} - BOS ID: {bos_id} - EOS ID: {eos_id} - PAD ID: {pad_id} - UNK ID : {unk_id}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGYmwvn3mPPp",
        "outputId": "a6647dfa-7adf-491f-de36-392b95ee3761"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded SentencePiece model from llama2.c-zh/tokenizers/llama2enzh/tokenizer.model\n",
            "#words: 55296 - BOS ID: 1 - EOS ID: 2 - PAD ID: -1 - UNK ID : 0\n",
            "Loaded SentencePiece model from meng.model\n",
            "#words: 5000 - BOS ID: 1 - EOS ID: 2 - PAD ID: -1 - UNK ID : 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 使用HF bigscience-data/roots_zh-cn_wikipedia 数据 扩展llama tokenizer词表"
      ],
      "metadata": {
        "id": "ErB2LoitzEqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uL-Mrer00hFH",
        "outputId": "6d886dde-8248-419f-d21a-490215890474"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: \n",
            "Add token as git credential? (Y/n) y\n",
            "Token is valid (permission: write).\n",
            "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
            "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
            "\n",
            "git config --global credential.helper store\n",
            "\n",
            "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
            "Token has not been saved to git credential helper.\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli download \\\n",
        "  --repo-type dataset bigscience-data/roots_zh-cn_wikipedia \\\n",
        "  --local-dir ./data/bigscience-data/roots_zh-cn_wikipedia \\\n",
        "  --local-dir-use-symlinks False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eFTLdPtzW-f",
        "outputId": "46129aed-43d2-43be-a200-3fcc29619f61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Consider using `hf_transfer` for faster downloads. This solution comes with some limitations. See https://huggingface.co/docs/huggingface_hub/hf_transfer for more details.\n",
            "Fetching 5 files:   0% 0/5 [00:00<?, ?it/s]downloading https://huggingface.co/datasets/bigscience-data/roots_zh-cn_wikipedia/resolve/ba4990a9de8e3ceaf3f15a4ee97e1aea8659caf7/.gitattributes to /root/.cache/huggingface/hub/tmp86omvl_l\n",
            "downloading https://huggingface.co/datasets/bigscience-data/roots_zh-cn_wikipedia/resolve/ba4990a9de8e3ceaf3f15a4ee97e1aea8659caf7/README.md to /root/.cache/huggingface/hub/tmp1feror20\n",
            "downloading https://huggingface.co/datasets/bigscience-data/roots_zh-cn_wikipedia/resolve/ba4990a9de8e3ceaf3f15a4ee97e1aea8659caf7/data/train-00001-of-00002.parquet to /root/.cache/huggingface/hub/tmpyokm5233\n",
            "downloading https://huggingface.co/datasets/bigscience-data/roots_zh-cn_wikipedia/resolve/ba4990a9de8e3ceaf3f15a4ee97e1aea8659caf7/dataset_infos.json to /root/.cache/huggingface/hub/tmpam9u5x_s\n",
            "downloading https://huggingface.co/datasets/bigscience-data/roots_zh-cn_wikipedia/resolve/ba4990a9de8e3ceaf3f15a4ee97e1aea8659caf7/data/train-00000-of-00002.parquet to /root/.cache/huggingface/hub/tmpgmx26vaq\n",
            "\n",
            ".gitattributes: 100% 1.57k/1.57k [00:00<00:00, 7.06MB/s]\n",
            "Fetching 5 files:  20% 1/5 [00:00<00:03,  1.25it/s]\n",
            "README.md: 100% 3.66k/3.66k [00:00<00:00, 15.0MB/s]\n",
            "\n",
            "dataset_infos.json: 100% 925/925 [00:00<00:00, 5.04MB/s]\n",
            "\n",
            "train-00001-of-00002.parquet:   0% 0.00/260M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "train-00000-of-00002.parquet:   0% 0.00/262M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "train-00000-of-00002.parquet:   4% 10.5M/262M [00:00<00:02, 95.5MB/s]\u001b[A\u001b[A\n",
            "train-00001-of-00002.parquet:   4% 10.5M/260M [00:00<00:02, 85.4MB/s]\u001b[A\n",
            "\n",
            "train-00000-of-00002.parquet:  12% 31.5M/262M [00:00<00:01, 140MB/s] \u001b[A\u001b[A\n",
            "train-00001-of-00002.parquet:  12% 31.5M/260M [00:00<00:01, 138MB/s] \u001b[A\n",
            "train-00001-of-00002.parquet:  20% 52.4M/260M [00:00<00:01, 164MB/s]\u001b[A\n",
            "\n",
            "train-00000-of-00002.parquet:  24% 62.9M/262M [00:00<00:01, 174MB/s]\u001b[A\u001b[A\n",
            "train-00001-of-00002.parquet:  28% 73.4M/260M [00:00<00:01, 180MB/s]\u001b[A\n",
            "\n",
            "train-00000-of-00002.parquet:  32% 83.9M/262M [00:00<00:00, 182MB/s]\u001b[A\u001b[A\n",
            "train-00001-of-00002.parquet:  36% 94.4M/260M [00:00<00:00, 186MB/s]\u001b[A\n",
            "\n",
            "train-00000-of-00002.parquet:  44% 115M/262M [00:00<00:00, 193MB/s] \u001b[A\u001b[A\n",
            "train-00001-of-00002.parquet:  44% 115M/260M [00:00<00:00, 191MB/s] \u001b[A\n",
            "\n",
            "train-00000-of-00002.parquet:  52% 136M/262M [00:00<00:00, 197MB/s]\u001b[A\u001b[A\n",
            "train-00001-of-00002.parquet:  52% 136M/260M [00:00<00:00, 196MB/s]\u001b[A\n",
            "\n",
            "train-00000-of-00002.parquet:  60% 157M/262M [00:00<00:00, 195MB/s]\u001b[A\u001b[A\n",
            "train-00001-of-00002.parquet:  60% 157M/260M [00:00<00:00, 199MB/s]\u001b[A\n",
            "train-00001-of-00002.parquet:  68% 178M/260M [00:00<00:00, 200MB/s]\u001b[A\n",
            "\n",
            "train-00000-of-00002.parquet:  72% 189M/262M [00:01<00:00, 203MB/s]\u001b[A\u001b[A\n",
            "train-00001-of-00002.parquet:  77% 199M/260M [00:01<00:00, 201MB/s]\u001b[A\n",
            "\n",
            "train-00000-of-00002.parquet:  80% 210M/262M [00:01<00:00, 201MB/s]\u001b[A\u001b[A\n",
            "train-00001-of-00002.parquet:  85% 220M/260M [00:01<00:00, 202MB/s]\u001b[A\n",
            "\n",
            "train-00000-of-00002.parquet:  88% 231M/262M [00:01<00:00, 200MB/s]\u001b[A\u001b[A\n",
            "train-00001-of-00002.parquet:  93% 241M/260M [00:01<00:00, 198MB/s]\u001b[A\n",
            "\n",
            "train-00001-of-00002.parquet: 100% 260M/260M [00:01<00:00, 187MB/s]\n",
            "train-00000-of-00002.parquet: 100% 262M/262M [00:01<00:00, 188MB/s]\n",
            "Fetching 5 files: 100% 5/5 [00:02<00:00,  2.04it/s]\n",
            "/content/data/bigscience-data/roots_zh-cn_wikipedia\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -hlg /content/data/bigscience-data/roots_zh-cn_wikipedia/data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lm7iWCvJ2h8K",
        "outputId": "60d0a3df-1db5-4cb0-8e32-f55213863c7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 499M\n",
            "-rw-r--r-- 1 root 251M Jan 24 14:20 train-00000-of-00002.parquet\n",
            "-rw-r--r-- 1 root 249M Jan 24 14:20 train-00001-of-00002.parquet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# 读取.parquet文件\n",
        "parquet_file = './data/bigscience-data/roots_zh-cn_wikipedia/data/train-00000-of-00002.parquet'\n",
        "df = pd.read_parquet(parquet_file)\n",
        "\n",
        "# 获取text列的前1万条数据，只用10000条来做测试\n",
        "text_col = df['text'][:10000]\n",
        "\n",
        "# 指定要写入的txt文件\n",
        "txt_file = './data/bigscience-data/roots_zh-cn_wikipedia/sample.txt'\n",
        "\n",
        "# 将数据追加写入txt文件\n",
        "with open(txt_file, 'a') as file:\n",
        "    text_col.to_csv(file, sep='\\t', index=False, header=False)\n",
        "print(f'前1万条content数据已写入到 {txt_file}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhEDs8Uz1yYK",
        "outputId": "da7f1201-5a5a-4ca9-b888-2dea7982c061"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "前1万条content数据已写入到 ./data/bigscience-data/roots_zh-cn_wikipedia/sample.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -n 100 ./data/bigscience-data/roots_zh-cn_wikipedia/sample.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxlgpnh74MJt",
        "outputId": "37497242-4872-4daa-d32a-291c71fa9c11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"卡内基大厅\n",
            "\n",
            "卡内基大厅（Carnegie Hall），也称作卡内基音乐厅，位于纽约市第七大道881号，第56大街和第57大街中间，占据第七大道东侧。由慈善家安德鲁·卡内基（Andrew Carnegie）出资建于1890年，是美国古典音乐与流行音乐界的标志性建筑。卡内基大厅以历史悠久，外形美观以及声音效果出色而著称。设有自己的艺术策划、开发和市场部门，每季度演出100余场；此外也出租给表演团体。目前无常驻乐团，纽约爱乐乐团在1962年之前驻扎于此。\n",
            "\n",
            "演出厅\n",
            "\n",
            "卡内基大厅由三个结构截然不同的小厅组成，内部结构颇为特殊。三个厅分别是：主厅、独奏厅和室内乐厅。\n",
            "\n",
            "建筑\n",
            "\n",
            "卡内基大厅是由纽约宗教剧社团的业余大提琴手，并不出名的威廉·波奈特·杜斯尔（William Burnet Tuthill）设计的，设计成意大利文艺复兴式样，用砖和棕色砂石建成的。\n",
            "卡内基大厅是纽约仅存不多的，完全没有金属构架的全砖石结构的大型建筑之一，在20世纪初，由于要在演出厅添加一些楼梯，才增加了一些金属构件。外部全是由“罗马”式的窄砖构成，形成一种深棕色色调，细部是陶土和棕色砂石的雕塑。大厅避免了当时流行的巴洛克装饰风格，采用了佛罗伦萨文艺复兴时期著名建筑师和雕塑家菲利坡·布鲁奈尔斯基（Filippo Brunelleschi）的作品，帕奇礼拜堂高尚的风格：圆拱顶是由白色石膏和灰色石头组成的和谐色彩，四外是科林斯式柱头的壁柱支撑着连续的檐口，檐口上面，拱顶下面是一序列的半圆窗，组成著名的金色和白色的内部色调。\n",
            "\n",
            "历史\n",
            "\n",
            "卡内基大厅以安德鲁·卡内基的名字命名，卡内基当年出资建造大厅是为了将其作为他董事会下的纽约宗教剧协会的会馆。工程由伊萨克·A·霍伯（Isaac A. Hopper）及其公司承包，1890年动土兴建。1891年投入使用，同年5月5日举办正式开幕音乐会，著名指挥家瓦尔特·达姆罗施（Walter Damrosch）和作曲家彼得·伊里奇·柴科夫斯基（Peter Ilyich Tchaikovsky）出任指挥。一开始大厅的名字仅是简单的“音乐厅”（建筑正面华盖上方有\"\"音乐厅由安德鲁·卡内基出资建造\"\"的字样），后来在纽约音乐厅公司（大厅最初的管理机构）董事会成员们的劝说下，卡内基同意用他的名字命名，大厅于1893年正式更名为卡内基大厅。大厅在1893—1896年间多次改建，增加了两座艺术家工作室塔，并改造了建筑下层的礼堂。\n",
            "大厅的所有权在1925年之前属于卡内基家族，卡内基去世后，他的遗孀将其卖给房地产开发商罗伯特·E·西蒙（Robert E. Simon）。西蒙于1935年过世，他的儿子接管了大厅。40年代中期，音乐界的风云变幻促使西蒙将大厅出售给当时占据着大厅每年大部分演出档期的纽约爱乐乐团，但因乐团正准备搬往林肯中心，交易未能成行。而那时候大家都认为纽约城无法担负同时两个大音乐场馆。面对失去大厅最大客户的危险，西蒙不得不计划将其变卖。但随着与一家广告开发商谈判的破裂，纽约爱乐乐团又迁往林肯中心，大厅面临着为商业摩天大厦让路将被拆除的命运。后来，在小提琴家伊萨克·斯特恩领导的团体的压力下，政府通过特别法案，允许纽约市以5百万美元将大厅从西蒙手中买下，并于1960年成立非盈利性质的卡内基大厅协会来管理大厅的运作。1964年，卡内基大厅被指定为国家历史地标。\n",
            "1983年到1995年间，大厅进行了大规模的修缮。修缮工程由詹姆斯·波尔夏克（James Polshek）负责，波尔夏克的成名作是为美国自然历史博物馆（American Museum of Natural History）设计的的后现代派风格天文馆。在此期间出现了争议。在1986年对主厅的改造完成后，有批评说大厅著名的音场效果受到了影响。但官方拒绝重新改建，批评持续了九年。直到1995年发现罪魁祸首是舞台下厚厚的混凝土板。板子随后被移掉。1987—1989年间，一座60层高的办公塔在大厅旁边拔地而起，名为卡内基塔。塔楼与卡内基大厅相连，具有后台及宴会厅等功能。2003年6月，纽约爱乐乐团计划在2006年初重返卡内基大厅并与大厅进行商业合并；2003年晚些时候宣布计划流产。\n",
            "\n",
            "管理\n",
            "\n",
            "现任大厅执行与艺术总监是克里夫·基林森爵士（Clive Gillinson）（2005年7月上任），他同时也是伦敦交响乐团的团长。\n",
            "\n",
            "档案馆\n",
            "\n",
            "1986年，出现了一件让广大爱乐者意想不到的事情，原来卡内基大厅一直没有系统地保存过档案。因为没有地方保存，大厅的许多重要历史文献都已失散。1991年，为庆祝卡内基大厅落成100周年，卡内基大厅档案馆被建立了起来。广告商和记者们在媒体上报到了卡内基大厅如何翻箱倒柜地寻找历史记录。结果报道在保留着大厅节目单的人群中形成了极大反响：历史文物从世界各地接踵而来。大量的材料被找回，其中包括12000分节目单，让档案馆得以记录下较完整的大厅历史。\n",
            "\n",
            "地理位置与民间笑话\n",
            "\n",
            "卡内基大厅位于第七大道和第57街的东南角，往北两个街区即是中央公园（Central Park）。\n",
            "民间流传着一个关于大厅的笑话：问：“我怎么才能去卡内基大厅？” 答：“练习，练习，再练习。”卡内基大厅官方网站的导航页 上也间接引用了这个笑话。\"\n",
            "\"多巴胺受体D4\n",
            "\n",
            "48-碱基对VNTR(可变数量串联重复)\n",
            "\n",
            "外显子3中的48-碱基对可变数量串联重复（VNTR）有2至11次重复。\n",
            "等位基因的频率在人群中变化很大，例如，7-重复版本在美洲很高而在亚洲则很低。 “长”版本的多态基因是重复6到10次的等位基因。7R对多巴胺分子的反应强度似乎要略弱一些。\n",
            "\n",
            "'长DRD4'变体, 或更具体地即7重复(7R)，松散地与形成ADHD \n",
            "以及其它的心理特征和异常的易感性相关。\n",
            "48-碱基对VNTR已经成为了在跨文化环境下对其在人类行为的进化和角色方面所作出的诸多推测的主题。7R等位基因似乎在4万年前就已经被选择出来。 1999年，陈（音）及其同事 观察到那些在过去3万年到1万年间迁移得比较远的人类群体带有7R/长等位基因的频率较高。他们也指出游牧人群带有7R等位基因的频率比定居人群高。 较近期，也有观察到拥有7R等位基因的游牧人阿里尔人健康状况更好。然而，定居不久的（非游牧）带有7R等位基因的阿里尔人似乎有轻微的健康退化状况。\n",
            "\n",
            "寻奇性格\n",
            "\n",
            "尽管有关于DRD4 48碱基对VNTR与“寻奇性格”（具有爱探索和爱刺激人的一种性格特质）之间关联的早期发现， 2008年的一项元分析对比了36份出版了的关于“寻奇性格”和多态性的研究，没有找到有效相关性。关于11份研究的元分析确发现了基因的另一多态性——-521C/T显示出与“寻奇性格”的联系。 。究其各种情况，“寻奇”行为可能是由几个基因介导的，仅归因于DRD4本身所造成的变化并不是特别大。\n",
            "\n",
            "认知发展\n",
            "\n",
            "有一些研究指出育儿过程可能影响带有DRD4 7-重复等位基因儿童的认知发展。 具有母性感受、正念和自治支持的育儿过程在15个月时对儿童后来在18至20个月的执行性功能有益 经历较差育儿过程的儿童比那些有较好经历者更冲动且更追求感官刺激。高质量的育儿过程与儿童在四岁时较好的努力控制 相关。\"\n",
            "\"新疆時間\n",
            "\n",
            "新疆时间，或称乌鲁木齐时间，是一个出于当地地理位置因素而设定的时间标准。该时间标准相当于UTC+06:00时间，与哈萨克斯坦时间一样并比北京时间慢两小时。此时间标准与北京时间共同平行地在中国新疆境内使用。\n",
            "\n",
            "历史\n",
            "\n",
            "在1970-1980年代间，新疆时间曾被多次废除后再恢复。在1986年2月，中国政府批准了在新疆民间采用新疆时间（UTC+6），而在铁路、航空和邮电等业务上继续采用北京时间。但此决定遭当地汉族和政府部门反对。\n",
            "\n",
            "应用\n",
            "\n",
            "现时，新疆当地使用的时区基本上是按民族界线划分，大部分汉族人采用北京时间而大部分维吾尔族等其他民族的人则采用乌鲁木齐时间。部分当地政府部门同时使用两个时间。两个标准的共存导致当地居民沟通时容易出现混乱，特别是在不同民族居民间进行沟通时。在这种情况下当地居民需要特别声明所指的时间为哪个时区，或者按照谈话对象转换时区以免混淆。在新疆电视台，曾经长期使用两套时间标准（其中文频道采用北京时间而维吾尔语和哈萨克语频道采用新疆时间）的情况反映了此一现象。\n",
            "2014年，苹果公司发布了新版本的iOS移动操作系统，并静默地把位于新疆的用户的时间改为乌鲁木齐时间。由于该区域部分用户此前使用北京时间来设置闹铃，此未声明的更动导致部分用户的闹铃没有在预定的时刻响起，从而导致当天该部分居民的日常生活受到影响。\n",
            "2018年，人权观察报告说，一名维吾尔族人因为将自己的手表设置为乌鲁木齐时间而被捕并被送往拘留中心。\"\n",
            "\"人民剧场 (北京)\n",
            "\n",
            "人民剧场是一座位于北京市西城区护国寺街74号的剧场，现隶属于国家京剧院。\n",
            "\n",
            "简介\n",
            "\n",
            "人民剧场位于护国寺街路南，斜对护国寺。人民剧场坐南朝北。该剧场原属华北人民话剧团并由该话剧团负责建造。但在剧场设计工作接近完成时，该话剧团被并入中国青年艺术剧院。上级便将该剧场的所有权交给了中国戏曲研究院（中国京剧团的前身），该剧场自然改以演出京剧为主。当时，人民剧场的设计图纸已完成，无法再根据京剧的演出特点修改，只在原设计图纸上加了附台，并且在后台安排了跑场通道，将衣箱、扮戏的所在改在后台中央。该剧场于1954年8月开工建设，1955年4月完工。\n",
            "人民剧场的建筑风格富有民族特色，是中国近代优秀建筑。该剧场建成之后，曾经是北京市演出条件最好的剧场之一。1999年5月18日，人民剧场经重新整修正式重张营业。为祝贺人民剧场重张，中国京剧院组织了12台大戏在该剧场上演。不久，由于存在安全隐患等问题，人民剧场于21世纪初停业。随后该剧场进行了重修。\n",
            "2011年3月3日，已经停业近十年的人民剧场经过重修，在护国寺街重新亮相。此次重修保留了原有的建筑风格，将剧场观众区至舞台部分拆除重建，对前厅门脸进行了加固大修，还重新进行了油漆彩绘。2011年8月15日，国家京剧院（2007年由中国京剧院更名而来）在经过维修改造后的人民剧场举行了人民剧场重新启用仪式。重新改造后的人民剧场，建筑面积达8488平方米，主要有六大功能即“戏曲影视拍摄、戏曲资料整理保存、戏曲专场演出、重点剧目的合成排练、文化发布展示、会务会议”。\"\n",
            "\"马克·扎克伯格\n",
            "\n",
            "家庭背景\n",
            "\n",
            "马克·扎克伯格出生于纽约州白原市的一个犹太裔家庭，但他声称自己为无神论者。\n",
            "他的父亲Edward Zuckerberg是一名自行开业的牙医医师，母亲Karen Kempner曾是一名精神科医师。有一个姐姐兰迪·扎克伯格。\n",
            "\n",
            "成长经历\n",
            "\n",
            "扎克伯格开始写程序是中学时期；因为他喜欢玩计算机因此他并没有朋友，他的思想也远超于同龄人。他的父亲在90年代教导他Atari BASIC Programming之后聘请软件研发者David Newman当他的家教。扎克伯格高中时，已经在家里附近的Mercy College上课。扎克伯格很喜欢程序设计，特别是沟通工具与游戏类。他还开发过名为ZuckNet的软件程序，让父亲可以在家里和牙医诊所之间消息交流。这一套系统甚至可视为是后来美国在线（即AOL）即时通信软件的原始版本。\n",
            "根据记者Jose Antonio Vargas所描述的：“一些孩子玩计算机游戏，扎克伯格创造计算机游戏。”\n",
            "在扎克伯格高中时代，他也创作了名为Synapse Media Player的音乐程序，并且借由人工智能来学习用户听音乐的习惯，并且被贴到Slashdot上，被PC Magazine的五星评价为3颗星。微软与美国在线当时就已经想要招揽并训练扎克伯格，并且微软更是不惜给出98万美元的年薪试图招揽这位贤才，不过扎克伯格仍选择于2002年9月进入哈佛大学\n",
            "哈佛岁月\n",
            "在哈佛时代，Vargas表示，扎克伯格被称誉为是“程序人”（a programming person）。他修习心理学与计算机并加入犹太学生兄弟会Alpha Epsilon Pi。\n",
            "二年级时他开发出名为CourseMatch的程序，这是一个依据其他学生选课逻辑而让用户参考选课的程序。一段时间后，他又开发了另外一个不一样的程序，名为Facemash，让学生可以在一堆照片中选择最佳外貌的人。根据扎克伯格室友Arie Hasit的回忆，“他做这个只是因为好玩”。Hasit如此解释：“他有几本名为脸谱（Face Books）的书，里面包括著学生的名字与照片。起初，他创建一个网站，放上两张照片，或两张男生照片和两张女生照片。浏览者可以选择哪一张最‘辣’，并且根据投票结果来排行。”\n",
            "这个的竞赛进行了一个周末之久，但是到周一早晨，被校方关闭，因为哈佛的服务器处理量远超正常值，因此不准学生进入这个网站。此外，很多学生也反应，他们的照片在未经授权下被使用。扎克伯格为此公开道歉，并且在校报上公开表示“这是不适当的举动”。不过，扎克伯格出自好玩的这个网站，后来一直被学生要求，要发展出一个包含照片与交往细节的校内网站。根据Hasit的回忆，“马克听到这个消息后非常高兴，并且决定如果学校不干的话，他要干，他将会建一个比学校更棒的站。”\n",
            "接下来一个学期（2004-1），他开始开发一个新的网站，说其灵感来源于某主笔的一篇文章，后来这篇关于Facemash后续事件的文章被指失实。2004年2月4日，扎克伯格发布了\"\"Thefacebook\"\"，刚开始的域名为thefacebook.com\n",
            "网站发布6天后，Cameron Winklevoss, Tyler Winklevoss和Divya Narendra指责扎克伯格格误导了他们，让他们认为扎克在帮助自己创建名为HarvardConnection.com的网站，但他却偷窃了自己的想法。三人抱怨，同时一些报纸也展开调查。随后，他们提交文件起诉扎克伯格。后来，扎克伯格给予他们3亿美金的股份（IPO），终于解决纠纷。\n",
            "为专心发展自己的网站事业，扎克伯格在哈佛待了不到一个学期便辍学了。\n",
            "2017年5月25日，扎克伯格获哈佛颁发荣誉法学博士。\n",
            "\n",
            "创业经历\n",
            "\n",
            "因此，扎克伯格在他的哈佛宿舍内，于2004年2月24日发起了Facebook。不过更早启迪他的Facebook观念的，是2002年他从Phillips Exeter学院毕业时，当时一个名为“The Photo Address Book”的。学生们称其为“The Facebook”。这样以照片为核心的网站，大大拓展了许多私校学生的交流，学生们可以列出彼此的基本数据，比如班级、学年、交友偏好、电话号码等。\n",
            "在哈佛时期，扎克伯格才决心要发起Facebook，并且获得室友Dustin Moskovitz的支持。他们第一波合作对象是斯坦福大学、达特茅斯学院、哥伦比亚大学、纽约大学、康乃尔大学、宾夕法尼亚大学、布朗大学、耶鲁大学。\n",
            "之后，扎克伯格跟Moskovitz与一些朋友搬到加州的帕罗奥图，他们把一间小房子改成办公室，稍后与napster共同创办人西恩·帕克偶遇，并邀请他同住。一个夏天以后，扎克伯格通过西恩·帕克邀约到Peter Thiel来投资他的公司，此时约为2004年中。根据扎克伯格的回忆，虽然团队打算回哈佛，但最后还是留在加州。他们也拒绝了一些人想购买Facebook。2007年扎克伯格在访谈中解释原因：“不是因为钱的因素。对我与我的同伴而言，最重要的就是要创造人际之间公开的信息管道。如果媒体公司拥有了这个所有权，对我一点都不好。”\n",
            "他在2010年受“连线”杂志访谈时表示，他还在为相同的目标在努力：“我最关心的就是，如何让世界更开放。”\n",
            "在2009年4月，扎克伯格把Facebook的财务策略规划，交给前网景首席财务官Peter Currie。\n",
            "在2010年7月21日，扎克伯格宣布他的网站会员已经达5亿人。在问到未来的发展策略时，他表示：“如果我们观察我们网页平均的广告搜索率，其实点击率才是我们网页的10%。但它被要求要升到20%。...要做这件事情不难，但是我们不想这么做，我们已经赚够了。的确，我想说的是，我们正走在我们想走的路上。”\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!spm_train --input './data/bigscience-data/roots_zh-cn_wikipedia/sample.txt' \\\n",
        "--input_format text \\\n",
        "--model_prefix bpe_test \\\n",
        "--model_type bpe \\\n",
        "--vocab_size 10000 \\\n",
        "--character_coverage 0.9995 \\\n",
        "--num_threads 32 \\\n",
        "--split_digits True \\\n",
        "--byte_fallback True \\\n",
        "--max_sentence_length 24000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCumbt_u7S_6",
        "outputId": "8069d362-3290-433a-afd6-8c5be53f553d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
            "trainer_spec {\n",
            "  input: ./data/bigscience-data/roots_zh-cn_wikipedia/sample.txt\n",
            "  input_format: text\n",
            "  model_prefix: bpe_test\n",
            "  model_type: BPE\n",
            "  vocab_size: 10000\n",
            "  self_test_sample_size: 0\n",
            "  character_coverage: 0.9995\n",
            "  input_sentence_size: 0\n",
            "  shuffle_input_sentence: 1\n",
            "  seed_sentencepiece_size: 1000000\n",
            "  shrinking_factor: 0.75\n",
            "  max_sentence_length: 24000\n",
            "  num_threads: 32\n",
            "  num_sub_iterations: 2\n",
            "  max_sentencepiece_length: 16\n",
            "  split_by_unicode_script: 1\n",
            "  split_by_number: 1\n",
            "  split_by_whitespace: 1\n",
            "  split_digits: 1\n",
            "  pretokenization_delimiter: \n",
            "  treat_whitespace_as_suffix: 0\n",
            "  allow_whitespace_only_pieces: 0\n",
            "  required_chars: \n",
            "  byte_fallback: 1\n",
            "  vocabulary_output_piece_score: 1\n",
            "  train_extremely_large_corpus: 0\n",
            "  hard_vocab_limit: 1\n",
            "  use_all_vocab: 0\n",
            "  unk_id: 0\n",
            "  bos_id: 1\n",
            "  eos_id: 2\n",
            "  pad_id: -1\n",
            "  unk_piece: <unk>\n",
            "  bos_piece: <s>\n",
            "  eos_piece: </s>\n",
            "  pad_piece: <pad>\n",
            "  unk_surface:  ⁇ \n",
            "  enable_differential_privacy: 0\n",
            "  differential_privacy_noise_level: 0\n",
            "  differential_privacy_clipping_threshold: 0\n",
            "}\n",
            "normalizer_spec {\n",
            "  name: nmt_nfkc\n",
            "  add_dummy_prefix: 1\n",
            "  remove_extra_whitespaces: 1\n",
            "  escape_whitespaces: 1\n",
            "  normalization_rule_tsv: \n",
            "}\n",
            "denormalizer_spec {}\n",
            "trainer_interface.cc(348) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
            "trainer_interface.cc(180) LOG(INFO) Loading corpus: ./data/bigscience-data/roots_zh-cn_wikipedia/sample.txt\n",
            "trainer_interface.cc(404) LOG(INFO) Loaded all 149328 sentences\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <unk>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <s>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: </s>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x00>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x01>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x02>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x03>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x04>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x05>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x06>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x07>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x08>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x09>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x0A>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x0B>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x0C>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x0D>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x0E>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x0F>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x10>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x11>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x12>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x13>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x14>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x15>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x16>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x17>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x18>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x19>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x1A>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x1B>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x1C>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x1D>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x1E>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x1F>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x20>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x21>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x22>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x23>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x24>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x25>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x26>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x27>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x28>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x29>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x2A>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x2B>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x2C>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x2D>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x2E>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x2F>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x30>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x31>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x32>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x33>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x34>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x35>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x36>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x37>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x38>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x39>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x3A>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x3B>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x3C>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x3D>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x3E>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x3F>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x40>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x41>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x42>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x43>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x44>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x45>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x46>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x47>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x48>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x49>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x4A>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x4B>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x4C>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x4D>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x4E>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x4F>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x50>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x51>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x52>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x53>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x54>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x55>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x56>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x57>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x58>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x59>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x5A>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x5B>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x5C>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x5D>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x5E>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x5F>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x60>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x61>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x62>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x63>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x64>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x65>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x66>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x67>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x68>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x69>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x6A>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x6B>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x6C>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x6D>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x6E>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x6F>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x70>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x71>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x72>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x73>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x74>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x75>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x76>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x77>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x78>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x79>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x7A>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x7B>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x7C>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x7D>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x7E>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x7F>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x80>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x81>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x82>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x83>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x84>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x85>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x86>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x87>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x88>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x89>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x8A>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x8B>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x8C>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x8D>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x8E>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x8F>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x90>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x91>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x92>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x93>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x94>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x95>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x96>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x97>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x98>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x99>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x9A>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x9B>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x9C>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x9D>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x9E>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0x9F>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xA0>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xA1>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xA2>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xA3>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xA4>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xA5>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xA6>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xA7>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xA8>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xA9>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xAA>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xAB>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xAC>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xAD>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xAE>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xAF>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xB0>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xB1>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xB2>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xB3>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xB4>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xB5>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xB6>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xB7>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xB8>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xB9>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xBA>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xBB>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xBC>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xBD>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xBE>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xBF>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xC0>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xC1>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xC2>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xC3>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xC4>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xC5>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xC6>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xC7>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xC8>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xC9>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xCA>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xCB>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xCC>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xCD>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xCE>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xCF>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xD0>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xD1>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xD2>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xD3>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xD4>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xD5>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xD6>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xD7>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xD8>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xD9>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xDA>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xDB>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xDC>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xDD>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xDE>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xDF>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xE0>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xE1>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xE2>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xE3>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xE4>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xE5>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xE6>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xE7>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xE8>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xE9>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xEA>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xEB>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xEC>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xED>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xEE>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xEF>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xF0>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xF1>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xF2>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xF3>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xF4>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xF5>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xF6>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xF7>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xF8>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xF9>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xFA>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xFB>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xFC>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xFD>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xFE>\n",
            "trainer_interface.cc(420) LOG(INFO) Adding meta_piece: <0xFF>\n",
            "trainer_interface.cc(425) LOG(INFO) Normalizing sentences...\n",
            "trainer_interface.cc(534) LOG(INFO) all chars count=14390746\n",
            "trainer_interface.cc(545) LOG(INFO) Done: 99.95% characters are covered.\n",
            "trainer_interface.cc(555) LOG(INFO) Alphabet size=6675\n",
            "trainer_interface.cc(556) LOG(INFO) Final character coverage=0.9995\n",
            "trainer_interface.cc(587) LOG(INFO) Done! preprocessed 149251 sentences.\n",
            "trainer_interface.cc(593) LOG(INFO) Tokenizing input sentences with whitespace: 149251\n",
            "trainer_interface.cc(604) LOG(INFO) Done! 197827\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=14581 min_freq=30\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7735 size=20 all=968685 active=65656 piece=进行\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6114 size=40 all=990724 active=87695 piece=之后\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5133 size=60 all=1012782 active=109753 piece=第二\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4257 size=80 all=1029559 active=126530 piece=。”\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3988 size=100 all=1046954 active=143925 piece=政治\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3956 min_freq=27\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3624 size=120 all=1066300 active=70834 piece=活动\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3372 size=140 all=1086087 active=90621 piece=决定\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3103 size=160 all=1103746 active=108280 piece=▁A\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2828 size=180 all=1118380 active=122914 piece=民国\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2663 size=200 all=1131455 active=135989 piece=ol\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2663 min_freq=25\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2460 size=220 all=1144791 active=69797 piece=结束\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2353 size=240 all=1158808 active=83814 piece=独立\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2231 size=260 all=1175468 active=100474 piece=另外\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2165 size=280 all=1191955 active=116961 piece=除了\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2057 size=300 all=1202323 active=127329 piece=于是\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2054 min_freq=23\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1988 size=320 all=1217007 active=73948 piece=结果\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1932 size=340 all=1230323 active=87264 piece=另一\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1868 size=360 all=1243716 active=100657 piece=结构\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1787 size=380 all=1258346 active=115287 piece=现在\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1731 size=400 all=1270742 active=127683 piece=媒体\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1731 min_freq=21\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1681 size=420 all=1281074 active=73149 piece=环境\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1594 size=440 all=1294779 active=86854 piece=银行\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1552 size=460 all=1307145 active=99220 piece=多数\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1511 size=480 all=1317030 active=109105 piece=严重\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1476 size=500 all=1329316 active=121391 piece=统治\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1476 min_freq=20\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1430 size=520 all=1340215 active=76798 piece=目标\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1390 size=540 all=1352790 active=89373 piece=▁《\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1344 size=560 all=1363654 active=100237 piece=作用\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1313 size=580 all=1374816 active=111399 piece=议员\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1284 size=600 all=1385646 active=122229 piece=联邦\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1280 min_freq=19\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1257 size=620 all=1397999 active=81141 piece=的主\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1227 size=640 all=1408280 active=91422 piece=外交\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1194 size=660 all=1419446 active=102588 piece=iv\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1165 size=680 all=1430461 active=113603 piece=模式\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1133 size=700 all=1439671 active=122813 piece=同样\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1132 min_freq=19\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1108 size=720 all=1450632 active=82288 piece=▁m\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1088 size=740 all=1459244 active=90900 piece=透过\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1072 size=760 all=1471424 active=103080 piece=此时\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1054 size=780 all=1481941 active=113597 piece=十分\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1036 size=800 all=1492326 active=123982 piece=并没有\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1032 min_freq=18\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1015 size=820 all=1503620 active=85109 piece=克里\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=995 size=840 all=1514351 active=95840 piece=共有\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=970 size=860 all=1524132 active=105621 piece=科技\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=953 size=880 all=1533868 active=115357 piece=公民\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=937 size=900 all=1543589 active=125078 piece=杂志\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=936 min_freq=17\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=925 size=920 all=1552584 active=85758 piece=长期\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=913 size=940 all=1563390 active=96564 piece=ard\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=899 size=960 all=1572606 active=105780 piece=▁d\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=889 size=980 all=1580623 active=113797 piece=以上\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=873 size=1000 all=1589697 active=122871 piece=力的\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=873 min_freq=16\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=862 size=1020 all=1599222 active=88362 piece=的前\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=845 size=1040 all=1607311 active=96451 piece=每年\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=830 size=1060 all=1616478 active=105618 piece=委会\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=817 size=1080 all=1625042 active=114182 piece=失去\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=806 size=1100 all=1634259 active=123399 piece=各地\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=805 min_freq=16\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=789 size=1120 all=1643324 active=90222 piece=及其\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=777 size=1140 all=1653410 active=100308 piece=用的\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=766 size=1160 all=1663164 active=110062 piece=尔顿\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=758 size=1180 all=1672403 active=119301 piece=喜欢\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=745 size=1200 all=1680194 active=127092 piece=从事\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=744 min_freq=15\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=732 size=1220 all=1688845 active=92015 piece=也被\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=724 size=1240 all=1697185 active=100355 piece=if\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=712 size=1260 all=1705366 active=108536 piece=来到\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=704 size=1280 all=1713424 active=116594 piece=iginal\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=694 size=1300 all=1719871 active=123041 piece=联系\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=693 min_freq=15\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=688 size=1320 all=1727090 active=92808 piece=马克\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=676 size=1340 all=1733901 active=99619 piece=资格\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=669 size=1360 all=1741979 active=107697 piece=埃及\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=662 size=1380 all=1749881 active=115599 piece=食物\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=655 size=1400 all=1756731 active=122449 piece=水平\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=655 min_freq=15\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=648 size=1420 all=1764488 active=95180 piece=受伤\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=643 size=1440 all=1771818 active=102510 piece=维亚\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=636 size=1460 all=1780878 active=111570 piece=这样的\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=627 size=1480 all=1789466 active=120158 piece=主题\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=622 size=1500 all=1797115 active=127807 piece=驾驶\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=621 min_freq=14\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=615 size=1520 all=1805717 active=98033 piece=突然\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=609 size=1540 all=1813366 active=105682 piece=公交\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=603 size=1560 all=1820249 active=112565 piece=墨西\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=597 size=1580 all=1827186 active=119502 piece=参加了\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=589 size=1600 all=1834395 active=126711 piece=重点\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=588 min_freq=14\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=582 size=1620 all=1841894 active=98905 piece=在中国\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=575 size=1640 all=1849252 active=106263 piece=高度\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=568 size=1660 all=1856891 active=113902 piece=海外\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=563 size=1680 all=1863846 active=120857 piece=▁de\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=556 size=1700 all=1869832 active=126843 piece=加强\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=555 min_freq=14\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=551 size=1720 all=1876994 active=100206 piece=逮捕\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=543 size=1740 all=1882906 active=106118 piece=告诉\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=537 size=1760 all=1889794 active=113006 piece=大使\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=532 size=1780 all=1896211 active=119423 piece=的中\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=529 size=1800 all=1903668 active=126880 piece=当天\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=529 min_freq=13\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=522 size=1820 all=1910740 active=101902 piece=ec\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=518 size=1840 all=1917923 active=109085 piece=德华\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=513 size=1860 all=1924517 active=115679 piece=IS\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=509 size=1880 all=1931184 active=122346 piece=体系\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=502 size=1900 all=1937718 active=128880 piece=的工作\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=501 min_freq=13\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=496 size=1920 all=1943377 active=102081 piece=ud\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=491 size=1940 all=1950518 active=109222 piece=up\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=485 size=1960 all=1956109 active=114813 piece=缅甸\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=481 size=1980 all=1961916 active=120620 piece=隆美尔\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=476 size=2000 all=1968013 active=126717 piece=文明\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=476 min_freq=13\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=473 size=2020 all=1973953 active=103997 piece=工具\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=469 size=2040 all=1980229 active=110273 piece=任职\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=465 size=2060 all=1986282 active=116326 piece=婚姻\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=459 size=2080 all=1992760 active=122804 piece=ive\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=453 size=2100 all=1998965 active=129009 piece=涉及\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=453 min_freq=12\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=448 size=2120 all=2005108 active=105642 piece=质疑\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=444 size=2140 all=2010693 active=111227 piece=暴力\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=440 size=2160 all=2016778 active=117312 piece=...\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=435 size=2180 all=2021483 active=122017 piece=下了\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=432 size=2200 all=2027364 active=127898 piece=基金会\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=432 min_freq=12\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=428 size=2220 all=2033149 active=106853 piece=戏剧\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=425 size=2240 all=2038110 active=111814 piece=市政府\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=422 size=2260 all=2044640 active=118344 piece=月台\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=417 size=2280 all=2049778 active=123482 piece=考古\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=415 size=2300 all=2056212 active=129916 piece=我的\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=415 min_freq=12\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=412 size=2320 all=2061492 active=107760 piece=敌人\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=409 size=2340 all=2066762 active=113030 piece=特点\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=405 size=2360 all=2072531 active=118799 piece=商店\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=402 size=2380 all=2077884 active=124152 piece=勋章\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=401 size=2400 all=2083609 active=129877 piece=车厢\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=401 min_freq=12\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=398 size=2420 all=2088910 active=109247 piece=▁中国\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=394 size=2440 all=2094737 active=115074 piece=推广\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=391 size=2460 all=2100299 active=120636 piece=消失\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=387 size=2480 all=2105075 active=125412 piece=授权\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=385 size=2500 all=2110473 active=130810 piece=的最\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=385 min_freq=12\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=381 size=2520 all=2116115 active=110811 piece=会被\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=379 size=2540 all=2121798 active=116494 piece=理想\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=375 size=2560 all=2127492 active=122188 piece=会有\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=373 size=2580 all=2132691 active=127387 piece=uc\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=370 size=2600 all=2137315 active=132011 piece=三人\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=370 min_freq=11\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=368 size=2620 all=2142259 active=111458 piece=培养\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=366 size=2640 all=2147972 active=117171 piece=普鲁\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=364 size=2660 all=2152764 active=121963 piece=▁台湾\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=361 size=2680 all=2158098 active=127297 piece=出版社\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=359 size=2700 all=2163420 active=132619 piece=带着\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=359 min_freq=11\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=357 size=2720 all=2168973 active=113306 piece=签约\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=355 size=2740 all=2174184 active=118517 piece=集会\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=353 size=2760 all=2178893 active=123226 piece=当地的\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=350 size=2780 all=2184503 active=128836 piece=克劳\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=347 size=2800 all=2189574 active=133907 piece=停车\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=347 min_freq=11\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=345 size=2820 all=2193955 active=113663 piece=前后\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=344 size=2840 all=2199220 active=118928 piece=▁背景\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=340 size=2860 all=2204312 active=124020 piece=城的\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=338 size=2880 all=2209048 active=128756 piece=指挥官\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=336 size=2900 all=2214701 active=134409 piece=销量\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=336 min_freq=11\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=333 size=2920 all=2218251 active=114086 piece=边境\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=330 size=2940 all=2223210 active=119045 piece=性别\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=328 size=2960 all=2227416 active=123251 piece=委员会委员\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=326 size=2980 all=2232032 active=127867 piece=奥斯曼帝国\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=324 size=3000 all=2236983 active=132818 piece=绝对\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=324 min_freq=11\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=322 size=3020 all=2241183 active=115798 piece=放在\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=319 size=3040 all=2245988 active=120603 piece=圆形\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=317 size=3060 all=2251035 active=125650 piece=也因此\n",
            "trainer_interface.cc(682) LOG(INFO) Saving model: bpe_test.model\n",
            "trainer_interface.cc(694) LOG(INFO) Saving vocabs: bpe_test.vocab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check\n",
        "\n",
        "import sentencepiece as spm\n",
        "sp_bpe = spm.SentencePieceProcessor()\n",
        "sp_bpe.load('bpe_test.model')\n",
        "print('*** BPE ***')\n",
        "print(sp_bpe.encode_as_pieces('The excellence of a translation can only be judged by noting'))\n",
        "print(len(sp_bpe.encode_as_pieces('The excellence of a translation can only be judged by noting')))\n",
        "print(sp_bpe.encode_as_pieces('麒麟，是中国古代神话中的一种瑞兽'))\n",
        "print(len(sp_bpe.encode_as_pieces('麒麟，是中国古代神话中的一种瑞兽')))\n",
        "\n",
        "# 结果\n",
        "#*** BPE ***\n",
        "#['▁The', '▁', 'ex', 'c', 'ell', 'en', 'ce', '▁of', '▁a', '▁t', 'ran', 's', 'l', 'ation', '▁c', 'an', '▁', 'on', 'ly', '▁b', 'e', '▁', 'j', 'ud', 'g', 'ed', '▁b', 'y', '▁n', 'ot', 'ing']\n",
        "#31\n",
        "#['▁', '麒', '麟', ',', '是中国', '古代', '神', '话', '中', '的一种', '瑞', '兽']\n",
        "#12\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qStN7Nha9oe5",
        "outputId": "43071c63-c7b3-468d-b90a-ec794887ff7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** BPE ***\n",
            "['▁The', '▁', 'ex', 'c', 'ell', 'en', 'ce', '▁of', '▁a', '▁t', 'ran', 's', 'l', 'ation', '▁c', 'an', '▁', 'on', 'ly', '▁b', 'e', '▁', 'j', 'ud', 'g', 'ed', '▁b', 'y', '▁n', 'ot', 'ing']\n",
            "31\n",
            "['▁', '麒', '麟', ',', '是中国', '古代', '神', '话', '中', '的一种', '瑞', '兽']\n",
            "12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#合并Llama词表\n",
        "# from: https://github.com/ymcui/Chinese-LLaMA-Alpaca/blob/main/scripts/merge_tokenizer/merge_tokenizers.py\n",
        "\n",
        "import os\n",
        "os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"]=\"python\"\n",
        "from transformers import LlamaTokenizer\n",
        "from sentencepiece import sentencepiece_model_pb2 as sp_pb2_model\n",
        "import sentencepiece as spm\n",
        "\n",
        "# 位置\n",
        "llama_tokenizer_dir = \"meta-llama/Llama-2-7b-hf\" # 换成你自己模型的位置\n",
        "chinese_sp_model_file =\"./bpe_test.model\" # 刚才训练的模型\n",
        "\n",
        "# 加载\n",
        "llama_tokenizer = LlamaTokenizer.from_pretrained(llama_tokenizer_dir)\n",
        "chinese_sp_model = spm.SentencePieceProcessor()\n",
        "chinese_sp_model.Load(chinese_sp_model_file)\n",
        "llama_spm = sp_pb2_model.ModelProto()\n",
        "llama_spm.ParseFromString(llama_tokenizer.sp_model.serialized_model_proto())\n",
        "chinese_spm = sp_pb2_model.ModelProto()\n",
        "chinese_spm.ParseFromString(chinese_sp_model.serialized_model_proto())\n",
        "\n",
        "\n",
        "# 打印两个词表的大小和原llama的特殊token\n",
        "print(len(llama_tokenizer),len(chinese_sp_model))\n",
        "print(llama_tokenizer.all_special_tokens)\n",
        "print(llama_tokenizer.all_special_ids)\n",
        "print(llama_tokenizer.special_tokens_map)\n",
        "\n",
        "# 结果\n",
        "#32000 10000\n",
        "#['<s>', '</s>', '<unk>']\n",
        "#[1, 2, 0]\n",
        "#{'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>'}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3wnudE--D9A",
        "outputId": "ab7ba967-e83e-42e6-fcee-aa9b51d6831a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32000 10000\n",
            "['<s>', '</s>', '<unk>']\n",
            "[1, 2, 0]\n",
            "{'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 开始往llama词表里添加，这里你也可以直接加入你想要加入词表的词，或者是领域内的特殊词\n",
        "llama_spm_tokens_set=set(p.piece for p in llama_spm.pieces)\n",
        "print(len(llama_spm_tokens_set))\n",
        "print(f\"Before:{len(llama_spm_tokens_set)}\")\n",
        "for p in chinese_spm.pieces:\n",
        "    piece = p.piece\n",
        "    if piece not in llama_spm_tokens_set:\n",
        "        new_p = sp_pb2_model.ModelProto().SentencePiece()\n",
        "        new_p.piece = piece\n",
        "        new_p.score = 0\n",
        "        llama_spm.pieces.append(new_p)\n",
        "print(f\"New model pieces: {len(llama_spm.pieces)}\")\n",
        "\n",
        "# 结果\n",
        "#32000\n",
        "#Before:32000\n",
        "#New model pieces: 40114\n",
        "\n",
        "# 我们中文词表原来有1万，去重添加后，添加了8114个词。"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGxpp35wBDOn",
        "outputId": "67c16643-a817-4614-dd99-663588db11e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32000\n",
            "Before:32000\n",
            "New model pieces: 40114\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 保存合并后的模型\n",
        "output_sp_dir = 'merged_tokenizer_sp_test'\n",
        "output_hf_dir = 'merged_tokenizer_hf_test'\n",
        "os.makedirs(output_sp_dir,exist_ok=True)\n",
        "with open(output_sp_dir+'/chinese_llama.model', 'wb') as f:\n",
        "    f.write(llama_spm.SerializeToString())\n",
        "tokenizer = LlamaTokenizer(vocab_file=output_sp_dir+'/chinese_llama.model')\n",
        "\n",
        "tokenizer.save_pretrained(output_hf_dir)\n",
        "print(f\"Chinese-LLaMA tokenizer has been saved to {output_hf_dir}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMMzNTzsEjkq",
        "outputId": "950566fc-d714-4d87-e426-66edb0c48ae0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chinese-LLaMA tokenizer has been saved to merged_tokenizer_hf_test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 看一下效果\n",
        "llama_tokenizer = LlamaTokenizer.from_pretrained(llama_tokenizer_dir)\n",
        "chinese_llama_tokenizer = LlamaTokenizer.from_pretrained(output_hf_dir)\n",
        "\n",
        "\n",
        "text = \"The excellence of a translation can only be judged by noting\"\n",
        "print(\"Test text:\\n\",text)\n",
        "print(f\"Tokenized by LLaMA tokenizer:{llama_tokenizer.tokenize(text)}\")\n",
        "print(f\"Tokenized length by LLaMA tokenizer:{len(llama_tokenizer.tokenize(text))}\")\n",
        "print(f\"Tokenized by chinese_llama tokenizer:{chinese_llama_tokenizer.tokenize(text)}\")\n",
        "print(f\"Tokenized length by LLaMA-extent-1 tokenizer:{len(chinese_llama_tokenizer.tokenize(text))}\")\n",
        "\n",
        "#结果，可以看到在英文上是没有变化的\n",
        "#Test text:\n",
        "# The excellence of a translation can only be judged by noting\n",
        "#Tokenized by LLaMA tokenizer:['▁The', '▁excell', 'ence', '▁of', '▁a', '▁translation', '▁can', '▁only', '▁be', '▁jud', 'ged', '▁by', '▁not', 'ing']\n",
        "#Tokenized length by LLaMA tokenizer:14\n",
        "#Tokenized by chinese_llama tokenizer:['▁The', '▁excell', 'ence', '▁of', '▁a', '▁translation', '▁can', '▁only', '▁be', '▁jud', 'ged', '▁by', '▁not', 'ing']\n",
        "#Tokenized length by chinese_llama tokenizer:14\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O48Ka2JdBMRf",
        "outputId": "176078b8-063e-4bbf-bfff-962f34761ca3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test text:\n",
            " The excellence of a translation can only be judged by noting\n",
            "Tokenized by LLaMA tokenizer:['▁The', '▁excell', 'ence', '▁of', '▁a', '▁translation', '▁can', '▁only', '▁be', '▁jud', 'ged', '▁by', '▁not', 'ing']\n",
            "Tokenized length by LLaMA tokenizer:14\n",
            "Tokenized by chinese_llama tokenizer:['The', '▁excell', 'ence', '▁of', '▁a', '▁translation', '▁can', '▁only', '▁be', '▁jud', 'ged', '▁by', '▁not', 'ing']\n",
            "Tokenized length by LLaMA-extent-1 tokenizer:14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"麒麟，是中国古代神话中的一种瑞兽\"\n",
        "print(\"Test text:\\n\",text)\n",
        "print(f\"Tokenized by LLaMA tokenizer:{llama_tokenizer.tokenize(text)}\")\n",
        "print(f\"Tokenized length by LLaMA tokenizer:{len(llama_tokenizer.tokenize(text))}\")\n",
        "print(f\"Tokenized by chinese_llama tokenizer:{chinese_llama_tokenizer.tokenize(text)}\")\n",
        "print(f\"Tokenized length by chinese_llama tokenizer:{len(chinese_llama_tokenizer.tokenize(text))}\")\n",
        "\n",
        "# 结果\n",
        "#Test text:\n",
        "# 麒麟，是中国古代神话中的一种瑞兽\n",
        "#Tokenized by LLaMA tokenizer:['▁', '<0xE9>', '<0xBA>', '<0x92>', '<0xE9>', '<0xBA>', '<0x9F>', '，', '是', '中', '国', '古', '代', '神', '话', '中', '的', '一', '种', '<0xE7>', '<0x91>', '<0x9E>', '<0xE5>', '<0x85>', '<0xBD>']\n",
        "#Tokenized length by LLaMA tokenizer:25\n",
        "#Tokenized by chinese_llama tokenizer:['▁', '麒', '麟', '，', '是中国', '古代', '神', '话', '中的', '一种', '瑞', '兽']\n",
        "#Tokenized length by chinese_llama tokenizer:11\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkA-mIyOBnTC",
        "outputId": "d1039899-a5c4-418a-f003-15a824dfc8d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test text:\n",
            " 麒麟，是中国古代神话中的一种瑞兽\n",
            "Tokenized by LLaMA tokenizer:['▁', '<0xE9>', '<0xBA>', '<0x92>', '<0xE9>', '<0xBA>', '<0x9F>', '，', '是', '中', '国', '古', '代', '神', '话', '中', '的', '一', '种', '<0xE7>', '<0x91>', '<0x9E>', '<0xE5>', '<0x85>', '<0xBD>']\n",
            "Tokenized length by LLaMA tokenizer:25\n",
            "Tokenized by chinese_llama tokenizer:['麒', '麟', '，', '是中国', '古代', '神', '话', '中的', '一种', '瑞', '兽']\n",
            "Tokenized length by chinese_llama tokenizer:11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 使用52AI/TinyStoriesZh 数据 训练tokenizer"
      ],
      "metadata": {
        "id": "5cjyR-pR6XMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli download \\\n",
        "  --repo-type dataset 52AI/TinyStoriesZh \\\n",
        "  --local-dir ./data/52AI/TinyStoriesZh \\\n",
        "  --local-dir-use-symlinks False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9i4u0Cn_6Wlc",
        "outputId": "d70c344d-0519-4bb3-b8f5-0194b24d7850"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Consider using `hf_transfer` for faster downloads. This solution comes with some limitations. See https://huggingface.co/docs/huggingface_hub/hf_transfer for more details.\n",
            "Fetching 4 files:   0% 0/4 [00:00<?, ?it/s]downloading https://huggingface.co/datasets/52AI/TinyStoriesZh/resolve/96e998aab7ce3311f8a8497b2aa6ed5088630672/.gitattributes to /root/.cache/huggingface/hub/tmp2lpg2h55\n",
            "downloading https://huggingface.co/datasets/52AI/TinyStoriesZh/resolve/96e998aab7ce3311f8a8497b2aa6ed5088630672/README.md to /root/.cache/huggingface/hub/tmpvmle1b6y\n",
            "downloading https://huggingface.co/datasets/52AI/TinyStoriesZh/resolve/96e998aab7ce3311f8a8497b2aa6ed5088630672/TinyStories_all_data_zh_1M.tar.gz to /root/.cache/huggingface/hub/tmp6mhvxmyk\n",
            "downloading https://huggingface.co/datasets/52AI/TinyStoriesZh/resolve/96e998aab7ce3311f8a8497b2aa6ed5088630672/TinyStories_all_data_zh_2M.tar.gz to /root/.cache/huggingface/hub/tmpeje4db4y\n",
            "\n",
            "README.md: 100% 2.94k/2.94k [00:00<00:00, 15.3MB/s]\n",
            "\n",
            ".gitattributes: 100% 2.31k/2.31k [00:00<00:00, 10.9MB/s]\n",
            "Fetching 4 files:  25% 1/4 [00:00<00:01,  1.69it/s]\n",
            "TinyStories_all_data_zh_2M.tar.gz:   0% 0.00/510M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "TinyStories_all_data_zh_1M.tar.gz:   0% 0.00/261M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "TinyStories_all_data_zh_1M.tar.gz:   4% 10.5M/261M [00:00<00:02, 85.6MB/s]\u001b[A\u001b[A\n",
            "TinyStories_all_data_zh_2M.tar.gz:   2% 10.5M/510M [00:00<00:07, 68.3MB/s]\u001b[A\n",
            "TinyStories_all_data_zh_2M.tar.gz:   4% 21.0M/510M [00:00<00:07, 68.5MB/s]\u001b[A\n",
            "\n",
            "TinyStories_all_data_zh_1M.tar.gz:   8% 21.0M/261M [00:00<00:04, 54.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "TinyStories_all_data_zh_1M.tar.gz:  12% 31.5M/261M [00:00<00:05, 40.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "TinyStories_all_data_zh_1M.tar.gz:  16% 41.9M/261M [00:00<00:04, 44.4MB/s]\u001b[A\u001b[A\n",
            "TinyStories_all_data_zh_2M.tar.gz:   8% 41.9M/510M [00:01<00:12, 37.7MB/s]\u001b[A\n",
            "TinyStories_all_data_zh_2M.tar.gz:  10% 52.4M/510M [00:01<00:11, 38.3MB/s]\u001b[A\n",
            "\n",
            "TinyStories_all_data_zh_1M.tar.gz:  20% 52.4M/261M [00:01<00:06, 31.1MB/s]\u001b[A\u001b[A\n",
            "TinyStories_all_data_zh_2M.tar.gz:  12% 62.9M/510M [00:01<00:11, 40.6MB/s]\u001b[A\n",
            "TinyStories_all_data_zh_2M.tar.gz:  14% 73.4M/510M [00:01<00:09, 44.0MB/s]\u001b[A\n",
            "\n",
            "TinyStories_all_data_zh_1M.tar.gz:  28% 73.4M/261M [00:01<00:04, 40.1MB/s]\u001b[A\u001b[A\n",
            "TinyStories_all_data_zh_2M.tar.gz:  16% 83.9M/510M [00:02<00:11, 36.7MB/s]\u001b[A\n",
            "\n",
            "TinyStories_all_data_zh_1M.tar.gz:  32% 83.9M/261M [00:02<00:05, 33.4MB/s]\u001b[A\u001b[A\n",
            "TinyStories_all_data_zh_2M.tar.gz:  21% 105M/510M [00:02<00:08, 46.9MB/s] \u001b[A\n",
            "\n",
            "TinyStories_all_data_zh_1M.tar.gz:  36% 94.4M/261M [00:02<00:04, 37.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "TinyStories_all_data_zh_1M.tar.gz:  40% 105M/261M [00:02<00:03, 42.8MB/s] \u001b[A\u001b[A\n",
            "TinyStories_all_data_zh_2M.tar.gz:  23% 115M/510M [00:02<00:09, 43.3MB/s]\u001b[A\n",
            "TinyStories_all_data_zh_2M.tar.gz:  27% 136M/510M [00:02<00:07, 53.3MB/s]\u001b[A\n",
            "\n",
            "TinyStories_all_data_zh_1M.tar.gz:  44% 115M/261M [00:03<00:04, 35.3MB/s]\u001b[A\u001b[A\n",
            "TinyStories_all_data_zh_2M.tar.gz:  29% 147M/510M [00:03<00:08, 44.3MB/s]\u001b[A\n",
            "TinyStories_all_data_zh_2M.tar.gz:  31% 157M/510M [00:03<00:06, 51.3MB/s]\u001b[A\n",
            "\n",
            "TinyStories_all_data_zh_1M.tar.gz:  52% 136M/261M [00:03<00:03, 39.9MB/s]\u001b[A\u001b[A\n",
            "TinyStories_all_data_zh_2M.tar.gz:  33% 168M/510M [00:03<00:06, 50.3MB/s]\u001b[A\n",
            "TinyStories_all_data_zh_2M.tar.gz:  35% 178M/510M [00:03<00:06, 53.6MB/s]\u001b[A\n",
            "\n",
            "TinyStories_all_data_zh_1M.tar.gz:  56% 147M/261M [00:03<00:03, 36.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "TinyStories_all_data_zh_1M.tar.gz:  64% 168M/261M [00:04<00:02, 45.5MB/s]\u001b[A\u001b[A\n",
            "TinyStories_all_data_zh_2M.tar.gz:  39% 199M/510M [00:04<00:05, 55.7MB/s]\u001b[A\n",
            "TinyStories_all_data_zh_2M.tar.gz:  41% 210M/510M [00:04<00:05, 54.0MB/s]\u001b[A\n",
            "\n",
            "TinyStories_all_data_zh_1M.tar.gz:  68% 178M/261M [00:04<00:01, 42.0MB/s]\u001b[A\u001b[A\n",
            "TinyStories_all_data_zh_2M.tar.gz:  45% 231M/510M [00:04<00:05, 54.3MB/s]\u001b[A\n",
            "\n",
            "TinyStories_all_data_zh_1M.tar.gz:  76% 199M/261M [00:04<00:01, 47.0MB/s]\u001b[A\u001b[A\n",
            "TinyStories_all_data_zh_2M.tar.gz:  47% 241M/510M [00:05<00:05, 49.7MB/s]\u001b[A\n",
            "\n",
            "TinyStories_all_data_zh_1M.tar.gz:  80% 210M/261M [00:05<00:01, 40.0MB/s]\u001b[A\u001b[A\n",
            "TinyStories_all_data_zh_2M.tar.gz:  51% 262M/510M [00:05<00:04, 55.4MB/s]\u001b[A\n",
            "TinyStories_all_data_zh_2M.tar.gz:  53% 273M/510M [00:05<00:04, 49.3MB/s]\u001b[A\n",
            "\n",
            "TinyStories_all_data_zh_1M.tar.gz:  89% 231M/261M [00:05<00:00, 37.8MB/s]\u001b[A\u001b[A\n",
            "TinyStories_all_data_zh_2M.tar.gz:  58% 294M/510M [00:06<00:04, 49.9MB/s]\u001b[A\n",
            "\n",
            "TinyStories_all_data_zh_1M.tar.gz:  93% 241M/261M [00:06<00:00, 36.6MB/s]\u001b[A\u001b[A\n",
            "TinyStories_all_data_zh_2M.tar.gz:  60% 304M/510M [00:06<00:03, 52.1MB/s]\u001b[A\n",
            "TinyStories_all_data_zh_2M.tar.gz:  64% 325M/510M [00:06<00:03, 47.3MB/s]\u001b[A\n",
            "\n",
            "TinyStories_all_data_zh_1M.tar.gz: 100% 261M/261M [00:06<00:00, 38.7MB/s]\n",
            "Fetching 4 files:  75% 3/4 [00:07<00:02,  2.83s/it]\n",
            "TinyStories_all_data_zh_2M.tar.gz:  68% 346M/510M [00:07<00:03, 53.3MB/s]\u001b[A\n",
            "TinyStories_all_data_zh_2M.tar.gz:  70% 357M/510M [00:07<00:02, 51.5MB/s]\u001b[A\n",
            "TinyStories_all_data_zh_2M.tar.gz:  74% 377M/510M [00:07<00:03, 44.1MB/s]\u001b[A\n",
            "TinyStories_all_data_zh_2M.tar.gz:  76% 388M/510M [00:08<00:03, 39.0MB/s]\u001b[A\n",
            "TinyStories_all_data_zh_2M.tar.gz:  80% 409M/510M [00:08<00:02, 48.5MB/s]\u001b[A\n",
            "TinyStories_all_data_zh_2M.tar.gz:  82% 419M/510M [00:09<00:02, 38.1MB/s]\u001b[A\n",
            "TinyStories_all_data_zh_2M.tar.gz:  86% 440M/510M [00:09<00:01, 37.0MB/s]\u001b[A\n",
            "TinyStories_all_data_zh_2M.tar.gz:  88% 451M/510M [00:09<00:01, 39.1MB/s]\u001b[A\n",
            "TinyStories_all_data_zh_2M.tar.gz:  93% 472M/510M [00:10<00:00, 45.0MB/s]\u001b[A\n",
            "TinyStories_all_data_zh_2M.tar.gz:  95% 482M/510M [00:10<00:00, 41.0MB/s]\u001b[A\n",
            "TinyStories_all_data_zh_2M.tar.gz:  99% 503M/510M [00:10<00:00, 50.5MB/s]\u001b[A\n",
            "TinyStories_all_data_zh_2M.tar.gz: 100% 510M/510M [00:10<00:00, 46.9MB/s]\n",
            "Fetching 4 files: 100% 4/4 [00:11<00:00,  2.98s/it]\n",
            "/content/data/52AI/TinyStoriesZh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -hgl /content/data/52AI/TinyStoriesZh\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vA3fnLIFIXeV",
        "outputId": "9915bccc-7358-4b6a-e56c-8aa239ee4bc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 735M\n",
            "-rw-r--r-- 1 root 2.9K Jan 25 01:49 README.md\n",
            "-rw-r--r-- 1 root 249M Jan 25 01:49 TinyStories_all_data_zh_1M.tar.gz\n",
            "-rw-r--r-- 1 root 487M Jan 25 01:49 TinyStories_all_data_zh_2M.tar.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/data/52AI/TinyStoriesZh && tar -zxvf TinyStories_all_data_zh_1M.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pfb6t9Y1OhyB",
        "outputId": "272f2f01-206a-4ccc-dc3e-bf1c2c10df7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data00.json\n",
            "data01.json\n",
            "data02.json\n",
            "data03.json\n",
            "data04.json\n",
            "data05.json\n",
            "data06.json\n",
            "data07.json\n",
            "data08.json\n",
            "data09.json\n",
            "data10.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/data/52AI/TinyStoriesZh && tar -zxvf TinyStories_all_data_zh_2M.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFQzUrhAO1oU",
        "outputId": "7ec46d42-303b-4c1f-ce1b-d52c65e21f8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data11.json\n",
            "data12.json\n",
            "data13.json\n",
            "data14.json\n",
            "data15.json\n",
            "data16.json\n",
            "data17.json\n",
            "data18.json\n",
            "data19.json\n",
            "data30.json\n",
            "data31.json\n",
            "data32.json\n",
            "data33.json\n",
            "data34.json\n",
            "data35.json\n",
            "data36.json\n",
            "data37.json\n",
            "data38.json\n",
            "data39.json\n",
            "data46.json\n",
            "data47.json\n",
            "data48.json\n",
            "data49.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -f /content/data/52AI/TinyStoriesZh/*.gz\n",
        "!ls -hgl /content/data/52AI/TinyStoriesZh\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ng2EhU7lPA5i",
        "outputId": "798a3894-5d20-47e3-b213-3a1d6ea6817d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 2.2G\n",
            "-rw-r--r-- 1 staff  71M Aug 12 15:31 data00.json\n",
            "-rw-r--r-- 1 staff  70M Aug 13 01:18 data01.json\n",
            "-rw-r--r-- 1 staff  70M Aug 12 15:32 data02.json\n",
            "-rw-r--r-- 1 staff  71M Aug 12 15:33 data03.json\n",
            "-rw-r--r-- 1 staff  71M Aug 12 15:34 data04.json\n",
            "-rw-r--r-- 1 staff  70M Aug 12 15:35 data05.json\n",
            "-rw-r--r-- 1 staff  73M Aug 12 15:38 data06.json\n",
            "-rw-r--r-- 1 staff  70M Aug 12 15:39 data07.json\n",
            "-rw-r--r-- 1 staff  70M Aug 12 15:40 data08.json\n",
            "-rw-r--r-- 1 staff  70M Aug 12 15:41 data09.json\n",
            "-rw-r--r-- 1 staff  41M Aug 12 15:41 data10.json\n",
            "-rw-rw-r-- 1  1004  69M Aug 19 08:07 data11.json\n",
            "-rw-rw-r-- 1  1004  70M Aug 19 08:07 data12.json\n",
            "-rw-rw-r-- 1  1004  70M Aug 19 08:07 data13.json\n",
            "-rw-rw-r-- 1  1004  61M Aug 19 08:07 data14.json\n",
            "-rw-rw-r-- 1  1004  43M Aug 19 08:07 data15.json\n",
            "-rw-rw-r-- 1  1004  70M Aug 19 08:07 data16.json\n",
            "-rw-rw-r-- 1  1004  70M Aug 19 08:07 data17.json\n",
            "-rw-rw-r-- 1  1004  70M Aug 19 08:07 data18.json\n",
            "-rw-rw-r-- 1  1004  47M Aug 19 08:07 data19.json\n",
            "-rw-rw-r-- 1  1004  73M Aug 19 08:07 data30.json\n",
            "-rw-rw-r-- 1  1004  73M Aug 19 08:07 data31.json\n",
            "-rw-rw-r-- 1  1004  34M Aug 19 08:07 data32.json\n",
            "-rw-rw-r-- 1  1004  73M Aug 19 08:07 data33.json\n",
            "-rw-rw-r-- 1  1004  73M Aug 19 08:07 data34.json\n",
            "-rw-rw-r-- 1  1004  73M Aug 19 08:07 data35.json\n",
            "-rw-rw-r-- 1  1004  73M Aug 19 08:07 data36.json\n",
            "-rw-rw-r-- 1  1004  73M Aug 19 08:07 data37.json\n",
            "-rw-rw-r-- 1  1004  44M Aug 19 08:07 data38.json\n",
            "-rw-rw-r-- 1  1004  45M Aug 19 08:07 data39.json\n",
            "-rw-rw-r-- 1  1004  71M Aug 19 08:07 data46.json\n",
            "-rw-rw-r-- 1  1004  71M Aug 19 08:07 data47.json\n",
            "-rw-rw-r-- 1  1004  71M Aug 19 08:07 data48.json\n",
            "-rw-rw-r-- 1  1004  48M Aug 19 08:07 data49.json\n",
            "-rw-r--r-- 1 root  2.9K Jan 25 01:49 README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob,json,os\n",
        "from tqdm import tqdm\n",
        "import sentencepiece as spm\n",
        "\n",
        "def train_vocab(data_dir, vocab_size):\n",
        "    \"\"\"\n",
        "    Trains a custom sentencepiece tokenizer on the TinyStories dataset.\n",
        "    The custom tokenizer files will be saved in data_dir/tok{N} directories,\n",
        "    where N is the vocab size. This is also where the pretok .bin files will go.\n",
        "    \"\"\"\n",
        "    assert vocab_size > 0, \"Vocab size must be positive\"\n",
        "\n",
        "    # output file prefix path for sentencepiece\n",
        "    prefix = os.path.join(data_dir, f\"tok{vocab_size}\")\n",
        "\n",
        "    # how many shards we'll use for vocab training, kept low for efficiency\n",
        "    num_shards = 10\n",
        "\n",
        "    # 1) export a large chunk of text as a single text file tiny.txt\n",
        "    tiny_file = os.path.join(data_dir, \"tiny.txt\")\n",
        "    shard_filenames = sorted(glob.glob(os.path.join(data_dir, \"*.json\")))\n",
        "\n",
        "    print(f\"Writing temporary file {tiny_file} with {num_shards} shards...\")\n",
        "    with open(tiny_file, \"w\", encoding=\"utf-8\") as of:\n",
        "        for shard in tqdm(shard_filenames[:num_shards]):\n",
        "            with open(shard, \"r\") as f:\n",
        "                data = json.load(f)\n",
        "            for example in data:\n",
        "                text = example[\"story\"]\n",
        "                text = text.strip()\n",
        "                of.write(text + \"\\n\")\n",
        "    print(f\"Size is: {os.path.getsize(tiny_file) / 1024 / 1024:.2f} MB\")\n",
        "\n",
        "    # 2) train the sentencepiece model\n",
        "    print(\"Will now train the vocab...\")\n",
        "    # https://github.com/google/sentencepiece/blob/master/doc/options.md\n",
        "    spm.SentencePieceTrainer.train(input=tiny_file,\n",
        "                                   model_prefix=prefix,\n",
        "                                   model_type=\"bpe\",\n",
        "                                   vocab_size=vocab_size,\n",
        "                                   self_test_sample_size=0,\n",
        "                                   input_format=\"text\",\n",
        "                                   character_coverage=1.0,\n",
        "                                   num_threads=os.cpu_count(),\n",
        "                                   split_digits=True,\n",
        "                                   allow_whitespace_only_pieces=True,\n",
        "                                   byte_fallback=True,\n",
        "                                   unk_surface=r\" \\342\\201\\207 \",\n",
        "                                   normalization_rule_name=\"identity\")\n",
        "\n",
        "    # 3) optional cleanup, ask the user if they'd like to delete tiny.txt\n",
        "    dec = input(f\"Delete the temporary file {tiny_file}? [y/N] \")\n",
        "    if dec.lower() == \"y\":\n",
        "        os.remove(tiny_file)\n",
        "        print(f\"Deleted {tiny_file}\")\n",
        "\n",
        "    print(f\"Trained tokenizer is in {prefix}.model\")\n",
        "    print(\"Done.\")"
      ],
      "metadata": {
        "id": "dudjmRQQaIvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 训练tokenizer词表\n",
        "train_vocab(\"/content/data/52AI/TinyStoriesZh\",8192)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZRSp0U-PPmA",
        "outputId": "8bdc86ef-87b0-4be7-b675-13533e506332"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing temporary file /content/data/52AI/TinyStoriesZh/tiny.txt with 10 shards...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:05<00:00,  1.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size is: 685.92 MB\n",
            "Will now train the vocab...\n",
            "Delete the temporary file /content/data/52AI/TinyStoriesZh/tiny.txt? [y/N] n\n",
            "Trained tokenizer is in /content/data/52AI/TinyStoriesZh/tok8192.model\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import struct\n",
        "import argparse\n",
        "from typing import List\n",
        "\n",
        "from sentencepiece import SentencePieceProcessor\n",
        "\n",
        "\n",
        "class Tokenizer:\n",
        "    def __init__(self, model_path):\n",
        "        assert os.path.isfile(model_path), model_path\n",
        "        self.sp_model = SentencePieceProcessor(model_file=model_path)\n",
        "        self.model_path = model_path\n",
        "\n",
        "        # BOS / EOS token IDs\n",
        "        self.n_words: int = self.sp_model.vocab_size()\n",
        "        self.bos_id: int = self.sp_model.bos_id()\n",
        "        self.eos_id: int = self.sp_model.eos_id()\n",
        "        self.pad_id: int = self.sp_model.pad_id()\n",
        "        #print(f\"#words: {self.n_words} - BOS ID: {self.bos_id} - EOS ID: {self.eos_id}\")\n",
        "        assert self.sp_model.vocab_size() == self.sp_model.get_piece_size()\n",
        "\n",
        "    def encode(self, s: str, bos: bool, eos: bool) -> List[int]:\n",
        "        assert type(s) is str\n",
        "        t = self.sp_model.encode(s)\n",
        "        if bos:\n",
        "            t = [self.bos_id] + t\n",
        "        if eos:\n",
        "            t = t + [self.eos_id]\n",
        "        return t\n",
        "\n",
        "    def decode(self, t: List[int]) -> str:\n",
        "        return self.sp_model.decode(t)\n",
        "\n",
        "    def export(self):\n",
        "\n",
        "        # get all the tokens (postprocessed) and their scores as floats\n",
        "        tokens, scores = [], []\n",
        "        for i in range(self.n_words):\n",
        "\n",
        "            # decode the token and light postprocessing\n",
        "            t = self.sp_model.id_to_piece(i)\n",
        "            s = self.sp_model.get_score(i)\n",
        "            if i == self.bos_id:\n",
        "                t = '\\n<s>\\n'\n",
        "            elif i == self.eos_id:\n",
        "                t = '\\n</s>\\n'\n",
        "            t = t.replace('▁', ' ') # sentencepiece uses this character as whitespace\n",
        "            b = t.encode('utf-8') # bytes of this token, utf-8 encoded\n",
        "\n",
        "            tokens.append(b)\n",
        "            scores.append(s)\n",
        "\n",
        "        # record the max token length\n",
        "        max_token_length = max(len(t) for t in tokens)\n",
        "\n",
        "        # write to a binary file\n",
        "        # the tokenizer.bin file is the same as .model file, but .bin\n",
        "        tokenizer_bin = self.model_path.replace('.model', '.bin')\n",
        "        with open(tokenizer_bin, 'wb') as f:\n",
        "            f.write(struct.pack(\"I\", max_token_length))\n",
        "            for bytes, score in zip(tokens, scores):\n",
        "                f.write(struct.pack(\"fI\", score, len(bytes)))\n",
        "                f.write(bytes)"
      ],
      "metadata": {
        "id": "hozcjPiem6ZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 对使用该分词器训练的模型，在进行推理时也需要使用对应分词器；且格式必须.bin，导出分词器用于推理\n",
        "t = Tokenizer(\"/content/data/52AI/TinyStoriesZh/tok8192.model\")\n",
        "t.export()"
      ],
      "metadata": {
        "id": "hnAmSzYqpSNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 对TinyStoriesZh数据集通过训练好的分词器进行分词预处理(tokenid uint16)；\n",
        "# 通过进程池并发异步读取每个分割的文件data*.json进行处理，然后归并，生成pretok.bin文件的位置。\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "from functools import partial\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def process_shard(args, data_dir, vocab_size):\n",
        "    shard_id, shard = args\n",
        "    tokenizer_model = os.path.join(data_dir, f\"tok{vocab_size}.model\")\n",
        "    enc = Tokenizer(tokenizer_model)\n",
        "    with open(shard, \"r\") as f:\n",
        "        data = json.load(f)\n",
        "    all_tokens = []\n",
        "    for example in tqdm(data, position=shard_id):\n",
        "        text = example[\"story\"]\n",
        "        text = text.strip()  # get rid of leading/trailing whitespace\n",
        "        tokens = enc.encode(text, bos=True, eos=False)  # encode the text, use BOS\n",
        "        all_tokens.extend(tokens)\n",
        "    # convert to uint16 nparray\n",
        "    all_tokens = np.array(all_tokens, dtype=np.uint16)\n",
        "    # calculate the output filename\n",
        "    if vocab_size == 0:\n",
        "        # if we're using Llama 2, just save the tokenized file in the same dir\n",
        "        tokenized_filename = shard.replace(\".json\", \".bin\")\n",
        "    else:\n",
        "        # save .bin files into a new tok{N} directory\n",
        "        bin_dir = os.path.join(data_dir, f\"tok{vocab_size}\")\n",
        "        shard_basename = os.path.basename(shard)\n",
        "        bin_basename = shard_basename.replace(\".json\", \".bin\")\n",
        "        tokenized_filename = os.path.join(bin_dir, bin_basename)\n",
        "    # write the bytes\n",
        "    with open(tokenized_filename, \"wb\") as f:\n",
        "        f.write(all_tokens.tobytes())\n",
        "    # calculate the average sequence length (they are separated by BOS=1)\n",
        "    avg_seq_len = all_tokens.size / ((all_tokens == 1).sum())\n",
        "    print(f\"Saved {tokenized_filename}, average seqlen: {avg_seq_len:.2f}\")\n",
        "\n",
        "\n",
        "def pretokenize(data_dir, vocab_size):\n",
        "    # iterate the shards and tokenize all of them one by one\n",
        "    shard_filenames = sorted(glob.glob(os.path.join(data_dir, \"*.json\")))\n",
        "    if vocab_size > 0:\n",
        "        # .bin files will be saved into tok{N} directory, create it once here\n",
        "        bin_dir = os.path.join(data_dir, f\"tok{vocab_size}\")\n",
        "        os.makedirs(bin_dir, exist_ok=True)\n",
        "\n",
        "    # process all the shards in a process pool\n",
        "    fun = partial(process_shard, data_dir=data_dir, vocab_size=vocab_size)\n",
        "    with ProcessPoolExecutor() as executor:\n",
        "        executor.map(fun, enumerate(shard_filenames))\n",
        "    print(\"Done.\")"
      ],
      "metadata": {
        "id": "Q09N4Py_lYll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretokenize(\"/content/data/52AI/TinyStoriesZh\",8192)"
      ],
      "metadata": {
        "id": "snaH3lPBqAi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -hgl /content/data/52AI/TinyStoriesZh\n",
        "!ls -hgl /content/data/52AI/TinyStoriesZh/tok8192"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQ9dqmogp20L",
        "outputId": "c0d433ef-f34d-4a13-8ffc-ec6e94e36c30"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 2.9G\n",
            "-rw-r--r-- 1 staff  71M Aug 12 15:31 data00.json\n",
            "-rw-r--r-- 1 staff  70M Aug 13 01:18 data01.json\n",
            "-rw-r--r-- 1 staff  70M Aug 12 15:32 data02.json\n",
            "-rw-r--r-- 1 staff  71M Aug 12 15:33 data03.json\n",
            "-rw-r--r-- 1 staff  71M Aug 12 15:34 data04.json\n",
            "-rw-r--r-- 1 staff  70M Aug 12 15:35 data05.json\n",
            "-rw-r--r-- 1 staff  73M Aug 12 15:38 data06.json\n",
            "-rw-r--r-- 1 staff  70M Aug 12 15:39 data07.json\n",
            "-rw-r--r-- 1 staff  70M Aug 12 15:40 data08.json\n",
            "-rw-r--r-- 1 staff  70M Aug 12 15:41 data09.json\n",
            "-rw-r--r-- 1 staff  41M Aug 12 15:41 data10.json\n",
            "-rw-rw-r-- 1  1004  69M Aug 19 08:07 data11.json\n",
            "-rw-rw-r-- 1  1004  70M Aug 19 08:07 data12.json\n",
            "-rw-rw-r-- 1  1004  70M Aug 19 08:07 data13.json\n",
            "-rw-rw-r-- 1  1004  61M Aug 19 08:07 data14.json\n",
            "-rw-rw-r-- 1  1004  43M Aug 19 08:07 data15.json\n",
            "-rw-rw-r-- 1  1004  70M Aug 19 08:07 data16.json\n",
            "-rw-rw-r-- 1  1004  70M Aug 19 08:07 data17.json\n",
            "-rw-rw-r-- 1  1004  70M Aug 19 08:07 data18.json\n",
            "-rw-rw-r-- 1  1004  47M Aug 19 08:07 data19.json\n",
            "-rw-rw-r-- 1  1004  73M Aug 19 08:07 data30.json\n",
            "-rw-rw-r-- 1  1004  73M Aug 19 08:07 data31.json\n",
            "-rw-rw-r-- 1  1004  34M Aug 19 08:07 data32.json\n",
            "-rw-rw-r-- 1  1004  73M Aug 19 08:07 data33.json\n",
            "-rw-rw-r-- 1  1004  73M Aug 19 08:07 data34.json\n",
            "-rw-rw-r-- 1  1004  73M Aug 19 08:07 data35.json\n",
            "-rw-rw-r-- 1  1004  73M Aug 19 08:07 data36.json\n",
            "-rw-rw-r-- 1  1004  73M Aug 19 08:07 data37.json\n",
            "-rw-rw-r-- 1  1004  44M Aug 19 08:07 data38.json\n",
            "-rw-rw-r-- 1  1004  45M Aug 19 08:07 data39.json\n",
            "-rw-rw-r-- 1  1004  71M Aug 19 08:07 data46.json\n",
            "-rw-rw-r-- 1  1004  71M Aug 19 08:07 data47.json\n",
            "-rw-rw-r-- 1  1004  71M Aug 19 08:07 data48.json\n",
            "-rw-rw-r-- 1  1004  48M Aug 19 08:07 data49.json\n",
            "-rw-r--r-- 1 root  2.9K Jan 25 01:49 README.md\n",
            "-rw-r--r-- 1 root  686M Jan 25 02:26 tiny.txt\n",
            "drwxr-xr-x 2 root  4.0K Jan 25 03:41 tok8192\n",
            "-rw-r--r-- 1 root  111K Jan 25 03:25 tok8192.bin\n",
            "-rw-r--r-- 1 root  120K Jan 25 02:54 tok8192.model\n",
            "-rw-r--r-- 1 root  101K Jan 25 02:54 tok8192.vocab\n",
            "total 790M\n",
            "-rw-r--r-- 1 root 26M Jan 25 03:36 data00.bin\n",
            "-rw-r--r-- 1 root 25M Jan 25 03:36 data01.bin\n",
            "-rw-r--r-- 1 root 26M Jan 25 03:36 data02.bin\n",
            "-rw-r--r-- 1 root 26M Jan 25 03:36 data03.bin\n",
            "-rw-r--r-- 1 root 26M Jan 25 03:36 data04.bin\n",
            "-rw-r--r-- 1 root 26M Jan 25 03:36 data05.bin\n",
            "-rw-r--r-- 1 root 27M Jan 25 03:36 data06.bin\n",
            "-rw-r--r-- 1 root 26M Jan 25 03:36 data07.bin\n",
            "-rw-r--r-- 1 root 26M Jan 25 03:38 data08.bin\n",
            "-rw-r--r-- 1 root 26M Jan 25 03:38 data09.bin\n",
            "-rw-r--r-- 1 root 15M Jan 25 03:37 data10.bin\n",
            "-rw-r--r-- 1 root 25M Jan 25 03:38 data11.bin\n",
            "-rw-r--r-- 1 root 26M Jan 25 03:38 data12.bin\n",
            "-rw-r--r-- 1 root 26M Jan 25 03:38 data13.bin\n",
            "-rw-r--r-- 1 root 22M Jan 25 03:38 data14.bin\n",
            "-rw-r--r-- 1 root 16M Jan 25 03:37 data15.bin\n",
            "-rw-r--r-- 1 root 26M Jan 25 03:39 data16.bin\n",
            "-rw-r--r-- 1 root 26M Jan 25 03:39 data17.bin\n",
            "-rw-r--r-- 1 root 26M Jan 25 03:40 data18.bin\n",
            "-rw-r--r-- 1 root 17M Jan 25 03:39 data19.bin\n",
            "-rw-r--r-- 1 root 26M Jan 25 03:39 data30.bin\n",
            "-rw-r--r-- 1 root 27M Jan 25 03:39 data31.bin\n",
            "-rw-r--r-- 1 root 13M Jan 25 03:39 data32.bin\n",
            "-rw-r--r-- 1 root 26M Jan 25 03:39 data33.bin\n",
            "-rw-r--r-- 1 root 26M Jan 25 03:40 data34.bin\n",
            "-rw-r--r-- 1 root 26M Jan 25 03:40 data35.bin\n",
            "-rw-r--r-- 1 root 26M Jan 25 03:40 data36.bin\n",
            "-rw-r--r-- 1 root 26M Jan 25 03:40 data37.bin\n",
            "-rw-r--r-- 1 root 16M Jan 25 03:40 data38.bin\n",
            "-rw-r--r-- 1 root 16M Jan 25 03:40 data39.bin\n",
            "-rw-r--r-- 1 root 26M Jan 25 03:40 data46.bin\n",
            "-rw-r--r-- 1 root 26M Jan 25 03:41 data47.bin\n",
            "-rw-r--r-- 1 root 26M Jan 25 03:41 data48.bin\n",
            "-rw-r--r-- 1 root 18M Jan 25 03:40 data49.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -n100 /content/data/52AI/TinyStoriesZh/tiny.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qL6ZRi3iZiA",
        "outputId": "ce309240-1d20-4626-8987-794eb311f862"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "从前，有一只胖乎乎的小兔子，名叫本尼。本尼很饿，想吃一些胡萝卜。然而，他没有胡萝卜。突然，他的朋友，一只名叫比利的善良小鸟过来，给了他一些胡萝卜。\n",
            "本尼非常高兴和感激，他想给比利一些东西作为回报。他记得自己口袋里有一枚闪闪发亮的铜币。本尼将铜币送给比利作为答谢礼物。\n",
            "比利也很高兴，并感谢本尼送的礼物。从那天起，本尼和比利成了最好的朋友，总是互相分享食物和玩具。\n",
            "从前，有一个小女孩，名叫莉莉。她喜欢每周和妈妈一起去图书馆。图书馆是一座很大的建筑，里面有很多书。莉莉喜欢读有关公主和动物的书籍。\n",
            "有一天，莉莉和妈妈去图书馆，但有些不一样。那里没有人！莉莉感到孤独和悲伤。她向妈妈提到，她想念那些经常和她一起去图书馆的朋友们。\n",
            "突然，他们听到图书馆后面传来一声巨响。他们前去查看，发现一群友善的动物正在开派对！有兔子、松鼠，甚至还有一只友善的狐狸。他们一直躲在图书馆里。莉莉很高兴有新朋友一起读书。从那天起，莉莉和她的新朋友们每周都在图书馆度过了愉快的时光。\n",
            "从前，有一只大狮子。他喜欢大声吼叫。有一天，他遇到了一只小老鼠。老鼠被狮子的大吼声吓坏了。但狮子想了想，说道：“小老鼠，别害怕，我不会伤害你的。”\n",
            "老鼠感觉好多了，说：“谢谢你，狮子先生。我们可以成为朋友吗？”狮子微笑着说：“当然，我们可以成为朋友。”\n",
            "但有一天，狮子非常饿了。他看到小老鼠，心想：“也许我可以吃掉我的朋友。”于是，他追赶老鼠，抓住了它。老鼠叫道：“狮子先生，你为什么这么做？我以为我们是朋友呢！”\n",
            "狮子心里很难受，说：“对不起，小老鼠，我饿了，犯了一个错误。”但老鼠已经不见了，飞快地逃到了安全的地方。狮子很伤心，意识到做朋友比挨饿更重要。\n",
            "莉莉和本是朋友。他们喜欢在公园里玩。有一天，他们看到一棵有秋千的大树。莉莉想尝试秋千。她跑到树旁，爬上秋千。\n",
            "“推我吧，本！”她说。本轻轻地推了她一下。莉莉感觉很幸福。她荡得越来越高。她又笑又叫。\n",
            "本看着莉莉。他觉得她很可爱。他也想摇摆。他等着莉莉停下来。但莉莉并没有停下来。她摆动得越来越快。她玩得太开心了。\n",
            "“我也可以荡秋千吗，莉莉？”本问。莉莉没有听见他的话。她正忙着荡秋千。本感到难过。他走开了。\n",
            "莉莉荡得太高，以至于她失去了抓力。她从秋千上摔下来。她降落在地上。她的脚受伤了。她哭了。\n",
            "“呜呜呜！”她说。她寻找本。她想要他帮助她。但本不在那儿。他已经去了。\n",
            "莉莉感到抱歉。她希望自己能和本一起荡秋千。她希望他能在那里拥抱她。她一瘸一拐地走向树。她看到树枝上挂着什么东西。这是本的帽子。他留给她了。\n",
            "莉莉微笑着。她认为本很好。她戴上他的帽子。她希望他能回来。她想说对不起。她想再次成为朋友。\n",
            "有一天，一个名叫蒂姆的男孩去散步。他看到街上有一个大垃圾箱。垃圾箱是空的。蒂姆觉得很奇怪，但他还是继续走。他看到垃圾箱附近有一个球，就把它捡了起来。\n",
            "那天晚些时候，蒂姆看到一些孩子在玩耍。他们试图将球射入球门。但他们没有球。蒂姆记得他在空垃圾箱附近发现的球。他认为这可以帮助孩子们玩游戏。\n",
            "蒂姆回到空垃圾箱并拿到了球。他把它带给了孩子们。他们太高兴了！他们让蒂姆和他们一起玩。他们都轮流尝试将球射入球门。蒂姆很高兴他在空垃圾箱附近找到了球。这对每个人来说都是有趣的一天。\n",
            "从前，有一个小女孩，名叫莉莉。她有一只她非常喜欢的泰迪熊。有一天，她在公园玩耍时把它弄丢了。她到处找，却没有找到。没有泰迪熊，她感到悲伤和害怕。\n",
            "莉莉的妈妈看到她哭了，就问她怎么了。莉莉告诉她她丢了泰迪熊。妈妈抱住她说：“别担心，我们一起去找。”他们回到公园，四处寻找。过了一会儿，他们在一棵树下发现了泰迪熊。莉莉真是太高兴了！\n",
            "她抱着她的泰迪熊，感觉又舒服了。她说：“我希望我再也不会失去你了，泰迪熊。”妈妈微笑着说：“我也是，莉莉。你和泰迪熊是最好的朋友。”他们都高兴又满足地回家了。结束。\n",
            "从前，有一个小男孩，名叫蒂米。蒂米喜欢梦想像小鸟一样在天空中飞翔。他会闭上眼睛，想象自己在云端翱翔，感受风吹过头发。\n",
            "有一天，蒂米的妈妈给了他一只蓝色的风筝。蒂米太高兴了！他跑到外面试图放风筝，但飞不高。提米想提高他的放风筝技巧，所以他向爸爸寻求帮助。\n",
            "蒂米和他的爸爸一起练习放风筝。他们跑呀跑，直到风筝飞得越来越高。蒂米为自己感到非常自豪！他知道，通过练习，他可以取得更大的进步，让风筝飞得和他梦想中的鸟一样高。\n",
            "从前，有一个小女孩，名叫莉莉。她喜欢随着音乐的节奏跳舞和唱歌。有一天，她和朋友们去公园玩。玩耍时，她看到一个男人正在努力修复损坏的秋千。\n",
            "莉莉走到那个男人面前，说道：“嗨，你在做什么？”\n",
            "“我正在努力修复这个秋千，”该男子回答道。\n",
            "莉莉看了男人干活了一会，说道：“你工作很辛苦，需要我帮忙吗？”\n",
            "那人微笑着说：“是的，你拿着这把螺丝刀可以帮我。”\n",
            "莉莉拿着螺丝刀，帮男人修好秋千。当他们一起工作时，他们随着公园里播放的音乐的节奏跳舞。结束后，男子感谢莉莉的帮助，说道：“你真是个好帮手。”\n",
            "莉莉微笑着说：“谢谢你。我喜欢帮忙，随着音乐的节奏跳舞。”\n",
            "从前，有一只蓝色的小鸟住在一棵树上。有一天，一个小女孩来到树前说道：“你好，小鸟！我可以成为你的朋友吗？”小鸟回答说：“是的，你可以成为我的朋友！”\n",
            "小女孩高兴极了，赶紧跑到家里去给小鸟拿点面包。当她回来时，她看到了一只大动物。那是一只猫！猫看到了小鸟，赶紧冲过去捉住它。小女孩喊道：“不，不，别抓我的朋友！”但猫跑得太快，抓住了小鸟。\n",
            "小女孩非常伤心，哭了很多。她回到家，把发生的事情告诉了妈妈。她妈妈拥抱了她，说：“亲爱的，别担心。这只鸟现在在一个更好的地方了。”小女孩感觉好一些了，但她仍然想念她的朋友。\n",
            "从前，在一个小村庄里，有一个小男孩，名叫蒂姆。蒂姆有一个他喜欢玩的哨子。有一天，他去公园玩哨子。在公园里，他看到一只大狗，眼神凶狠。蒂姆很害怕，但他想玩他的哨子，所以他留下来了。\n",
            "大狗靠近蒂姆并开始表演有趣的舞蹈。蒂姆觉得这很有趣，开始大笑。他吹响口哨，让狗跳得更多。狗喜欢哨声，更加跳舞了。蒂姆不再害怕那只大狗了。\n",
            "大狗和蒂姆成了好朋友。他们每天都在公园里玩。当蒂姆吹口哨时，大狗总是会跳舞。村民们都会来看他们一起玩耍、一起欢笑。蒂姆和大狗很幸福，从此过上了幸福的生活。\n",
            "有一天，天开始下雨了。一个名叫蒂姆的小男孩和他的狗斑点在他们的房子里。他们想出去玩，但必须等雨停。当他们等待的时候，他们玩着蒂姆在盒子里找到的一根长绳子。他们把绳子拉紧，用它玩拔河游戏。\n",
            "雨停了，太阳出来了。蒂姆和斯波出去玩。他们随身带着绳子。蒂姆将绳子的一端绑在一棵树上，另一端绑在斯波的项圈上。关系很紧，所以 Spot 不会逃跑。他们在院子里玩耍，跑着跳着，玩得很开心。\n",
            "很快，就到了吃晚饭的时间。蒂姆的妈妈叫他们进去。蒂姆解开了树上和斯波衣领上的绳子。他们进去吃了一顿大餐。晚餐后，蒂姆和斯波很累。他们上床睡觉，很高兴他们度过了愉快的一天，尽管下着雨。\n",
            "从前，有一只小甲虫，名叫贝特西。贝特西非常难过，因为她失去了她最喜欢吃的叶子。她到处找，但没有找到。\n",
            "然后，贝特西的朋友，一只名叫露西的友好瓢虫，走过来对她说：“贝特西，别难过。让我们放松一下，一起寻找新的叶子。”\n",
            "贝特西感觉好多了，他们继续冒险去寻找新的叶子。他们到处寻找，直到找到适合贝特西吃的完美叶子。贝特西非常高兴也很感激有露西成为她的朋友。他们都很放松，一起度过了余下的一天。\n",
            "从前，有一只小鸭子，名叫黛西。黛西喜欢和她的朋友们一起在池塘里游泳。有一天，黛西看到一只顽皮的青蛙正在向大家泼水。\n",
            "黛西对青蛙说：“你为什么这么调皮？你把大家都弄湿了！”\n",
            "青蛙回答说：“对不起，我只是想玩得开心。”\n",
            "黛西说：“玩得开心是可以的，但如果你调皮的话就不行了。我们一起游泳，玩得开心，不要互相溅水。”\n",
            "于是，青蛙道歉了，从此他们就一起快乐地游泳了。\n",
            "从前，有一个小女孩，名叫莉莉。她有一件她喜欢穿的粉色裙子。有一天，莉莉一家决定去海滩度假。他们都上了车，莉莉坐在她舒适的汽车座椅上。\n",
            "当他们开车时，莉莉向窗外望去，看到了许多树木和房屋。她问妈妈：“我们到了吗？”但她妈妈说：“还不行，我们还有很长的路要走。”\n",
            "终于，他们到达了海滩，莉莉高兴极了！她跑到沙滩上玩她的粉红色水桶和铲子。她还找了一个舒适的地方坐下来看海浪。莉莉和家人去海滩旅行玩得很开心。\n",
            "有一天，一个名叫苏的女孩在地板上发现了一本肮脏的旧书。这本书充满了咒语。苏想帮助她悲伤的朋友汤姆。她以为咒语可以让他快乐。\n",
            "苏试图解读咒语，但很难。她问汤姆：“你能帮我读一下这个吗？”汤姆看着那本脏书说：“我可以试试。”他们一起大声读出咒语。\n",
            "当他们完成咒语时，房间开始摇晃。一个又大又可怕的怪物出现了。怪物不高兴了。它把苏和汤姆赶出了家门。他们非常害怕和悲伤。咒语对他们根本没有帮助。\n",
            "从前，有一座小房子。房子有屋顶。有一天，一只不知名的大动物来到了家里。这种动物很大，脖子很长。\n",
            "这只未知的大动物想要触碰屋顶。它把长长的脖子向上、向上、向上伸长。它用鼻子碰了碰屋顶。屋顶发出奇怪的声音。那只不知名的大动物害怕了，逃跑了。\n",
            "但就在这时，那头不知名的大动物又回来了。它不是一种可怕的动物，而是一种友好的动物。这只不知名的大动物想玩。房子和这只不知名的大动物成了最好的朋友。他们每天都在一起玩耍、欢笑。\n",
            "从前有一个脾气暴躁的男孩。他什么都不喜欢，也从不笑。有一天，他决定去寻找他喜欢的东西。他设法找到一本小说并拿起它。他惊讶地发现自己竟然喜欢它！\n",
            "他每天都看小说，很快，他就开始微笑。他设法与其他男孩和女孩交上朋友，甚至从小说中学到新东西。\n",
            "脾气暴躁的男孩很高兴，他继续看更多的小说。他从未停止脾气暴躁，但他设法以不同的方式表达自己的情绪。他是一个比以前快乐多了的孩子！\n",
            "从前，有一只小狗，名叫波波。他喜欢玩他的球。有一天，他在公园里看到一只大鞋子。波波也想玩这只鞋。\n",
            "波波试图把脚放进鞋里，但鞋太大了。他请求他的朋友卡特帮助他。猫说：“波波，这鞋不适合你。”但Bobo坚持说：“我也想玩这只鞋。”\n",
            "于是，猫和波波把鞋子推啊推，直到波波的脚踩进去为止。他们整天都在玩这双鞋，玩得很开心。最后，当他的朋友帮助他时，波波发现他可以玩任何东西，甚至是大鞋子。\n",
            "莎拉和汤姆是朋友。他们喜欢玩洋娃娃和汽车。昨天，他们和妈妈一起去了公园。他们看到了许多鸟儿、鲜花和秋千。\n",
            "“看，莎拉，一只鸭子！”汤姆说。他指着池塘边一只大白鸭子。 “我们可以喂它吗？”\n",
            "莎拉点点头。她的包里有一些面包。她拿出一块，把它分成小块。她给了汤姆一些。他们走到鸭子身边，把面包扔在地上。\n",
            "鸭子很高兴。它吃了面包，嘎嘎叫起来。莎拉和汤姆笑了。他们扔了更多的面包。但就在这时，他们听到了一声响亮的喇叭声。他们回头一看，看见了一只大鹅。鹅很生气。它也想要面包。\n",
            "鹅跑向莎拉和汤姆。它张开大嘴，向他们咬去。莎拉和汤姆很害怕。他们扔下面包就跑了。鹅追赶他们。它鸣叫着，拍打着翅膀。\n",
            "“救命啊，妈妈！”莎拉和汤姆哭了。他们的妈妈听到了他们的声音并赶来营救。他们抱起莎拉和汤姆，把他们从鹅身边带走。鹅停下来吃面包。\n",
            "“你们还好吗，亲爱的？”萨拉的妈妈问道。\n",
            "“是的，妈妈，我们很好，”萨拉说。 “但是那只鹅很卑鄙。它想要我们的面包。”\n",
            "汤姆点点头。 “我们只是想喂鸭子。鸭子很好吃。”\n",
            "萨拉的妈妈拥抱了他们。 “我知道，亲爱的。但是有时候，动物会很贪婪，或者很害怕。你喂它们的时候一定要小心。下次，我们可以多带一些面包，远远地喂它们。”\n",
            "莎拉和汤姆同意了。他们吸取了教训。他们仍然喜欢鸭子，但不喜欢鹅。他们去荡秋千，忘记了鹅。鹅吃完了所有的面包，也很高兴。\n",
            "从前，有一个小男孩，名叫蒂姆。蒂姆喜欢在外面玩球。有一天，蒂姆正在他的院子里玩球。他很高兴，玩得很开心。但蒂姆有点粗心，没有看球踢的地方。\n",
            "蒂姆把球踢得很用力。球飞到了高高的空中。蒂姆抬起头，开始思考球会落在哪里。他希望它不会走得太远。球越飞越高。它就像一只小鸟在天空中飞翔。\n",
            "球落了下来，落在了他家的屋顶上。蒂姆很伤心，因为他无法到达那里。他试图接住球，但球卡在了屋顶的球场上。蒂姆的妈妈看到了他，并告诉他下次要小心。但现在，蒂姆的球不见了，他不能再玩了。结束。\n",
            "从前，有一个小女孩，名叫简。简喜欢和她的朋友们一起在公园里跑步和玩耍。有一天，简在地上发现了一根线。这是一条非常漂亮的线，有很多颜色。\n",
            "简把线带回家给她妈妈看。她妈妈说：“哇，这真是一条丰富的线！太漂亮了！”简很高兴。她想用线做点什么。\n",
            "简和她妈妈用线做了一个手镯。简每天在公园跑步、玩耍时都戴着手镯。她的朋友们也很喜欢这款手链。简因为她漂亮的线手镯而感到非常富有和特别。他们从此过上了幸福的生活。\n",
            "从前，有一只小兔子，名叫包子。小面包喜欢在花园里吃美味的香草。但有一天，包子吃了一种不好的药草，肚子疼。\n",
            "包子的朋友，一只聪明的老猫头鹰，看到包子心情不好，就问：“包子，怎么了？”\n",
            "“我吃了一种不好的药草，现在我的肚子疼，”小面包回答道。\n",
            "“别担心，我知道如何帮忙。”猫头鹰说。 “我们去寻找一些好药材，让你的心情好一些。”\n",
            "于是，小面包和猫头鹰继续寻找好的草药。他们发现了一些好吃的，包子把它们全吃了。很快，包子的肚子痛就消失了，他又高兴了。 “谢谢你帮助我摆脱了严重的肚子疼痛，”小面包对猫头鹰说。\n",
            "从前，有一个小女孩，名叫莉莉，她喜欢跑步。她速度很快，喜欢感受风吹过头发的感觉。有一天，莉莉在外面玩，她感到很热。她摸了摸额头，感觉到了热度。\n",
            "莉莉的妈妈看到女儿说：“莉莉，你需要停下来休息一下，你太热了。”\n",
            "莉莉回答：“但我想继续跑步，很好玩！”\n",
            "她妈妈解释说：“照顾好我们的身体很重要。如果我们在太热的时候继续运动，我们可能会生病。”\n",
            "莉莉明白了，休息了一会儿。她喝了一些水，感觉好多了。从那天起，她总是在感觉太热的时候就休息一下。这个故事的寓意是，倾听我们身体的声音并照顾好自己很重要。\n",
            "萨姆和梅格是最好的朋友。他们一起做所有事情。有一天，萨姆说：“我们去慢跑吧。”梅格说：“是的！”\n",
            "于是他们出发去慢跑。紫色的天空照亮了他们周围的世界。鸟儿叽叽喳喳地叫着，河水发出喧闹的声音。\n",
            "萨姆和梅格慢跑时，他们感到非常疲倦。萨姆说：“我们坐下吧。”但梅格坚持继续前进。突然，他们听到一声撞击声。梅格被绊倒了，全身都是擦伤和瘀伤。\n",
            "萨姆拥抱梅格说：“你应该听我的话。”\n",
            "这个故事的主旨？有时最好听听朋友的意见，即使有些事情看起来很有趣！\n",
            "从前，有一个小女孩，名叫露西。每天早上露西都会帮忙清理壁炉。她为能帮助家人确保房间干净整洁而感到自豪。\n",
            "有一天，她在收拾壁炉后感到特别自豪，因为她不再帮忙做家务了。她心里想：“我已经做了很多了，为什么还要做更多呢？”\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 使用52AI/TinyStoriesZh 训练好的tokenizer 去扩展 原有llama tokenizer 词表"
      ],
      "metadata": {
        "id": "yoNNaRzg94f_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#check\n",
        "\n",
        "import sentencepiece as spm\n",
        "sp_bpe = spm.SentencePieceProcessor()\n",
        "sp_bpe.load('/content/data/52AI/TinyStoriesZh/tok8192.model')\n",
        "print('*** BPE ***')\n",
        "print(sp_bpe.encode_as_pieces('The excellence of a translation can only be judged by noting'))\n",
        "print(len(sp_bpe.encode_as_pieces('The excellence of a translation can only be judged by noting')))\n",
        "print(sp_bpe.encode_as_pieces('麒麟，是中国古代神话中的一种瑞兽'))\n",
        "print(len(sp_bpe.encode_as_pieces('麒麟，是中国古代神话中的一种瑞兽')))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nw1vYIRH-ONA",
        "outputId": "f1530f48-53fa-480c-ff6f-92d993db2a48"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** BPE ***\n",
            "['▁', 'T', 'h', 'e', '▁', 'e', 'x', 'c', 'e', 'l', 'l', 'e', 'n', 'c', 'e', '▁', 'o', 'f', '▁', 'a', '▁', 't', 'r', 'a', 'n', 's', 'l', 'a', 't', 'i', 'o', 'n', '▁', 'c', 'a', 'n', '▁', 'o', 'n', 'l', 'y', '▁', 'b', 'e', '▁', 'j', 'u', 'd', 'g', 'e', 'd', '▁', 'b', 'y', '▁', 'n', 'ot', 'in', 'g']\n",
            "59\n",
            "['▁', '麒', '麟', '，', '是', '中', '国', '古', '代', '神', '话', '中', '的一', '种', '瑞', '兽']\n",
            "16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"]=\"python\"\n",
        "from transformers import LlamaTokenizer\n",
        "from sentencepiece import sentencepiece_model_pb2 as sp_pb2_model\n",
        "import sentencepiece as spm\n",
        "\n",
        "# 位置\n",
        "llama_tokenizer_dir = \"meta-llama/Llama-2-7b-hf\" # 原始模型llama2-7b tokenizer\n",
        "chinese_sp_model_file =\"/content/data/52AI/TinyStoriesZh/tok8192.model\" # 刚才训练的tokenizer模型\n",
        "\n",
        "# 加载\n",
        "llama_tokenizer = LlamaTokenizer.from_pretrained(llama_tokenizer_dir)\n",
        "llama_spm = sp_pb2_model.ModelProto()\n",
        "llama_spm.ParseFromString(llama_tokenizer.sp_model.serialized_model_proto())\n",
        "\n",
        "chinese_sp_model = spm.SentencePieceProcessor()\n",
        "chinese_sp_model.Load(chinese_sp_model_file)\n",
        "chinese_spm = sp_pb2_model.ModelProto()\n",
        "chinese_spm.ParseFromString(chinese_sp_model.serialized_model_proto())\n",
        "\n",
        "\n",
        "# 打印两个词表的大小和原llama的特殊token\n",
        "print(len(llama_tokenizer),len(chinese_sp_model))\n",
        "print(llama_tokenizer.all_special_tokens)\n",
        "print(llama_tokenizer.all_special_ids)\n",
        "print(llama_tokenizer.special_tokens_map)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhmLIwe_oCAz",
        "outputId": "d5843305-8d7f-4245-8f64-58374632bec3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32000 8192\n",
            "['<s>', '</s>', '<unk>']\n",
            "[1, 2, 0]\n",
            "{'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#合并Llama词表\n",
        "# 开始往llama词表里添加，这里你也可以直接加入你想要加入词表的词，或者是领域内的特殊词\n",
        "llama_spm_tokens_set=set(p.piece for p in llama_spm.pieces)\n",
        "print(len(llama_spm_tokens_set))\n",
        "print(f\"Before:{len(llama_spm_tokens_set)}\")\n",
        "for p in chinese_spm.pieces:\n",
        "    piece = p.piece\n",
        "    if piece not in llama_spm_tokens_set:\n",
        "        new_p = sp_pb2_model.ModelProto().SentencePiece()\n",
        "        new_p.piece = piece\n",
        "        new_p.score = 0\n",
        "        llama_spm.pieces.append(new_p)\n",
        "print(f\"New model pieces: {len(llama_spm.pieces)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0M_zug9AQim",
        "outputId": "66011285-d9f8-4835-a5be-c6532d6a0ad0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32000\n",
            "Before:32000\n",
            "New model pieces: 39200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 保存合并后的模型\n",
        "output_sp_dir = 'merged_tokenizer_sp_test'\n",
        "output_hf_dir = 'merged_tokenizer_hf_test'\n",
        "os.makedirs(output_sp_dir,exist_ok=True)\n",
        "with open(output_sp_dir+'/chinese_llama.model', 'wb') as f:\n",
        "    f.write(llama_spm.SerializeToString())\n",
        "tokenizer = LlamaTokenizer(vocab_file=output_sp_dir+'/chinese_llama.model')\n",
        "\n",
        "tokenizer.save_pretrained(output_hf_dir)\n",
        "print(f\"Chinese-LLaMA tokenizer has been saved to {output_hf_dir}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVL1Ho9XAfl9",
        "outputId": "137678ae-f842-4657-f48d-fda4cec58a1e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chinese-LLaMA tokenizer has been saved to merged_tokenizer_hf_test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 看一下效果\n",
        "llama_tokenizer = LlamaTokenizer.from_pretrained(llama_tokenizer_dir)\n",
        "chinese_llama_tokenizer = LlamaTokenizer.from_pretrained(output_hf_dir)\n",
        "\n",
        "# check 和原来 英文的对比\n",
        "text = \"The excellence of a translation can only be judged by noting\"\n",
        "print(\"Test text:\\n\",text)\n",
        "print(f\"Tokenized by LLaMA tokenizer:{llama_tokenizer.tokenize(text)}\")\n",
        "print(f\"Tokenized length by LLaMA tokenizer:{len(llama_tokenizer.tokenize(text))}\")\n",
        "print(f\"Tokenized by chinese_llama tokenizer:{chinese_llama_tokenizer.tokenize(text)}\")\n",
        "print(f\"Tokenized length by LLaMA-extent-1 tokenizer:{len(chinese_llama_tokenizer.tokenize(text))}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnljjYfeA3Qm",
        "outputId": "f057d94d-2a20-432f-b9f6-64608f791873"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test text:\n",
            " The excellence of a translation can only be judged by noting\n",
            "Tokenized by LLaMA tokenizer:['▁The', '▁excell', 'ence', '▁of', '▁a', '▁translation', '▁can', '▁only', '▁be', '▁jud', 'ged', '▁by', '▁not', 'ing']\n",
            "Tokenized length by LLaMA tokenizer:14\n",
            "Tokenized by chinese_llama tokenizer:['The', '▁excell', 'ence', '▁of', '▁a', '▁translation', '▁can', '▁only', '▁be', '▁jud', 'ged', '▁by', '▁not', 'ing']\n",
            "Tokenized length by LLaMA-extent-1 tokenizer:14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"麒麟，是中国古代神话中的一种瑞兽\"\n",
        "print(\"Test text:\\n\",text)\n",
        "print(f\"Tokenized by LLaMA tokenizer:{llama_tokenizer.tokenize(text)}\")\n",
        "print(f\"Tokenized length by LLaMA tokenizer:{len(llama_tokenizer.tokenize(text))}\")\n",
        "print(f\"Tokenized by chinese_llama tokenizer:{chinese_llama_tokenizer.tokenize(text)}\")\n",
        "print(f\"Tokenized length by chinese_llama tokenizer:{len(chinese_llama_tokenizer.tokenize(text))}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7nPkNUFA64h",
        "outputId": "6ec8e7bb-54d2-4595-bd5a-8220f4fbcf06"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test text:\n",
            " 麒麟，是中国古代神话中的一种瑞兽\n",
            "Tokenized by LLaMA tokenizer:['▁', '<0xE9>', '<0xBA>', '<0x92>', '<0xE9>', '<0xBA>', '<0x9F>', '，', '是', '中', '国', '古', '代', '神', '话', '中', '的', '一', '种', '<0xE7>', '<0x91>', '<0x9E>', '<0xE5>', '<0x85>', '<0xBD>']\n",
            "Tokenized length by LLaMA tokenizer:25\n",
            "Tokenized by chinese_llama tokenizer:['麒', '麟', '，', '是', '中', '国', '古', '代', '神', '话', '中的', '一种', '瑞', '兽']\n",
            "Tokenized length by chinese_llama tokenizer:14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [tiktoken](https://github.com/openai/tiktoken)"
      ],
      "metadata": {
        "id": "SZr6FgIfDxN5"
      }
    }
  ]
}