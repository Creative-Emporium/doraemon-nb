{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weedge/doraemon-nb/blob/main/sft_peft_prompt_tuning_bloomz_560m.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# prompt tuning\n",
        "\n",
        "- https://huggingface.co/docs/peft/package_reference/prompt_tuning\n",
        "- [The Power of Scale for Parameter-Efficient Prompt Tuning](https://arxiv.org/pdf/2104.08691.pdf)\n",
        "\n",
        "\n",
        "**注**：训练参数量少，直接可以在cpu上训练，注意内存需要hold住训练的模型参数加载到内从中进行训练。如果有条件使用gpu加速\n",
        "\n",
        "\n",
        "Prompt tuning(提示调整)是一种用于调整预训练语言模型以执行特定下游任务的技术。在这种方法中，会向输入中添加特定于任务的提示（prompts），而这些提示参数是独立于预训练模型参数进行更新的，预训练模型的参数则保持固定。\n",
        "\n",
        "论文[The Power of Scale for Parameter-Efficient Prompt Tuning](https://arxiv.org/pdf/2104.08691.pdf)摘要:\n",
        "\n",
        "这篇论文的摘要介绍了一种名为“prompt tuning”的技术，这是一种用于调整冻结语言模型以执行特定下游任务的方法。与GPT-3使用的离散文本提示不同，软提示（soft prompts）是通过反向传播学习得到的，并且可以根据标记样本的数量进行调整。文章展示了通过prompt tuning的方法，可以在不调整模型权重的情况下，通过调整输入文本前的软提示来改善模型性能。\n",
        "\n",
        "研究者们发现，prompt tuning在模型规模扩大时变得更加有竞争力，尤其是在模型参数超过数十亿时，其性能与模型调整（调整所有模型权重）相当。这一点特别重要，因为大型模型共享和部署成本高昂，能够重用一个冻结模型来处理多个下游任务可以减轻这一负担。\n",
        "\n",
        "文章还比较了prompt tuning与最近提出的“prefix tuning”等方法，并展示了prompt tuning在鲁棒性和效率方面的优势。此外，文章还探讨了prompt tuning在领域转移任务中的性能，以及如何通过学习多个提示（prompt ensembling）来提高任务性能。\n",
        "\n",
        "总的来说，这篇论文提出了一种有效的、参数高效的调整方法，适用于大型预训练语言模型，并且在多个方面展示了其优越性。\n",
        "\n",
        "## 数据集\n",
        "\n",
        "- ought/raft twitter_complaints 数据,用于标记是否是投诉的微博 50条用作训练(20%作为训练验证loss)，3399条用做测试验证\n",
        "\n",
        "\n",
        "中文数据集可以找下微博相关数据集， 如下场景：\n",
        "- 用户@官方账号，进行投诉，或者产品改进建议， 比如这条改进建议：\n",
        "```\n",
        "类似其他页面文档也是， 但是存在一个问题，如果能把每页的阅读过的会话保存，能够直接查阅以往阅读会话就好了， 这样不用回到原来页面在加载分析一次，貌似这样会增加浏览器本地缓存。@Kimi智能助手\n",
        "```\n",
        "- 标识为危险信息，进行过滤，风控服务中会用到，对模型微调风控数据。比如UGC中的发布信息功能\n"
      ],
      "metadata": {
        "id": "sFZ-OXMDfBCk"
      },
      "id": "sFZ-OXMDfBCk"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers datasets peft tqdm torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGfAWWcGYBQ9",
        "outputId": "fbe0769b-45d5-4726-8a2d-8e00683f9ea2"
      },
      "id": "TGfAWWcGYBQ9",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/510.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/510.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m501.8/510.5 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.1/290.1 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m695.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "配置参数："
      ],
      "metadata": {
        "id": "lWt0dF7fgp-z"
      },
      "id": "lWt0dF7fgp-z"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "71fbfca2",
      "metadata": {
        "id": "71fbfca2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90add826-dbfc-430f-a0bd-436b2ebe6690"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "peft_config PromptTuningConfig(peft_type=<PeftType.PROMPT_TUNING: 'PROMPT_TUNING'>, auto_mapping=None, base_model_name_or_path=None, revision=None, task_type=<TaskType.CAUSAL_LM: 'CAUSAL_LM'>, inference_mode=False, num_virtual_tokens=8, token_dim=None, num_transformer_submodules=None, num_attention_heads=None, num_layers=None, prompt_tuning_init=<PromptTuningInit.TEXT: 'TEXT'>, prompt_tuning_init_text='Classify if the tweet is a complaint or not:', tokenizer_name_or_path='bigscience/bloomz-560m', tokenizer_kwargs=None)\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM\n",
        "from peft import get_peft_config, get_peft_model, PromptTuningInit, PromptTuningConfig, TaskType, PeftType\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "import os\n",
        "from transformers import AutoTokenizer\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import default_data_collator, get_linear_schedule_with_warmup\n",
        "from tqdm import tqdm\n",
        "from datasets import load_dataset\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)\n",
        "\n",
        "model_name_or_path = \"bigscience/bloomz-560m\"\n",
        "tokenizer_name_or_path = \"bigscience/bloomz-560m\"\n",
        "peft_config = PromptTuningConfig(\n",
        "    task_type=TaskType.CAUSAL_LM,\n",
        "    prompt_tuning_init=PromptTuningInit.TEXT,\n",
        "    num_virtual_tokens=8,\n",
        "    prompt_tuning_init_text=\"Classify if the tweet is a complaint or not:\",\n",
        "    tokenizer_name_or_path=model_name_or_path,\n",
        ")\n",
        "print(\"peft_config\",peft_config)\n",
        "\n",
        "dataset_name = \"twitter_complaints\"\n",
        "checkpoint_name = f\"{dataset_name}_{model_name_or_path}_{peft_config.peft_type}_{peft_config.task_type}_v1.pt\".replace(\n",
        "    \"/\", \"_\"\n",
        ")\n",
        "text_column = \"Tweet text\"\n",
        "label_column = \"text_label\"\n",
        "max_length = 64\n",
        "lr = 3e-2\n",
        "num_epochs = 50\n",
        "\n",
        "batch_size = 8"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`PromptTuningConfig` 的配置，用于配置 Prompt Tuning（PT）的相关选项。Prompt Tuning 是一种通过微调预训练语言模型来实现零样本或小样本学习的技术，它通过添加自定义的提示（prompt）来指导模型进行特定任务的学习。以下是各个参数的含义解释：\n",
        "\n",
        "1. `peft_type`: PEFT（Parameter-Efficient Fine-Tuning）类型。在这里，设置为 `PeftType.PROMPT_TUNING`，表示使用 Prompt Tuning 进行微调。\n",
        "\n",
        "2. `auto_mapping`: 自动映射。用于指定是否自动映射预训练模型的参数以适应新任务。\n",
        "\n",
        "3. `base_model_name_or_path`: 基础模型名称或路径。用于指定要微调的基础语言模型的名称或路径。\n",
        "\n",
        "4. `revision`: 模型修订版本。\n",
        "\n",
        "5. `task_type`: 任务类型。在这里，设置为 `TaskType.CAUSAL_LM`，表示任务类型为因果语言建模（Causal Language Modeling）。\n",
        "\n",
        "6. `inference_mode`: 推理模式。用于指定是否在推理时使用 Prompt Tuning。\n",
        "\n",
        "7. `num_virtual_tokens`: 虚拟token数量。用于指定在 PT 中使用的虚拟token数量。\n",
        "\n",
        "8. `token_dim`: token维度。用于指定 PT 中标记的维度。\n",
        "\n",
        "9. `num_transformer_submodules`: Transformer 子模块数量。\n",
        "\n",
        "10. `num_attention_heads`: 注意力头数量。\n",
        "\n",
        "11. `num_layers`: 层数量。\n",
        "\n",
        "12. `prompt_tuning_init`: Prompt Tuning 初始化方法。在这里，设置为 `PromptTuningInit.TEXT`，表示使用文本作为初始化。\n",
        "\n",
        "13. `prompt_tuning_init_text`: Prompt Tuning 初始化文本。指定了用于初始化的文本提示。\n",
        "\n",
        "14. `tokenizer_name_or_path`: 分词器名称或路径。用于指定分词器的名称或路径。\n",
        "\n",
        "15. `tokenizer_kwargs`: 分词器参数。用于指定分词器的其他参数，如词汇表大小、特殊标记等。\n",
        "\n",
        "这些参数用于配置 Prompt Tuning 过程中的各个方面，包括任务类型、模型初始化、分词器设置等。通过调整这些参数，可以根据具体的任务和需求来定制 Prompt Tuning 的行为。"
      ],
      "metadata": {
        "id": "Eyo3uE03txQB"
      },
      "id": "Eyo3uE03txQB"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "e1a3648b",
      "metadata": {
        "id": "e1a3648b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc9cf30d-b5db-4758-d505-e4ebe296842a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['Tweet text', 'ID', 'Label'],\n",
            "        num_rows: 50\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['Tweet text', 'ID', 'Label'],\n",
            "        num_rows: 3399\n",
            "    })\n",
            "})\n",
            "{'Tweet text': '@HMRCcustomers No this is my first job', 'ID': 0, 'Label': 2}\n",
            "['Unlabeled', 'complaint', 'no complaint']\n",
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['Tweet text', 'ID', 'Label', 'text_label'],\n",
            "        num_rows: 50\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['Tweet text', 'ID', 'Label', 'text_label'],\n",
            "        num_rows: 3399\n",
            "    })\n",
            "})\n",
            "{'Tweet text': '@HMRCcustomers No this is my first job', 'ID': 0, 'Label': 2, 'text_label': 'no complaint'}\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"ought/raft\", dataset_name)\n",
        "print(dataset)\n",
        "print(dataset[\"train\"][0])\n",
        "\n",
        "classes = [k.replace(\"_\", \" \") for k in dataset[\"train\"].features[\"Label\"].names]\n",
        "print(classes)\n",
        "dataset = dataset.map(\n",
        "    lambda x: {\"text_label\": [classes[label] for label in x[\"Label\"]]},\n",
        "    batched=True,\n",
        "    num_proc=1,\n",
        ")\n",
        "print(dataset)\n",
        "print(dataset[\"train\"][0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "fe12d4d3",
      "metadata": {
        "id": "fe12d4d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379,
          "referenced_widgets": [
            "dc03d9b8864342b29d6c26b49740f2bc",
            "6f3c34925fb94290baeb0e72ba964ef9",
            "2d27cd965e524f6b98822f8a5cd97d47",
            "5b4e0961a90741dbae58ab89e4b172fa",
            "037b25dd188b483db344ebbb203ec726",
            "f5059d5c50c44a5ab407a994757762c6",
            "103245d659104befbef58eae2a014ffe",
            "28f3db8de4064f36ba02a3e467e18391",
            "660f0436ed044d518e99b0e531008120",
            "d8085ecd9afc48fbb77c84fb436b058e",
            "5ddd714807454aceb50d624e7f3c02d8",
            "ab9120693bb844f89da85242f1140b4e",
            "ffff094e7d7141ee89d97e7e56b550e6",
            "6b33161c53524a28907b937a6b9a30f4",
            "132988e4594f4a2da972a25cbd0b012e",
            "82fe720350cc400e9beae923b2811b44",
            "3b712967a865402db16310011c78d894",
            "9026225b8c224a2cad4286c2fc27d0b0",
            "001aa4ecd364435eae589010777be538",
            "6a69b2fc660a4c2994ac6b6c384532d8",
            "c2b7981937e5400ca1276178adedfa9b",
            "9cf79423f7064445880342aa5580ce9e"
          ]
        },
        "outputId": "430779a6-7699-4a5e-e2b7-26c6181848b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Running tokenizer on dataset:   0%|          | 0/50 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dc03d9b8864342b29d6c26b49740f2bc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Running tokenizer on dataset:   0%|          | 0/3399 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab9120693bb844f89da85242f1140b4e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processed_datasets DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['input_ids', 'attention_mask', 'labels'],\n",
            "        num_rows: 50\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['input_ids', 'attention_mask', 'labels'],\n",
            "        num_rows: 3399\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['input_ids', 'attention_mask', 'labels'],\n",
            "        num_rows: 3399\n",
            "    })\n",
            "})\n",
            "{'input_ids': [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 227985, 5484, 915, 2566, 169403, 15296, 36272, 525, 3928, 1119, 632, 2670, 3968, 15270, 77658, 915, 210, 1936, 106863, 2], 'attention_mask': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 1936, 106863, 2]}\n"
          ]
        }
      ],
      "source": [
        "# data preprocessing\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
        "if tokenizer.pad_token_id is None:\n",
        "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "target_max_length = max([len(tokenizer(class_label)[\"input_ids\"]) for class_label in classes])\n",
        "print(target_max_length)\n",
        "\n",
        "#这里和lora稍有不同，应为是prompt tuning, 对input进行了 PE 模版操作，\"{key} : {val} Lable : \"\n",
        "def preprocess_function(examples):\n",
        "    batch_size = len(examples[text_column])\n",
        "    inputs = [f\"{text_column} : {x} Label : \" for x in examples[text_column]]\n",
        "    targets = [str(x) for x in examples[label_column]]\n",
        "    model_inputs = tokenizer(inputs)\n",
        "    labels = tokenizer(text_target=targets, add_special_tokens=False)  # don't add bos token because we concatenate with inputs\n",
        "    for i in range(batch_size):\n",
        "        sample_input_ids = model_inputs[\"input_ids\"][i]\n",
        "        label_input_ids = labels[\"input_ids\"][i] + [tokenizer.eos_token_id]\n",
        "        # print(i, sample_input_ids, label_input_ids)\n",
        "        model_inputs[\"input_ids\"][i] = sample_input_ids + label_input_ids\n",
        "        labels[\"input_ids\"][i] = [-100] * len(sample_input_ids) + label_input_ids\n",
        "        model_inputs[\"attention_mask\"][i] = [1] * len(model_inputs[\"input_ids\"][i])\n",
        "    # print(model_inputs)\n",
        "    for i in range(batch_size):\n",
        "        sample_input_ids = model_inputs[\"input_ids\"][i]\n",
        "        label_input_ids = labels[\"input_ids\"][i]\n",
        "        model_inputs[\"input_ids\"][i] = [tokenizer.pad_token_id] * (\n",
        "            max_length - len(sample_input_ids)\n",
        "        ) + sample_input_ids\n",
        "        model_inputs[\"attention_mask\"][i] = [0] * (max_length - len(sample_input_ids)) + model_inputs[\n",
        "            \"attention_mask\"\n",
        "        ][i]\n",
        "        labels[\"input_ids\"][i] = [-100] * (max_length - len(sample_input_ids)) + label_input_ids\n",
        "        model_inputs[\"input_ids\"][i] = torch.tensor(model_inputs[\"input_ids\"][i][:max_length])\n",
        "        model_inputs[\"attention_mask\"][i] = torch.tensor(model_inputs[\"attention_mask\"][i][:max_length])\n",
        "        labels[\"input_ids\"][i] = torch.tensor(labels[\"input_ids\"][i][:max_length])\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "\n",
        "raw_processed_datasets = dataset.map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        "    num_proc=1,\n",
        "    #移除不需要的字段，为了model(**batch)推理，input_ids(输入)，attention_mask(self attention mask)，labels(输出期望)\n",
        "    remove_columns=dataset[\"train\"].column_names,\n",
        "    load_from_cache_file=False,\n",
        "    desc=\"Running tokenizer on dataset\",\n",
        ")\n",
        "#processed_datasets=raw_processed_datasets[\"train\"].train_test_split(test_size=0.2)\n",
        "processed_datasets=raw_processed_datasets\n",
        "processed_datasets[\"validation\"]=raw_processed_datasets[\"test\"]\n",
        "print(\"processed_datasets\",processed_datasets)\n",
        "print(processed_datasets[\"train\"][0])\n",
        "\n",
        "# train_dataset is the same as eval_dataset\n",
        "train_dataset = processed_datasets[\"train\"]\n",
        "eval_dataset = processed_datasets[\"train\"]\n",
        "#eval_dataset = processed_datasets[\"test\"]\n",
        "\n",
        "# but train data is shuffle random; eval data don't shuffle\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset, shuffle=True, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True\n",
        ")\n",
        "eval_dataloader = DataLoader(eval_dataset, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "641b21fe",
      "metadata": {
        "id": "641b21fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "39ec50b3805b43d09a20653521d89ba7",
            "1af706e0fe084fd4b0181536406f1c45",
            "51248925284e47388a49077a4f274b00",
            "2b8a2800aba34f26b03e94b8db9bb0db",
            "562bc262aac948cb82bb7336b187549e",
            "2b810dd32aa045b8882b1c04d719d701",
            "50c028570ca94892ab83b3baaf1a2ab8",
            "57e3c9285bf446d4a23cdbb3b00179ca",
            "b030635c2b2d4046af46b32b2a26b9e0",
            "607f5dbbd95a4347824a48e7c8c772a5",
            "4f7714e27eea49f79dfa252f50cf6e6f"
          ]
        },
        "outputId": "68ab33b2-c507-4e0b-dc15-58ce1f93ac54"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Running tokenizer on dataset:   0%|          | 0/3399 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "39ec50b3805b43d09a20653521d89ba7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "          227985,   5484,    915,   2566,  74757,  64626,  12384,  44639,    613,\n",
              "           52282,   2670,  79920,   3344,   1002,    368,  17646,  14472,   8348,\n",
              "             664,    718,      4,  19036,     17,  31849,     17,   6312,     76,\n",
              "              44,  62470,     56,     91,     50,  14839,     21,  77658,    915,\n",
              "             210],\n",
              "         [     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3,      3, 227985,   5484,    915,    405, 187059,\n",
              "            2256,    664,   2550,  18833,  18607, 162467,      4,   1387,   6199,\n",
              "            3291,  23405,    613,   4657,  17082,    566,   3432,    368,  78851,\n",
              "            1185,  61273,  23181,   1553,  15596,    212, 116057,  77658,    915,\n",
              "             210],\n",
              "         [     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3,      3,      3,      3,      3, 227985,   5484,\n",
              "             915,  39762,   2566,  22253,   6201,  75701,     15,    632,    718,\n",
              "            5840,  10006,   6201,  18881,    427,   3804,  19528,    267, 158974,\n",
              "            1320,    368,  10029,    632,  49666,     92,     34,  77658,    915,\n",
              "             210],\n",
              "         [     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3, 227985,   5484,    915,   2566, 104565,   8695,   2089,   6140,\n",
              "          109676,  99579,   1369,    512,    368,   4570,     54,    632,    368,\n",
              "            1503, 241485, 132226,     15,    982,    727,   1152,  18100,    861,\n",
              "           32596,  77597, 168154,   1306, 132226,   4346,  87843,     17, 130462,\n",
              "             364,  32923,     89,     53,   8309,     20,     75,  77658,    915,\n",
              "             210],\n",
              "         [     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3,      3,      3, 227985,   5484,    915,   2566,\n",
              "           14173,   2960,  29906,    387,  20706,  49337,   1369,  77658,    915,\n",
              "             210],\n",
              "         [     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3, 227985,   5484,    915,   2566, 219553,  45736,\n",
              "           36876,   1713,     72,    707, 187205,  13002, 177324,  77658,    915,\n",
              "             210],\n",
              "         [     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3, 227985,   5484,    915,   2566, 233938,  28518,  13716,\n",
              "             427,  28146,   1119,  17918,     17, 236706,    368, 214997,   7555,\n",
              "           48659,   5276,  21600,    343,     17,  51416,  22403,    318,   1531,\n",
              "            1306,   1130,  20934,    567, 101161, 184849,  87843,     17,   1594,\n",
              "           15231,   2052,  16642,     20,   7180,     80,     26,  77658,    915,\n",
              "             210],\n",
              "         [     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "          227985,   5484,    915,   2566,     80,   2068,    479,   2566,     80,\n",
              "            1376,    878, 147587,   3904,    632,    368,   6084,  65673,  78851,\n",
              "           11736,  15527,  19082,  33151,    461,     17,  45575,  17887,    632,\n",
              "            5219,  14216,  68870,   5967,   1841,   4346,  87843,     17,   1594,\n",
              "           14512,     27,     71,   8184,     19,    290,  63748,  77658,    915,\n",
              "             210]]),\n",
              " 'attention_mask': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "def test_preprocess_function(examples):\n",
        "    batch_size = len(examples[text_column])\n",
        "    inputs = [f\"{text_column} : {x} Label : \" for x in examples[text_column]]\n",
        "    model_inputs = tokenizer(inputs)\n",
        "    # print(model_inputs)\n",
        "    for i in range(batch_size):\n",
        "        sample_input_ids = model_inputs[\"input_ids\"][i]\n",
        "        model_inputs[\"input_ids\"][i] = [tokenizer.pad_token_id] * (\n",
        "            max_length - len(sample_input_ids)\n",
        "        ) + sample_input_ids\n",
        "        model_inputs[\"attention_mask\"][i] = [0] * (max_length - len(sample_input_ids)) + model_inputs[\n",
        "            \"attention_mask\"\n",
        "        ][i]\n",
        "        model_inputs[\"input_ids\"][i] = torch.tensor(model_inputs[\"input_ids\"][i][:max_length])\n",
        "        model_inputs[\"attention_mask\"][i] = torch.tensor(model_inputs[\"attention_mask\"][i][:max_length])\n",
        "    return model_inputs\n",
        "\n",
        "\n",
        "test_dataset = dataset[\"test\"].map(\n",
        "    test_preprocess_function,\n",
        "    batched=True,\n",
        "    num_proc=1,\n",
        "    #移除不需要的字段，为了model(**batch)推理\n",
        "    remove_columns=dataset[\"test\"].column_names,\n",
        "    load_from_cache_file=False,\n",
        "    desc=\"Running tokenizer on dataset\",\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(test_dataset, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True)\n",
        "next(iter(test_dataloader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "accc5012",
      "metadata": {
        "id": "accc5012",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3eb67d86-0cb8-4549-d046-4a3155cf471a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3,      3,      3,      3,      3, 227985,   5484,\n",
              "             915,   2566,     44,    256,  67875,  21033,  86274,  79707,   2632,\n",
              "            9999,    427,   2150,  54036,  98091,     34, 112164,  15971,  16154,\n",
              "            5382,    861,   7220,     17,  77658,    915,    210,   1936, 106863,\n",
              "               2],\n",
              "         [     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3,      3,      3,      3,      3, 227985,   5484,\n",
              "             915,   2566,  88653,   2321, 144017, 138861,  59283,   1152,    613,\n",
              "            2632,  12120,      4,   5673,   1152,  32153,    427,  36992,     15,\n",
              "            1152,   1400,   5065, 114438,  66455,    919,    404, 146304,  14078,\n",
              "           87856,   7061,   2906,     17,  77658,    915,    210,   1936, 106863,\n",
              "               2],\n",
              "         [     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3,      3, 227985,   5484,    915,   5673,    473,\n",
              "           11229,   2213,   2670,  35307,  28629,    461,   2566,   2765,   1531,\n",
              "            3470,  47134,  10144,   2765,   1531,    427,   2909,  17918,   6782,\n",
              "           27268,   4390,   1517,     17,   3904,    632,    267,   6497,    483,\n",
              "             361,   2670, 101848,     17,  32465,   9585,   2566,     37,   2481,\n",
              "            2566,     37,   2481,  12384,  77658,    915,    210,  16449,   5952,\n",
              "               2],\n",
              "         [     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3,      3, 227985,   5484,    915,  35673,   8562,\n",
              "           29826, 102530,     15,   1427, 207595,     17,    915,     12,   2550,\n",
              "           81623,  14282,   5715,  37623,  77658,    915,    210,   1936, 106863,\n",
              "               2],\n",
              "         [     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3, 227985,   5484,    915,   2566,     60,  80772,   1400,\n",
              "            1701,   2213,    368,  12171,  67777,    613,    267,  18210,  76252,\n",
              "             375,    916,   6635,   1320,   3776,    934,  44805,   1965,  13002,\n",
              "             934,     17,     21,     12,    791,    727,   1701,   2971,    267,\n",
              "           35307,  20845,  10172,     34,  77658,    915,    210,   1936, 106863,\n",
              "               2],\n",
              "         [     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3, 227985,   5484,    915,   2566,     58,  24673,     21,\n",
              "           34274,   1244,    613,   2910,  77658,    915,    210,   1936, 106863,\n",
              "               2],\n",
              "         [     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3, 227985,   5484,    915,   2566, 137538,  78869,  12122,   2963,\n",
              "            3226,  15756,   1965,   3276,  14967,   6610,    664,   3509,    427,\n",
              "          112046,   1800,  21859,   3250,  77658,    915,    210,   1936, 106863,\n",
              "               2],\n",
              "         [     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3, 227985,   5484,    915,   5161,  13500,    386,\n",
              "               4, 122906,    415,  66027,  42431,    613,  70016,    361,   2550,\n",
              "              51,  21351,    322,  17896,     15,   2550,     49,     45,   2550,\n",
              "           21450,    388,    655,   2550,     75,  14263,    916,     86,   1881,\n",
              "           36534,  53902,      4,   4346,  87843,     17, 130462,   8188,     23,\n",
              "            5949, 187347,     78, 130589,  77658,    915,    210,   1936, 106863,\n",
              "               2]]),\n",
              " 'attention_mask': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n",
              " 'labels': tensor([[  -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
              "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
              "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
              "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
              "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
              "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
              "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   1936, 106863,\n",
              "               2],\n",
              "         [  -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
              "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
              "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
              "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
              "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
              "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
              "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   1936, 106863,\n",
              "               2],\n",
              "         [  -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
              "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
              "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
              "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
              "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
              "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
              "            -100,   -100,   -100,   -100,   -100,   -100,   -100,  16449,   5952,\n",
              "               2],\n",
              "         [  -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
              "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
              "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
              "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
              "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
              "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
              "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   1936, 106863,\n",
              "               2],\n",
              "         [  -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
              "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
              "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
              "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
              "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
              "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
              "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   1936, 106863,\n",
              "               2],\n",
              "         [  -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
              "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
              "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
              "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
              "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
              "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
              "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   1936, 106863,\n",
              "               2],\n",
              "         [  -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
              "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
              "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
              "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
              "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
              "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
              "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   1936, 106863,\n",
              "               2],\n",
              "         [  -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
              "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
              "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
              "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
              "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
              "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
              "            -100,   -100,   -100,   -100,   -100,   -100,   -100,   1936, 106863,\n",
              "               2]])}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "next(iter(train_dataloader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "218df807",
      "metadata": {
        "id": "218df807",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13fa2bf7-eacc-4ba3-9912-76abf22ea22b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "425"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "len(test_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "47d1fedf",
      "metadata": {
        "id": "47d1fedf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3397ccc9-e4da-4e9f-81b9-dfb214bda18a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "          227985,   5484,    915,   2566,  74757,  64626,  12384,  44639,    613,\n",
              "           52282,   2670,  79920,   3344,   1002,    368,  17646,  14472,   8348,\n",
              "             664,    718,      4,  19036,     17,  31849,     17,   6312,     76,\n",
              "              44,  62470,     56,     91,     50,  14839,     21,  77658,    915,\n",
              "             210],\n",
              "         [     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3,      3, 227985,   5484,    915,    405, 187059,\n",
              "            2256,    664,   2550,  18833,  18607, 162467,      4,   1387,   6199,\n",
              "            3291,  23405,    613,   4657,  17082,    566,   3432,    368,  78851,\n",
              "            1185,  61273,  23181,   1553,  15596,    212, 116057,  77658,    915,\n",
              "             210],\n",
              "         [     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3,      3,      3,      3,      3, 227985,   5484,\n",
              "             915,  39762,   2566,  22253,   6201,  75701,     15,    632,    718,\n",
              "            5840,  10006,   6201,  18881,    427,   3804,  19528,    267, 158974,\n",
              "            1320,    368,  10029,    632,  49666,     92,     34,  77658,    915,\n",
              "             210],\n",
              "         [     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3, 227985,   5484,    915,   2566, 104565,   8695,   2089,   6140,\n",
              "          109676,  99579,   1369,    512,    368,   4570,     54,    632,    368,\n",
              "            1503, 241485, 132226,     15,    982,    727,   1152,  18100,    861,\n",
              "           32596,  77597, 168154,   1306, 132226,   4346,  87843,     17, 130462,\n",
              "             364,  32923,     89,     53,   8309,     20,     75,  77658,    915,\n",
              "             210],\n",
              "         [     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3,      3,      3, 227985,   5484,    915,   2566,\n",
              "           14173,   2960,  29906,    387,  20706,  49337,   1369,  77658,    915,\n",
              "             210],\n",
              "         [     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3, 227985,   5484,    915,   2566, 219553,  45736,\n",
              "           36876,   1713,     72,    707, 187205,  13002, 177324,  77658,    915,\n",
              "             210],\n",
              "         [     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3, 227985,   5484,    915,   2566, 233938,  28518,  13716,\n",
              "             427,  28146,   1119,  17918,     17, 236706,    368, 214997,   7555,\n",
              "           48659,   5276,  21600,    343,     17,  51416,  22403,    318,   1531,\n",
              "            1306,   1130,  20934,    567, 101161, 184849,  87843,     17,   1594,\n",
              "           15231,   2052,  16642,     20,   7180,     80,     26,  77658,    915,\n",
              "             210],\n",
              "         [     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "               3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
              "          227985,   5484,    915,   2566,     80,   2068,    479,   2566,     80,\n",
              "            1376,    878, 147587,   3904,    632,    368,   6084,  65673,  78851,\n",
              "           11736,  15527,  19082,  33151,    461,     17,  45575,  17887,    632,\n",
              "            5219,  14216,  68870,   5967,   1841,   4346,  87843,     17,   1594,\n",
              "           14512,     27,     71,   8184,     19,    290,  63748,  77658,    915,\n",
              "             210]]),\n",
              " 'attention_mask': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "next(iter(test_dataloader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "a773e092",
      "metadata": {
        "id": "a773e092",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fc5c6fa-0050-4d9d-cb51-463831ab91b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BloomForCausalLM(\n",
            "  (transformer): BloomModel(\n",
            "    (word_embeddings): Embedding(250880, 1024)\n",
            "    (word_embeddings_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "    (h): ModuleList(\n",
            "      (0-23): 24 x BloomBlock(\n",
            "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (self_attention): BloomAttention(\n",
            "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "          (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): BloomMLP(\n",
            "          (dense_h_to_4h): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (gelu_impl): BloomGelu()\n",
            "          (dense_4h_to_h): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=1024, out_features=250880, bias=False)\n",
            ")\n",
            "peft_model PeftModelForCausalLM(\n",
            "  (base_model): BloomForCausalLM(\n",
            "    (transformer): BloomModel(\n",
            "      (word_embeddings): Embedding(250880, 1024)\n",
            "      (word_embeddings_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      (h): ModuleList(\n",
            "        (0-23): 24 x BloomBlock(\n",
            "          (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (self_attention): BloomAttention(\n",
            "            (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (attention_dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): BloomMLP(\n",
            "            (dense_h_to_4h): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "            (gelu_impl): BloomGelu()\n",
            "            (dense_4h_to_h): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "    (lm_head): Linear(in_features=1024, out_features=250880, bias=False)\n",
            "  )\n",
            "  (prompt_encoder): ModuleDict(\n",
            "    (default): PromptEmbedding(\n",
            "      (embedding): Embedding(8, 1024)\n",
            "    )\n",
            "  )\n",
            "  (word_embeddings): Embedding(250880, 1024)\n",
            ")\n",
            "trainable params: 8,192 || all params: 559,222,784 || trainable%: 0.0014648902430985358\n"
          ]
        }
      ],
      "source": [
        "# creating model\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name_or_path)\n",
        "print(model)\n",
        "model = get_peft_model(model, peft_config)\n",
        "print(\"peft_model\",model)\n",
        "\n",
        "model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "peft_mode 在embedding层多了如下PromptEmbedding权重需要微调训练， 训练参数量才8*1024=8192，cpu就可以hold住训练，训练时间不长\n",
        "```\n",
        "  (prompt_encoder): ModuleDict(\n",
        "    (default): PromptEmbedding(\n",
        "      (embedding): Embedding(8, 1024)\n",
        "    )\n",
        "  )\n",
        "  (word_embeddings): Embedding(250880, 1024)\n",
        "```"
      ],
      "metadata": {
        "id": "TjQ-4qdFzA7_"
      },
      "id": "TjQ-4qdFzA7_"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "b2f91568",
      "metadata": {
        "id": "b2f91568"
      },
      "outputs": [],
      "source": [
        "# model\n",
        "# optimizer and lr scheduler\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "lr_scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=(len(train_dataloader) * num_epochs),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4fb69fc",
      "metadata": {
        "id": "e4fb69fc",
        "outputId": "78644ea1-7eda-46d6-a1f0-e8b3cdb91491",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7/7 [03:11<00:00, 27.32s/it]\n",
            "100%|██████████| 7/7 [01:24<00:00, 12.06s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch=0: train_ppl=tensor(166.0994) train_epoch_loss=tensor(5.1126) eval_ppl=tensor(14.0646) eval_epoch_loss=tensor(2.6437)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7/7 [04:02<00:00, 34.69s/it]\n",
            " 43%|████▎     | 3/7 [00:41<00:56, 14.03s/it]"
          ]
        }
      ],
      "source": [
        "# training and evaluation\n",
        "model = model.to(device)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for step, batch in enumerate(tqdm(train_dataloader)):\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        #         print(batch)\n",
        "        #         print(batch[\"input_ids\"].shape)\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.detach().float()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    model.eval()\n",
        "    eval_loss = 0\n",
        "    eval_preds = []\n",
        "    for step, batch in enumerate(tqdm(eval_dataloader)):\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "        eval_loss += loss.detach().float()\n",
        "        eval_preds.extend(\n",
        "            tokenizer.batch_decode(torch.argmax(outputs.logits, -1).detach().cpu().numpy(), skip_special_tokens=True)\n",
        "        )\n",
        "\n",
        "    eval_epoch_loss = eval_loss / len(eval_dataloader)\n",
        "    eval_ppl = torch.exp(eval_epoch_loss)\n",
        "    train_epoch_loss = total_loss / len(train_dataloader)\n",
        "    train_ppl = torch.exp(train_epoch_loss)\n",
        "    print(f\"{epoch=}: {train_ppl=} {train_epoch_loss=} {eval_ppl=} {eval_epoch_loss=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "53752a7b",
      "metadata": {
        "id": "53752a7b",
        "outputId": "1fb8889e-8ac1-4ccb-c064-2d562a362ffb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "@TommyHilfiger Dramatic shopping exp. ordered 6 jeans same size (30/32) 2 fits / 2 too large / 2 too slim : same brand &gt; different sizing\n",
            "{'input_ids': tensor([[227985,   5484,    915,   2566, 226154, 126015,   5385,    259, 239364,\n",
            "           3396,  70823,   5853,     17,  57247,   1231, 191040,   5025,   7869,\n",
            "            375,   2324, 149349,     12,    415, 122321,    897,    415,  10136,\n",
            "          10021,    897,    415,  10136,   6497,    381,    915,   5025,  51950,\n",
            "          66869,   5955,    272,  20311,  77658,    915,    210]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
            "tensor([[227985,   5484,    915,   2566, 226154, 126015,   5385,    259, 239364,\n",
            "           3396,  70823,   5853,     17,  57247,   1231, 191040,   5025,   7869,\n",
            "            375,   2324, 149349,     12,    415, 122321,    897,    415,  10136,\n",
            "          10021,    897,    415,  10136,   6497,    381,    915,   5025,  51950,\n",
            "          66869,   5955,    272,  20311,  77658,    915,    210,   1936, 106863,\n",
            "              2,     31,  43907,     54,  70198,    361,  17717,   1002]])\n",
            "['Tweet text : @TommyHilfiger Dramatic shopping exp. ordered 6 jeans same size (30/32) 2 fits / 2 too large / 2 too slim : same brand &gt; different sizing Label : no complaint<b>Stay in touch with']\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "i = 33\n",
        "inputs = tokenizer(f'{text_column} : {dataset[\"test\"][i][\"Tweet text\"]} Label : ', return_tensors=\"pt\")\n",
        "print(dataset[\"test\"][i][\"Tweet text\"])\n",
        "print(inputs)\n",
        "\n",
        "with torch.no_grad():\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    outputs = model.generate(\n",
        "        input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"], max_new_tokens=10, eos_token_id=3\n",
        "    )\n",
        "    print(outputs)\n",
        "    print(tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8f35152",
      "metadata": {
        "id": "c8f35152"
      },
      "source": [
        "\n",
        "- 将模型推送到 Hugging Face Hub\n",
        "```python\n",
        "model.push_to_hub(\n",
        "    f\"{dataset_name}_{model_name_or_path}_{peft_config.peft_type}_{peft_config.task_type}\".replace(\"/\", \"_\"),\n",
        "    token = \"hf_...\"\n",
        ")\n",
        "```\n",
        "token (`bool` 或 `str`, *可选*):\n",
        "    `token` 用于在访问远程文件时进行 HTTP Bearer 授权。如果设置为 `True`，将使用运行 `huggingface-cli login` 时生成的令牌（存储在 `~/.huggingface` 中）。如果未指定 `repo_url`，则默认为 `True`。\n",
        "    或者您可以从 https://huggingface.co/settings/token 获取您的令牌。\n",
        "\n",
        "\n",
        "- 或者将模型保存到本地\n",
        "```python\n",
        "peft_model_id = f\"{dataset_name}_{model_name_or_path}_{peft_config.peft_type}_{peft_config.task_type}\".replace(\"/\", \"_\")\n",
        "model.save_pretrained(peft_model_id)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "d8ba1f8c",
      "metadata": {
        "id": "d8ba1f8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46a68595-2db5-462d-a9ff-6c157577e5ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "twitter_complaints_bigscience_bloomz-560m_PROMPT_TUNING_CAUSAL_LM\n"
          ]
        }
      ],
      "source": [
        "# saving model\n",
        "peft_model_id = f\"{dataset_name}_{model_name_or_path}_{peft_config.peft_type}_{peft_config.task_type}\".replace(\n",
        "    \"/\", \"_\"\n",
        ")\n",
        "print(peft_model_id)\n",
        "model.save_pretrained(peft_model_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "4928c7f1",
      "metadata": {
        "id": "4928c7f1",
        "outputId": "d13f214e-eb9c-4e3f-c8f9-55ddeac66c98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "twitter_complaints_bigscience_bloomz-560m_PROMPT_TUNING_CAUSAL_LM/adapter_model.safetensors\n",
            "36K\ttwitter_complaints_bigscience_bloomz-560m_PROMPT_TUNING_CAUSAL_LM/adapter_model.safetensors\n",
            "total 48K\n",
            "-rw-r--r-- 1 root root  510 Apr  3 14:03 adapter_config.json\n",
            "-rw-r--r-- 1 root root  33K Apr  3 14:03 adapter_model.safetensors\n",
            "-rw-r--r-- 1 root root 5.0K Apr  3 14:03 README.md\n"
          ]
        }
      ],
      "source": [
        "ckpt = f\"{peft_model_id}/adapter_model.safetensors\"\n",
        "print(ckpt)\n",
        "!du -h $ckpt # 2^n file node size\n",
        "!ls -lh $peft_model_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "4d9476e1",
      "metadata": {
        "id": "4d9476e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "693c85a8-b161-4ddd-bc56-0b47caf466bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "twitter_complaints_bigscience_bloomz-560m_PROMPT_TUNING_CAUSAL_LM\n",
            "PromptTuningConfig(peft_type=<PeftType.PROMPT_TUNING: 'PROMPT_TUNING'>, auto_mapping=None, base_model_name_or_path='bigscience/bloomz-560m', revision=None, task_type='CAUSAL_LM', inference_mode=True, num_virtual_tokens=8, token_dim=1024, num_transformer_submodules=1, num_attention_heads=16, num_layers=24, prompt_tuning_init='TEXT', prompt_tuning_init_text='Classify if the tweet is a complaint or not:', tokenizer_name_or_path='bigscience/bloomz-560m', tokenizer_kwargs=None)\n",
            "BloomForCausalLM(\n",
            "  (transformer): BloomModel(\n",
            "    (word_embeddings): Embedding(250880, 1024)\n",
            "    (word_embeddings_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "    (h): ModuleList(\n",
            "      (0-23): 24 x BloomBlock(\n",
            "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (self_attention): BloomAttention(\n",
            "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "          (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): BloomMLP(\n",
            "          (dense_h_to_4h): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (gelu_impl): BloomGelu()\n",
            "          (dense_4h_to_h): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=1024, out_features=250880, bias=False)\n",
            ")\n",
            "PeftModelForCausalLM(\n",
            "  (base_model): BloomForCausalLM(\n",
            "    (transformer): BloomModel(\n",
            "      (word_embeddings): Embedding(250880, 1024)\n",
            "      (word_embeddings_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      (h): ModuleList(\n",
            "        (0-23): 24 x BloomBlock(\n",
            "          (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (self_attention): BloomAttention(\n",
            "            (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (attention_dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): BloomMLP(\n",
            "            (dense_h_to_4h): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "            (gelu_impl): BloomGelu()\n",
            "            (dense_4h_to_h): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "    (lm_head): Linear(in_features=1024, out_features=250880, bias=False)\n",
            "  )\n",
            "  (prompt_encoder): ModuleDict(\n",
            "    (default): PromptEmbedding(\n",
            "      (embedding): Embedding(8, 1024)\n",
            "    )\n",
            "  )\n",
            "  (word_embeddings): Embedding(250880, 1024)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "from peft import PeftModel, PeftConfig\n",
        "\n",
        "peft_model_id = f\"{dataset_name}_{model_name_or_path}_{peft_config.peft_type}_{peft_config.task_type}\".replace(\n",
        "    \"/\", \"_\"\n",
        ")\n",
        "print(peft_model_id)\n",
        "\n",
        "config = PeftConfig.from_pretrained(peft_model_id)\n",
        "print(config)\n",
        "model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path)\n",
        "print(model)\n",
        "model = PeftModel.from_pretrained(model, peft_model_id)\n",
        "print(model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "ebe174a6",
      "metadata": {
        "id": "ebe174a6",
        "outputId": "155b2a3f-3a8c-4b70-a597-8619f4fdf060",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "@greateranglia Ok thanks...\n",
            "{'input_ids': tensor([[227985,   5484,    915,   2566,  14173,   2960,  29906,    387,  20706,\n",
            "          49337,   1369,  77658,    915,    210]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
            "tensor([[227985,   5484,    915,   2566,  14173,   2960,  29906,    387,  20706,\n",
            "          49337,   1369,  77658,    915,    210,   1936, 106863,      2,     31,\n",
            "          43907,  20321,  97547,     29,   1387,   6747]])\n",
            "['Tweet text : @greateranglia Ok thanks... Label : no complaint<b>Note</b>: The following']\n"
          ]
        }
      ],
      "source": [
        "model.to(device)\n",
        "model.eval()\n",
        "i = 4\n",
        "inputs = tokenizer(f'{text_column} : {dataset[\"test\"][i][\"Tweet text\"]} Label : ', return_tensors=\"pt\")\n",
        "print(dataset[\"test\"][i][\"Tweet text\"])\n",
        "print(inputs)\n",
        "\n",
        "with torch.no_grad():\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    outputs = model.generate(\n",
        "        input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"], max_new_tokens=10, eos_token_id=3\n",
        "    )\n",
        "    print(outputs)\n",
        "    print(tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24041ee1",
      "metadata": {
        "id": "24041ee1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dc03d9b8864342b29d6c26b49740f2bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6f3c34925fb94290baeb0e72ba964ef9",
              "IPY_MODEL_2d27cd965e524f6b98822f8a5cd97d47",
              "IPY_MODEL_5b4e0961a90741dbae58ab89e4b172fa"
            ],
            "layout": "IPY_MODEL_037b25dd188b483db344ebbb203ec726"
          }
        },
        "6f3c34925fb94290baeb0e72ba964ef9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5059d5c50c44a5ab407a994757762c6",
            "placeholder": "​",
            "style": "IPY_MODEL_103245d659104befbef58eae2a014ffe",
            "value": "Running tokenizer on dataset: 100%"
          }
        },
        "2d27cd965e524f6b98822f8a5cd97d47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28f3db8de4064f36ba02a3e467e18391",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_660f0436ed044d518e99b0e531008120",
            "value": 50
          }
        },
        "5b4e0961a90741dbae58ab89e4b172fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8085ecd9afc48fbb77c84fb436b058e",
            "placeholder": "​",
            "style": "IPY_MODEL_5ddd714807454aceb50d624e7f3c02d8",
            "value": " 50/50 [00:00&lt;00:00, 489.31 examples/s]"
          }
        },
        "037b25dd188b483db344ebbb203ec726": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5059d5c50c44a5ab407a994757762c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "103245d659104befbef58eae2a014ffe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28f3db8de4064f36ba02a3e467e18391": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "660f0436ed044d518e99b0e531008120": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d8085ecd9afc48fbb77c84fb436b058e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ddd714807454aceb50d624e7f3c02d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab9120693bb844f89da85242f1140b4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ffff094e7d7141ee89d97e7e56b550e6",
              "IPY_MODEL_6b33161c53524a28907b937a6b9a30f4",
              "IPY_MODEL_132988e4594f4a2da972a25cbd0b012e"
            ],
            "layout": "IPY_MODEL_82fe720350cc400e9beae923b2811b44"
          }
        },
        "ffff094e7d7141ee89d97e7e56b550e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b712967a865402db16310011c78d894",
            "placeholder": "​",
            "style": "IPY_MODEL_9026225b8c224a2cad4286c2fc27d0b0",
            "value": "Running tokenizer on dataset: 100%"
          }
        },
        "6b33161c53524a28907b937a6b9a30f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_001aa4ecd364435eae589010777be538",
            "max": 3399,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6a69b2fc660a4c2994ac6b6c384532d8",
            "value": 3399
          }
        },
        "132988e4594f4a2da972a25cbd0b012e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2b7981937e5400ca1276178adedfa9b",
            "placeholder": "​",
            "style": "IPY_MODEL_9cf79423f7064445880342aa5580ce9e",
            "value": " 3399/3399 [00:00&lt;00:00, 3840.17 examples/s]"
          }
        },
        "82fe720350cc400e9beae923b2811b44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b712967a865402db16310011c78d894": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9026225b8c224a2cad4286c2fc27d0b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "001aa4ecd364435eae589010777be538": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a69b2fc660a4c2994ac6b6c384532d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c2b7981937e5400ca1276178adedfa9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cf79423f7064445880342aa5580ce9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39ec50b3805b43d09a20653521d89ba7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1af706e0fe084fd4b0181536406f1c45",
              "IPY_MODEL_51248925284e47388a49077a4f274b00",
              "IPY_MODEL_2b8a2800aba34f26b03e94b8db9bb0db"
            ],
            "layout": "IPY_MODEL_562bc262aac948cb82bb7336b187549e"
          }
        },
        "1af706e0fe084fd4b0181536406f1c45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b810dd32aa045b8882b1c04d719d701",
            "placeholder": "​",
            "style": "IPY_MODEL_50c028570ca94892ab83b3baaf1a2ab8",
            "value": "Running tokenizer on dataset: 100%"
          }
        },
        "51248925284e47388a49077a4f274b00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57e3c9285bf446d4a23cdbb3b00179ca",
            "max": 3399,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b030635c2b2d4046af46b32b2a26b9e0",
            "value": 3399
          }
        },
        "2b8a2800aba34f26b03e94b8db9bb0db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_607f5dbbd95a4347824a48e7c8c772a5",
            "placeholder": "​",
            "style": "IPY_MODEL_4f7714e27eea49f79dfa252f50cf6e6f",
            "value": " 3399/3399 [00:01&lt;00:00, 2408.08 examples/s]"
          }
        },
        "562bc262aac948cb82bb7336b187549e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b810dd32aa045b8882b1c04d719d701": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50c028570ca94892ab83b3baaf1a2ab8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57e3c9285bf446d4a23cdbb3b00179ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b030635c2b2d4046af46b32b2a26b9e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "607f5dbbd95a4347824a48e7c8c772a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f7714e27eea49f79dfa252f50cf6e6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}