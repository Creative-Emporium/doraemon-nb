{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNGE6HFtnmnt6cOaYNLXGmf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weedge/doraemon-nb/blob/main/faiss_composite_indexes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. https://www.pinecone.io/learn/series/faiss/composite-indexes/\n",
        "2. https://www.youtube.com/watch?v=GEhmmcx1lvM\n",
        "3. https://www.youtube.com/watch?v=3Wqh4iUupbM\n",
        "\n"
      ],
      "metadata": {
        "id": "5jQb9BbZxa-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install libomp-dev\n",
        "!pip install --upgrade faiss-cpu faiss-gpu\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7hElrk5ybT_",
        "outputId": "fc213655-41ca-4225-ece7-3cc89ddfd756"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libomp-14-dev libomp5-14\n",
            "Suggested packages:\n",
            "  libomp-14-doc\n",
            "The following NEW packages will be installed:\n",
            "  libomp-14-dev libomp-dev libomp5-14\n",
            "0 upgraded, 3 newly installed, 0 to remove and 18 not upgraded.\n",
            "Need to get 738 kB of archives.\n",
            "After this operation, 8,991 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libomp5-14 amd64 1:14.0.0-1ubuntu1.1 [389 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libomp-14-dev amd64 1:14.0.0-1ubuntu1.1 [347 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libomp-dev amd64 1:14.0-55~exp2 [3,074 B]\n",
            "Fetched 738 kB in 0s (1,785 kB/s)\n",
            "Selecting previously unselected package libomp5-14:amd64.\n",
            "(Reading database ... 120895 files and directories currently installed.)\n",
            "Preparing to unpack .../libomp5-14_1%3a14.0.0-1ubuntu1.1_amd64.deb ...\n",
            "Unpacking libomp5-14:amd64 (1:14.0.0-1ubuntu1.1) ...\n",
            "Selecting previously unselected package libomp-14-dev.\n",
            "Preparing to unpack .../libomp-14-dev_1%3a14.0.0-1ubuntu1.1_amd64.deb ...\n",
            "Unpacking libomp-14-dev (1:14.0.0-1ubuntu1.1) ...\n",
            "Selecting previously unselected package libomp-dev:amd64.\n",
            "Preparing to unpack .../libomp-dev_1%3a14.0-55~exp2_amd64.deb ...\n",
            "Unpacking libomp-dev:amd64 (1:14.0-55~exp2) ...\n",
            "Setting up libomp5-14:amd64 (1:14.0.0-1ubuntu1.1) ...\n",
            "Setting up libomp-14-dev (1:14.0.0-1ubuntu1.1) ...\n",
            "Setting up libomp-dev:amd64 (1:14.0-55~exp2) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m111.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting faiss-gpu\n",
            "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-gpu, faiss-cpu\n",
            "Successfully installed faiss-cpu-1.7.4 faiss-gpu-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "首先，我们需要数据。我们将使用[Sift1M 数据集](http://corpus-texmex.irisa.fr/)，我们可以使用以下命令将其下载并加载到笔记本中：\n"
      ],
      "metadata": {
        "id": "CKxsG_GPy8-G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import urllib.request as request\n",
        "from contextlib import closing\n",
        "\n",
        "# first we download the Sift1M dataset\n",
        "with closing(request.urlopen('ftp://ftp.irisa.fr/local/texmex/corpus/sift.tar.gz')) as r:\n",
        "    with open('sift.tar.gz', 'wb') as f:\n",
        "        shutil.copyfileobj(r, f)"
      ],
      "metadata": {
        "id": "x1Ebybw5y-rk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tarfile\n",
        "\n",
        "# the download leaves us with a tar.gz file, we unzip it\n",
        "tar = tarfile.open('sift.tar.gz', \"r:gz\")\n",
        "tar.extractall()"
      ],
      "metadata": {
        "id": "AszWRJj20xHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# now define a function to read the fvecs file format of Sift1M dataset\n",
        "def read_fvecs(fp):\n",
        "    a = np.fromfile(fp, dtype='int32')\n",
        "    d = a[0]\n",
        "    return a.reshape(-1, d + 1)[:, 1:].copy().view('float32')\n",
        "\n",
        "# data we will search through\n",
        "xb = read_fvecs('./sift/sift_base.fvecs')  # 1M samples\n",
        "# also get some query vectors to search with\n",
        "xq = read_fvecs('./sift/sift_query.fvecs')\n",
        "# take just one query (there are many in sift_learn.fvecs)\n",
        "xq = xq[0].reshape(1, xq.shape[1])"
      ],
      "metadata": {
        "id": "qC6YGV2m00-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "657Su0xx1Ilx",
        "outputId": "4942c269-db42-4202-dadc-a49a8250cf82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  1.,   3.,  11., 110.,  62.,  22.,   4.,   0.,  43.,  21.,  22.,\n",
              "         18.,   6.,  28.,  64.,   9.,  11.,   1.,   0.,   0.,   1.,  40.,\n",
              "        101.,  21.,  20.,   2.,   4.,   2.,   2.,   9.,  18.,  35.,   1.,\n",
              "          1.,   7.,  25., 108., 116.,  63.,   2.,   0.,   0.,  11.,  74.,\n",
              "         40., 101., 116.,   3.,  33.,   1.,   1.,  11.,  14.,  18., 116.,\n",
              "        116.,  68.,  12.,   5.,   4.,   2.,   2.,   9., 102.,  17.,   3.,\n",
              "         10.,  18.,   8.,  15.,  67.,  63.,  15.,   0.,  14., 116.,  80.,\n",
              "          0.,   2.,  22.,  96.,  37.,  28.,  88.,  43.,   1.,   4.,  18.,\n",
              "        116.,  51.,   5.,  11.,  32.,  14.,   8.,  23.,  44.,  17.,  12.,\n",
              "          9.,   0.,   0.,  19.,  37.,  85.,  18.,  16., 104.,  22.,   6.,\n",
              "          2.,  26.,  12.,  58.,  67.,  82.,  25.,  12.,   2.,   2.,  25.,\n",
              "         18.,   8.,   2.,  19.,  42.,  48.,  11.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xq.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67sBI0zu1Lc4",
        "outputId": "eca429e6-40b9-4b91-b10d-639b93b9b5df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 128)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xb.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOIH_miI1M1q",
        "outputId": "11c89276-c633-4d2d-9597-f525bd1e4bb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000000, 128)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[在向量搜索](https://www.pinecone.io/learn/what-is-similarity-search/)领域，有许多索引方法和向量处理技术，使我们能够在召回率、延迟和内存使用之间确定优先级。\n",
        "\n",
        "[使用 IVF、 PQ](https://www.pinecone.io/learn/series/faiss/product-quantization/)或[HNSW](https://www.pinecone.io/learn/series/faiss/hnsw/)等特定方法，我们通常可以获得良好的结果。但为了获得*最佳性能，*我们通常希望使用*复合索引*。\n",
        "\n",
        "我们可以将复合索引视为向量变换和一种或多种索引方法的逐步过程。允许我们将多个索引和/或处理步骤放在一起来创建我们的“理想”索引。\n",
        "\n",
        "[例如，我们可以使用倒排文件（IVF）索引来缩小搜索范围（提高搜索速度），然后添加乘积量化（PQ）](https://www.pinecone.io/learn/series/faiss/product-quantization/)等压缩技术，以将较大的索引保持在合理的大小限制内。\n",
        "\n",
        "如果能够自定义索引，则存在生成具有不必要的不良召回、延迟或内存使用率的索引的风险。\n",
        "\n",
        "如果我们想构建强大且高性能的向量相似性搜索应用程序，我们必须了解复合索引的工作原理。必须了解在哪里可以使用不同的索引或向量转换以及何时不需要它们。\n",
        "\n",
        "[在本文中，我们将学习如何使用Facebook AI 相似性搜索 (Faiss)](https://www.pinecone.io/learn/series/faiss/)构建高性能复合索引——这是一个强大的库，许多人使用它来构建快速、准确的向量相似性搜索索引。我们还将介绍 Faiss **index_factory**，它允许我们用更清晰、更优雅的代码构建复合索引。\n",
        "\n",
        "## 什么是复合索引(Composite Indexes)\n",
        "\n",
        "复合索引类似于*乐高积木*；我们把一个放在另一个上面。我们会发现大多数块都可以组合在一起，但不同的组合可以产生任何东西，从艺术杰作到无法辨认的混乱。\n",
        "\n",
        "这同样适用于费斯。大多数组件*可以*放置在一起 - 但这并不意味着它们*应该*放置在一起。\n",
        "\n",
        "综合索引由以下各项的任意组合构建：\n",
        "\n",
        "- **矢量变换**— 在索引之前应用于矢量的预处理步骤（PCA、OPQ）。\n",
        "- **粗量化器**-将向量*粗略*组织到子域（用于限制搜索范围，包括 IVF、IMI 和 HNSW）。\n",
        "- **精细量化器**—将向量*更精细地*压缩为更小的域（用于压缩索引大小，例如 PQ）。\n",
        "- **细化**——搜索时的最后一步，使用原始平面向量上的距离计算对结果进行重新排序。或者，可以使用另一个索引（非平坦）索引。\n",
        "\n",
        "请注意，粗量化是指向量的“聚类”（例如 IVF 的反向索引）。通过使用粗量化，我们通过限制搜索范围来实现*非穷举搜索。*\n",
        "\n",
        "精细量化描述了将向量压缩为*代码*（与 PQ 一样）[1][2][3]。这样做的目的是为了减少索引的内存使用。\n",
        "\n",
        "### 指数成分\n",
        "\n",
        "我们可以使用以下组件构建复合索引：\n",
        "\n",
        "|            矢量变换            |                           粗量化器                           |                  精细量化器                   |     细化      |\n",
        "| :----------------------------: | :----------------------------------------------------------: | :-------------------------------------------: | :-----------: |\n",
        "| PCA、OPQ、RR、L2norm、ITQ、Pad | IVF、扁平、IMI、IVF、HNSW、IVF、PQ、IVF、RCQ、HNSW、扁平、HNSW、SQ、HNSW、PQ | 扁平*、PQ、SQ、残差*、RQ、LSQ、ZnLattice、LSH | RF扁平、精炼* |\n",
        "\n",
        "例如，我们可以构建一个索引，其中：\n",
        "\n",
        "- **使用OPQ**转换传入向量。\n",
        "- 通过将向量存储在倒排文件列表**IVF**中来执行向量的粗量化，从而实现非穷举搜索。\n",
        "- 压缩向量，通过每个 IVF 单元内的**PQ**减少内存使用*（向量被量化，但它们的单元分配不会改变）*。\n",
        "- 搜索后，根据原始平面向量**RFlat**对结果重新排序。\n",
        "\n",
        "**构建这些索引时，使用不同 Faiss 类的列表可能会变得混乱 - 因此使用 Faiss index_factory**构建索引通常会更清晰。\n",
        "\n",
        "![我们可以合并 IVF 和 PQ 索引，将量化的 PQ 向量存储在 IVF 结构中。](https://cdn.sanity.io/images/vr8gru94/production/409e12bad9ca16b82d685bf6c203ea9c0d282b59-1920x1080.png)\n",
        "\n",
        "我们可以合并 IVF 和 PQ 索引，将量化的 PQ 向量存储在 IVF 结构中。\n",
        "\n",
        "## Faiss Index Factory\n",
        "\n",
        "Faiss **index_factory**函数允许我们使用字符串来构建复合索引。它允许我们切换："
      ],
      "metadata": {
        "id": "JzWSqrg7xQWv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "i6rJvFy9waNy"
      },
      "outputs": [],
      "source": [
        "import faiss\n",
        "quantizer = faiss.IndexFlatL2(128)\n",
        "index = faiss.IndexIVFFlat(quantizer, 128, 256)\n",
        "#index.is_trained\n",
        "index.train(xb)\n",
        "index.add(xb)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_f = faiss.index_factory(128, \"IVF256,Flat\")\n",
        "#index_f.is_trained\n",
        "index_f.train(xb)\n",
        "index_f.add(xb)\n"
      ],
      "metadata": {
        "id": "mRDEIIq1yn3w"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "我们没有在 index_factory 示例中指定L2距离，因为 index_factory 默认使用L2。如果我们想使用 IndexFlatIP， 我们将 faiss.METRIC_INNER_PRODUCT 添加到我们的 index_factory 参数中。\n",
        "\n",
        "通过比较它们的性能，我们可以确认这两种方法产生相同的综合指数。首先，它们是否返回相同的最近邻居？\n",
        "\n"
      ],
      "metadata": {
        "id": "XEvJ4cbIyq-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k = 100\n",
        "D, I = index.search(xq, k)  # search class-based index\n",
        "print(I,D)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNABiSnByrjL",
        "outputId": "92063602-362d-4015-94a9-2a7c7e7e13a4"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[701258 455537 562594 600499 619660  36267   2176 454263 722642 779712\n",
            "  721706 480497 619829 701919 224263 871568 225116 904911 391655 957845\n",
            "  930567 882961 221339 486457 104122 710644 465294 919197  16429 398306\n",
            "  989762 670103 403035 656997  87759 293551 839679 679408 931855 169794\n",
            "  703365 722837 882943  14218 392032  95545 932068 828457 782458 436743\n",
            "  403442 565750 977462 480765 875747 703631 561735 564474 185891 491343\n",
            "  454389 831924 727687 253993 827372 377461 629490 245147 746238 574941\n",
            "  955881 222238 730997 722935 744176 170348 839745 394538 879897  88584\n",
            "  628092 174301 172378 753423 310902 931722 842594 873615 820116  20822\n",
            "  742261  15892 236119 710839 656501 312288 562343 561910 928461 710969]] [[69844. 71441. 73537. 73793. 74356. 76583. 76608. 76664. 77587. 78092.\n",
            "  78655. 79223. 79309. 79508. 80246. 80499. 80639. 80668. 80749. 81399.\n",
            "  81870. 81991. 82049. 82210. 82455. 82615. 82742. 83031. 83307. 83377.\n",
            "  83466. 83576. 83632. 83646. 83828. 83899. 83911. 84504. 84617. 84829.\n",
            "  85459. 85573. 85654. 85932. 86033. 86101. 86360. 86578. 86601. 86812.\n",
            "  86824. 86870. 86933. 87084. 87134. 87135. 87395. 87414. 87658. 87691.\n",
            "  88186. 88266. 88420. 88465. 88641. 88661. 88722. 88772. 88870. 89198.\n",
            "  89278. 89303. 89393. 89400. 89591. 89661. 89830. 89938. 89959. 89997.\n",
            "  90054. 90222. 90354. 90482. 90500. 90517. 90531. 90730. 90830. 90875.\n",
            "  90885. 90976. 91062. 91078. 91082. 91171. 91253. 91315. 91380. 91395.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "D_f, I_f = index_f.search(xq, k)  # search index_factory index\n",
        "print(I_f,D_f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8Pv9yG9ytM_",
        "outputId": "34332cd2-b7e3-44b7-e030-c1f44de85a4d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[701258 455537 562594 600499 619660  36267   2176 454263 722642 779712\n",
            "  721706 480497 619829 701919 224263 871568 225116 904911 391655 957845\n",
            "  930567 882961 221339 486457 104122 710644 465294 919197  16429 398306\n",
            "  989762 670103 403035 656997  87759 293551 839679 679408 931855 169794\n",
            "  703365 722837 882943  14218 392032  95545 932068 828457 782458 436743\n",
            "  403442 565750 977462 480765 875747 703631 561735 564474 185891 491343\n",
            "  454389 831924 727687 253993 827372 377461 629490 245147 746238 574941\n",
            "  955881 222238 730997 722935 744176 170348 839745 394538 879897  88584\n",
            "  628092 174301 172378 753423 310902 931722 842594 873615 820116  20822\n",
            "  742261  15892 236119 710839 656501 312288 562343 561910 928461 710969]] [[69844. 71441. 73537. 73793. 74356. 76583. 76608. 76664. 77587. 78092.\n",
            "  78655. 79223. 79309. 79508. 80246. 80499. 80639. 80668. 80749. 81399.\n",
            "  81870. 81991. 82049. 82210. 82455. 82615. 82742. 83031. 83307. 83377.\n",
            "  83466. 83576. 83632. 83646. 83828. 83899. 83911. 84504. 84617. 84829.\n",
            "  85459. 85573. 85654. 85932. 86033. 86101. 86360. 86578. 86601. 86812.\n",
            "  86824. 86870. 86933. 87084. 87134. 87135. 87395. 87414. 87658. 87691.\n",
            "  88186. 88266. 88420. 88465. 88641. 88661. 88722. 88772. 88870. 89198.\n",
            "  89278. 89303. 89393. 89400. 89591. 89661. 89830. 89938. 89959. 89997.\n",
            "  90054. 90222. 90354. 90482. 90500. 90517. 90531. 90730. 90830. 90875.\n",
            "  90885. 90976. 91062. 91078. 91082. 91171. 91253. 91315. 91380. 91395.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "I_f.tolist() == I.tolist()  # check that both output same results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ratVpCYpyvnT",
        "outputId": "4db93405-a740-4b88-d284-2cea24bf4c86"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "相同的结果，它们的搜索速度和内存使用情况如何比较？\n",
        "\n"
      ],
      "metadata": {
        "id": "bIGd_BO631td"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "index.search(xq, k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmgTrdOp32em",
        "outputId": "13690307-1d30-4d7e-a367-66218ed227c9"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "116 µs ± 10.9 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "index_f.search(xq, k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nH32AxrG384A",
        "outputId": "011bb340-9bcd-40aa-dc86-8613ac7ccc21"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "117 µs ± 12.5 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def get_memory(index):\n",
        "    # write index to file\n",
        "    faiss.write_index(index, './temp.index')\n",
        "    # get file size\n",
        "    file_size = os.path.getsize('./temp.index')\n",
        "    # delete saved index\n",
        "    os.remove('./temp.index')\n",
        "    return file_size"
      ],
      "metadata": {
        "id": "iOhHtcI16U0g"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_memory(index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBztwOAz4Her",
        "outputId": "caffdd99-589d-4636-ff6f-f61a3e3fc3d1"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "520133259"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_memory(index_f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmrY9hzd4OIt",
        "outputId": "5497d709-fdfb-41fc-8e43-3e5fbff34f26"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "520133259"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "get_memory函数返回内存使用情况的精确匹配。搜索速度非常接近，index_factory版本快了 5μs——差异可以忽略不计。\n",
        "\n",
        " 我们将召回率计算为平坦 L2 索引与测试索引之间top- k的匹配百分比。\n",
        "\n",
        "文献中更常用的指标是recall@k；这不是 这里 计算的召回率。 Recall@k 是返回前k 个 返回记录中最近邻居的查询的百分比。\n",
        "\n",
        " 如果我们在使用k 值为 100时有 50% 的时间返回真实的最近邻，则我们可以说recall@100 性能为 0.5。\n",
        "\n"
      ],
      "metadata": {
        "id": "NVu4mtBr8i3l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 为什么使用索引工厂\n",
        "从我们的测试来看，我们可以确信这两种索引构建方法只不过是通往同一目的地的不同路径。\n",
        "\n",
        "考虑到这一点——我们为什么要关心学习如何使用index_factory？首先，这可以取决于个人喜好。如果您更喜欢基于类的索引构建方法，请坚持使用。\n",
        "\n",
        "然而，通过使用index_factory我们可以大大提高代码的优雅性和清晰度。当使用index_factory时，我们将看到五行复杂的代码可以用一行更易读的代码表示。\n",
        "\n",
        "让我们组合一个复合索引，其中使用 OPQ 预处理向量，使用 IVF 聚类，使用 PQ 量化，然后使用平面索引重新排序。\n",
        "\n"
      ],
      "metadata": {
        "id": "ojgFDvHT8mhU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d = xb.shape[1]\n",
        "m = 32\n",
        "nbits = 8\n",
        "nlist = 256\n",
        "\n",
        "# we initialize our OPQ and coarse+fine quantizer steps separately\n",
        "opq = faiss.OPQMatrix(d, m)\n",
        "# d now refers to shape of rotated vectors from OPQ (which are equal)\n",
        "vecs = faiss.IndexFlatL2(d)\n",
        "sub_index = faiss.IndexIVFPQ(vecs, d, nlist, m, nbits)\n",
        "# now we merge the preprocessing, coarse, and fine quantization steps\n",
        "index = faiss.IndexPreTransform(opq, sub_index)\n",
        "# we will add all of the previous steps to our final refinement step\n",
        "index = faiss.IndexRefineFlat(q)\n",
        "# train the index, and index vectors\n",
        "index.train(xb)\n",
        "index.add(xb)"
      ],
      "metadata": {
        "id": "JxayrdVj8kOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "此代码演示了向索引添加多个组件可能产生的复杂性。如果我们使用index_factory重写它，我们会得到更简单的代码：\n"
      ],
      "metadata": {
        "id": "zrqs3v_g8_IB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d = xb.shape[1]\n",
        "# in index string, m==32, nlist==256, nbits is 8 by default\n",
        "\n",
        "index = faiss.index_factory(d, \"OPQ32,IVF256,PQ32,RFlat\")\n",
        "# train and index vectors\n",
        "index.train(xb)\n",
        "index.add(xb)"
      ],
      "metadata": {
        "id": "5ZqpICBn9AF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "两种方法产生完全相同的索引。每个的性能：\n",
        "\n",
        "|              | 记起 | 搜索时间 | 内存使用情况 |\n",
        "| :----------: | :--: | :------: | :----------: |\n",
        "| 没有索引工厂 | 31%  | 181微秒  |    552MB     |\n",
        "| 使用索引工厂 | 31%  | 174微秒  |    552MB     |\n",
        "\n",
        "**使用index_factory**时，搜索时间确实会稍微快一些，但除此之外，使用或不使用**index_factory**构建的等效索引之间没有性能差异。\n",
        "\n",
        "## 热门复合索引\n",
        "\n",
        "现在我们知道如何使用**index_factory**快速构建复合索引，让我们探索一些流行的高性能组合。"
      ],
      "metadata": {
        "id": "UhmXiJiL9BeT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IVFADC\n",
        "\n",
        "我们在上面介绍了修改后的**IVFADC**索引 -我们之前示例中的**IVF256、PQ32**部分构成了 IVFADC 的核心。让我们更详细地探讨一下。\n",
        "\n",
        "该指数于 2010 年与产品量化一起引入[4]。从那时起，它仍然是最受欢迎的索引之一 - 由于它是一种易于使用的索引，可以产生合理的召回率、快速的速度和*令人难以置信的*内存使用率。\n",
        "\n",
        "当我们的首要任务是最大限度地减少内存使用同时保持快速搜索速度时，IVFADC 是理想的选择。*这是以好的*但不好*的*召回性能为代价的。\n",
        "\n",
        "使用 IVFADC 建立索引有两个步骤：\n",
        "\n",
        "1. 向量被分配到IVF 结构中的不同列表（*或Voronoi 单元）。*\n",
        "2. 使用 PQ 压缩向量。\n",
        "\n",
        "![IVFADC 的索引过程，改编自[4]。](https://cdn.sanity.io/images/vr8gru94/production/0b9d996a8476e1bbe0ceea54ea7703f304125ffd-1920x980.png)\n",
        "\n",
        "IVFADC 的索引过程，改编自[4]。\n",
        "\n",
        "对向量进行索引后，在查询向量**xq**和我们的索引量化向量**之间**执行对称距离计算 ( **ADC** ) **。**\n",
        "\n",
        "该搜索被称为*非对称搜索*，因为它将未压缩的**xq与压缩的 PQ 向量（我们之前索引的）进行比较。**\n",
        "\n",
        "![通过对称距离计算（SDC，左），我们在将 xq 与之前量化的 xb 向量进行比较之前对其进行量化。 ADC（右）跳过 xq 的量化，并将其直接与量化的 xb 向量进行比较。](https://cdn.sanity.io/images/vr8gru94/production/e6008652a7306c91155c9dd1b95a8e934a2ffefa-1920x1000.png)\n",
        "\n",
        "通过对称距离计算（SDC，左），我们在将 xq 与之前量化的 xb 向量进行比较之前对其进行量化。ADC（右）跳过 xq 的量化，并将其直接与量化的 xb 向量进行比较。\n",
        "\n",
        "要使用**index_factory**实现索引，我们可以编写："
      ],
      "metadata": {
        "id": "h7u5NDPK9mg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index = faiss.index_factory(d, \"IVF256,PQ32x8\")\n",
        "index.train(xb)\n",
        "index.add(xb)\n",
        "D, I = index.search(xq, k)\n",
        "recall(I)"
      ],
      "metadata": {
        "id": "jo7iU2559Min"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "由此，我们创建了包含256 个IVF 细胞的 IVFADC 索引；每个向量分别使用m和nbits值32和8通过 PQ 进行压缩。PQ默认使用nbits == 8所以我们也可以写\"IVF256,PQ32\"。\n",
        "\n",
        "m : 原始向量被分割成的子向量的数量\n",
        "\n",
        "nbits：每个子量化器使用的位数，我们可以计算每个子量化器使用的质心数量为 2**nbits\n",
        "\n",
        "我们可以减少nbits以减少索引内存使用量，或增加 nbits 以提高召回率和搜索速度。然而，当前版本的 Faiss 确实将IVF ,PQ的nbits限制为>= 8。\n",
        "\n",
        "还可以增加index.nprobe值来搜索更多 IVF 细胞 - 默认情况下，该值为1。\n",
        "\n"
      ],
      "metadata": {
        "id": "MhYB227s95oa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index.nprobe = 8\n",
        "D, I = index.search(xq, k)\n",
        "recall(I)"
      ],
      "metadata": {
        "id": "EC6116wN93Gi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "这里我们有不同**nbits**和**nprobe**值的索引性能：\n",
        "\n",
        "|      指数      | 探针 | 记起 | 搜索时间 | 记忆 |\n",
        "| :------------: | :--: | :--: | :------: | :--: |\n",
        "| IVF256，PQ32x4 |  1   | 27%  | 329微秒  | 25MB |\n",
        "| IVF256，PQ32x4 |  6   | 45%  | 975微秒  | 25MB |\n",
        "| IVF256，PQ32x8 |  1   | 30%  | 136微秒  | 40MB |\n",
        "| IVF256，PQ32x8 |  8   | 74%  | 729微秒  | 40MB |\n",
        "\n",
        "#### 优化产品量化\n",
        "\n",
        "IVFADC和其他使用 PQ 的索引可以从优化产品量化( OPQ)中受益。\n",
        "\n",
        "OPQ 的工作原理是旋转向量以使 PQ 中使用的子向量上的值分布变平。这对于数据分布不均匀的不平衡向量特别有利。\n",
        "\n",
        "在 Faiss 中，我们添加 OPQ 作为预处理步骤。对于IVFADC，OPQ索引字符串看起来像“OPQ32，IVF256，PQ32”，其中OPQ32和PQ32中的32指的是PQ生成的代码中的字节数m 。  \n",
        "\n",
        "Faiss中的OPQ矩阵并不是 整个 旋转和PQ过程。这只是旋转。下游必须包含 PQ 步骤才能实施 OPQ。\n",
        "\n",
        "和以前一样，我们需要在初始化时训练索引。\n",
        "\n"
      ],
      "metadata": {
        "id": "k-sle7kE-KQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we can add pre-processing vector rotation to\n",
        "# improve distribution for the PQ step using OPQ\n",
        "index = faiss.index_factory(d, \"OPQ32,IVF256,PQ32x8\")\n",
        "index.train(xb)\n",
        "index.add(xb)\n",
        "D, I = index.search(xq, k)\n",
        "recall(I)"
      ],
      "metadata": {
        "id": "-GU5QBGj97zV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "index.search(xq, k)"
      ],
      "metadata": {
        "id": "Z4K71VYj-Qbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sift1M 数据集的数据分布已经很平衡，因此 OPQ 只给我们带来了召回性能的微小提升。当nprobe == 1时，我们的召回率从 30% 增加到 31%。\n",
        "\n",
        "我们可以增加nprobe值来提高召回率（以速度为代价）。但是，由于我们向索引添加了预处理步骤，因此我们无法直接使用index.nprobe访问nprobe，因为该索引不再引用索引的 IVF 部分。\n",
        "\n",
        "相反，我们必须在修改nprobe值之前提取IVF 索引- 我们可以使用extract_index_ivf函数来完成此操作。\n",
        "\n"
      ],
      "metadata": {
        "id": "eCwVZ7zd-S1z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ivf = faiss.extract_index_ivf(index)\n",
        "ivf.nprobe = 13\n",
        "D, I = index.search(xq, k)\n",
        "recall(I)"
      ],
      "metadata": {
        "id": "wB19cjAB-Vxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "index.search(xq, k)"
      ],
      "metadata": {
        "id": "7ssP5MST-XHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "当**nprobe**值为**14 时**，我们返回 74% 的召回率。与单独 PQ 类似的召回结果，同时搜索时间从 729μs -> 1060μs 增加。\n",
        "\n",
        "|      指数      | 探针 | 记起 | 搜索时间 |  记忆  |\n",
        "| :------------: | :--: | :--: | :------: | :----: |\n",
        "| IVF256，PQ32x4 |  1   | 30%  | 136微秒  | 40.2MB |\n",
        "| IVF256，PQ32x4 |  1   | 31%  | 143微秒  | 40.3MB |\n",
        "| IVF256，PQ32x8 |  8   | 74%  | 729微秒  | 40.2MB |\n",
        "| IVF256，PQ32x8 |  13  | 74%  | 1060微秒 | 40.3MB |\n",
        "\n",
        "我们将在本文后面看到 OPQ 可用于提高性能，但正如我们在这里看到的，情况并非*总是*如此。\n",
        "\n",
        "![各种 nprobe 值的搜索时间（上）和召回率（下）。 我们纳入了“IVF256，Flat”进行比较。 扁平索引的内存使用量要高得多，为 520MB。](https://cdn.sanity.io/images/vr8gru94/production/2f8651fdfc87169f2b088c95d37a8a033701ad7a-1920x1080.png)\n",
        "\n",
        "各种 nprobe 值的搜索时间（上）和召回率（下）。我们纳入了“IVF256，Flat”进行比较。扁平索引的内存使用量要高得多，为 520MB。\n",
        "\n",
        "OPQ 还可用于降低预处理步骤中向量的维数。这个维度D必须是M的倍数，最好是D == 4M。为了将维度减少到64，我们可以使用\"OPQ16_64,IVF256,PQ16\"。\n",
        "\n"
      ],
      "metadata": {
        "id": "8aHQ5FKM-jym"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multi-D-ADC 是指**多维**索引，以及在搜索时产生非对称距离计算的 PQ 步骤（如我们之前讨论的**）** [ **5** ] **。**\n",
        "\n",
        "多**D-ADC**指数基于倒置多指数 (IMI)，是 IVF 的延伸。\n",
        "\n",
        "IMI 在召回和搜索速度方面都优于 IVF，但确实增加了内存使用量 [7]。这使得 IMI 索引（例如多 D-ADC）在 IVFADC 无法完全达到所需的召回率和速度的情况下成为理想选择，并且您可以节省更多内存使用量。IMI 索引的工作方式与 IVF 非常相似，但 Voronoi 单元在向量维度上进行分割。它产生的结果类似于多级 Voronoi 单元结构。\n",
        "\n",
        "![沃罗诺伊细胞分裂到多个向量子空间。 给定一个查询向量 xq，我们将每个 xq 子向量与其各自的子空间单元进行比较。](https://cdn.sanity.io/images/vr8gru94/production/ce81a066f489fe38b681d4fd7111f9cb5e4c804e-1920x1020.png)\n",
        "\n",
        "沃罗诺伊细胞分裂到多个向量子空间。给定一个查询向量 xq，我们将每个 xq 子向量与其各自的子空间单元进行比较。\n",
        "\n",
        "当我们使用 PQ 将矢量压缩添加到 IMI 时，我们会生成**多 D-ADC**索引。其中 ADC 是指将查询向量与 PQ 向量进行比较时进行的不对称距离计算。\n",
        "\n",
        "将所有这些放在一起，我们可以使用索引工厂字符串“IMI2x8,PQ32”创建多 D-ADC 索引。\n",
        "\n"
      ],
      "metadata": {
        "id": "Sao8OuWm-rg8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index = faiss.index_factory(d, \"IMI2x8,PQ32\")\n",
        "index.train(xb)  # index construction time is large for IMI\n",
        "index.add(xb)"
      ],
      "metadata": {
        "id": "4xkjMGLI-wHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imi = faiss.extract_index_ivf(index)  # access nprobe\n",
        "imi.nprobe = 620\n",
        "D, I = index.search(xq, k)\n",
        "recall(I)"
      ],
      "metadata": {
        "id": "G1e_C9G7-wnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "index.search(xq, k)"
      ],
      "metadata": {
        "id": "HlMBVy_x-yBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "为了返回与 IVFADC 等效的类似召回，我们将搜索时间增加到 1.3 毫秒，这非常慢。但是，如果我们将 OPQ 添加到索引中，我们将返回更好的结果。\n",
        "\n"
      ],
      "metadata": {
        "id": "xn8b5a61-0Zu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index = faiss.index_factory(d, \"OPQ32,IMI2x8,PQ32\")  # lets try with OPQ\n",
        "index.train(xb)  # index construction time is even larger for OPQ,IMI\n",
        "index.add(xb)"
      ],
      "metadata": {
        "id": "xS7BSVnN-0w7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imi = faiss.extract_index_ivf(index)  # we increase nprobe\n",
        "imi.nprobe = 100\n",
        "D, I = index.search(xq, k)\n",
        "recall(I)"
      ],
      "metadata": {
        "id": "B1YfQ4H--2GI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "index.search(xq, k)"
      ],
      "metadata": {
        "id": "eHdLSY7Y-4gl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "对于 74% 的召回率，我们的 OPQ multi-D-ADC 索引速度最快，平均搜索时间仅为 461μs。\n",
        "\n",
        "|       Index       | Recall | Search Time | Memory |\n",
        "| :---------------: | :----: | :---------: | :----: |\n",
        "|    IVF256,PQ32    |  74%   |    729µs    | 40.2MB |\n",
        "|    IMI2x8,PQ32    |  72%   |   1350µs    | 40.8MB |\n",
        "| OPQ32,IMI2x8,PQ32 |  74%   |    461µs    | 40.7MB |\n",
        "\n",
        "和以前一样，我们可以使用nprobe微调索引以优先考虑召回或速度。\n",
        "\n",
        "![各种 nprobe 值的搜索时间（上）和召回率（下）。 我们包含“IMI2x8，Flat”进行比较。 扁平索引的内存使用量要高得多，为 520MB。](https://cdn.sanity.io/images/vr8gru94/production/3500949c3274050f2c7bcc970dd74e24c46a7e95-1920x1080.png)\n",
        "\n",
        "各种 nprobe 值的搜索时间（上）和召回率（下）。我们包含“IMI2x8，Flat”进行比较。扁平索引的内存使用量要高得多，为 520MB。\n",
        "\n",
        "“**OPQ32，IMI2x8，PQ32**”是我们在低内存的召回率和速度方面最好的指标之一。然而，我们将看到我们可以通过以下索引进一步改进这些指标。\n",
        "\n",
        "\n",
        "\n",
        "### HNSW Indexes\n",
        "\n",
        "IVF 与 分层导航小型世界(HNSW) 图是我们最终的复合索引。该索引将我们的索引向量按照通常的 IVF 方式分割成单元格，但这次我们将使用 HNSW 优化该过程。\n",
        "\n",
        "与我们之前的两个指数相比，采用 HNSW 的 IVF 可以产生相当或更好的速度以及显着更高的召回率，但代价是内存使用量更高*。*\n",
        "\n",
        "在较高层面上，HNSW 基于*小世界图理论*，即网络中的所有顶点（*节点*）（无论有多大）都可以通过少量步骤遍历。\n",
        "\n",
        "![](https://d33wubrfki0l68.cloudfront.net/2c46ea2a595c6ecb10a7c1d729bb85620bcc3b3e/b9423/images/composite-indexes-11.mp4)\n",
        "\n",
        "可导航的小世界图的示例，图中的所有节点都通过少量的边遍历连接。小世界图论假设即使对于具有数十亿个顶点的巨大网络也是如此。\n",
        "\n",
        "在这个小世界图中，我们看到了短程和长程链接。当遍历远程链接时，我们在图表中移动得更快。\n",
        "\n",
        "HNSW 通过将图链接拆分为多个层来利用这一点。在较高的入口层，我们只找到远程链接。当我们向下移动层时，会添加较短距离的链接。\n",
        "\n",
        "搜索时，我们从这些具有远程链接的较高层开始。这意味着我们的第一次遍历是跨越远程链接的。当我们向下移动层时，当我们遍历更多的短程链接时，我们的搜索变得更加精细。\n",
        "\n",
        "![HNSW 图将包含远程和短程链接的典型图分解为多个层（层次结构）。 在搜索过程中，我们从最高层开始，它由远程链接组成。 当我们向下移动每一层时，链接变得更加细化。](https://cdn.sanity.io/images/vr8gru94/production/0b4b19e673df19f684dbfe5ed91f80f283cda10c-1920x1080.png)\n",
        "\n",
        "HNSW 图将包含远程和短程链接的典型图分解为多个层（层次结构）。在搜索过程中，我们从最高层开始，它由远程链接组成。当我们向下移动每一层时，链接变得更加细化。\n",
        "\n",
        "这种方法应该最大限度地减少遍历次数（加快搜索速度），同时仍然在较低层中执行非常精细的搜索（保持高召回率）。\n",
        "\n",
        "那就是HNSW，但是我们如何才能将HNSW与IVF结合起来呢？\n",
        "\n",
        "使用普通 IVF，我们引入查询向量并将其与每个细胞质心进行比较，识别最近的质心以限制我们的搜索范围。\n",
        "\n",
        "为了将此过程与 HNSW 配对，我们生成所有这些细胞质心的 HNSW 图，使穷举质心搜索*近似*。\n",
        "\n",
        "![HNSW 可用于使用 IVF 细胞质心快速找到近似最近邻。](https://cdn.sanity.io/images/vr8gru94/production/0c94d256ebe92cf3ffea7429f54ede89477a6513-1920x1080.png)\n",
        "\n",
        "HNSW 可用于使用 IVF 细胞质心快速找到近似最近邻。\n",
        "\n",
        "之前，我们一直使用具有 256 个细胞质心的 IVF 索引。256 的穷举搜索很快，并且没有理由使用具有如此少质心的近似搜索。\n",
        "\n",
        "由于我们的单元格很少，因此每个单元格必须包含许多向量 - 仍将使用穷举搜索来搜索这些向量。在这种情况下，细胞质心上的 IVF+HNSW 没有帮助。\n",
        "\n",
        "对于 IVF+HNSW 索引，我们需要将“少数质心和大单元”替换为“许多质心和小单元”。\n",
        "\n",
        "对于我们的 1M 索引，建议nlist值为65536 [8]。但是，我们应该向index.train提供至少 30\\*nlist == 1.97M个向量，但我们没有。所以16384或更小的nlist更合适。对于此数据集，nlist == 4096返回最高的召回率（速度较慢）。\n",
        "\n",
        "使用 IVF+HNSW，我们使用 HNSW 快速识别近似最近的细胞质心，然后将我们的穷举搜索限制到那些最近的细胞。\n",
        "\n",
        "可以使用\"IVF4096_HNSW32,Flat\"构建标准 IVF+HNSW 索引。利用这个，我们有：\n",
        "\n",
        "- 4096 个IVF 单元。\n",
        "- 单元质心存储在 HNSW 图中。每个质心都与其他32 个质心相连。\n",
        "- 向量本身没有改变。它们是平面向量。"
      ],
      "metadata": {
        "id": "IjTsq8_xfXrI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index = faiss.index_factory(d, \"IVF4096_HNSW32,Flat\")\n",
        "index.train(xb)\n",
        "index.add(xb)"
      ],
      "metadata": {
        "id": "1X5ueHFnf5V3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "D, I = index.search(xq, k)\n",
        "recall(I)"
      ],
      "metadata": {
        "id": "W_m8-X4Zf6T6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "index.search(xq, k)"
      ],
      "metadata": {
        "id": "MNMWHAh0f7km"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index.nprobe = 146\n",
        "D, I = index.search(xq, k)\n",
        "recall(I)"
      ],
      "metadata": {
        "id": "xnK1sgL4f-6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "index.search(xq, k)"
      ],
      "metadata": {
        "id": "_OFTHjzmgAo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "有了这个索引，我们可以在 58.9μs -> 916μs 的搜索时间内实现从 25% -> 100% 召回率的令人难以置信的性能。\n",
        "\n",
        "![各种 nprobe 值的搜索时间（上）和召回率（下）。 以更长的搜索时间为代价，我们可以通过减少 nlist 来提高召回率。](https://cdn.sanity.io/images/vr8gru94/production/ae39ade8751b67c4acdc7f960c9a0ee9e565ff95-1920x1080.png)\n",
        "\n",
        "各种 nprobe 值的搜索时间（上）和召回率（下）。以更长的搜索时间为代价，我们可以通过减少 nlist 来提高召回率。\n",
        "\n",
        "然而，IVF+HNSW 指数也并非没有缺陷。尽管我们拥有令人难以置信的召回率和快速的搜索速度，但这个索引的内存使用量是*巨大的*。我们的 1M 128 维向量产生的索引大小为 523MB+。\n",
        "\n",
        "正如我们之前所做的那样，我们可以使用 PQ 和 OPQ 来减少这种情况，但这会减少召回率并增加搜索时间。\n",
        "\n",
        "\n",
        "\n",
        "|             Index             | Recall | Search Time | Memory |\n",
        "| :---------------------------: | :----: | :---------: | :----: |\n",
        "|       IVF4096_HNSW,Flat       |  90%   |    550µs    | 523MB  |\n",
        "|    IVF4096_HNSW,PQ32 (PQ)     |  69%   |    550µs    |  43MB  |\n",
        "| OPQ32,IVF4096_HNSW,PQ32 (OPQ) |  74%   |    364µs    |  43MB  |\n",
        "\n",
        "如果可以接受较低的召回率以最大限度地减少搜索时间和内存使用量，则带有 OPQ 的 IVF+HNSW 索引是理想的选择。另一方面，带有 PQ 的 IVF+HNSW 并没有比我们之前的*IVFADC*和*Multi-D-ADC*指数有任何优势。\n",
        "\n",
        "|    Name     |   Index String    | Recall | Search Time | Memory |\n",
        "| :---------: | :---------------: | :----: | :---------: | :----: |\n",
        "|   IVFADC    |    IVF256,PQ32    |  74%   |    729µs    |  40MB  |\n",
        "| Multi-D-ADC | OPQ32,IMI2x8,PQ32 |  74%   |    461µs    |  41MB  |\n",
        "\n",
        "\n",
        "\n",
        "这就是本文的内容！我们介绍了复合索引以及如何使用 Faiss **index_factory**构建它们。我们研究了几个最流行的综合指数，包括：\n",
        "\n",
        "- IVFADC\n",
        "- Multi-D-ADC\n",
        "- IVF-HNSW\n",
        "\n",
        "通过索引和搜索 Sift1M 数据集，我们学习了如何修改每个索引的参数以优先考虑召回率、速度和内存使用情况。\n",
        "\n",
        "根据我们在此介绍的内容，您将能够设计和测试各种复合索引，并更好地决定最适合您需求的索引结构。"
      ],
      "metadata": {
        "id": "5i5sv1gOgK7z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "[1] Y.Chen, et al., Approximate Nearest Neighbor Search by Residual Vector Quantization (2010), Sensors\n",
        "\n",
        "[2] Y. Matsui, et al., A Survey of Product Quantization (2018), ITE Trans. on MTA\n",
        "\n",
        "[3] T. Ge, et. al., Optimized Product Quantization (2014), TPAMI\n",
        "\n",
        "[4] H. Jégou, et al., Product quantization for nearest neighbor search (2010), TPAMI\n",
        "\n",
        "[5] A. Babenko, V. Lempitsky, The Inverted Multi-Index (2012), CVPR\n",
        "\n",
        "[6] H. Jégou, et al., Searching in One Billion Vectors: Re-rank with Source Coding (2011), ICASSP\n",
        "\n",
        "[7] D. Baranchuk, et al., Revisiting the Inverted Indices for Billion-Scale Approximate Nearest Neighbors (2018), ECCV\n",
        "\n",
        "[8] Guidelines to choose an index, Faiss wiki\n",
        "\n",
        "[9] The Index Factory, Faiss wiki\n",
        "\n"
      ],
      "metadata": {
        "id": "wOBhtOk2gnz1"
      }
    }
  ]
}